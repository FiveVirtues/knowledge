<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark-01-SparkCore | 知识库</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="manifest" href="/manifest.webmanifest" crossorigin="use-credentials">
    <meta name="description" content="">
    <meta property="og:url" content="/bigdata/Spark/part1.html">
    <meta property="og:site_name" content="知识库">
    <meta property="og:title" content="Spark-01-SparkCore">
    <meta property="og:description" content="Spark 概述 之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。 但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。 Spark 其实也是一个计">
    <meta property="og:type" content="article">
    <meta property="og:locale" content="en-US">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image:alt" content="知识库">
    <meta property="article:author" content="causes">
    <meta property="article:tag" content="spark">
    <meta name="theme-color" content="#46bd87">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
    
    <link rel="preload" href="/assets/css/0.styles.272a7e09.css" as="style"><link rel="preload" href="/assets/js/app.00946664.js" as="script"><link rel="preload" href="/assets/js/vendors~layout-Layout.d74da02a.js" as="script"><link rel="preload" href="/assets/js/vendors~layout-Blog~layout-Layout~layout-NotFound.70129eef.js" as="script"><link rel="preload" href="/assets/js/page-Spark-01-SparkCore.e1b13d59.js" as="script"><link rel="prefetch" href="/assets/js/54.7c746378.js"><link rel="prefetch" href="/assets/js/55.adda53bb.js"><link rel="prefetch" href="/assets/js/56.0f8d034a.js"><link rel="prefetch" href="/assets/js/57.830d518c.js"><link rel="prefetch" href="/assets/js/58.fcb3cf84.js"><link rel="prefetch" href="/assets/js/59.2826e1cb.js"><link rel="prefetch" href="/assets/js/layout-Blog.65a26112.js"><link rel="prefetch" href="/assets/js/layout-Layout.ae1bffbb.js"><link rel="prefetch" href="/assets/js/layout-NotFound.afd3c492.js"><link rel="prefetch" href="/assets/js/layout-Slide.5d36817b.js"><link rel="prefetch" href="/assets/js/page--6ce8a11a.1f6d1c8c.js"><link rel="prefetch" href="/assets/js/page-Concurrent-01-基础.40d9681c.js"><link rel="prefetch" href="/assets/js/page-Docker-01-基础.83220b10.js"><link rel="prefetch" href="/assets/js/page-Docker-02-进阶.52df0704.js"><link rel="prefetch" href="/assets/js/page-Flink-01-基础.068f6e0e.js"><link rel="prefetch" href="/assets/js/page-Flink-02-进阶.a6789756.js"><link rel="prefetch" href="/assets/js/page-Flink-03-机制.c3604e6d.js"><link rel="prefetch" href="/assets/js/page-Flume.578f4bbc.js"><link rel="prefetch" href="/assets/js/page-Git-01-常用指令.93e85005.js"><link rel="prefetch" href="/assets/js/page-HBase-01-起步.7316acb2.js"><link rel="prefetch" href="/assets/js/page-HBase-02-进阶.11b27c25.js"><link rel="prefetch" href="/assets/js/page-Hadoop-01-起步.f49b25f0.js"><link rel="prefetch" href="/assets/js/page-Hadoop-02-HDFS.c28c360c.js"><link rel="prefetch" href="/assets/js/page-Hadoop-03-MapReduce.01e7c831.js"><link rel="prefetch" href="/assets/js/page-Hadoop-04-Yarn.ffaa99bb.js"><link rel="prefetch" href="/assets/js/page-Hive-01-起步.c51a8ed6.js"><link rel="prefetch" href="/assets/js/page-Hive-02-DDL.62ca23de.js"><link rel="prefetch" href="/assets/js/page-Hive-03-DML.d3eb8c90.js"><link rel="prefetch" href="/assets/js/page-Hive-04-DQL.c2e0815a.js"><link rel="prefetch" href="/assets/js/page-Hive-05-函数.585851e7.js"><link rel="prefetch" href="/assets/js/page-JVM-01-概述.ebc66336.js"><link rel="prefetch" href="/assets/js/page-JVM-02-类加载子系统.4442a927.js"><link rel="prefetch" href="/assets/js/page-JVM-03-运行时数据区.947c0cac.js"><link rel="prefetch" href="/assets/js/page-Kafka-01-起步.246fa824.js"><link rel="prefetch" href="/assets/js/page-Kafka-02-架构和API.95741e08.js"><link rel="prefetch" href="/assets/js/page-Kafka-03-组件对接.adf6b6fb.js"><link rel="prefetch" href="/assets/js/page-Kubernetes-01-环境搭建.ee022329.js"><link rel="prefetch" href="/assets/js/page-Kubernetes-02-操作.0263d70c.js"><link rel="prefetch" href="/assets/js/page-Linux-01-基础篇.7a082019.js"><link rel="prefetch" href="/assets/js/page-Linux-02-实际操作篇.a1a0de05.js"><link rel="prefetch" href="/assets/js/page-Linux-03-安装配置.4afb662a.js"><link rel="prefetch" href="/assets/js/page-Linux-04-Shell.4bea5dda.js"><link rel="prefetch" href="/assets/js/page-Proxy.4595451b.js"><link rel="prefetch" href="/assets/js/page-Spark-02-SparkSQL.0e447d14.js"><link rel="prefetch" href="/assets/js/page-Zookeeper.d3a8c3a8.js"><link rel="prefetch" href="/assets/js/page-数据结构与算法-01-概述.da9332d8.js"><link rel="prefetch" href="/assets/js/page-注意事项.97c989bf.js"><link rel="prefetch" href="/assets/js/page-设计模式-01-介绍.2a0d66a1.js"><link rel="prefetch" href="/assets/js/page-设计模式-02-创建者模式.4c12c25f.js"><link rel="prefetch" href="/assets/js/page-设计模式-03-结构型模式.af84c495.js"><link rel="prefetch" href="/assets/js/page-设计模式-04-行为型模式.2a0f6172.js"><link rel="prefetch" href="/assets/js/vendors~flowchart.f091f770.js"><link rel="prefetch" href="/assets/js/vendors~mermaid.9c96c271.js"><link rel="prefetch" href="/assets/js/vendors~photo-swipe.e4b622ba.js"><link rel="prefetch" href="/assets/js/vendors~reveal.80ac799a.js">
    <link rel="stylesheet" href="/assets/css/0.styles.272a7e09.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container has-navbar has-anchor"><header class="navbar"><!----> <div class="content__navbar-start"></div> <button title="Sidebar Button" class="sidebar-button"><span class="icon"></span></button> <a href="/" class="home-link router-link-active"><!----> <!----> <span class="site-name can-hide">知识库</span></a> <!----> <div class="content__navbar-center"></div> <div class="links"><button tabindex="-1" aria-hidden="true" class="color-button"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="skin-icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4
        38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32
        51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0
        102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2
        6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4
        0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2
        9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224
        419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4
        470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0
        22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6
        12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128
        505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2
        16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8
        86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4
        80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6
        6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg> <div class="color-picker-menu" style="display:none;"><div class="theme-options"><ul class="themecolor-select"><label for="themecolor-select">Theme Color:</label> <li><span class="default-theme"></span></li> </ul> <div class="darkmode-toggle"><label for="darkmode-toggle" class="desc">Theme Mode:</label> <div class="darkmode-switch"><div class="item day"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon light-icon"><path d="M512 256a42.667 42.667 0 0 0 42.667-42.667V128a42.667 42.667 0 0 0-85.334 0v85.333A42.667 42.667 0 0 0 512 256zm384 213.333h-85.333a42.667 42.667 0 0 0 0 85.334H896a42.667 42.667 0 0 0 0-85.334zM256 512a42.667 42.667 0 0 0-42.667-42.667H128a42.667 42.667 0 0 0 0 85.334h85.333A42.667 42.667 0 0 0 256 512zm9.387-298.667a42.667 42.667 0 0 0-59.307 62.72l61.44 59.307a42.667 42.667 0 0 0 31.147 11.947 42.667 42.667 0 0 0 30.72-13.227 42.667 42.667 0 0 0 0-60.16zm459.946 133.974a42.667 42.667 0 0 0 29.44-11.947l61.44-59.307a42.667 42.667 0 0 0-57.6-62.72l-61.44 60.587a42.667 42.667 0 0 0 0 60.16 42.667 42.667 0 0 0 28.16 13.227zM512 768a42.667 42.667 0 0 0-42.667 42.667V896a42.667 42.667 0 0 0 85.334 0v-85.333A42.667 42.667 0 0 0 512 768zm244.48-79.36a42.667 42.667 0 0 0-59.307 61.44l61.44 60.587a42.667 42.667 0 0 0 29.44 11.946 42.667 42.667 0 0 0 30.72-12.8 42.667 42.667 0 0 0 0-60.586zm-488.96 0-61.44 59.307a42.667 42.667 0 0 0 0 60.586 42.667 42.667 0 0 0 30.72 12.8 42.667 42.667 0 0 0 28.587-10.666l61.44-59.307a42.667 42.667 0 0 0-59.307-61.44zM512 341.333A170.667 170.667 0 1 0 682.667 512 170.667 170.667 0 0 0 512 341.333z" fill="currentColor"></path></svg></div> <div class="item auto active"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon auto-icon"><path d="M460.864 539.072H564.8L510.592 376l-49.728 163.072zM872 362.368V149.504H659.648L510.528 0l-149.12 149.504H149.12v212.928L0 511.872l149.12 149.504v212.928h212.352l149.12 149.504 149.12-149.504h212.352V661.376l149.12-149.504L872 362.368zM614.464 693.12l-31.616-90.624H438.272l-31.616 90.624h-85.888l144.576-407.68h90.368l144.576 407.68h-85.824zm0 0" fill="currentColor"></path></svg></div> <div class="item night"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon dark-icon"><path d="M935.539 630.402c-11.43-11.432-28.674-14.739-43.531-8.354-46.734 20.103-96.363 30.297-147.508 30.297-99.59 0-193.221-38.784-263.64-109.203-108.637-108.637-139.61-270.022-78.908-411.148a39.497 39.497 0 0 0-51.886-51.887c-52.637 22.64-100.017 54.81-140.826 95.616-85.346 85.346-132.346 198.821-132.346 319.52 0 120.7 47.001 234.172 132.347 319.519S408.063 947.11 528.76 947.11c120.7 0 234.172-47.003 319.52-132.351 40.809-40.81 72.978-88.19 95.616-140.826a39.497 39.497 0 0 0-8.356-43.532z" fill="currentColor"></path></svg></div></div> <!----></div></div></div></button> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link router-link-active"><i class="iconfont icon-reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="/about.html" class="nav-link"><i class="iconfont icon-reco-faq"></i>
  关于
</a></div></nav> <!----> <a rel="noopener noreferrer" href="https://gitlab.com/team401/knowledge" target="_blank" class="repo-link can-hide">
  GitLab
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <!----> <div class="content__navbar-end"></div></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><div vocab="https://schema.org/" typeof="Person" class="blogger-info"><div data-balloon-pos="" role="navigation" class="blogger"><!----> <div property="name" class="name">知识库</div> <!----></div> <div class="num-wrapper"><div><div class="num">41</div> <div>Articles</div></div> <div><div class="num">3</div> <div>Category</div></div> <div><div class="num">17</div> <div>Tags</div></div> <div><div class="num">41</div> <div>Timeline</div></div></div> <!----></div> <hr> <!----> <div class="content__sidebar-top"></div> <nav class="sidebar-nav-links"><div class="nav-item"><a href="/" class="nav-link router-link-active"><i class="iconfont icon-reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="/about.html" class="nav-link"><i class="iconfont icon-reco-faq"></i>
  关于
</a></div> <a rel="noopener noreferrer" href="https://gitlab.com/team401/knowledge" target="_blank" class="repo-link">
  GitLab
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav> <!----> <div class="content__sidebar-center"></div> <!----> <!----> <div class="content__sidebar-bottom"></div> <!----></aside> <main class="page"><nav class="breadcrumb disable"><!----></nav> <!----> <div class="content__page-top"></div> <div vocab="https://schema.org/" typeof="Article" class="page-title"><h1><!----> <span property="headline">Spark-01-SparkCore</span></h1> <div class="page-info"><!----> <span aria-label="Author🖊" data-balloon-pos="down"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon author-icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z" fill="currentColor"></path></svg> <span property="author">causes</span></span><!----><span aria-label="Writing Date📅" data-balloon-pos="down" class="time-info"><svg viewBox="0 0 1030 1024" xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 0 1-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 0 1-33.473-33.473V143.657H180.6A134.314 134.314 0 0 0 46.66 277.595v535.756A134.314 134.314 0 0 0 180.6 947.289h669.74a134.36 134.36 0 0 0 133.94-133.938V277.595a134.314 134.314 0 0 0-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 0 1-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 0 1-33.472 33.473z" fill="currentColor"></path></svg> <span property="datePublished">2022-1-4</span></span><!----><span aria-label="Tags🏷" data-balloon-pos="down"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon tag-icon"><path d="M939.902 458.563 910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 0 0 0 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z" fill="currentColor"></path></svg> <ul class="tags-wrapper"><li class="tag clickable tag0"><span role="navigation">Spark</span></li></ul> <meta property="keywords" content="Spark"></span><span aria-label="Reading Time⌛" data-balloon-pos="down" class="reading-time-info"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon timer-icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z" fill="currentColor"></path></svg> <span>About 31 min</span> <meta property="timeRequired" content="PT31M"></span></div> <!----> <hr></div> <div class="anchor-place-holder"><aside id="anchor"><div class="anchor-wrapper"><ul class="anchor-list"><li class="anchor"><a href="/bigdata/Spark/part1/#spark-概述" class="anchor-link heading2"><div>Spark 概述</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#环境搭建" class="anchor-link heading2"><div>环境搭建</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#快速起步" class="anchor-link heading2"><div>快速起步</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#spark-运行环境" class="anchor-link heading2"><div>Spark 运行环境</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#local-模式" class="anchor-link heading3"><div>Local 模式</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#standalone-模式" class="anchor-link heading3"><div>Standalone 模式</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#yarn-模式" class="anchor-link heading3"><div>Yarn 模式</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#k8s-mesos-模式" class="anchor-link heading3"><div>K8s &amp;&amp; Mesos 模式</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#windows-模式" class="anchor-link heading3"><div>Windows 模式</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#spark-运行架构" class="anchor-link heading2"><div>Spark 运行架构</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd" class="anchor-link heading2"><div>RDD</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-概述" class="anchor-link heading3"><div>RDD 概述</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-基础编程" class="anchor-link heading3"><div>RDD 基础编程</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-算子" class="anchor-link heading3"><div>RDD 算子</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-序列化" class="anchor-link heading3"><div>RDD 序列化</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-依赖关系" class="anchor-link heading3"><div>RDD 依赖关系</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-持久化" class="anchor-link heading3"><div>RDD 持久化</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#rdd-分区器" class="anchor-link heading3"><div>RDD 分区器</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#累加器" class="anchor-link heading2"><div>累加器</div></a></li><li class="anchor"><a href="/bigdata/Spark/part1/#广播变量" class="anchor-link heading2"><div>广播变量</div></a></li></ul></div></aside></div> <!----> <div class="content__content-top"></div> <div class="theme-default-content content__default"><h2 id="spark-概述"><a href="#spark-概述" class="header-anchor">#</a> Spark 概述</h2> <p>之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。</p> <p>但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。</p> <p>Spark 其实也是一个计算框架，它和 MapReduce 的主要不同点就是：Spark 是基于内存进行计算的框架，多个作业之间的衔接也是用的内存，那么它的效率就大大提高了。在现在的大数据框架中，Spark 往往是替代 MapReduce 的方案。</p> <p>Spark 的核心模块：</p> <ul><li>Spark Core：Spark 的核心，在它的基础上，Spark 进行了很多扩展的功能。</li> <li>Spark SQL：类似于 Hive SQL 简化了 MapReduce 的操作，Spark SQL 也简化了编写 Spark 代码的操作，同样类似 HSQL，也专门用于处理结构化数据。</li> <li>Spark Streaming：根据 Spark Core 扩展，用于流式计算，但是相较于 Flink 这种框架来说，Spark 的流式计算要差劲一些。</li> <li>Spark MLlib：根据 Spark Core 扩展，处理机器学习，这里不做涉及。</li> <li>Spark GraphX：根据 Spark Core 扩展，处理图形挖掘计算，这里不做涉及。</li></ul> <h2 id="环境搭建"><a href="#环境搭建" class="header-anchor">#</a> 环境搭建</h2> <p>学习 Spark Core，首先就需要进行环境搭建。</p> <ol><li><p>Scala 环境：<a href="https://www.scala-lang.org/download/2.12.11.html" target="_blank" rel="noopener noreferrer">scala_2.12.11<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，注意配置好环境变量。</p></li> <li><p>将 Scala 加入到 IDEA 中的全局库中，并且将框架假如到当前模块中。</p> <p><img src="/assets/img/2021-11-22-21-56-09.22459d49.png" alt=""></p> <p><img src="data:image/png;base64,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" alt=""></p> <p><img src="/assets/img/2021-11-22-21-58-38.8b76ff71.png" alt=""></p></li> <li><p>添加 Spark 依赖到当前项目中。</p> <div class="language-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
        <span class="token comment">&lt;!-- 该插件用于将 Scala 代码编译成 class 文件 --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                    <span class="token comment">&lt;!-- 声明绑定到 maven 的 compile 阶段 --&gt;</span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">&gt;</span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br></div></div></li> <li><p><code>log4j.properties</code>：Spark 在运行时会产生大量日志，所以直接设置日志配置信息：</p> <div class="language-xml line-numbers-mode"><pre class="language-xml"><code>log4j.rootCategory=ERROR, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Set the default spark-shell log level to ERROR. When running the spark-shell, the
# log level for this class is used to overwrite the root logger's log level, so that
# the user can have different defaults for the shell and regular Spark apps. log4j.logger.org.apache.spark.repl.Main=ERROR

# Settings to quiet third party logs that are too verbose log4j.logger.org.spark_project.jetty=ERROR log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR

# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div></li> <li><p>假如使用的是 Windows，那么可能会由于缺少 Hadoop 的相关支持，可能会报错，直接关联 Hadoop 的配置到 Windows 即可，这一步在之前学习 Hadoop 应该已经做过。</p></li></ol> <h2 id="快速起步"><a href="#快速起步" class="header-anchor">#</a> 快速起步</h2> <p>下面来实现一个大数据版本的 HELLO WORLD：实现一次 Word Count，使用 Java 语言也完全支持，但是 Scala 开发比较快速，所以本次采用的是 Scala 语言。</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 1. 定义 Spark 的配置，之后详细讲配置是什么东西</span>
val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// 2. 创建 Spark 上下文，也就是创建 Spark 环境</span>
val sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token comment">// 3. 读取文件数据</span>
val fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">&quot;input/word.txt&quot;</span><span class="token punctuation">)</span>
<span class="token comment">/*
    1. 将数据进行转换，学过 Scala 或者 Java 应该有一定的基础。

    其中 '_' 代表的就是任意的单词：
    _.split(&quot; &quot;)：代表将每一行使用空格符切割
    flatMap 为扁平化处理
    map((_, 1)) 代表将 word =&gt; (word, 1)
    reduceByKey 代表将 (word, 1) 按照 word 分组，组内聚合
    */</span>
val wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
<span class="token comment">// 5. collect 代表收集，最终形成的结果如：(A, 2), (B, 3), (D, 2), ....</span>
val wordCount<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
wordCount<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>println<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><h2 id="spark-运行环境"><a href="#spark-运行环境" class="header-anchor">#</a> Spark 运行环境</h2> <h3 id="local-模式"><a href="#local-模式" class="header-anchor">#</a> Local 模式</h3> <p>Local 模式指的就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学、调试、演示等。我们之前在 IDEA 的快速开始案例是开发环境，和 Local 模式不太一样。</p> <p>TODO：待补充</p> <h3 id="standalone-模式"><a href="#standalone-模式" class="header-anchor">#</a> Standalone 模式</h3> <p>TODO：待补充</p> <h3 id="yarn-模式"><a href="#yarn-模式" class="header-anchor">#</a> Yarn 模式</h3> <p>TODO：待补充</p> <h3 id="k8s-mesos-模式"><a href="#k8s-mesos-模式" class="header-anchor">#</a> K8s &amp;&amp; Mesos 模式</h3> <p>TODO：待补充</p> <h3 id="windows-模式"><a href="#windows-模式" class="header-anchor">#</a> Windows 模式</h3> <p>TODO：待补充</p> <h2 id="spark-运行架构"><a href="#spark-运行架构" class="header-anchor">#</a> Spark 运行架构</h2> <p><strong>Driver &amp;&amp; Executor</strong></p> <p>Spark 核心是一个计算引擎，采用了标准 master-slave 架构，Spark 在执行时的基本架构为 Driver-Executor。</p> <p>其中 Driver 就是 master，负责任务调度；Executor 是 slave，负责任务的实际执行。下图的 Cluster Manager 的主要作用就是启动 Executor，之后 Executor 就与 Driver 直接通信了。</p> <p><img src="/assets/img/2021-11-23-09-18-51.8050a78a.png" alt=""></p> <p>从上图可以看到，Spark 有两个核心组件：</p> <ul><li><p>Driver：Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行操作。</p> <p>主要用于：将用户程序转换为作业（Job）、在各个 Executor 中调度任务（Task）、跟踪 Executor 的执行情况、通过 UI 展示运行情况。</p> <p>简单来说，Driver 用于统一调度，也叫 Driver 类。</p></li> <li><p>Executor：</p> <p>Spark 中的工作节点，每一个 Executor 都是一个 JVM 进程。Executor 负责运行具体任务（Task），任务之间相互独立，互不影响。</p> <p>Spark 启动时 Executor 会同时启动，并且伴随整个 Spark 的生命周期。假如有 Executor 发生故障，Spark Task 调度到其他 Executor 上继续执行。</p> <p>Executor 有两个核心功能：负责运行 Spark Task，并将结果返回 Driver、通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。</p></li></ul> <p><strong>Master &amp;&amp; Worker</strong></p> <p>Spark 集群的独立部署模式中，不需要其他资源调度框架，所以自己实现了一套资源调度框架：Master、Worker。</p> <p>Master 是一个进程，主要用于集群资源分配、调度，类似于 YARN 的 RM。Worker 类似于 YARN 中的 NM，可以提供给 Executor 资源（例如 CPU 核心数量 Core、内存大小等）。</p> <p><strong>Application Master</strong></p> <p>类似 Hadoop ，Application Master 是单个任务的老大，简单来说就是：ResourceManager 和 Driver 之间的解耦合就是利用 ApplicationMaster。</p> <p><strong>并行度</strong></p> <p>并行度 Parallelism：这里是并行，不是并发。</p> <p>在分布式计算框架中，一般都是多个任务同时执行，由于任务分布在不同的计算节点上进行计算，所以可以实现真正的多任务并行执行，集群中并行执行任务的个数叫做并行度。</p> <p>一个作业（Job）的并行度主要取决于配置，当然也可以在运行中动态修改。</p> <p><strong>有向无环图</strong></p> <p>有向无环图 DAG：Spark 擅长进行有向无环图的计算，而 Hadoop 不行。</p> <p>简单来说，有向无环图就是这个任务依赖于上个任务的执行结果，是一种抽象的结构，其中箭头所指向的方向是依赖的方向，例如： <code>A -&gt; B</code>，就是 A 依赖于 B 的结果，下图中 stage0 依赖于 stage1 的结果。</p> <p><img src="/assets/img/2021-11-23-09-37-19.cda26412.png" alt=""></p> <p><strong>Spark 数据结构</strong></p> <p>Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构，用于处理不同的应用场景：</p> <ul><li>RDD：弹性分布式数据集。</li> <li>累加器：分布式共享只写变量。</li> <li>广播变量：分布式共享只读变量。</li></ul> <h2 id="rdd"><a href="#rdd" class="header-anchor">#</a> RDD</h2> <h3 id="rdd-概述"><a href="#rdd-概述" class="header-anchor">#</a> RDD 概述</h3> <p>RDD，Resilient Distributed Dataset，弹性分布式数据集，是 Spark 最基本的数据处理模型：</p> <ul><li>弹性：存储弹性（内存和磁盘自动切换）、容错弹性（数据丢失自动恢复）、计算弹性（计算出错重试）、分片弹性（根据需要重新分片）。</li> <li>分布式：数据存储到大数据集群不同节点上。</li> <li>数据集：RDD 封装了计算逻辑，并不保存数据。</li> <li>不可变：RDD 封装的计算逻辑不可改变，如果要改变只能重新生成新的 RDD。</li> <li>数据抽象：RDD 是一个抽象类，需要子类具体实现。</li></ul> <p><strong>RDD 核心属性</strong></p> <p><img src="/assets/img/2021-11-23-13-08-41.ece805b3.png" alt=""></p> <p>上图是 RDD 的注解，其中说明了五大核心属性：</p> <ul><li>分区列表：RDD 数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。</li> <li>分区计算函数：Spark 使用分区计算函数对每一个分区进行计算。</li> <li>RDD 依赖：RDD 之间存在依赖关系。</li> <li>分区器：可选，当为 KV 类型数据时，可以设定分区器自定义数据分区。</li> <li>首选位置：可选，计算数据可以根据计算节点的状态选择不同位置计算。</li></ul> <p><strong>RDD 简易理解</strong></p> <p>使用文字的方式确实比较抽象了，所以在这里先行一个概述，有人使用薯片的加工流程做了比喻。</p> <p><img src="/assets/img/2021-12-29-18-15-20.5f2d1ab9.png" alt=""></p> <p>首先一开始那一袋子土豆，就可以将其看为一个 RDD。</p> <p>RDD 中有分区的概念，这其实就可以看成带泥土豆阶段，在这个阶段中，每一个带泥土豆都是 RDD 的一个分区。</p> <p>接下来进行土豆的清洗、切片、烘焙、分发、装桶，这其实就是 RDD 使用算子的过程中进行的转换。具体算子是什么之后会讲。</p> <p>从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承。</p> <p>在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承。</p> <h3 id="rdd-基础编程"><a href="#rdd-基础编程" class="header-anchor">#</a> RDD 基础编程</h3> <p><strong>RDD 创建</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token comment">// 1. 从集合（内存）中创建 RDD，其实 makeRDD 底层就是 parallelize</span>
<span class="token keyword">val</span> memoryRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> memoryRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// 2. 从文件（磁盘）创建 RDD</span>
<span class="token keyword">val</span> diskRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input.txt&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// 3. 基于 RDD 创建 RDD，是运算完成之后产生新的 RDD，详情见后续张杰</span>
<span class="token keyword">val</span> rddtoRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> diskRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// 4. 直接创建 RDD，一般是 Spark 框架自身使用</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p><strong>RDD 的并行度与分区</strong></p> <ul><li><p>并行度：</p> <p>Spark 将一个 Job 切分为多个 Task，然后将这些 Task 发送给 Executor 去执行。能够同时并行计算的 Task 的数量被被称为并行度。</p> <p>注意，Job 切分 Task 的个数和 Executor 能够执行 Task 的个数不一定相同，能够执行 Task 的个数才叫做并行度。</p></li> <li><p>分区：</p> <p>默认情况下，分区的规则在使用内存和使用文件有所不同：</p> <p>读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，读取文件数据时，默认采用 Hadoop 的规则进行切片分区。</p></li></ul> <h3 id="rdd-算子"><a href="#rdd-算子" class="header-anchor">#</a> RDD 算子</h3> <p>RDD 的算子其实就是封装的数据计算逻辑，类似于俄罗斯套娃，上一个 RDD 可以根据规则形成新的 RDD。RDD 的算子就分为两类：</p> <ul><li>RDD 转换算子：这一类 RDD 算子可以看成只是封装了逻辑，每一层的封装都会产生新的 RDD，但是这些 RDD 不会真正去执行数据操作。</li> <li>RDD 行动算子：这一类 RDD 算子是真正的去执行数据操作的算子，只要出现 RDD 的行动算子，那么 RDD 之前的所有逻辑（包括转换算子的逻辑）都会按顺序执行。</li></ul> <h4 id="rdd-转换算子"><a href="#rdd-转换算子" class="header-anchor">#</a> RDD 转换算子</h4> <p>RDD 根据数据处理方式的不同，可以分为 Value 类型、双 Value 类型，Key Value 类型。</p> <p><strong>Value 类型</strong></p> <ul><li><p>map：将输入数据逐条映射转换，包括值和类型的转换。</p></li> <li><p>mapPartitions：将待处理的数据以分区为单位，发送到计算节点进行处理，这里的处理可以为任意处理，比如过滤数据。</p> <p>map 和 mapPartitions 有区别：</p> <p>从数据的角度考虑，map 是一个数据一个数据地执行，而 mapPartitions 是以分区为单位进行批处理操作。</p> <p>从功能的角度考虑，map 是将数据进行转换，但是不会去改变数据的数量，而 mapPartitions 需要一个迭代器，返回一个迭代器，没有要求总数不变，所以可以对数据进行增删。</p> <p>从性能的角度来考虑：map 类似串行执行，而 mapPartitions 类似批处理，但是 mapPartitions 会长时间占用内存，有可能会导致内存溢出。所以内存有限情况下优先使用 map。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// map：一进一出，将数据逐条进行转换处理，这里就是乘 2 处理操作。</span>
sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_ <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

<span class="token comment">/*
    mapPartitions：按照分区为单位，将数据发送到计算节点去处理。输入为一个迭代器，输入也是一个迭代器。

    与 map 有所不同：
        - map 是按照分区内的数据为单位去处理，速度较慢。
        - mapPartitions：按照分区为单位去处理，速度较快，但是应当警惕当数据量过于庞大时，内存可能会溢出。
*/</span>
sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>iterator <span class="token keyword">=&gt;</span> iterator<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>_ <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div></li> <li><p>flatMap：将数据扁平化处理：</p> <p>例如 <code>List(List(1, 2), List(3, 4)) =&gt; List(1, 2, 3, 4)</code></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">/*
在这里可以将 List(1, 2) 和 List(3, 4) 看成两条河流：
    - 一般的 map 操作都是对这里两条河流分别进行操作，最后分别输出。
    - flatMap 可以看成将这两条河流分别进行处理，然后将处理的结果汇总到一起输出。在这里没有对 list 进行处理，直接输出，就是做了一层汇总的效果。
*/</span>
sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> List<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>list <span class="token keyword">=&gt;</span> list<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div></li> <li><p>glom：将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> List<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> arrRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div></li> <li><p>groupBy：将数据根据指定的规则进行分组：</p> <p>分区默认不变，但是数据会被打乱重新组合，这种操作我们称为 Shuffle，极限情况下，数据有可能被分到同一个分区中，Shuffle 还有其他的坏处，要尽量避免 Shuffle 操作。</p> <p>注意，上面说的分组并不是分区，一个分区中可能有多个分组。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">/*
    数字对 2 进行取余共有两种结果：0、1.

    这里进行分组，条件为 List 中的元素是否为 2 的余数，那么就会分为两组：
    - 一组的 key 为 0，value 为 2 的余数。
    - 一组的 key 为 1，value 非 2 的余数。
*/</span>
<span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_ <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment">// scala 中 ，_1 和 _2 分别对应 key、value</span>
rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>group <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
    println<span class="token punctuation">(</span>group<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
    println<span class="token punctuation">(</span>group<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toString<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div></li> <li><p>filter：按照指定规则进行过滤，分区不变。过滤之后有可能导致数据倾斜。</p></li> <li><p>sample：按照指定的规则从数据集中抽取数据。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">/*
    sample，简单来说是做随机取样的一个函数，它可以根据指定的规则从数据集中抽取数据。

    简单来说，假如有这样一个箱子，箱子里有各种各样的小球，对于这些小球，有这样的抽取方法：

    - 抽到的数据不放回箱子：伯努利算法：

        也叫做 0、1 算法，简单来说就是非黑即白，和扔硬币一样，不是正面就是反面，采取这样的算法，sample 有三个参数：

        - 参数一：抽取的数据是否放回，选择伯努利算法当然是 false。
        - 参数二：一个数据被抽取到的几率，范围在 [0, 1]，0 为全取，1 为全不取。
        - 参数三：随机种子，一般来说可以不填。

    - 抽到的数据放回箱子：泊松算法：

        如果选择泊松分布，有以下几个参数：

        - 参数一：抽取的数据是否放回，选择泊松分布当然选择 true。
        - 参数二：重复数据的几率，范围 &gt;= 0，表示每个元素被期望抽取到的次数。
        - 参数三：随机数种子，一般来说可以不填。
*/</span>

rdd<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>print<span class="token punctuation">)</span>
println<span class="token punctuation">(</span><span class="token punctuation">)</span>
rdd<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>print<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br></div></div><p>为啥这里说第三个参数中子数可以不填呢，如果玩过游戏都知道，地图的种子确定了，那么地图就确定了，如果写死了种子，写死了算法，那么最终的数据就是确定的。</p></li> <li><p>distinct：数据集去重。</p></li> <li><p>coalesce：缩减分区：</p> <p>如果当前 Spark 程序中存在过多的小任务，每个任务的数据量都很少，那么启动多个 task 就显得很不划算：</p> <ol><li>因为资源有时候是不太好动态调整的。比如每启动一个 task，都需要给 executor 1核2G 来进行计算一个 1M 的数据，简直大材小用，还容易导致资源紧张。</li> <li>调度问题也是个问题，有那调度的时间，早就算好好几次了。</li></ol> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// 指定分区为 6</span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
<span class="token comment">// 将分区数缩减到 2</span>
rdd<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>coalesce 参数：</p> <ul><li>参数一：想要缩减到几个分区。</li> <li>参数二：shuffle，默认为 false。</li> <li>参数三：分区器。</li></ul></li> <li><p>repartition：重置分区。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Operator&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
rdd<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>其实调用了 coalesce，参数 shuffle 的默认值为 true。其实无论是将分区多的 RDD 转为分区少的 RDD，还是将分区少的 RDD 转换为分区多的 RDD，它都可以胜任，因为无论如何都会经过 shuffle。</p> <p>coalesce 的 shuffle 可以自由选择，而 repartition 必须进行 shuffle。这里其实涉及到了一个宽窄依赖的问题，宽窄依赖在后面会有详细的解释。</p></li> <li><p>sortBy：按照规则进行排序：用于排序处理，排序后，新产生的 RDD 分区数量和原来的 RDD 分区数量保持一致，中间存在 shuffle 过程。</p></li></ul> <p><strong>双 Value 型</strong></p> <ul><li>intersection：两个 RDD 取交集，返回一个新的 RDD。</li> <li>union：两个 RDD 去并集，返回一个新的 RDD。</li> <li>subtract：两个 RDD 取差集：以一个 RDD 为主，去除两个 RDD 的重复元素，将其他的元素保留。</li> <li>zip：将两个 RDD 中的元素以键值对形式进行合并，注意这不是压缩。</li></ul> <p><strong>Key Value 型</strong></p> <ul><li><p>partitionBy：将数据按照指定 partitioner 重新分区，Spark 默认分区器为 HashPartitioner。</p></li> <li><p>reduceByKey：将数据按照相同的 key 对 value 进行聚合。</p></li> <li><p>groupByKey：将数据按照相同的 key 对 value 进行分组。</p> <p>reduceByKey 和 groupByKey 其实很相似：</p> <p>两者都存在 shuffle 操作，但是 reduceByKey 会在 shuffle 之前对分区内相同 key 的数据进行一次预聚合，类似于 MapReduce 的 combine 阶段，这样做的好处是可以减少落盘的数据量。</p> <p>groupByKey 仅仅是分组，不会进行 combine 操作。</p> <p>所以从 reduceByKey 性能较高。</p></li> <li><p>aggregateByKey：将分区内和分区间指定两套规则，分区内和分区间分别使用这两套规则进行计算。</p></li> <li><p>foldByKey：指定一套规则，分区内和分区间的计算都使用这一套规则，相当于 aggregateByKey 的简化版。</p></li> <li><p>combineByKey：进行聚集操作，它允许用户的返回值类型和输入类型不一致。</p></li> <li><p>sortByKey：根据 key 来进行排序，其中 key 必须可以排序（自定义的 Bean 实现排序接口）。</p></li> <li><p>join：在两个 RDD 之间进行 JOIN 操作，返回一个相同的 key 连接到一起的 RDD。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">&quot;a&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">&quot;b&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">&quot;c&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">&quot;x&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">&quot;y&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">&quot;z&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">/*
(1,(a,x))
(2,(b,y))
(3,(c,z))
*/</span>
rdd1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div></li> <li><p>leftOuterJoin：类似 SQL 的左外链接。</p></li> <li><p>cogroup：两种 (K, V) 和 (K, W) 类型的 RDD 调用形成：<code>(K, (Iterable&lt;V&gt;, (Iterable&lt;W&gt;)))</code></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">&quot;a&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">&quot;b&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">&quot;c&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">&quot;x&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">&quot;y&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">&quot;z&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">/*
(1, (CompactBuffer(a), CompactBuffer(x)))
(2, (CompactBuffer(b), CompactBuffer(y)))
(3, (CompactBuffer(c), CompactBuffer(z)))
*/</span>
rdd1<span class="token punctuation">.</span>cogroup<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
<span class="token comment">/*
ax
by
cz
*/</span>
rdd1<span class="token punctuation">.</span>cogroup<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>v<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> value <span class="token operator">=</span> v<span class="token punctuation">.</span>_2
    value<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>print<span class="token punctuation">)</span>
    value<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>print<span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div></li></ul> <h4 id="rdd-行动算子"><a href="#rdd-行动算子" class="header-anchor">#</a> RDD 行动算子</h4> <ul><li><p>reduce：聚集 RDD 中的元素，首先聚集分区内，之后聚集分区间。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div></li> <li><p>collect：将 RDD 中的所有数据从 Executor 收集到 Driver。</p></li> <li><p>count：返回 RDD 中元素的个数。</p></li> <li><p>first：返回 RDD 中第一个元素。</p></li> <li><p>task：返回一个由 RDD 的前 n 个元素组成的数组。</p></li> <li><p>taskOrdered：返回 RDD 的后 n 个元素组成的数组。</p></li> <li><p>aggregate：分区数值进行聚合。给一个初始值，初始值聚合第一个元素，形成的结果聚合第二个元素，形成的结果聚合第三个元素……</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token comment">// 切片数量为 2，最终分区数量为 2</span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment">/*
第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}
10 + 1 + 2 = 13
10 + 3 + 4 = 17
10 + 13 + 17 = 40
*/</span>
println<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">,</span> _ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div></li> <li><p>fold：aggregate 的简化版本，两个分区的聚合方式都相同。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

<span class="token comment">// 切片数量为 2，最终分区数量为 2</span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment">/*
第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}
10 + 1 + 2 = 13
10 + 3 + 4 = 17
10 + 13 + 17 = 40
*/</span>
println<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>fold<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div></li> <li><p>countByKey：根据 key 统计 value 的个数，返回 <code>key, count(value)</code>。</p></li> <li><p>saveAsTextFile：保存为 Text。</p></li> <li><p>saveAsObjectFile：序列化为对象保存文件。</p></li> <li><p>saveAsSequenceFile：保存为 sequence 文件。</p></li> <li><p>foreach：分布式遍历每个，所以有可能顺序不一致。</p></li></ul> <h3 id="rdd-序列化"><a href="#rdd-序列化" class="header-anchor">#</a> RDD 序列化</h3> <p><strong>闭包检查</strong></p> <p>从计算的角度来考虑，RDD 算子之外的代码其实都是在 Driver 端运行，算子内的逻辑都是在 Executor 中运行。</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code>object <span class="token class-name">CreateRDDDemo</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
    val sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

    val search <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Search</span><span class="token punctuation">(</span><span class="token string">&quot;SPARK&quot;</span><span class="token punctuation">)</span>

    search<span class="token punctuation">.</span><span class="token function">getMatch</span><span class="token punctuation">(</span>sc<span class="token punctuation">.</span><span class="token function">makeRDD</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token punctuation">(</span><span class="token string">&quot;HELLO WORLD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;HELLO SPARK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">class</span> <span class="token class-name">Search</span><span class="token punctuation">(</span>query<span class="token operator">:</span> <span class="token class-name">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">Serializable</span> <span class="token punctuation">{</span>
  def <span class="token function">isMatch</span><span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token class-name">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    s<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  def <span class="token function">getMatch</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    rdd<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>isMatch<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>在 Scala 中，当算子内使用到了算子外的变量，也就是说 Executor 使用到了 Driver 的变量，这个时候假如对应的变量没有进行序列化，就无法通过网络传输给 Executor。</p> <p>在执行任务之前，检测对象是否可以进行序列化，这个过程叫做闭包检测。</p> <p><strong>Kryo</strong></p> <p>原生的 Java 序列化字节比较多，比较重，序列化之后对象比较大，Spark 出于性能考虑，从 Spark2.0 开始支持<a href="https://github.com/EsotericSoftware/kryo" target="_blank" rel="noopener noreferrer">kryo<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>它是一个序列化框架，速度是 Serializable 的 10 倍，但是注意，即使是使用 kryo 也需要实现 Serializable。</p> <h3 id="rdd-依赖关系"><a href="#rdd-依赖关系" class="header-anchor">#</a> RDD 依赖关系</h3> <p><strong>RDD 的血缘关系</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>
<span class="token comment">/*
(2) input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []
 |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []
*/</span>
<span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input/1.txt&quot;</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>fileRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>
println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

<span class="token comment">/*
(2) MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []
 |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []
 |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []
*/</span>
<span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>wordRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>
println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

<span class="token comment">/*
(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []
 |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []
 |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []
 |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []
*/</span>
<span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>mapRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>
println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

<span class="token comment">/*
(2) ShuffledRDD[4] at reduceByKey at CreateRDDDemo.scala:23 []
 +-(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []
    |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []
    |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []
    |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []
*/</span>
<span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
println<span class="token punctuation">(</span>resultRDD<span class="token punctuation">.</span>toDebugString<span class="token punctuation">)</span>

resultRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br></div></div><p>RDD 使用这种直接记录操作的方式记录下了一系列血缘（Lineage），当分区丢失时，可以使用重新走一遍操作的方式恢复丢失的分区。</p> <p>除了直接记录操作之外，RDD 还会记录相邻的 RDD 之间的关系，我们叫做依赖关系：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>

  <span class="token comment">// List(org.apache.spark.OneToOneDependency@5dd903be)，一对一的关系</span>
  <span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input/1.txt&quot;</span><span class="token punctuation">)</span>
  println<span class="token punctuation">(</span>fileRDD<span class="token punctuation">.</span>dependencies<span class="token punctuation">)</span>
  println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

  <span class="token comment">// List(org.apache.spark.OneToOneDependency@784abd3e)，一对一的关系</span>
  <span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  println<span class="token punctuation">(</span>wordRDD<span class="token punctuation">.</span>dependencies<span class="token punctuation">)</span>
  println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

  <span class="token comment">// List(org.apache.spark.OneToOneDependency@37df14d1)，一对一的关系</span>
  <span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  println<span class="token punctuation">(</span>mapRDD<span class="token punctuation">.</span>dependencies<span class="token punctuation">)</span>
  println<span class="token punctuation">(</span><span class="token string">&quot;----------------------&quot;</span><span class="token punctuation">)</span>

  <span class="token comment">// List(org.apache.spark.ShuffleDependency@34585ac9)，进行了 Shuffle 操作</span>
  <span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
  println<span class="token punctuation">(</span>resultRDD<span class="token punctuation">.</span>dependencies<span class="token punctuation">)</span>

  resultRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>

  sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p><strong>RDD 宽窄依赖、阶段划分、任务划分</strong></p> <p>RDD 的算子就像是俄罗斯套娃，之前讲过 RDD 的逻辑不能更改，如果需要更改，那么就要重新生成一个新的算子。</p> <p>在从老的 RDD 到新 RDD 之间就产生了变化，例如：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_ <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在这里，<code>makeRDD</code> 就产生了 RDD（老的 RDD），之后经过 <code>map</code> 操作就产生了一个新的 RDD。</p> <p><img src="/assets/img/2021-12-29-18-15-20.5f2d1ab9.png" alt=""></p> <p>还是使用薯片制作的流程看宽窄依赖。</p> <p>从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承，也可以理解为独生子女。</p> <p>在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承，可以理解为多胎。</p> <p>在进行宽依赖的过程中，进行了一个薯片重新分区的情况，这其实就是进行了数据的 Shuffle，就是打乱重新排序。</p> <hr> <p>每一个 Spark 程序都是一个 Application，每一个 Application 遇到行动算子之后就会形成一个 Job，所以一个 Application 中可能有多个 Job。</p> <p>在 Job 的执行过程中，可能会遇到 Shuffle，那么此时就会划分为一个或者多个可以并行计算的 stage。</p> <p>每一个 stage 可以根据当前 RDD 的 partition 分为多个 Task，Task 由 Executor 去执行。</p> <p><img src="/assets/img/2021-12-30-09-28-33.44aea5e1.png" alt=""></p> <p><img src="/assets/img/2021-12-30-09-43-35.4125cd6a.png" alt=""></p> <p>在上图中，RDD 经过了 map、filter 操作，这两个操作并没有改变 RDD 的分区，但是经过 ReduceByKey 算子之后，分区中的数据被打乱重新排序了，这个操作就是宽依赖。</p> <p>我们任务的阶段划分即从开始的 RDD 到 Filtered RDD 为一个阶段。Reduced RDD 为一个阶段。也就是说任务阶段的划分完全取决与可以进行 Shuffle 的算子。</p> <p>在上图第一个阶段中，Task 的数量取决于此阶段最后一个 RDD 中分区数量，也就是 Filtered RDD 中的 4 个分区将会形成 4 个 Task。</p> <p>在第二个阶段中，Task 的数量取决于最后此阶段最后一个 RDD 中分区数量，也就是说取决于 Reduced RDD 的数量，也是 4 个。</p> <h3 id="rdd-持久化"><a href="#rdd-持久化" class="header-anchor">#</a> RDD 持久化</h3> <p>RDD 虽然叫做弹性分布式数据集，但其实没有进行 Shuffle 之前，它并不会保存数据。不会保存数据的意思是，假如在计算的过程中出现了某些错误，那么并不会从之前的 RDD 开始算，而是从头开始，例如：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input/1.txt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>在这个例子中，假如中间在计算时忽然发生了错误导致任务失败（例如在进行 map 操作时失败），那么数据的计算不会从 map 再次开始，而是从数据的源头开始，也就是 <code>textFile</code>。</p> <p>这肯定是我们不能忍受的，假如有一批数据量很大，耗时很久的任务，在执行过程中失败了，我们肯定不能接受从头再来。</p> <p>所以 Spark 提供了保存中间结果的功能，也就是 RDD 的持久化。利用 RDD 的持久化可以将计算结果中间的 RDD 保存到 JVM 的堆中。</p> <p>但是注意，进行持久化的操作并不是行动算子，也仅仅是一个逻辑的封装，要等到行动算子进行任务的执行之后，到达缓存的逻辑才会将 RDD 缓存起来。</p> <p><strong>Cache</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input/1.txt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

wordRDD<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>简单来说，利用 <code>cache()</code> 方法就可以将 RDD 缓存，假如上述案例在 map 操作时出错了，也不需要从头开始计算。</p> <p>但是我们也说过，存储默认是存到 JVM 堆中的，那么假如内存不够了，缓存也可以丢失，所以可以更改存储级别：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;input/1.txt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

wordRDD<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
wordRDD<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY_SER<span class="token punctuation">)</span>

<span class="token keyword">val</span> mapRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><table><thead><tr><th>级别</th> <th>备注</th></tr></thead> <tbody><tr><td>MEMORY_ONLY</td> <td>以序列化的方式，仅存在内存中。内存不够不会再缓存。默认方式。</td></tr> <tr><td>MEMORY_ONLY_SER</td> <td>以序列化的方式，仅存在内存中。这种方式比反序列化对象的方式很大程度上节省空间，但是会增加 CPU 负担。内存不够不会再缓存。</td></tr> <tr><td>MEMORY_AND_DISK</td> <td>反序列化方式，内存不够放硬盘。</td></tr> <tr><td>MEMORY_AND_DISK_SER</td> <td>序列化方式，内存不够放硬盘。</td></tr> <tr><td>DISK_ONLY</td> <td>在硬盘上缓存</td></tr> <tr><td>MEMORY_ONLY_2</td> <td>与上面功能相同，只不过会在集群中的两个节点上建立副本</td></tr> <tr><td>MEMORY_AND_DISK_2</td> <td>与上面功能相同，只不过会在集群中的两个节点上建立副本</td></tr></tbody></table> <p>Spark 的存储级别本质其实就是 CPU 和 内存之间的权衡。</p> <p>如果内存可以缓存全部的 RDD，那么使用默认方式即可，默认方式可以最大程度提高 CPU 效率。
假如内存不可缓存全部的 RDD，那么可以优先使用 <code>MEMORY_ONLY_SER</code> 以减少磁盘浪费，然后挑一个快速序列化对象的框架（之前说的 Kryo），不必要尽量不要溢写到磁盘，效率太低。</p> <p><strong>CheckPoint</strong></p> <p>和 Cache 不同，CheckPoint 就是将中间 RDD 写入到磁盘中。</p> <p>如果 RDD 的血缘关系过长，那么还不如在中间节点做点容错处理，好过之后有错误从头开始执行。</p> <p>但是只要使用了 CheckPoint，就会切断之前的血缘关系，从检查点的这一刻开始作为根。</p> <p><strong>Cache 和 CheckPoint 区别</strong></p> <ul><li>Cache 不会切断血缘，CheckPoint 会切断血缘。</li> <li>Cache 可靠性低，一般保存在内存、磁盘中。CheckPoint 通常保存在 HDFS 等高容错系统中。</li></ul> <h3 id="rdd-分区器"><a href="#rdd-分区器" class="header-anchor">#</a> RDD 分区器</h3> <p><img src="/assets/img/2022-01-01-12-20-48.2ac2596f.png" alt=""></p> <p>分区器决定了 RDD 中分区的个数，RDD 中的每条数据经过 Shuffle 之后进入到哪个分区。</p> <ul><li>只有 KV 类型的 RDD 才有分区器，非 KV 类型的 RDD 分区值为 None。</li> <li>每个 RDD 的分区 ID 范围 <code>0 ~ (numPartitions - 1)</code>，决定这个值是属于哪个分区的。</li></ul> <p>Spark 支持多种分区器，我们主要探索 Hash（默认分区器）、Range、自定义分区。</p> <p><strong>Hash 分区</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">class</span> HashPartitioner<span class="token punctuation">(</span>partitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Partitioner <span class="token punctuation">{</span>

  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

  <span class="token keyword">def</span> getPartition<span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token builtin">Any</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> key <span class="token keyword">match</span> <span class="token punctuation">{</span>
    <span class="token comment">// 之前说的是，假如不是 KV 类型，那么 K 为 null，这里就是 0 号分区，也就是没有分区。</span>
    <span class="token keyword">case</span> <span class="token keyword">null</span> <span class="token keyword">=&gt;</span> <span class="token number">0</span>
    <span class="token comment">// 这里调用工具进行分区，第一个参数为 hashcode，第二个参数为指定的分区数量</span>
    <span class="token keyword">case</span> _ <span class="token keyword">=&gt;</span> Utils<span class="token punctuation">.</span>nonNegativeMod<span class="token punctuation">(</span>key<span class="token punctuation">.</span>hashCode<span class="token punctuation">,</span> numPartitions<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">def</span> nonNegativeMod<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> mod<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">// 首先进行 hashCode 对 分区数量取余操作</span>
    <span class="token keyword">val</span> rawMod <span class="token operator">=</span> x <span class="token operator">%</span> mod
    <span class="token comment">// 保证为 0 ~ 分区数</span>
    rawMod <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">if</span> <span class="token punctuation">(</span>rawMod <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> mod <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>Range 分区</strong></p> <p>将一定范围内的数据映射到一个分区中，保证每隔分区内的数据均匀，而且分区见有序。</p> <h2 id="累加器"><a href="#累加器" class="header-anchor">#</a> 累加器</h2> <p><strong>累加器的概念和原理</strong></p> <p>之前说 Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构。RDD 我们已经看过了，接下来就是累加器和广播变量。</p> <p>累加器其实是一个分布式的，只写的变量。它的实现原理是这样的：</p> <p>在 Driver 端先定义变量，在 RDD 形成 Task 分发到每一个 Executor 时，Executor 端的每一个 Task 都会得到累加器的一个新的副本，每一个 Task 更新这个变量之后，都会传到 Driver 端，然后 merge 改变的值。</p> <p><strong>系统累加器</strong></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;AccumulatorDemo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">// 声明一个 Long 的累加器</span>
<span class="token keyword">val</span> sum <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator<span class="token punctuation">(</span><span class="token string">&quot;sum&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// 累加器的使用</span>
rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>num <span class="token keyword">=&gt;</span> sum<span class="token punctuation">.</span>add<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>sum<span class="token punctuation">.</span>value<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>除了 longAccumulator 之外，系统的累加器还有：</p> <p><img src="/assets/img/2022-01-04-09-26-16.5c7030eb.png" alt=""></p> <p><strong>自定义累加器</strong></p> <p>实际上，我们大部分在使用累加器的过程中都不会单纯地使用系统的累加器，结合业务场景，我们需要自定义的累加器。</p> <p>自定义累加器仅需两个步骤：</p> <ul><li>继承 <code>AccumulatorV2</code>，设定泛型。</li> <li>重写抽象方法。</li> <li>向 Spark 中注册累加器。</li></ul> <p>接下来使用 WordCountAccumulator 来作为案例，实现自定义累加器。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">/**
 * AccumulatorV2 共有两个泛型：输入、输出。
 * 这里定义了输入为 String，输出为 Map[String, Long]
 */</span>
<span class="token keyword">class</span> WordCountAccumulator <span class="token keyword">extends</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>

  <span class="token comment">// 定义 map 作为输出</span>
  <span class="token keyword">var</span> map<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token comment">// 累加器为初始状态的条件，这里就是当 map 为空时</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> isZero<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    map<span class="token punctuation">.</span>isEmpty
  <span class="token punctuation">}</span>

  <span class="token comment">// 复制累加器，这一步用于 Driver 和 Executor 做交互时，复制累加器的副本</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">new</span> WordCountAccumulator
  <span class="token punctuation">}</span>

  <span class="token comment">// 重置累加器</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    map<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment">// 累加器累加数据，word 就是输入的 String</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>word<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">/*
      查询 map 中是否拥有相同的单词：

      - 假如存在此单词，则在 map 中 +1 数量
      - 假如不存在此单词，则在 map 中增加这个词
     */</span>
    map<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token operator">=</span> map<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1L</span>
  <span class="token punctuation">}</span>

  <span class="token comment">// 用于 Driver 端合并从 Executor 传过来的累加器</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>other<span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> map1 <span class="token operator">=</span> map
    <span class="token keyword">val</span> map2 <span class="token operator">=</span> other<span class="token punctuation">.</span>value

    <span class="token comment">// map2 为初始值。innerMap 为返回结果对象，是一个迭代值。kv 表示 map1 中的每个值。</span>
    map <span class="token operator">=</span> map1<span class="token punctuation">.</span>foldLeft<span class="token punctuation">(</span>map2<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">(</span>innerMap<span class="token punctuation">,</span> kv<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
        <span class="token comment">/*
          查询 innerMap 中是否拥有相同的单词：

          - 假如存在此单词，则在 innerMap 中 +1 数量
          - 假如不存在此单词，则在 innerMap 中增加这个词
         */</span>
        innerMap<span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> <span class="token operator">=</span> innerMap<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span> <span class="token operator">+</span> kv<span class="token punctuation">.</span>_2
        innerMap
      <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment">// 返回累加器的结果</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> value<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> map
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br></div></div><div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;AccumulatorDemo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token string">&quot;HELLO WORLD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;HELLO SPARK&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;HELLO SCALA&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> wcAcc <span class="token operator">=</span> <span class="token keyword">new</span> WordCountAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span>
sc<span class="token punctuation">.</span>register<span class="token punctuation">(</span>wcAcc<span class="token punctuation">,</span><span class="token string">&quot;WordCountAccumulator&quot;</span><span class="token punctuation">)</span>
rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>word <span class="token keyword">=&gt;</span> wcAcc<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>wcAcc<span class="token punctuation">.</span>value<span class="token punctuation">)</span>

sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="广播变量"><a href="#广播变量" class="header-anchor">#</a> 广播变量</h2> <p>Spark 的最后一个结构，广播变量，它是一个分布式的，共享的，只读变量。广播变量的分发是比较高效的。</p> <p>广播变量一般情况下会用来分发较大的对象，它会向所有的 Executor 发送一个较大的只读值，来让一个或多个 Spark 操作使用。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;b&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;c&quot;</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;d&quot;</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;b&quot;</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;c&quot;</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;d&quot;</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>
<span class="token comment">// 声明广播变量</span>
<span class="token keyword">val</span> broadcast<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>list<span class="token punctuation">)</span>

<span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map <span class="token punctuation">{</span>
  <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> num<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
    <span class="token keyword">var</span> num2 <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token comment">// 使用广播变量</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">&lt;-</span> broadcast<span class="token punctuation">.</span>value<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>k <span class="token operator">==</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        num2 <span class="token operator">=</span> v
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">(</span>num<span class="token punctuation">,</span> num2<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div></div> <!----> <div class="content__content-bottom"></div> <footer class="page-meta"><div class="edit-link"><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="icon edit-icon"><path d="M117.953 696.992 64.306 959.696l265.931-49.336 450.204-452.505-212.284-213.376-450.204 452.513zm496.384-296.326L219.039 797.993l-46.108-46.34L568.233 354.33l46.104 46.335zm345.357-122.99-114.45 115.04-212.288-213.377 114.45-115.035 212.288 213.371zm0 0" fill="currentColor"></path></svg> <a href="https://gitlab.com/team401/knowledge/-/edit/main/bigdata/Spark/part1.md" target="_blank" rel="noopener noreferrer">Edit this page</a></div> <div class="meta-item update-time"><span class="label">Last update:</span> <span class="info">April 29, 2022 16:43</span></div> <div class="meta-item contributors"><span class="label">Contributors: </span> <span class="info"><span title="email: 2592716753@qq.com" class="contributor">
          红枫
        </span> , <span title="email: maple.wang@maiscrm.com" class="contributor">
          Maple Wang
        </span> <!----></span></div></footer> <!----> <!----> <!----> <div class="content__page-bottom"></div></main> <footer class="footer-wrapper"><!----> <div class="footer"><a href="https://beian.miit.gov.cn/#/Integrated/index">鲁ICP备20021989号-2</a></div> <!----></footer></div><div class="global-ui"><!----><!----><div id="pwa-install"><!----> <div id="install-modal-wrapper" style="display:none;"><div class="background"></div> <div class="install-modal"><div class="header"><button aria-label="Close" class="close-button"><svg width="23" height="22" xmlns="http://www.w3.org/2000/svg" class="icon close-icon"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.12.358a1.224 1.224 0 011.729 0l8.92 8.914L20.686.358a1.224 1.224 0 011.73 1.728L13.497 11l8.92 8.913a1.222 1.222 0 11-1.73 1.729l-8.919-8.913-8.92 8.913a1.224 1.224 0 01-1.729-1.729L10.04 11l-8.92-8.914a1.222 1.222 0 010-1.728z" fill="currentColor"></path></svg></button> <div class="logo"><!----> <div class="title"><h1></h1> <p class="desc">This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. </p></div></div></div> <div class="content"><div class="highlight"><!----> <!----></div> <div class="description"><h3>Description</h3> <p></p></div></div> <div class="button-wrapper"><button class="install-button">
        Install <span></span></button> <button class="cancel-button">
        Cancel
      </button></div></div></div></div><div tabindex="-1" role="dialog" aria-hidden="true" class="pswp"><div class="pswp__bg"></div> <div class="pswp__scroll-wrap"><div class="pswp__container"><div class="pswp__item"></div> <div class="pswp__item"></div> <div class="pswp__item"></div></div> <div class="pswp__ui pswp__ui--hidden"><div class="pswp__top-bar"><div class="pswp__counter"></div> <button title="Close" aria-label="Close" class="pswp__button pswp__button--close"></button> <button title="Share" aria-label="Share" class="pswp__button pswp__button--share"></button> <button title="Switch to full screen" aria-label="Switch to full screen" class="pswp__button pswp__button--fs"></button> <button title="Zoom in/out" aria-label="Zoom in/out" class="pswp__button pswp__button--zoom"></button> <div class="pswp__preloader"><div class="pswp__preloader__icn"><div class="pswp__preloader__cut"><div class="pswp__preloader__donut"></div></div></div></div></div> <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class="pswp__share-tooltip"></div></div> <button title="Prev (Arrow Left)" aria-label="Prev (Arrow Left)" class="pswp__button pswp__button--arrow--left"></button> <button title="Next (Arrow Right)" aria-label="Next (Arrow Right)" class="pswp__button pswp__button--arrow--right"></button> <div class="pswp__caption"><div class="pswp__caption__center"></div></div></div></div></div></div></div>
    <script src="/assets/js/app.00946664.js" defer></script><script src="/assets/js/vendors~layout-Layout.d74da02a.js" defer></script><script src="/assets/js/vendors~layout-Blog~layout-Layout~layout-NotFound.70129eef.js" defer></script><script src="/assets/js/page-Spark-01-SparkCore.e1b13d59.js" defer></script>
  </body>
</html>
