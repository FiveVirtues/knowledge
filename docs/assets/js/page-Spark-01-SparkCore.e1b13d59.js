(window.webpackJsonp=window.webpackJsonp||[]).push([[40],{1062:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"spark-概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-概述"}},[t._v("#")]),t._v(" Spark 概述")]),t._v(" "),n("p",[t._v("之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。")]),t._v(" "),n("p",[t._v("但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。")]),t._v(" "),n("p",[t._v("Spark 其实也是一个计算框架，它和 MapReduce 的主要不同点就是：Spark 是基于内存进行计算的框架，多个作业之间的衔接也是用的内存，那么它的效率就大大提高了。在现在的大数据框架中，Spark 往往是替代 MapReduce 的方案。")]),t._v(" "),n("p",[t._v("Spark 的核心模块：")]),t._v(" "),n("ul",[n("li",[t._v("Spark Core：Spark 的核心，在它的基础上，Spark 进行了很多扩展的功能。")]),t._v(" "),n("li",[t._v("Spark SQL：类似于 Hive SQL 简化了 MapReduce 的操作，Spark SQL 也简化了编写 Spark 代码的操作，同样类似 HSQL，也专门用于处理结构化数据。")]),t._v(" "),n("li",[t._v("Spark Streaming：根据 Spark Core 扩展，用于流式计算，但是相较于 Flink 这种框架来说，Spark 的流式计算要差劲一些。")]),t._v(" "),n("li",[t._v("Spark MLlib：根据 Spark Core 扩展，处理机器学习，这里不做涉及。")]),t._v(" "),n("li",[t._v("Spark GraphX：根据 Spark Core 扩展，处理图形挖掘计算，这里不做涉及。")])]),t._v(" "),n("h2",{attrs:{id:"环境搭建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#环境搭建"}},[t._v("#")]),t._v(" 环境搭建")]),t._v(" "),n("p",[t._v("学习 Spark Core，首先就需要进行环境搭建。")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("Scala 环境："),n("a",{attrs:{href:"https://www.scala-lang.org/download/2.12.11.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("scala_2.12.11"),n("OutboundLink")],1),t._v("，注意配置好环境变量。")])]),t._v(" "),n("li",[n("p",[t._v("将 Scala 加入到 IDEA 中的全局库中，并且将框架假如到当前模块中。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(984),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(985),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(986),alt:""}})])]),t._v(" "),n("li",[n("p",[t._v("添加 Spark 依赖到当前项目中。")]),t._v(" "),n("div",{staticClass:"language-xml line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-core_2.12"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.0.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 该插件用于将 Scala 代码编译成 class 文件 --\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("net.alchim31.maven"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-maven-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.2.2"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 声明绑定到 maven 的 compile 阶段 --\x3e")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("testCompile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.maven.plugins"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("maven-assembly-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.1.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("descriptorRefs")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("descriptorRef")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("jar-with-dependencies"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("descriptorRef")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("descriptorRefs")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("id")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("make-assembly"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("id")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("package"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("single"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br"),n("span",{staticClass:"line-number"},[t._v("28")]),n("br"),n("span",{staticClass:"line-number"},[t._v("29")]),n("br"),n("span",{staticClass:"line-number"},[t._v("30")]),n("br"),n("span",{staticClass:"line-number"},[t._v("31")]),n("br"),n("span",{staticClass:"line-number"},[t._v("32")]),n("br"),n("span",{staticClass:"line-number"},[t._v("33")]),n("br"),n("span",{staticClass:"line-number"},[t._v("34")]),n("br"),n("span",{staticClass:"line-number"},[t._v("35")]),n("br"),n("span",{staticClass:"line-number"},[t._v("36")]),n("br"),n("span",{staticClass:"line-number"},[t._v("37")]),n("br"),n("span",{staticClass:"line-number"},[t._v("38")]),n("br"),n("span",{staticClass:"line-number"},[t._v("39")]),n("br"),n("span",{staticClass:"line-number"},[t._v("40")]),n("br"),n("span",{staticClass:"line-number"},[t._v("41")]),n("br"),n("span",{staticClass:"line-number"},[t._v("42")]),n("br"),n("span",{staticClass:"line-number"},[t._v("43")]),n("br"),n("span",{staticClass:"line-number"},[t._v("44")]),n("br"),n("span",{staticClass:"line-number"},[t._v("45")]),n("br")])])]),t._v(" "),n("li",[n("p",[n("code",[t._v("log4j.properties")]),t._v("：Spark 在运行时会产生大量日志，所以直接设置日志配置信息：")]),t._v(" "),n("div",{staticClass:"language-xml line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("log4j.rootCategory=ERROR, console\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\n\n# Set the default spark-shell log level to ERROR. When running the spark-shell, the\n# log level for this class is used to overwrite the root logger's log level, so that\n# the user can have different defaults for the shell and regular Spark apps. log4j.logger.org.apache.spark.repl.Main=ERROR\n\n# Settings to quiet third party logs that are too verbose log4j.logger.org.spark_project.jetty=ERROR log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR log4j.logger.org.apache.parquet=ERROR\nlog4j.logger.parquet=ERROR\n\n# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("假如使用的是 Windows，那么可能会由于缺少 Hadoop 的相关支持，可能会报错，直接关联 Hadoop 的配置到 Windows 即可，这一步在之前学习 Hadoop 应该已经做过。")])])]),t._v(" "),n("h2",{attrs:{id:"快速起步"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#快速起步"}},[t._v("#")]),t._v(" 快速起步")]),t._v(" "),n("p",[t._v("下面来实现一个大数据版本的 HELLO WORLD：实现一次 Word Count，使用 Java 语言也完全支持，但是 Scala 开发比较快速，所以本次采用的是 Scala 语言。")]),t._v(" "),n("div",{staticClass:"language-java line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 定义 Spark 的配置，之后详细讲配置是什么东西")]),t._v("\nval sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setMaster")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setAppName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 创建 Spark 上下文，也就是创建 Spark 环境")]),t._v("\nval sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkContext")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3. 读取文件数据")]),t._v("\nval fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("textFile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/word.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n    1. 将数据进行转换，学过 Scala 或者 Java 应该有一定的基础。\n\n    其中 '_' 代表的就是任意的单词：\n    _.split(\" \")：代表将每一行使用空格符切割\n    flatMap 为扁平化处理\n    map((_, 1)) 代表将 word => (word, 1)\n    reduceByKey 代表将 (word, 1) 按照 word 分组，组内聚合\n    */")]),t._v("\nval wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("flatMap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduceByKey")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 5. collect 代表收集，最终形成的结果如：(A, 2), (B, 3), (D, 2), ....")]),t._v("\nval wordCount"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Array")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwordCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("foreach")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("stop")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br")])]),n("h2",{attrs:{id:"spark-运行环境"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-运行环境"}},[t._v("#")]),t._v(" Spark 运行环境")]),t._v(" "),n("h3",{attrs:{id:"local-模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#local-模式"}},[t._v("#")]),t._v(" Local 模式")]),t._v(" "),n("p",[t._v("Local 模式指的就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学、调试、演示等。我们之前在 IDEA 的快速开始案例是开发环境，和 Local 模式不太一样。")]),t._v(" "),n("p",[t._v("TODO：待补充")]),t._v(" "),n("h3",{attrs:{id:"standalone-模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#standalone-模式"}},[t._v("#")]),t._v(" Standalone 模式")]),t._v(" "),n("p",[t._v("TODO：待补充")]),t._v(" "),n("h3",{attrs:{id:"yarn-模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#yarn-模式"}},[t._v("#")]),t._v(" Yarn 模式")]),t._v(" "),n("p",[t._v("TODO：待补充")]),t._v(" "),n("h3",{attrs:{id:"k8s-mesos-模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#k8s-mesos-模式"}},[t._v("#")]),t._v(" K8s && Mesos 模式")]),t._v(" "),n("p",[t._v("TODO：待补充")]),t._v(" "),n("h3",{attrs:{id:"windows-模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#windows-模式"}},[t._v("#")]),t._v(" Windows 模式")]),t._v(" "),n("p",[t._v("TODO：待补充")]),t._v(" "),n("h2",{attrs:{id:"spark-运行架构"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-运行架构"}},[t._v("#")]),t._v(" Spark 运行架构")]),t._v(" "),n("p",[n("strong",[t._v("Driver && Executor")])]),t._v(" "),n("p",[t._v("Spark 核心是一个计算引擎，采用了标准 master-slave 架构，Spark 在执行时的基本架构为 Driver-Executor。")]),t._v(" "),n("p",[t._v("其中 Driver 就是 master，负责任务调度；Executor 是 slave，负责任务的实际执行。下图的 Cluster Manager 的主要作用就是启动 Executor，之后 Executor 就与 Driver 直接通信了。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(987),alt:""}})]),t._v(" "),n("p",[t._v("从上图可以看到，Spark 有两个核心组件：")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("Driver：Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行操作。")]),t._v(" "),n("p",[t._v("主要用于：将用户程序转换为作业（Job）、在各个 Executor 中调度任务（Task）、跟踪 Executor 的执行情况、通过 UI 展示运行情况。")]),t._v(" "),n("p",[t._v("简单来说，Driver 用于统一调度，也叫 Driver 类。")])]),t._v(" "),n("li",[n("p",[t._v("Executor：")]),t._v(" "),n("p",[t._v("Spark 中的工作节点，每一个 Executor 都是一个 JVM 进程。Executor 负责运行具体任务（Task），任务之间相互独立，互不影响。")]),t._v(" "),n("p",[t._v("Spark 启动时 Executor 会同时启动，并且伴随整个 Spark 的生命周期。假如有 Executor 发生故障，Spark Task 调度到其他 Executor 上继续执行。")]),t._v(" "),n("p",[t._v("Executor 有两个核心功能：负责运行 Spark Task，并将结果返回 Driver、通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。")])])]),t._v(" "),n("p",[n("strong",[t._v("Master && Worker")])]),t._v(" "),n("p",[t._v("Spark 集群的独立部署模式中，不需要其他资源调度框架，所以自己实现了一套资源调度框架：Master、Worker。")]),t._v(" "),n("p",[t._v("Master 是一个进程，主要用于集群资源分配、调度，类似于 YARN 的 RM。Worker 类似于 YARN 中的 NM，可以提供给 Executor 资源（例如 CPU 核心数量 Core、内存大小等）。")]),t._v(" "),n("p",[n("strong",[t._v("Application Master")])]),t._v(" "),n("p",[t._v("类似 Hadoop ，Application Master 是单个任务的老大，简单来说就是：ResourceManager 和 Driver 之间的解耦合就是利用 ApplicationMaster。")]),t._v(" "),n("p",[n("strong",[t._v("并行度")])]),t._v(" "),n("p",[t._v("并行度 Parallelism：这里是并行，不是并发。")]),t._v(" "),n("p",[t._v("在分布式计算框架中，一般都是多个任务同时执行，由于任务分布在不同的计算节点上进行计算，所以可以实现真正的多任务并行执行，集群中并行执行任务的个数叫做并行度。")]),t._v(" "),n("p",[t._v("一个作业（Job）的并行度主要取决于配置，当然也可以在运行中动态修改。")]),t._v(" "),n("p",[n("strong",[t._v("有向无环图")])]),t._v(" "),n("p",[t._v("有向无环图 DAG：Spark 擅长进行有向无环图的计算，而 Hadoop 不行。")]),t._v(" "),n("p",[t._v("简单来说，有向无环图就是这个任务依赖于上个任务的执行结果，是一种抽象的结构，其中箭头所指向的方向是依赖的方向，例如： "),n("code",[t._v("A -> B")]),t._v("，就是 A 依赖于 B 的结果，下图中 stage0 依赖于 stage1 的结果。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(988),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("Spark 数据结构")])]),t._v(" "),n("p",[t._v("Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构，用于处理不同的应用场景：")]),t._v(" "),n("ul",[n("li",[t._v("RDD：弹性分布式数据集。")]),t._v(" "),n("li",[t._v("累加器：分布式共享只写变量。")]),t._v(" "),n("li",[t._v("广播变量：分布式共享只读变量。")])]),t._v(" "),n("h2",{attrs:{id:"rdd"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd"}},[t._v("#")]),t._v(" RDD")]),t._v(" "),n("h3",{attrs:{id:"rdd-概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-概述"}},[t._v("#")]),t._v(" RDD 概述")]),t._v(" "),n("p",[t._v("RDD，Resilient Distributed Dataset，弹性分布式数据集，是 Spark 最基本的数据处理模型：")]),t._v(" "),n("ul",[n("li",[t._v("弹性：存储弹性（内存和磁盘自动切换）、容错弹性（数据丢失自动恢复）、计算弹性（计算出错重试）、分片弹性（根据需要重新分片）。")]),t._v(" "),n("li",[t._v("分布式：数据存储到大数据集群不同节点上。")]),t._v(" "),n("li",[t._v("数据集：RDD 封装了计算逻辑，并不保存数据。")]),t._v(" "),n("li",[t._v("不可变：RDD 封装的计算逻辑不可改变，如果要改变只能重新生成新的 RDD。")]),t._v(" "),n("li",[t._v("数据抽象：RDD 是一个抽象类，需要子类具体实现。")])]),t._v(" "),n("p",[n("strong",[t._v("RDD 核心属性")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(989),alt:""}})]),t._v(" "),n("p",[t._v("上图是 RDD 的注解，其中说明了五大核心属性：")]),t._v(" "),n("ul",[n("li",[t._v("分区列表：RDD 数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。")]),t._v(" "),n("li",[t._v("分区计算函数：Spark 使用分区计算函数对每一个分区进行计算。")]),t._v(" "),n("li",[t._v("RDD 依赖：RDD 之间存在依赖关系。")]),t._v(" "),n("li",[t._v("分区器：可选，当为 KV 类型数据时，可以设定分区器自定义数据分区。")]),t._v(" "),n("li",[t._v("首选位置：可选，计算数据可以根据计算节点的状态选择不同位置计算。")])]),t._v(" "),n("p",[n("strong",[t._v("RDD 简易理解")])]),t._v(" "),n("p",[t._v("使用文字的方式确实比较抽象了，所以在这里先行一个概述，有人使用薯片的加工流程做了比喻。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(552),alt:""}})]),t._v(" "),n("p",[t._v("首先一开始那一袋子土豆，就可以将其看为一个 RDD。")]),t._v(" "),n("p",[t._v("RDD 中有分区的概念，这其实就可以看成带泥土豆阶段，在这个阶段中，每一个带泥土豆都是 RDD 的一个分区。")]),t._v(" "),n("p",[t._v("接下来进行土豆的清洗、切片、烘焙、分发、装桶，这其实就是 RDD 使用算子的过程中进行的转换。具体算子是什么之后会讲。")]),t._v(" "),n("p",[t._v("从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承。")]),t._v(" "),n("p",[t._v("在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承。")]),t._v(" "),n("h3",{attrs:{id:"rdd-基础编程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-基础编程"}},[t._v("#")]),t._v(" RDD 基础编程")]),t._v(" "),n("p",[n("strong",[t._v("RDD 创建")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 从集合（内存）中创建 RDD，其实 makeRDD 底层就是 parallelize")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" memoryRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" memoryRDD2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 从文件（磁盘）创建 RDD")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" diskRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3. 基于 RDD 创建 RDD，是运算完成之后产生新的 RDD，详情见后续张杰")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rddtoRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" diskRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 4. 直接创建 RDD，一般是 Spark 框架自身使用")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br")])]),n("p",[n("strong",[t._v("RDD 的并行度与分区")])]),t._v(" "),n("ul",[n("li",[n("p",[t._v("并行度：")]),t._v(" "),n("p",[t._v("Spark 将一个 Job 切分为多个 Task，然后将这些 Task 发送给 Executor 去执行。能够同时并行计算的 Task 的数量被被称为并行度。")]),t._v(" "),n("p",[t._v("注意，Job 切分 Task 的个数和 Executor 能够执行 Task 的个数不一定相同，能够执行 Task 的个数才叫做并行度。")])]),t._v(" "),n("li",[n("p",[t._v("分区：")]),t._v(" "),n("p",[t._v("默认情况下，分区的规则在使用内存和使用文件有所不同：")]),t._v(" "),n("p",[t._v("读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，读取文件数据时，默认采用 Hadoop 的规则进行切片分区。")])])]),t._v(" "),n("h3",{attrs:{id:"rdd-算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-算子"}},[t._v("#")]),t._v(" RDD 算子")]),t._v(" "),n("p",[t._v("RDD 的算子其实就是封装的数据计算逻辑，类似于俄罗斯套娃，上一个 RDD 可以根据规则形成新的 RDD。RDD 的算子就分为两类：")]),t._v(" "),n("ul",[n("li",[t._v("RDD 转换算子：这一类 RDD 算子可以看成只是封装了逻辑，每一层的封装都会产生新的 RDD，但是这些 RDD 不会真正去执行数据操作。")]),t._v(" "),n("li",[t._v("RDD 行动算子：这一类 RDD 算子是真正的去执行数据操作的算子，只要出现 RDD 的行动算子，那么 RDD 之前的所有逻辑（包括转换算子的逻辑）都会按顺序执行。")])]),t._v(" "),n("h4",{attrs:{id:"rdd-转换算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-转换算子"}},[t._v("#")]),t._v(" RDD 转换算子")]),t._v(" "),n("p",[t._v("RDD 根据数据处理方式的不同，可以分为 Value 类型、双 Value 类型，Key Value 类型。")]),t._v(" "),n("p",[n("strong",[t._v("Value 类型")])]),t._v(" "),n("ul",[n("li",[n("p",[t._v("map：将输入数据逐条映射转换，包括值和类型的转换。")])]),t._v(" "),n("li",[n("p",[t._v("mapPartitions：将待处理的数据以分区为单位，发送到计算节点进行处理，这里的处理可以为任意处理，比如过滤数据。")]),t._v(" "),n("p",[t._v("map 和 mapPartitions 有区别：")]),t._v(" "),n("p",[t._v("从数据的角度考虑，map 是一个数据一个数据地执行，而 mapPartitions 是以分区为单位进行批处理操作。")]),t._v(" "),n("p",[t._v("从功能的角度考虑，map 是将数据进行转换，但是不会去改变数据的数量，而 mapPartitions 需要一个迭代器，返回一个迭代器，没有要求总数不变，所以可以对数据进行增删。")]),t._v(" "),n("p",[t._v("从性能的角度来考虑：map 类似串行执行，而 mapPartitions 类似批处理，但是 mapPartitions 会长时间占用内存，有可能会导致内存溢出。所以内存有限情况下优先使用 map。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map：一进一出，将数据逐条进行转换处理，这里就是乘 2 处理操作。")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n    mapPartitions：按照分区为单位，将数据发送到计算节点去处理。输入为一个迭代器，输入也是一个迭代器。\n\n    与 map 有所不同：\n        - map 是按照分区内的数据为单位去处理，速度较慢。\n        - mapPartitions：按照分区为单位去处理，速度较快，但是应当警惕当数据量过于庞大时，内存可能会溢出。\n*/")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iterator "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" iterator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("flatMap：将数据扁平化处理：")]),t._v(" "),n("p",[t._v("例如 "),n("code",[t._v("List(List(1, 2), List(3, 4)) => List(1, 2, 3, 4)")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n在这里可以将 List(1, 2) 和 List(3, 4) 看成两条河流：\n    - 一般的 map 操作都是对这里两条河流分别进行操作，最后分别输出。\n    - flatMap 可以看成将这两条河流分别进行处理，然后将处理的结果汇总到一起输出。在这里没有对 list 进行处理，直接输出，就是做了一层汇总的效果。\n*/")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("glom：将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" arrRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glom"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("groupBy：将数据根据指定的规则进行分组：")]),t._v(" "),n("p",[t._v("分区默认不变，但是数据会被打乱重新组合，这种操作我们称为 Shuffle，极限情况下，数据有可能被分到同一个分区中，Shuffle 还有其他的坏处，要尽量避免 Shuffle 操作。")]),t._v(" "),n("p",[t._v("注意，上面说的分组并不是分区，一个分区中可能有多个分组。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n    数字对 2 进行取余共有两种结果：0、1.\n\n    这里进行分组，条件为 List 中的元素是否为 2 的余数，那么就会分为两组：\n    - 一组的 key 为 0，value 为 2 的余数。\n    - 一组的 key 为 1，value 非 2 的余数。\n*/")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Iterable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// scala 中 ，_1 和 _2 分别对应 key、value")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("group "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("filter：按照指定规则进行过滤，分区不变。过滤之后有可能导致数据倾斜。")])]),t._v(" "),n("li",[n("p",[t._v("sample：按照指定的规则从数据集中抽取数据。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n    sample，简单来说是做随机取样的一个函数，它可以根据指定的规则从数据集中抽取数据。\n\n    简单来说，假如有这样一个箱子，箱子里有各种各样的小球，对于这些小球，有这样的抽取方法：\n\n    - 抽到的数据不放回箱子：伯努利算法：\n\n        也叫做 0、1 算法，简单来说就是非黑即白，和扔硬币一样，不是正面就是反面，采取这样的算法，sample 有三个参数：\n\n        - 参数一：抽取的数据是否放回，选择伯努利算法当然是 false。\n        - 参数二：一个数据被抽取到的几率，范围在 [0, 1]，0 为全取，1 为全不取。\n        - 参数三：随机种子，一般来说可以不填。\n\n    - 抽到的数据放回箱子：泊松算法：\n\n        如果选择泊松分布，有以下几个参数：\n\n        - 参数一：抽取的数据是否放回，选择泊松分布当然选择 true。\n        - 参数二：重复数据的几率，范围 >= 0，表示每个元素被期望抽取到的次数。\n        - 参数三：随机数种子，一般来说可以不填。\n*/")]),t._v("\n\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br"),n("span",{staticClass:"line-number"},[t._v("28")]),n("br"),n("span",{staticClass:"line-number"},[t._v("29")]),n("br"),n("span",{staticClass:"line-number"},[t._v("30")]),n("br"),n("span",{staticClass:"line-number"},[t._v("31")]),n("br")])]),n("p",[t._v("为啥这里说第三个参数中子数可以不填呢，如果玩过游戏都知道，地图的种子确定了，那么地图就确定了，如果写死了种子，写死了算法，那么最终的数据就是确定的。")])]),t._v(" "),n("li",[n("p",[t._v("distinct：数据集去重。")])]),t._v(" "),n("li",[n("p",[t._v("coalesce：缩减分区：")]),t._v(" "),n("p",[t._v("如果当前 Spark 程序中存在过多的小任务，每个任务的数据量都很少，那么启动多个 task 就显得很不划算：")]),t._v(" "),n("ol",[n("li",[t._v("因为资源有时候是不太好动态调整的。比如每启动一个 task，都需要给 executor 1核2G 来进行计算一个 1M 的数据，简直大材小用，还容易导致资源紧张。")]),t._v(" "),n("li",[t._v("调度问题也是个问题，有那调度的时间，早就算好好几次了。")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指定分区为 6")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将分区数缩减到 2")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br")])]),n("p",[t._v("coalesce 参数：")]),t._v(" "),n("ul",[n("li",[t._v("参数一：想要缩减到几个分区。")]),t._v(" "),n("li",[t._v("参数二：shuffle，默认为 false。")]),t._v(" "),n("li",[t._v("参数三：分区器。")])])]),t._v(" "),n("li",[n("p",[t._v("repartition：重置分区。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Operator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("repartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br")])]),n("p",[t._v("其实调用了 coalesce，参数 shuffle 的默认值为 true。其实无论是将分区多的 RDD 转为分区少的 RDD，还是将分区少的 RDD 转换为分区多的 RDD，它都可以胜任，因为无论如何都会经过 shuffle。")]),t._v(" "),n("p",[t._v("coalesce 的 shuffle 可以自由选择，而 repartition 必须进行 shuffle。这里其实涉及到了一个宽窄依赖的问题，宽窄依赖在后面会有详细的解释。")])]),t._v(" "),n("li",[n("p",[t._v("sortBy：按照规则进行排序：用于排序处理，排序后，新产生的 RDD 分区数量和原来的 RDD 分区数量保持一致，中间存在 shuffle 过程。")])])]),t._v(" "),n("p",[n("strong",[t._v("双 Value 型")])]),t._v(" "),n("ul",[n("li",[t._v("intersection：两个 RDD 取交集，返回一个新的 RDD。")]),t._v(" "),n("li",[t._v("union：两个 RDD 去并集，返回一个新的 RDD。")]),t._v(" "),n("li",[t._v("subtract：两个 RDD 取差集：以一个 RDD 为主，去除两个 RDD 的重复元素，将其他的元素保留。")]),t._v(" "),n("li",[t._v("zip：将两个 RDD 中的元素以键值对形式进行合并，注意这不是压缩。")])]),t._v(" "),n("p",[n("strong",[t._v("Key Value 型")])]),t._v(" "),n("ul",[n("li",[n("p",[t._v("partitionBy：将数据按照指定 partitioner 重新分区，Spark 默认分区器为 HashPartitioner。")])]),t._v(" "),n("li",[n("p",[t._v("reduceByKey：将数据按照相同的 key 对 value 进行聚合。")])]),t._v(" "),n("li",[n("p",[t._v("groupByKey：将数据按照相同的 key 对 value 进行分组。")]),t._v(" "),n("p",[t._v("reduceByKey 和 groupByKey 其实很相似：")]),t._v(" "),n("p",[t._v("两者都存在 shuffle 操作，但是 reduceByKey 会在 shuffle 之前对分区内相同 key 的数据进行一次预聚合，类似于 MapReduce 的 combine 阶段，这样做的好处是可以减少落盘的数据量。")]),t._v(" "),n("p",[t._v("groupByKey 仅仅是分组，不会进行 combine 操作。")]),t._v(" "),n("p",[t._v("所以从 reduceByKey 性能较高。")])]),t._v(" "),n("li",[n("p",[t._v("aggregateByKey：将分区内和分区间指定两套规则，分区内和分区间分别使用这两套规则进行计算。")])]),t._v(" "),n("li",[n("p",[t._v("foldByKey：指定一套规则，分区内和分区间的计算都使用这一套规则，相当于 aggregateByKey 的简化版。")])]),t._v(" "),n("li",[n("p",[t._v("combineByKey：进行聚集操作，它允许用户的返回值类型和输入类型不一致。")])]),t._v(" "),n("li",[n("p",[t._v("sortByKey：根据 key 来进行排序，其中 key 必须可以排序（自定义的 Bean 实现排序接口）。")])]),t._v(" "),n("li",[n("p",[t._v("join：在两个 RDD 之间进行 JOIN 操作，返回一个相同的 key 连接到一起的 RDD。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"x"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"y"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"z"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(1,(a,x))\n(2,(b,y))\n(3,(c,z))\n*/")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("leftOuterJoin：类似 SQL 的左外链接。")])]),t._v(" "),n("li",[n("p",[t._v("cogroup：两种 (K, V) 和 (K, W) 类型的 RDD 调用形成："),n("code",[t._v("(K, (Iterable<V>, (Iterable<W>)))")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"x"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"y"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"z"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(1, (CompactBuffer(a), CompactBuffer(x)))\n(2, (CompactBuffer(b), CompactBuffer(y)))\n(3, (CompactBuffer(c), CompactBuffer(z)))\n*/")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cogroup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\nax\nby\ncz\n*/")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cogroup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2\n    value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br")])])])]),t._v(" "),n("h4",{attrs:{id:"rdd-行动算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-行动算子"}},[t._v("#")]),t._v(" RDD 行动算子")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("reduce：聚集 RDD 中的元素，首先聚集分区内，之后聚集分区间。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("collect：将 RDD 中的所有数据从 Executor 收集到 Driver。")])]),t._v(" "),n("li",[n("p",[t._v("count：返回 RDD 中元素的个数。")])]),t._v(" "),n("li",[n("p",[t._v("first：返回 RDD 中第一个元素。")])]),t._v(" "),n("li",[n("p",[t._v("task：返回一个由 RDD 的前 n 个元素组成的数组。")])]),t._v(" "),n("li",[n("p",[t._v("taskOrdered：返回 RDD 的后 n 个元素组成的数组。")])]),t._v(" "),n("li",[n("p",[t._v("aggregate：分区数值进行聚合。给一个初始值，初始值聚合第一个元素，形成的结果聚合第二个元素，形成的结果聚合第三个元素……")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 切片数量为 2，最终分区数量为 2")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}\n10 + 1 + 2 = 13\n10 + 3 + 4 = 17\n10 + 13 + 17 = 40\n*/")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("aggregate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("fold：aggregate 的简化版本，两个分区的聚合方式都相同。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 切片数量为 2，最终分区数量为 2")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}\n10 + 1 + 2 = 13\n10 + 3 + 4 = 17\n10 + 13 + 17 = 40\n*/")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fold"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])])]),t._v(" "),n("li",[n("p",[t._v("countByKey：根据 key 统计 value 的个数，返回 "),n("code",[t._v("key, count(value)")]),t._v("。")])]),t._v(" "),n("li",[n("p",[t._v("saveAsTextFile：保存为 Text。")])]),t._v(" "),n("li",[n("p",[t._v("saveAsObjectFile：序列化为对象保存文件。")])]),t._v(" "),n("li",[n("p",[t._v("saveAsSequenceFile：保存为 sequence 文件。")])]),t._v(" "),n("li",[n("p",[t._v("foreach：分布式遍历每个，所以有可能顺序不一致。")])])]),t._v(" "),n("h3",{attrs:{id:"rdd-序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-序列化"}},[t._v("#")]),t._v(" RDD 序列化")]),t._v(" "),n("p",[n("strong",[t._v("闭包检查")])]),t._v(" "),n("p",[t._v("从计算的角度来考虑，RDD 算子之外的代码其实都是在 Driver 端运行，算子内的逻辑都是在 Executor 中运行。")]),t._v(" "),n("div",{staticClass:"language-java line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("object "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CreateRDDDemo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  def "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Array")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    val sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setMaster")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setAppName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    val sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkContext")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    val search "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SPARK"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    search"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMatch")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("makeRDD")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HELLO WORLD"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HELLO SPARK"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("foreach")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("stop")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Serializable")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  def "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isMatch")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Boolean")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  def "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMatch")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isMatch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br")])]),n("p",[t._v("在 Scala 中，当算子内使用到了算子外的变量，也就是说 Executor 使用到了 Driver 的变量，这个时候假如对应的变量没有进行序列化，就无法通过网络传输给 Executor。")]),t._v(" "),n("p",[t._v("在执行任务之前，检测对象是否可以进行序列化，这个过程叫做闭包检测。")]),t._v(" "),n("p",[n("strong",[t._v("Kryo")])]),t._v(" "),n("p",[t._v("原生的 Java 序列化字节比较多，比较重，序列化之后对象比较大，Spark 出于性能考虑，从 Spark2.0 开始支持"),n("a",{attrs:{href:"https://github.com/EsotericSoftware/kryo",target:"_blank",rel:"noopener noreferrer"}},[t._v("kryo"),n("OutboundLink")],1),t._v("。")]),t._v(" "),n("p",[t._v("它是一个序列化框架，速度是 Serializable 的 10 倍，但是注意，即使是使用 kryo 也需要实现 Serializable。")]),t._v(" "),n("h3",{attrs:{id:"rdd-依赖关系"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-依赖关系"}},[t._v("#")]),t._v(" RDD 依赖关系")]),t._v(" "),n("p",[n("strong",[t._v("RDD 的血缘关系")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(2) input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/1.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDebugString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(2) MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDebugString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []\n |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDebugString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n(2) ShuffledRDD[4] at reduceByKey at CreateRDDDemo.scala:23 []\n +-(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []\n    |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n    |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n    |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resultRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDebugString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nresultRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br"),n("span",{staticClass:"line-number"},[t._v("28")]),n("br"),n("span",{staticClass:"line-number"},[t._v("29")]),n("br"),n("span",{staticClass:"line-number"},[t._v("30")]),n("br"),n("span",{staticClass:"line-number"},[t._v("31")]),n("br"),n("span",{staticClass:"line-number"},[t._v("32")]),n("br"),n("span",{staticClass:"line-number"},[t._v("33")]),n("br"),n("span",{staticClass:"line-number"},[t._v("34")]),n("br"),n("span",{staticClass:"line-number"},[t._v("35")]),n("br"),n("span",{staticClass:"line-number"},[t._v("36")]),n("br"),n("span",{staticClass:"line-number"},[t._v("37")]),n("br"),n("span",{staticClass:"line-number"},[t._v("38")]),n("br"),n("span",{staticClass:"line-number"},[t._v("39")]),n("br"),n("span",{staticClass:"line-number"},[t._v("40")]),n("br"),n("span",{staticClass:"line-number"},[t._v("41")]),n("br")])]),n("p",[t._v("RDD 使用这种直接记录操作的方式记录下了一系列血缘（Lineage），当分区丢失时，可以使用重新走一遍操作的方式恢复丢失的分区。")]),t._v(" "),n("p",[t._v("除了直接记录操作之外，RDD 还会记录相邻的 RDD 之间的关系，我们叫做依赖关系：")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// List(org.apache.spark.OneToOneDependency@5dd903be)，一对一的关系")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/1.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dependencies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// List(org.apache.spark.OneToOneDependency@784abd3e)，一对一的关系")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dependencies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// List(org.apache.spark.OneToOneDependency@37df14d1)，一对一的关系")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dependencies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"----------------------"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// List(org.apache.spark.ShuffleDependency@34585ac9)，进行了 Shuffle 操作")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resultRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dependencies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  resultRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br")])]),n("p",[n("strong",[t._v("RDD 宽窄依赖、阶段划分、任务划分")])]),t._v(" "),n("p",[t._v("RDD 的算子就像是俄罗斯套娃，之前讲过 RDD 的逻辑不能更改，如果需要更改，那么就要重新生成一个新的算子。")]),t._v(" "),n("p",[t._v("在从老的 RDD 到新 RDD 之间就产生了变化，例如：")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("p",[t._v("在这里，"),n("code",[t._v("makeRDD")]),t._v(" 就产生了 RDD（老的 RDD），之后经过 "),n("code",[t._v("map")]),t._v(" 操作就产生了一个新的 RDD。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(552),alt:""}})]),t._v(" "),n("p",[t._v("还是使用薯片制作的流程看宽窄依赖。")]),t._v(" "),n("p",[t._v("从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承，也可以理解为独生子女。")]),t._v(" "),n("p",[t._v("在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承，可以理解为多胎。")]),t._v(" "),n("p",[t._v("在进行宽依赖的过程中，进行了一个薯片重新分区的情况，这其实就是进行了数据的 Shuffle，就是打乱重新排序。")]),t._v(" "),n("hr"),t._v(" "),n("p",[t._v("每一个 Spark 程序都是一个 Application，每一个 Application 遇到行动算子之后就会形成一个 Job，所以一个 Application 中可能有多个 Job。")]),t._v(" "),n("p",[t._v("在 Job 的执行过程中，可能会遇到 Shuffle，那么此时就会划分为一个或者多个可以并行计算的 stage。")]),t._v(" "),n("p",[t._v("每一个 stage 可以根据当前 RDD 的 partition 分为多个 Task，Task 由 Executor 去执行。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(990),alt:""}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(991),alt:""}})]),t._v(" "),n("p",[t._v("在上图中，RDD 经过了 map、filter 操作，这两个操作并没有改变 RDD 的分区，但是经过 ReduceByKey 算子之后，分区中的数据被打乱重新排序了，这个操作就是宽依赖。")]),t._v(" "),n("p",[t._v("我们任务的阶段划分即从开始的 RDD 到 Filtered RDD 为一个阶段。Reduced RDD 为一个阶段。也就是说任务阶段的划分完全取决与可以进行 Shuffle 的算子。")]),t._v(" "),n("p",[t._v("在上图第一个阶段中，Task 的数量取决于此阶段最后一个 RDD 中分区数量，也就是 Filtered RDD 中的 4 个分区将会形成 4 个 Task。")]),t._v(" "),n("p",[t._v("在第二个阶段中，Task 的数量取决于最后此阶段最后一个 RDD 中分区数量，也就是说取决于 Reduced RDD 的数量，也是 4 个。")]),t._v(" "),n("h3",{attrs:{id:"rdd-持久化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-持久化"}},[t._v("#")]),t._v(" RDD 持久化")]),t._v(" "),n("p",[t._v("RDD 虽然叫做弹性分布式数据集，但其实没有进行 Shuffle 之前，它并不会保存数据。不会保存数据的意思是，假如在计算的过程中出现了某些错误，那么并不会从之前的 RDD 开始算，而是从头开始，例如：")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/1.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br")])]),n("p",[t._v("在这个例子中，假如中间在计算时忽然发生了错误导致任务失败（例如在进行 map 操作时失败），那么数据的计算不会从 map 再次开始，而是从数据的源头开始，也就是 "),n("code",[t._v("textFile")]),t._v("。")]),t._v(" "),n("p",[t._v("这肯定是我们不能忍受的，假如有一批数据量很大，耗时很久的任务，在执行过程中失败了，我们肯定不能接受从头再来。")]),t._v(" "),n("p",[t._v("所以 Spark 提供了保存中间结果的功能，也就是 RDD 的持久化。利用 RDD 的持久化可以将计算结果中间的 RDD 保存到 JVM 的堆中。")]),t._v(" "),n("p",[t._v("但是注意，进行持久化的操作并不是行动算子，也仅仅是一个逻辑的封装，要等到行动算子进行任务的执行之后，到达缓存的逻辑才会将 RDD 缓存起来。")]),t._v(" "),n("p",[n("strong",[t._v("Cache")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/1.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br")])]),n("p",[t._v("简单来说，利用 "),n("code",[t._v("cache()")]),t._v(" 方法就可以将 RDD 缓存，假如上述案例在 map 操作时出错了，也不需要从头开始计算。")]),t._v(" "),n("p",[t._v("但是我们也说过，存储默认是存到 JVM 堆中的，那么假如内存不够了，缓存也可以丢失，所以可以更改存储级别：")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input/1.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fileRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("persist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MEMORY_ONLY_SER"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br")])]),n("table",[n("thead",[n("tr",[n("th",[t._v("级别")]),t._v(" "),n("th",[t._v("备注")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("MEMORY_ONLY")]),t._v(" "),n("td",[t._v("以序列化的方式，仅存在内存中。内存不够不会再缓存。默认方式。")])]),t._v(" "),n("tr",[n("td",[t._v("MEMORY_ONLY_SER")]),t._v(" "),n("td",[t._v("以序列化的方式，仅存在内存中。这种方式比反序列化对象的方式很大程度上节省空间，但是会增加 CPU 负担。内存不够不会再缓存。")])]),t._v(" "),n("tr",[n("td",[t._v("MEMORY_AND_DISK")]),t._v(" "),n("td",[t._v("反序列化方式，内存不够放硬盘。")])]),t._v(" "),n("tr",[n("td",[t._v("MEMORY_AND_DISK_SER")]),t._v(" "),n("td",[t._v("序列化方式，内存不够放硬盘。")])]),t._v(" "),n("tr",[n("td",[t._v("DISK_ONLY")]),t._v(" "),n("td",[t._v("在硬盘上缓存")])]),t._v(" "),n("tr",[n("td",[t._v("MEMORY_ONLY_2")]),t._v(" "),n("td",[t._v("与上面功能相同，只不过会在集群中的两个节点上建立副本")])]),t._v(" "),n("tr",[n("td",[t._v("MEMORY_AND_DISK_2")]),t._v(" "),n("td",[t._v("与上面功能相同，只不过会在集群中的两个节点上建立副本")])])])]),t._v(" "),n("p",[t._v("Spark 的存储级别本质其实就是 CPU 和 内存之间的权衡。")]),t._v(" "),n("p",[t._v("如果内存可以缓存全部的 RDD，那么使用默认方式即可，默认方式可以最大程度提高 CPU 效率。\n假如内存不可缓存全部的 RDD，那么可以优先使用 "),n("code",[t._v("MEMORY_ONLY_SER")]),t._v(" 以减少磁盘浪费，然后挑一个快速序列化对象的框架（之前说的 Kryo），不必要尽量不要溢写到磁盘，效率太低。")]),t._v(" "),n("p",[n("strong",[t._v("CheckPoint")])]),t._v(" "),n("p",[t._v("和 Cache 不同，CheckPoint 就是将中间 RDD 写入到磁盘中。")]),t._v(" "),n("p",[t._v("如果 RDD 的血缘关系过长，那么还不如在中间节点做点容错处理，好过之后有错误从头开始执行。")]),t._v(" "),n("p",[t._v("但是只要使用了 CheckPoint，就会切断之前的血缘关系，从检查点的这一刻开始作为根。")]),t._v(" "),n("p",[n("strong",[t._v("Cache 和 CheckPoint 区别")])]),t._v(" "),n("ul",[n("li",[t._v("Cache 不会切断血缘，CheckPoint 会切断血缘。")]),t._v(" "),n("li",[t._v("Cache 可靠性低，一般保存在内存、磁盘中。CheckPoint 通常保存在 HDFS 等高容错系统中。")])]),t._v(" "),n("h3",{attrs:{id:"rdd-分区器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd-分区器"}},[t._v("#")]),t._v(" RDD 分区器")]),t._v(" "),n("p",[n("img",{attrs:{src:a(992),alt:""}})]),t._v(" "),n("p",[t._v("分区器决定了 RDD 中分区的个数，RDD 中的每条数据经过 Shuffle 之后进入到哪个分区。")]),t._v(" "),n("ul",[n("li",[t._v("只有 KV 类型的 RDD 才有分区器，非 KV 类型的 RDD 分区值为 None。")]),t._v(" "),n("li",[t._v("每个 RDD 的分区 ID 范围 "),n("code",[t._v("0 ~ (numPartitions - 1)")]),t._v("，决定这个值是属于哪个分区的。")])]),t._v(" "),n("p",[t._v("Spark 支持多种分区器，我们主要探索 Hash（默认分区器）、Range、自定义分区。")]),t._v(" "),n("p",[n("strong",[t._v("Hash 分区")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" HashPartitioner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Partitioner "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" getPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Any")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" key "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 之前说的是，假如不是 KV 类型，那么 K 为 null，这里就是 0 号分区，也就是没有分区。")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这里调用工具进行分区，第一个参数为 hashcode，第二个参数为指定的分区数量")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" _ "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" Utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nonNegativeMod"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hashCode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" numPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br")])]),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" nonNegativeMod"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mod"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 首先进行 hashCode 对 分区数量取余操作")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rawMod "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" mod\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 保证为 0 ~ 分区数")]),t._v("\n    rawMod "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rawMod "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" mod "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br")])]),n("p",[n("strong",[t._v("Range 分区")])]),t._v(" "),n("p",[t._v("将一定范围内的数据映射到一个分区中，保证每隔分区内的数据均匀，而且分区见有序。")]),t._v(" "),n("h2",{attrs:{id:"累加器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#累加器"}},[t._v("#")]),t._v(" 累加器")]),t._v(" "),n("p",[n("strong",[t._v("累加器的概念和原理")])]),t._v(" "),n("p",[t._v("之前说 Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构。RDD 我们已经看过了，接下来就是累加器和广播变量。")]),t._v(" "),n("p",[t._v("累加器其实是一个分布式的，只写的变量。它的实现原理是这样的：")]),t._v(" "),n("p",[t._v("在 Driver 端先定义变量，在 RDD 形成 Task 分发到每一个 Executor 时，Executor 端的每一个 Task 都会得到累加器的一个新的副本，每一个 Task 更新这个变量之后，都会传到 Driver 端，然后 merge 改变的值。")]),t._v(" "),n("p",[n("strong",[t._v("系统累加器")])]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AccumulatorDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 声明一个 Long 的累加器")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sum "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("longAccumulator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sum"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 累加器的使用")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" sum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br")])]),n("p",[t._v("除了 longAccumulator 之外，系统的累加器还有：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(993),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("自定义累加器")])]),t._v(" "),n("p",[t._v("实际上，我们大部分在使用累加器的过程中都不会单纯地使用系统的累加器，结合业务场景，我们需要自定义的累加器。")]),t._v(" "),n("p",[t._v("自定义累加器仅需两个步骤：")]),t._v(" "),n("ul",[n("li",[t._v("继承 "),n("code",[t._v("AccumulatorV2")]),t._v("，设定泛型。")]),t._v(" "),n("li",[t._v("重写抽象方法。")]),t._v(" "),n("li",[t._v("向 Spark 中注册累加器。")])]),t._v(" "),n("p",[t._v("接下来使用 WordCountAccumulator 来作为案例，实现自定义累加器。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * AccumulatorV2 共有两个泛型：输入、输出。\n * 这里定义了输入为 String，输出为 Map[String, Long]\n */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" WordCountAccumulator "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" AccumulatorV2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义 map 作为输出")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" map"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 累加器为初始状态的条件，这里就是当 map 为空时")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" isZero"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isEmpty\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 复制累加器，这一步用于 Driver 和 Executor 做交互时，复制累加器的副本")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" copy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" AccumulatorV2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" WordCountAccumulator\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 重置累加器")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" reset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 累加器累加数据，word 就是输入的 String")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n      查询 map 中是否拥有相同的单词：\n\n      - 假如存在此单词，则在 map 中 +1 数量\n      - 假如不存在此单词，则在 map 中增加这个词\n     */")]),t._v("\n    map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0L")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1L")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用于 Driver 端合并从 Executor 传过来的累加器")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" merge"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("other"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" AccumulatorV2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" map1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" map\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" map2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" other"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// map2 为初始值。innerMap 为返回结果对象，是一个迭代值。kv 表示 map1 中的每个值。")]),t._v("\n    map "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" map1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foldLeft"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("map2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("innerMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*\n          查询 innerMap 中是否拥有相同的单词：\n\n          - 假如存在此单词，则在 innerMap 中 +1 数量\n          - 假如不存在此单词，则在 innerMap 中增加这个词\n         */")]),t._v("\n        innerMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" innerMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0L")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2\n        innerMap\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回累加器的结果")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" mutable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" map\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br"),n("span",{staticClass:"line-number"},[t._v("28")]),n("br"),n("span",{staticClass:"line-number"},[t._v("29")]),n("br"),n("span",{staticClass:"line-number"},[t._v("30")]),n("br"),n("span",{staticClass:"line-number"},[t._v("31")]),n("br"),n("span",{staticClass:"line-number"},[t._v("32")]),n("br"),n("span",{staticClass:"line-number"},[t._v("33")]),n("br"),n("span",{staticClass:"line-number"},[t._v("34")]),n("br"),n("span",{staticClass:"line-number"},[t._v("35")]),n("br"),n("span",{staticClass:"line-number"},[t._v("36")]),n("br"),n("span",{staticClass:"line-number"},[t._v("37")]),n("br"),n("span",{staticClass:"line-number"},[t._v("38")]),n("br"),n("span",{staticClass:"line-number"},[t._v("39")]),n("br"),n("span",{staticClass:"line-number"},[t._v("40")]),n("br"),n("span",{staticClass:"line-number"},[t._v("41")]),n("br"),n("span",{staticClass:"line-number"},[t._v("42")]),n("br"),n("span",{staticClass:"line-number"},[t._v("43")]),n("br"),n("span",{staticClass:"line-number"},[t._v("44")]),n("br"),n("span",{staticClass:"line-number"},[t._v("45")]),n("br"),n("span",{staticClass:"line-number"},[t._v("46")]),n("br"),n("span",{staticClass:"line-number"},[t._v("47")]),n("br"),n("span",{staticClass:"line-number"},[t._v("48")]),n("br"),n("span",{staticClass:"line-number"},[t._v("49")]),n("br"),n("span",{staticClass:"line-number"},[t._v("50")]),n("br"),n("span",{staticClass:"line-number"},[t._v("51")]),n("br"),n("span",{staticClass:"line-number"},[t._v("52")]),n("br"),n("span",{staticClass:"line-number"},[t._v("53")]),n("br"),n("span",{staticClass:"line-number"},[t._v("54")]),n("br"),n("span",{staticClass:"line-number"},[t._v("55")]),n("br"),n("span",{staticClass:"line-number"},[t._v("56")]),n("br"),n("span",{staticClass:"line-number"},[t._v("57")]),n("br")])]),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[*]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"AccumulatorDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HELLO WORLD"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HELLO SPARK"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HELLO SCALA"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wcAcc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" WordCountAccumulator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wcAcc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCountAccumulator"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" wcAcc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wcAcc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br")])]),n("h2",{attrs:{id:"广播变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#广播变量"}},[t._v("#")]),t._v(" 广播变量")]),t._v(" "),n("p",[t._v("Spark 的最后一个结构，广播变量，它是一个分布式的，共享的，只读变量。广播变量的分发是比较高效的。")]),t._v(" "),n("p",[t._v("广播变量一般情况下会用来分发较大的对象，它会向所有的 Executor 发送一个较大的只读值，来让一个或多个 Spark 操作使用。")]),t._v(" "),n("div",{staticClass:"language-scala line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"d"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" list "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"d"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 声明广播变量")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" broadcast"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" num2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 使用广播变量")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v(" broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        num2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br")])])])}),[],!1,null,null,null);s.default=e.exports},552:function(t,s,a){t.exports=a.p+"assets/img/2021-12-29-18-15-20.5f2d1ab9.png"},984:function(t,s,a){t.exports=a.p+"assets/img/2021-11-22-21-56-09.22459d49.png"},985:function(t,s){t.exports="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAicAAAByCAIAAAAH7ubnAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABweSURBVHhe7d17VFTXvQfwc4y9GkkgWbkYNb6AzOgSkRgbEkmzbJaCAlZD1vBHmyglqxUfXaLcOAm3ZtWupLVFLw8TJNi7yoUk7R+wLqYJoIze1OZeaDAJRdTgIL6rCaSNg2KT+jj3tx/zfjggMMPM97NYsvc+Z87YLuSb3z57zlY1Tevv76+qqlIUJTs7OyIighq+1TUdkq3byUxdJFukMVdN36OsadAq0qjXVZz7/vKKzUpxsj6/ZWGR+ZVOPR1VFGo2b9ax4+wAf6HL2JqGBiU9fY+4kLio40kAACPnyJEjMTExsuOff15qbz494dHHH468S5VDAXLu3Ln4+HjZGX6XLl2aPHnyGGpR0lDeUIOyhxKIHx02e14t7mLfdZsrHDKiJltmh9KSv7ORfT/ZKSOHtOTrc/kg1/Hqq/xczSFyiPNJAADBSLt5+fSp/qlzYwMeOYHCUodQ8BgMht7e3gYqJIZJ2otFC+kbpYNKnBKiRckyU9HVsIZ1OjpZLKVV0ADHR8UgJ0+uSG/cyyKHah5iZtd2OAkAIBj948JJy6S5MffK371hSP4vpxKntrY2Ojo6PT1djAwD3eZmGSxkT7pD8CzMWs7qnrRnrEf5bBoLJ2IvZ4Q1r4giqauzg32jCxE+G9fSeZKNAAAEJe16z8kL19W/tf/pfw79+cj5vpuaPBBOWOoM9L6ON5mpi1y+5AGhMZdiRpYwrvWLq67ibH63x3auV/Ikgd8xAgAITv3nu7+6e5IuceGTj8++p6+z/aTllhZ2wTNmqCJHeLrxrMuXPMCJsoTh9UvCbN83/+VcnGutY6Xb/ArlkTyJwW0dAAhemnb5wnlt2qyZ940b+y/3TJodG/11T89VeTCMjLl+/fp99903JJFzGw/PZrd1rKxr2TwTicIsLCryWuukVfDbOQAAo8A3lr5v7r57vOzddffd/3L9xj9lL4ywldOy6TdvK6czUxe5FDfkg7QZsgUAEHL8XzmtfX3+8J/O3v9Esi6S3dr4+sInH56/P/mJmAg1YIvZArJyejCp4wNSBwDCygBSR/vHhY+bzbcemjP7oYjrX5481n0zJvmx6RPk4UAI2Od1AABguKnq3VMTHokZf9n8cevhY5fGTH1k3rS75bFwgtQBABgh6vgHYhOfWLR48eJFyY/E/eu4wM2tBdAQz7ABAISVQTwRJ3hghg0AAEKcevToUdkEAIABunnzJmodP6HWAQCAkYbUAQCAkYPUAQCAkTOY1Gk/ed729dmZi3/vG+YtebzQzlY/N3fu3G0fyj4AAAS9O611/nnj5vmev/dcviL7PsmckJ6rPotF2wAA4WXMN998I5tWNHLt2jXZ8c+lLy87FkC2L3mYo8h5PqOwXfYAACAcqUVFRYsWLRo3bpzoU+QcOnQoIiLiySefFCPuXOLEh8SHp8kWpc6H2xLW1SqG8qPbnqLu2epthxb9bJXyFouiRGP50v3reCQlGuvfWT1D087yA/yVbOzt1TNUmVuG8nJl3bpaw+73YyqW76AuXfDDbXPp2vzEVTPC8uO+o9q3vvUt2QKAUMdSh76J4BGRY+vyEzy4o9SxRogc9FAA8eiY/r8/52dbGco7fvadcyKiEhPb29sVe+p0LD7IzkXkjFqUOpMnT5YdAAhpYyhg6BuFjcVi8SdyBu87OcZE+tZemJEwly0CcLypQ9HRcfTo0XIDtdv3Hzqnqk9toz7HB7tOn+MnknZlaT2dvO0pGTAHfy7C7JeIHACAYDeGAkYEj8lkoj+HK3KoqlJnrH5HRAhTuy7BHjyJsdP59+mxLJeI5rDwwLHkYQxrbaUSU1vLjrsMAgBAUGJr2ETwTJ069Q4jJ/HhaS5f8gCnfbiNYkaUMB0u9Uv7KWpR0hzazybbdDHTz7317+xuD6tp7EHlmcHISqjadc7FEwAABCO5cprC5oknnrjzKucn5+5x+ZIHOKpvRPkibtlQuohxfoSIOzyGxd8Rg3IuzrXWcRWz6pcid37+IZ6fDVx32ZLIvCbZ8YOmNeUtKevGzw/A8BvBZxPYps84Q3nHtqesc2KJRqMsaKi++dlTqjp91VrbgPWQV+qM1TJ3EhA8wMSuN+ZU1jc5/zCwaImkMOLfhCVlTZRPkZFRUYbK1oL5UVF8rFu+AAAGqK+vr66uzvdnbwbzzGlva9gSH57mUtyQN6ZflS1P5Bo2LD8Lb0O4ho2qnPkFrbLD5NTWKgZDpWxbSlKtP2Z0Zq5ScWBDHLUpkDaldG00rY81se9iEAAGivKmpqaGGllZWRMmeN6ce4h3OkDqwCAMYepoWvfulF06E0sXkSsm3a6o+oy+0lR5Bkf1TlShvo0dk4nkJGl7m2l9HH4gAQbutsEzgjNsAMNPVePWV+gLU3Z3d5flmo0eqxZW2RiUWpYrqaV9jMVSm0NJY5Hf++hliByAQaGkobyhBmWPx6m2ANc6AGSoah1e6DhPsClKTk5OZaVDPZO0/VPjiUcN/yXatZl1BucXUOpghg3gDn355ZfV1dV6vX758uVyyAp7iULgDfmzCWz3aahkYZNpfIatKW8JDVEV4+Ech7Y4CgCD5nuSDTNsEFLYmmmnNWl57MPPzuicvCZNOdV1LF7XvYmtW3Ncw8YWsWElJMBg3fa+Dv1XHv6BQYCZzeYhW03QXZYy32y0ZNSn1FM3w1QStztFrFWz1TrsnFzFmFlXrzOVprLiBrUOwJDwZw0bah0IHey+Tm5dZltJCuvpN5ooe3bvMyuZy2L5cUmN22CMLzAUxGekmMRHd5xqHf6ZHnkqAAzEjRs36F+Qj8ghSB0IHSrlyQG2/kz2lZSSCqXumEvo2FQaqL6xWBzXsPEVbX2iAAKAgaLIyczM9BE5BKkDIYXKnbIlvHaJ18WpqmlXQbzRdd6sKS+yUN9G6dKWWSfqG5daZ0BP0wGAARm5+zp1TWwbBWHC+HGzYmfMnDqUy5Zg9BrC+zoAEOQCU+tc+/qbtuPmE/Y9cwAAICwMptaxWCxjx46NiIiQfa6/v//GjRtRUVGy78ax1vEtM5Xt9wPhA7UOQPgYTK1TX19fVVVFMSP7PHJohMZlHwAAwJPBpM7KlSvpT1vwiMixjQ+5ruJkVcpttA7kNjbm0kBycRcb4W1ODgAAQFAa5GoCW9IYDAaxhXR2drbLnJuLQc6wUcToO1/RKtJkn7Ch/JY1DXKQIie9o8jcvFnHj8LoYzabv/efF2UHAELaIFcTUMBQzFCjvLyc/rxt5AyebnaCsifdrYZZ02DNoca9exYWVSFyAABGg8GvYRPBM2fOnGGMHCatgsoxrUrJxvwZAMCod0crpylssrKyhjNy2HRaMbuZo9vcbC5a2NJ5Uow6SHtmTUv+Tn7DhwqfYuQSAEAQu6PUGQm6zbP3ioUC+vwE27Sao7QKc1FHujhn72xMtQEABLHAPJvAN3xeJ9wM4WqCW4lzup5TjFuO1SkT39wRv1gO2/TQoXdV9ZYWYdwyo2sHa8sjbm5p0W9uiXhjx+mjj8R3PTdRjtp0HJv1Vi99X7nqMZ2pdefn7Dr83W1nyveSPW7O0sd+8nnr+nbXN701aWZTSv8yfkHB25kAox12OoDAG9o1bOw3eP6EcutvfJYE83pFQti4pA5/ycwYcUxRDr7zAf26d0ydpklnl+23f0BNoGCoW+wwvdxxTHckWryXuL658IzemPRjt8BywtMLqQPhA6kDgTesK6dXrvru0iMsRWTfY1qYIpqeV/J3nD6uqnR0w6Vjp1PtaXGwoye2p/dAQrxjftiTaUf0fiqtJsdQbKQ6p457LeUtS2yp41wtCR5qJoDRC6kDgTeEqUMZs67nMNUl1ChMkIMObDNszmnhnDoiGFgS8EHHWsdxPo3QyUXKcTokKipW6wx8hs3hr9r/myJ5cW/5BDDaBf1qAoCBePetP5ZPfGzf0ghqzDL+0dihnD54WPdOD5vIMtLIcf+LhrmJ0TETZ9ZtiZkrB1xRWlDkpO6bsLvwuxQ2B4/0sFH+Rroth3/De1T0vPjid08Uyi+qsRY/97TsvjhzDv9vPvqr6orOnKaSa8uZ2Hx51OOZACEAtQ4E3nDMsPFqJj72IKt7qEulQ11CbyavZqxHea3D65jU9miXWmftXya+uWVmrNKbb5pQlBKhdBzPV+Y4zMt5rmNE3SP7DqgScrkzxP4+E8/Y7jZZbyxhMg1CH2odCDVUguxeOrNpx8xTRR/QL3r6/b47UTu+/7DubaVox9PUZidNjojtuebjs11zl81UTGdOUesvx1JNLC3oCrx46v9N0QeiZqI3krWItTqJWfyY48iJVdH8YnSRswcSZqy0/hceZUzR4n5jNauGRDHURZHDiiSnUoyicXfhHNurAEIDUgdCCv0S1z3Yf6r99DLj4YbEpH1LeXUyKWbfizONKTNP8SUAbOTBCTFf9Iu6xyOd0vvGX2TbGzGJJ74ojQ529J/u6T99kIWT/LKWMmPU/sK3r63bEjNH03hZE32gSNY0dGjnTj7DZk0gW2h1sZXfEwt3PI0ZNgglSB0IMRNild6GS6xQ+Mni/vJ9V9nY570HlGjlyJnY5+JF6ZA5z3obxot39585KpsClR0sCQoTIn7Mb73IPOOlFXWXHml9g67HJ+KoKysqB2M+P5PKi60utqrbvh7BEQunHYczWS3FQku35dhBNuf2wayd9JeZSH8BcVn2jryKupVI74ViCEYZpA6ElskRsbyImbtsZuzBs9YJq6sNHcqSSb35ByPWLbuHflkXPnhGlDJzJ1lv1UycWUdVBZ8okyNOetfbKhj+tYwvk+N5w0LCtthMTMTtn8cXAlhn2PhcGZtGo2LL2MHKF/dYskl/HsUNhLJgX03g+ESDCePHzYqdMXPqsG06ybZQqMnCngkjbghXEzje0rd+9sW+HJkNsk/SzFHebi18UDxxgB0tVGI8rJx2+JSo22doFKXnjG1tguC+moC/12P8Uz6uywQoseRq6Y5jRiWe2qetCx8IX+zAH6zg9i4Ao91oSh1hji5mVsx02RlaSJ0AGdZPiQJAUBm51LFYLGPHjnV5QHV/f/+NGzeioqJk3w2e3hYOkDoA4WPk7uvU19fbNr0WxIakNC77AAAQ6kYudVauXEl/2oLHtge2GB9qjblqcnFjcTLf/yC3kQ9w9o3huuRRwk6QI6LJX17s9hIAALgzI5c6Yu9RalDY9PT0iMgZzn1IW/JfVao0TWtYsyddVfc+Q03NXKTIHeC6infyo4SdIHPHQUt+p+0l2cgdAIAhMdKrCUSJ09vbGx0d7U/kDPa+DhUrr86W6wK8tfnqgfwW1lLWNGgVaazf+Qo1nE6j0WylCksMhpHZbJ48ediWJgJAMAnAGjYKnoaGhvT0dH+qnOFKHYUFjlLER21hg9QJEEqdq1f5xzkBINSNvpXT3gwsdU7ax1jW5Ceg1gkg1DoA4SNcn02Q9mKRkq/niwWyOxMWylEAABheoVrrwGiCWgcgfAR76kA4QOoAhA88/ROCkcViaWpqqq+vv3DhghwCgJCAWgcCz6XWuXLlyuuvvz5+/PgJEyZcvHgxJycnJiZGHlOUmzdv/v73v+/s7NTpdOITYAAwiqDWgaDT3t4+duzYjRs3rl27Ni4u7qOPPpIHHCInOjr62WeflaNuNK27bElkXpP8LyrREW1Ba8pzGQEAQdM+KV9V/smwFSRIHQg6jvW36vCQf8fIeeGFF+699155wAGlCYmKml/QqlQaolgnMlJ0RNslbFgguVpS1u0UV+KaTvggnSdOAwhyPEhWreYoUOToHeDX++kfLsp/KeL6fl4ZqQNBZ968edevX3/99dcrKirMZvMXX3xx9epVfyKHpJb21eYkbW+z9HG1OUpOrWxLpanyVC5uwwEaa9ueRK+hhsVCTXmI6qXcusy2khS6Jj8kLsavVpqaUtKWWZdryyeAoEWJkJ1dqmyqlpJaWVxoF//wU1bRyJMGSF2wblPyuZqy9+hC1L303n83T8/69dpHxVHfkDoQdKKiotavXz9r1qyHHnooNja2t7f3t7/9LQUP1UC+I8eqtWC+rHIMlaxPJQurX+Q3NrsWRQdk9WOvbFyYdhXEG9fHedlRTVXj1hvjC3aZZB8gKFEV8mZJ88K8qnUL5E8yBcYvVkwRbT/xiHKdc3t0Lcuddz9V6GBZjZK14XtT/Nt+EKkDwej+++9PT09fvnz56tWr9Xr95cuX6+rqVqxY8aMf/eh2kUOcah13VLuIuoWfcmBDHPunEq+LFUcFTevuOpakj5Ndz+L0Sce6KMZkFyAIfdpKVchK5yKERdHql2rPqy2l2at++oe/3hJ1D58ls0+b3YaqLqDcaS7ZupVnzoopfkUOQepAUFNV9a677qIGVTxVVewp4WLcJ9daJ27DAcoWfsizbnOrbDEigGjMJYncxOriW824twOjDguM6l8bpmlUA71FhQ/Pi+aS1qTqalvXH2Ke7RyrcwbwebvQTJ3/OPo329eeE18d+fvX8oBvXcXJ2EwnONg+r/POO+989tlnlB/R0dE9PT1iqk2e5JWsdcSdmIwUdodmSWQkW2EQr/MyY+ZW1py6fakji51TsgMwqiVvWrvA7V+H9kn56tWrs7Nfrj1PdVE2takWksf40ZILyclKTdl7l+SQH0K/1rly/ZbpYv+fe/8h+xD0rly5UlZWdvTo0fPnz5vN5gceeOCFF154/vnn9Xq9P8GTWionzUyb6jMsJalULok1A8R5KQFfYL2krLupvtJW1ljLHr/qGD/qIYDAejQp+dxHHw8gFJxQNVNdXV1V9SvDNKqLqqhtuyfE7xhdyNqwdu2GLModfyfmwmeG7f++uOZYANm+5GFBt7lZw7OlA8/x8zo6nW7KlClU69DID37wg1mzZvkOHvFJHcFQWWmIklNtVnlNtjk6dnC+2Whatq+wMieDwkmO292ujqF6SLYAgpSqLlhJofDSVvsq50/KHeuVwdG0i+9tLWlOfnbFFFWdsoLnjlzPdlu4rwNBx+XzOrdu3RJtCp7vf//7voPHVtc4LXTm+IjE8oKvJtjYlTK/IL62JMV+gE+sqWpqRs7tih0qdTzHFUAQmbLiF9Wbpta+zObHmNYkdu9GnfLtx6eL1QR+Vyl2n775Us255E3WpdKTv8dy56U3PxVd30LziTiuRYx3/zb3Adki9v115K47LvuM1mTZt9yRHdfTeAsGyOWJOBaL5Y033pjAXbhw4Yc//GFcnP0Oy82bN3/3u9+dOHFCr9fTvyA5aqVpTZvYsmhCkcOm16j2YZ8S5ZK2tzkuK9Ca8qIMCp2Wopisr7KfQ1VTSq5SYfK8eJqKqt38sJjNAwA/IXU8pk5Xce77yyt4wjTmqukKCxT7Tm+28zydxq8EA+L+zOmvvvqqpaWFAmbevHkzZsyQoyOOJZbZqFQaZN8B1U2FeqcMAwB/IHW81Dru1Y5tg1G2+7WP02DA3FMHAEIV7ut4QkmiqtkK+3SIZi6y7jSa9syalpr3u7rer1GKXmTp4vk0AADwCqnjycnOloVFVeIWzvs1opAhbNvrmp07a5Ss5Xyhm5fTAADAG6SOJyxe8vUqk92ZYC9idMuzlD17El7hQeP9NAAA8AL3dbze14ERg/s6AOEDe4nasdCxLY6GEYTUAQgfmGHjGnNVVdXnJzQgcgAAhhNqHQg891pn69atsuXmtddeky0AGIVQ6wAAwMhBrQOB563WGXRZI54p4PKEaXdaU15K10anZ+TgOTcQ9vieb61J1R42PhgSqHUgqFH8eCPPcKN1l+UWtFo3qHaT10TniB0OxPkC29h6SZnLM6bZ86v5+YTvfG3FB6nvchGA4ERBUr5qlXj456ryT+ToHRvcZZE6EFLY0z9z6/i+bvanTQuW2hwapgKIztlV0Mo2HDVU0p8iRkzyAnYsveoy2/jjqNlzQvmDQuWlMuopb1JK2jLrcsu6MVsAQY2iITu7VNlULSW1ssdMa2LX6sH/9Hq8rDzmE1IHRoHXnMlRT0ybCvUVxngWKS4760RaHyqtnNpdKPJD5hBTat3qwM60qyDeyB44zZLMUJlTaylNlRMOqtg5To1bb4wv2OUeWADBgu+91rwwr2rdAutP74J1tp3Z/MQjihLKHlF3clmkDowCck7NSo56QnGwPlbsYe2h1qETNK17X11rpYFlkkOtE5my22nrcjrNvoW1qb4yaftG91wifA/rbtwchaD1aWvz9KyVch8cid+5ean2vCr21/nrLVH3sOkyf7fb8XRZP4Vm6tQ1HbJ97f/Tn89cGOz2rRAcZI1jJUd98F7rOGxn7Vjr9JnWu3xSy7/dqf3a6BoguKjqgrXVvzZM06hYeYtt8cYGm0tak6qrbd3hE/q1zrWvv2k7bj5x+pzswygkaxwrOeqFqqaWsLqG1TsiUWzkdm3WXa593dexbip6O7zY8b3RNcBokLzJw6I17ZPy1atXZ2e/XHue6iK2G+md734dLjNsx7tOOxZAti95GIKbrHGs5KgX7DYMq2tYvcMTxc5hyRnb3FrUOhZL2/YkOWrnWMSkZOS01u3zHC3+lUQAgfJoUvK5jz4e7HSPumBddXV1VdWvDNOoLqqitrx5cweXxX0dCEYu6SJrHCs56oltsRmLlJxaWeP09bF7Ojm1Prf+TCk9sME5PmQRQ8XTxu1KwfwU23I1vsqaRxKVRHwEIDip6oKVWUrNS1ttt2uofLnzeuVOLovUccS2actt5A9lSy7mN5d5m5MD4iQpt1EMOZxmHxQXc2378xZ+vil4YOrSU/FSmkr/R6WWZNTLGicysj7D4vlDo+ZdKVHzCxTXyTR6ORU4tjs2cRsOWGrjbcVTVH2GDDAqdXIy6N34WQDBaMqKX1Rvmlr7MpsfY1qT2L0bdcq3H58uVhP4tXzAjcfLymM+heazCfyfOstMXSRbDP1u1+e32Daipt/+fMtqvm2b3AXhYffdEOi09I4i67OqWU9hV7C+Qu46Ktvub+HwWsbPNw0pPp457aOy8TjVpnWXpcwvaBUdqnWsSdOUFykXTjsMUsliezYBfyoBf2XS9jYTXzBNl2KPKWBtcb4LPMgAYBDCK3WcM8adY1CIRNjDW9JCFg8n+ShviqRwjAnGU1Q4p47TWzi91u83DS1Bu9OBeLKOUmmQfWe1OUqhvs3nrB0AuAq7GTbz20tcvuQBj+j3PMWyFf+Vn1bBmlVKtuowAeZi4eyHZWswBvmmMPTYIuvSVHlryE1qqVwUBwD+C7vU0T9/wOVLHnCX9syalvyd9ls3/IZKV3Ex+6bb3GwuWtjSeVKelm2Lgsad+UrWclmRdHTy4a73a1p435XTWzQW00X8fFMAgNEJtY6PWietwlzUkc7u4JO9z/BZMd3m2XvFANsEjg9RIdKQkK8Xo+ymjpgG022uKlLEcHZnwkJ2QXeOb7F3tihr/HpTAIBRCfd1IPCwgzVA+Ai7/XXcixtfk2wwIpA6AOEj7FIHghBSByB8oNZBrRN4SB2A8IFaBwIPqQMQPvBEHAAAGDlIHQhBbCeDvCbZ8c7+EE8rvgkCjWkaHRPPXCNiwHpEnmrFzlxS1iT2TnDk8WSHqwq2v4DjX0buxOBZXhPmJ2D0UpT/B41vUKXtOe5iAAAAAElFTkSuQmCC"},986:function(t,s,a){t.exports=a.p+"assets/img/2021-11-22-21-58-38.8b76ff71.png"},987:function(t,s,a){t.exports=a.p+"assets/img/2021-11-23-09-18-51.8050a78a.png"},988:function(t,s,a){t.exports=a.p+"assets/img/2021-11-23-09-37-19.cda26412.png"},989:function(t,s,a){t.exports=a.p+"assets/img/2021-11-23-13-08-41.ece805b3.png"},990:function(t,s,a){t.exports=a.p+"assets/img/2021-12-30-09-28-33.44aea5e1.png"},991:function(t,s,a){t.exports=a.p+"assets/img/2021-12-30-09-43-35.4125cd6a.png"},992:function(t,s,a){t.exports=a.p+"assets/img/2022-01-01-12-20-48.2ac2596f.png"},993:function(t,s,a){t.exports=a.p+"assets/img/2022-01-04-09-26-16.5c7030eb.png"}}]);