(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{1060:function(s,a,t){"use strict";t.r(a);var e=t(1),r=Object(e.a)({},(function(){var s=this,a=s.$createElement,e=s._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h2",{attrs:{id:"kafka-概述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-概述"}},[s._v("#")]),s._v(" Kafka 概述")]),s._v(" "),e("p",[s._v("Kafka 是一个消息队列，是分布式的、基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。")]),s._v(" "),e("p",[s._v("消息队列的两种模式：")]),s._v(" "),e("ol",[e("li",[e("p",[s._v("点对点模式：")]),s._v(" "),e("p",[s._v("一对一模式，消费者主动去拉取数据，消息收到之后清除。")]),s._v(" "),e("p",[e("img",{attrs:{src:t(972),alt:""}})])]),s._v(" "),e("li",[e("p",[s._v("发布订阅模式：")]),s._v(" "),e("p",[s._v("一对多模式，消费者消费数据之后并不会清除数据。")]),s._v(" "),e("p",[s._v("生产者将消息发布到 topic 中，多个消费者消费这个消息。")]),s._v(" "),e("p",[e("img",{attrs:{src:t(973),alt:""}})])])]),s._v(" "),e("p",[e("strong",[s._v("Kafka 基本架构")])]),s._v(" "),e("p",[e("img",{attrs:{src:t(974),alt:""}})]),s._v(" "),e("p",[s._v("上图中描述了 Kafka 的基本架构：")]),s._v(" "),e("ol",[e("li",[e("p",[s._v("Broker")]),s._v(" "),e("p",[s._v("这里有三个 broker，在集群中，每一个 Kafka 服务（一般来说多个服务是在多台机器上的）我们称为 broker。")]),s._v(" "),e("p",[s._v("每一个 broker 都有自己的 ID。")])]),s._v(" "),e("li",[e("p",[s._v("Producer")]),s._v(" "),e("p",[s._v("生产者，用于生产消息放到 kafka 中。")])]),s._v(" "),e("li",[e("p",[s._v("Topic")]),s._v(" "),e("p",[s._v("topic 位于 broker 中，每一个 broker 都包含至少一个 topic。生产者会将消息放到 topic 中。")]),s._v(" "),e("p",[s._v("topic 也是存在分区的概念的，比如 broker1 中放了是 topicA 的 partition0，broker2 放了 topicA 的 partition2。")]),s._v(" "),e("p",[s._v("为了保证数据的可靠性，每一个 topic 的分区都存在副本（replica），比如在 broker1 中，topicA 的 partition0 是 Leader，broker2 中 topicA 的 partition0 是 follower。")]),s._v(" "),e("p",[s._v("注意，每一个 topic 的分区可以存在一个 broker 上，但是副本必须分开到不同的 broker 上，这是为了数据安全考虑。")])]),s._v(" "),e("li",[e("p",[s._v("Consumer")]),s._v(" "),e("p",[s._v("消费者，用于消费数据。消费者是从 topic 中的某个分区中消费的，但是在 leader 可用时，它是面对 topic 的 leader 来消费的。")]),s._v(" "),e("p",[s._v("kafka 中存在消费者组的概念，消费者是没有个人的概念的，即使只有一个 consumer，也是一个消费者组的概念。")]),s._v(" "),e("p",[s._v("在上图架构中，consumerA 和 consumerB 在同一个消费者组中。consumerC 在一个消费者组中。")]),s._v(" "),e("p",[s._v("kafka 消费有一个原则："),e("em",[s._v("一个消费者组中的一个消费者，可以消费同一个主题中的多个分区的数据；但是一个主题中的一个分区的数据只能被一个消费者组中的一个消费者消费")]),s._v("。")]),s._v(" "),e("p",[s._v("以 consumerA、consumerB 这个消费者组为例，当消费 topicA 时，两个消费者可以各自消费一个分区，例如 partition0 交给 A 消费，partition1 交给 B 消费。")]),s._v(" "),e("p",[s._v("但是假如一个主题中有三个分区，那么可以随意分配。假如一个主题中有一个分区，那么只能被一个消费者组中的一个消费者消费。")])])]),s._v(" "),e("h2",{attrs:{id:"kafka-安装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-安装"}},[s._v("#")]),s._v(" Kafka 安装")]),s._v(" "),e("p",[s._v("Hadoop102、Hadoop103、Hadoop104 三台机器分别部署 Zookeeper 和 Kafka。")]),s._v(" "),e("p",[s._v("Kafka 下载"),e("a",{attrs:{href:"http://kafka.apache.org/downloads.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("地址"),e("OutboundLink")],1),s._v("，我们需要 "),e("code",[s._v("kafka_2.11-2.41.tgz")])]),s._v(" "),e("ol",[e("li",[e("p",[s._v("解压到 "),e("code",[s._v("/opt/module")]),s._v("，修改名称为 "),e("code",[s._v("kafka")]),s._v("，配制好环境变量")])]),s._v(" "),e("li",[e("p",[s._v("在 "),e("code",[s._v("/opt/module/kafka")]),s._v(" 下创建文件夹 "),e("code",[s._v("logs")])])]),s._v(" "),e("li",[e("p",[s._v("修改配置文件："),e("code",[s._v("vim conf/server.properties")])]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# broker 的全局唯一编号，不能重复")]),s._v("\nbroker.id"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 删除topic 功能使能,当前版本此配置默认为 true，已从配置文件移除")]),s._v("\ndelete.topic.enable"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 处理网络请求的线程数量")]),s._v("\nnum.network.threads"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用来处理磁盘 IO 的线程数量")]),s._v("\nnum.io.threads"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 发送套接字的缓冲区大小")]),s._v("\nsocket.send.buffer.bytes"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("102400")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 接收套接字的缓冲区大小")]),s._v("\nsocket.receive.buffer.bytes"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("102400")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 请求套接字的缓冲区大小")]),s._v("\nsocket.request.max.bytes"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("104857600")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# kafka 运行日志存放的路径")]),s._v("\nlog.dirs"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/module/kafka/logs\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# topic 在当前 broker 上的分区个数")]),s._v("\nnum.partitions"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用来恢复和清理 data 下数据的线程数量")]),s._v("\nnum.recovery.threads.per.data.dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# segment 文件保留的最长时间，超时将被删除")]),s._v("\nlog.retention.hours"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("168")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 配置连接 Zookeeper 集群地址")]),s._v("\nzookeeper.connect"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("hadoop102:2181,hadoop103:2181,hadoop104:2181\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br"),e("span",{staticClass:"line-number"},[s._v("24")]),e("br")])])]),s._v(" "),e("li",[e("p",[s._v("分发到其他机器："),e("code",[s._v("xsync kafka/")])])]),s._v(" "),e("li",[e("p",[s._v("修改其他机器的配置文件 "),e("code",[s._v("conf/server.properties")]),s._v("，一定要修改 "),e("code",[s._v("broker.id")]),s._v("，可以分别为 "),e("code",[s._v("broker.id=1、broker.id=2")]),s._v(".")])]),s._v(" "),e("li",[e("p",[s._v("启动 kafka 之前，首先要启动 zookeeper 集群")])]),s._v(" "),e("li",[e("p",[s._v("依次在 hadoop102、hadoop103、hadoop104 上启动 kafka："),e("code",[s._v("bin/kafka-server-start.sh -daemon config/server.properties")])])]),s._v(" "),e("li",[e("p",[s._v("关闭 kafka："),e("code",[s._v("bin/kafka-server-stop.sh stop")])])]),s._v(" "),e("li",[e("p",[s._v("kafka 群起脚本：")]),s._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token shebang important"}},[s._v("#!/bin/bash")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$#")]),s._v(" -lt "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("then")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Input Args Error....."')]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("exit")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("fi")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token for-or-select variable"}},[s._v("i")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" hadoop102 hadoop103 hadoop104\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v("\n        start"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('"==================START '),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$i")]),s._v(' KAFKA==================="')]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("ssh")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$i")]),s._v(" /opt/module/kafka_2.11-2.4.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.11-2.4.1/config/server.properties\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        stop"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('"==================STOP '),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$i")]),s._v(' KAFKA==================="')]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("ssh")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$i")]),s._v(" /opt/module/kafka_2.11-2.4.1/bin/kafka-server-stop.sh stop\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        *"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Input Args Error....."')]),s._v("\n            "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("exit")]),s._v("\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("esac")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br")])])])]),s._v(" "),e("h2",{attrs:{id:"命令行操作-kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#命令行操作-kafka"}},[s._v("#")]),s._v(" 命令行操作 Kafka")]),s._v(" "),e("p",[e("strong",[s._v("topic 操作")])]),s._v(" "),e("p",[s._v("所有使用 "),e("code",[s._v("topic")]),s._v(" 的命令都使用 "),e("code",[s._v("bin/kafka-topics.sh")]),s._v(" 来进行操作。")]),s._v(" "),e("p",[s._v("本质上来讲，"),e("code",[s._v("topic")]),s._v(" 只是我们逻辑上的一个概念，实际上在存储的时候是按照分区来存储的。")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("查看 topic 列表："),e("code",[s._v("bin/kafka-topics.sh --list --bootstrap-server hadoop102:9092")])])]),s._v(" "),e("li",[e("p",[s._v("创建名为 first 的 topic："),e("code",[s._v("bin/kafka-topics.sh --create --bootstrap-server hadoop102:9092 --topic first")])])]),s._v(" "),e("li",[e("p",[s._v("带分区和副本创建 topic："),e("code",[s._v("bin/kafka-topics.sh --create --bootstrap-server hadoop102:9092 --topic second --partitions 2 --replication-factor 3")])]),s._v(" "),e("p",[s._v("副本不能随意指定，当前只有三台机器，所以只能有三个副本。")])]),s._v(" "),e("li",[e("p",[s._v("查看 topic 详情："),e("code",[s._v("bin/kafka-topics.sh --describe --bootstrap-server hadoop102:9092 --topic first")])])]),s._v(" "),e("li",[e("p",[s._v("修改 topic："),e("code",[s._v("bin/kafka-topics.sh --alter --bootstrap-server hadoop102:9092 --topic second --partitions 2 --replication-factor 3")])]),s._v(" "),e("p",[s._v("分区数量可以向大的改，不能向小的改，否则会报错。因为可能已经有消费者去消费了数据，记录下了 offset，万一将其他分区的数据放到一个分区，offset 没办法维护。")])]),s._v(" "),e("li",[e("p",[s._v("删除 topic："),e("code",[s._v("bin/kafka-topics.sh --delete --bootstrap-server hadoop102:9092 --topic first")])])])]),s._v(" "),e("p",[e("strong",[s._v("生产者和消费者操作")])]),s._v(" "),e("p",[s._v("生产者使用的是 "),e("code",[s._v("bin/kafka-console-producer.sh")]),s._v(" 命令。消费者使用的是 "),e("code",[s._v("bin/kafka-console-consumer.sh")]),s._v(" 命令，消费者在启动的时候会默认分配一个组。")]),s._v(" "),e("ul",[e("li",[e("p",[s._v("生产者进入到某个 broker 中的某个 topic 中："),e("code",[s._v("bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first")])]),s._v(" "),e("p",[s._v("进入到 broker 中的 topic 中后，就可以生产数据。")]),s._v(" "),e("p",[s._v("生产者生产的数据在逻辑上是放到 topic 中，但是 topic 毕竟只是一个逻辑的概念，所以在物理上是放到了分区中。")])]),s._v(" "),e("li",[e("p",[s._v("消费者进入到某个 broker 中的某个 topic 中："),e("code",[s._v("bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first")])]),s._v(" "),e("p",[s._v("进入到 broker 中的 topic 中，就可以消费数据。")]),s._v(" "),e("p",[s._v("消费者在启动的时候会被默认分配到一个组，如果要将多个消费者放到通过一个组就需要显示指定。")]),s._v(" "),e("p",[s._v("新启动的消费者组中的消费者默认不会消费 topic 中早已经存在的数据，这涉及到一个 offset 重置问题。")]),s._v(" "),e("p",[s._v("如果需要从头消费，需要加上命令 "),e("code",[s._v("--from-beginning")]),s._v(" 表示从头消费。但是注意，这样只能保证消费过程中，分区是有序的，但是哪个分区先消费就不一定了。")])]),s._v(" "),e("li",[e("p",[s._v("消费者组")]),s._v(" "),e("p",[s._v("在 "),e("code",[s._v("config/consumer.properties")]),s._v(" 文件下，有一个配置项 "),e("code",[s._v("group.id=test-consumer-group")])]),s._v(" "),e("p",[s._v("我们在启动消费者的时候，指定这个文件就可以使用这个 "),e("code",[s._v("group.id")]),s._v("，那么消费者就可以放到同一个消费者组中了。")]),s._v(" "),e("p",[e("code",[s._v("bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties")])]),s._v(" "),e("p",[s._v("当消费者的个数发生变化之后（无论是增加还是减少），topic 的分区就会重新规划一次，确保所有分区都会被消费到。")]),s._v(" "),e("p",[s._v("假如我们不想指定配置文件，那也可以直接指定组的名称来确保放到同一个组中：")]),s._v(" "),e("p",[e("code",[s._v("bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --group groupA")])])])])])}),[],!1,null,null,null);a.default=r.exports},972:function(s,a,t){s.exports=t.p+"assets/img/2022-04-17-15-13-44.4d3ab0eb.png"},973:function(s,a,t){s.exports=t.p+"assets/img/2022-04-17-15-14-22.4ccae49f.png"},974:function(s,a,t){s.exports=t.p+"assets/img/2022-04-17-15-18-12.c47c501c.png"}}]);