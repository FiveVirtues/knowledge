(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,i,s=e[0],c=e[1],l=e[2],p=0,d=[];p<s.length;p++)i=s[p],Object.prototype.hasOwnProperty.call(a,i)&&a[i]&&d.push(a[i][0]),a[i]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(n[r]=c[r]);for(u&&u(e);d.length;)d.shift()();return o.push.apply(o,l||[]),t()}function t(){for(var n,e=0;e<o.length;e++){for(var t=o[e],r=!0,s=1;s<t.length;s++){var c=t[s];0!==a[c]&&(r=!1)}r&&(o.splice(e--,1),n=i(i.s=t[0]))}return n}var r={},a={2:0},o=[];function i(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(n){var e=[],t=a[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=a[n]=[e,r]}));e.push(t[2]=r);var o,s=document.createElement("script");s.charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.src=function(n){return i.p+"assets/js/"+({1:"vendors~layout-Blog~layout-Layout~layout-NotFound",3:"layout-Blog",4:"layout-Layout",5:"layout-NotFound",6:"layout-Slide",7:"page--6ce8a11a",8:"page-Concurrent-01-基础",9:"page-Docker-01-基础",10:"page-Docker-02-进阶",11:"page-Flink-01-基础",12:"page-Flink-02-进阶",13:"page-Flink-03-机制",14:"page-Flume",15:"page-Git-01-常用指令",16:"page-HBase-01-起步",17:"page-HBase-02-进阶",18:"page-Hadoop-01-起步",19:"page-Hadoop-02-HDFS",20:"page-Hadoop-03-MapReduce",21:"page-Hadoop-04-Yarn",22:"page-Hive-01-起步",23:"page-Hive-02-DDL",24:"page-Hive-03-DML",25:"page-Hive-04-DQL",26:"page-Hive-05-函数",27:"page-JVM-01-概述",28:"page-JVM-02-类加载子系统",29:"page-JVM-03-运行时数据区",30:"page-Kafka-01-起步",31:"page-Kafka-02-架构和API",32:"page-Kafka-03-组件对接",33:"page-Kubernetes-01-环境搭建",34:"page-Kubernetes-02-操作",35:"page-Linux-01-基础篇",36:"page-Linux-02-实际操作篇",37:"page-Linux-03-安装配置",38:"page-Linux-04-Shell",39:"page-Proxy",40:"page-Spark-01-SparkCore",41:"page-Spark-02-SparkSQL",42:"page-Zookeeper",43:"page-数据结构与算法-01-概述",44:"page-注意事项",45:"page-设计模式-01-介绍",46:"page-设计模式-02-创建者模式",47:"page-设计模式-03-结构型模式",48:"page-设计模式-04-行为型模式",49:"vendors~flowchart",50:"vendors~layout-Layout",51:"vendors~mermaid",52:"vendors~photo-swipe",53:"vendors~reveal"}[n]||n)+"."+{1:"70129eef",3:"65a26112",4:"ae1bffbb",5:"afd3c492",6:"5d36817b",7:"1f6d1c8c",8:"40d9681c",9:"83220b10",10:"52df0704",11:"068f6e0e",12:"a6789756",13:"c3604e6d",14:"578f4bbc",15:"93e85005",16:"7316acb2",17:"11b27c25",18:"f49b25f0",19:"c28c360c",20:"01e7c831",21:"ffaa99bb",22:"c51a8ed6",23:"62ca23de",24:"d3eb8c90",25:"c2e0815a",26:"585851e7",27:"ebc66336",28:"4442a927",29:"947c0cac",30:"246fa824",31:"95741e08",32:"adf6b6fb",33:"ee022329",34:"0263d70c",35:"7a082019",36:"a1a0de05",37:"4afb662a",38:"4bea5dda",39:"4595451b",40:"e1b13d59",41:"0e447d14",42:"d3a8c3a8",43:"da9332d8",44:"97c989bf",45:"2a0d66a1",46:"4c12c25f",47:"af84c495",48:"2a0f6172",49:"f091f770",50:"d74da02a",51:"9c96c271",52:"e4b622ba",53:"80ac799a",54:"7c746378",55:"adda53bb",56:"0f8d034a",57:"830d518c",58:"fcb3cf84",59:"2826e1cb"}[n]+".js"}(n);var c=new Error;o=function(e){s.onerror=s.onload=null,clearTimeout(l);var t=a[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),o=e&&e.target&&e.target.src;c.message="Loading chunk "+n+" failed.\n("+r+": "+o+")",c.name="ChunkLoadError",c.type=r,c.request=o,t[1](c)}a[n]=void 0}};var l=setTimeout((function(){o({type:"timeout",target:s})}),12e4);s.onerror=s.onload=o,document.head.appendChild(s)}return Promise.all(e)},i.m=n,i.c=r,i.d=function(n,e,t){i.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},i.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},i.t=function(n,e){if(1&e&&(n=i(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)i.d(t,r,function(e){return n[e]}.bind(null,r));return t},i.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return i.d(e,"a",e),e},i.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},i.p="/",i.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],c=s.push.bind(s);s.push=e,s=s.slice();for(var l=0;l<s.length;l++)e(s[l]);var u=c;o.push([230,0]),t()}([function(n,e,t){"use strict";
/*!
 * Vue.js v2.6.14
 * (c) 2014-2021 Evan You
 * Released under the MIT License.
 */var r=Object.freeze({});function a(n){return null==n}function o(n){return null!=n}function i(n){return!0===n}function s(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return null!==n&&"object"==typeof n}var l=Object.prototype.toString;function u(n){return"[object Object]"===l.call(n)}function p(n){return"[object RegExp]"===l.call(n)}function d(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function m(n){return o(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function f(n){return null==n?"":Array.isArray(n)||u(n)&&n.toString===l?JSON.stringify(n,null,2):String(n)}function g(n){var e=parseFloat(n);return isNaN(e)?n:e}function h(n,e){for(var t=Object.create(null),r=n.split(","),a=0;a<r.length;a++)t[r[a]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}h("slot,component",!0);var v=h("key,ref,slot,slot-scope,is");function y(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var b=Object.prototype.hasOwnProperty;function S(n,e){return b.call(n,e)}function k(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var x=/-(\w)/g,E=k((function(n){return n.replace(x,(function(n,e){return e?e.toUpperCase():""}))})),T=k((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),w=/\B([A-Z])/g,C=k((function(n){return n.replace(w,"-$1").toLowerCase()}));var D=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function O(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function L(n,e){for(var t in e)n[t]=e[t];return n}function R(n){for(var e={},t=0;t<n.length;t++)n[t]&&L(e,n[t]);return e}function _(n,e,t){}var A=function(n,e,t){return!1},I=function(n){return n};function M(n,e){if(n===e)return!0;var t=c(n),r=c(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var a=Array.isArray(n),o=Array.isArray(e);if(a&&o)return n.length===e.length&&n.every((function(n,t){return M(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(a||o)return!1;var i=Object.keys(n),s=Object.keys(e);return i.length===s.length&&i.every((function(t){return M(n[t],e[t])}))}catch(n){return!1}}function F(n,e){for(var t=0;t<n.length;t++)if(M(n[t],e))return t;return-1}function P(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}var N=["component","directive","filter"],H=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],B={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:A,isReservedAttr:A,isUnknownElement:A,getTagNamespace:_,parsePlatformTagName:I,mustUseProp:A,async:!0,_lifecycleHooks:H},j=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var U=new RegExp("[^"+j.source+".$_\\d]");var W,J="__proto__"in{},V="undefined"!=typeof window,K="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,G=K&&WXEnvironment.platform.toLowerCase(),z=V&&window.navigator.userAgent.toLowerCase(),q=z&&/msie|trident/.test(z),Y=z&&z.indexOf("msie 9.0")>0,Q=z&&z.indexOf("edge/")>0,X=(z&&z.indexOf("android"),z&&/iphone|ipad|ipod|ios/.test(z)||"ios"===G),Z=(z&&/chrome\/\d+/.test(z),z&&/phantomjs/.test(z),z&&z.match(/firefox\/(\d+)/)),nn={}.watch,en=!1;if(V)try{var tn={};Object.defineProperty(tn,"passive",{get:function(){en=!0}}),window.addEventListener("test-passive",null,tn)}catch(n){}var rn=function(){return void 0===W&&(W=!V&&!K&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),W},an=V&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function on(n){return"function"==typeof n&&/native code/.test(n.toString())}var sn,cn="undefined"!=typeof Symbol&&on(Symbol)&&"undefined"!=typeof Reflect&&on(Reflect.ownKeys);sn="undefined"!=typeof Set&&on(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var ln=_,un=0,pn=function(){this.id=un++,this.subs=[]};pn.prototype.addSub=function(n){this.subs.push(n)},pn.prototype.removeSub=function(n){y(this.subs,n)},pn.prototype.depend=function(){pn.target&&pn.target.addDep(this)},pn.prototype.notify=function(){var n=this.subs.slice();for(var e=0,t=n.length;e<t;e++)n[e].update()},pn.target=null;var dn=[];function mn(n){dn.push(n),pn.target=n}function fn(){dn.pop(),pn.target=dn[dn.length-1]}var gn=function(n,e,t,r,a,o,i,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=a,this.ns=void 0,this.context=o,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},hn={child:{configurable:!0}};hn.child.get=function(){return this.componentInstance},Object.defineProperties(gn.prototype,hn);var vn=function(n){void 0===n&&(n="");var e=new gn;return e.text=n,e.isComment=!0,e};function yn(n){return new gn(void 0,void 0,void 0,String(n))}function bn(n){var e=new gn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var Sn=Array.prototype,kn=Object.create(Sn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Sn[n];$(kn,n,(function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];var a,o=e.apply(this,t),i=this.__ob__;switch(n){case"push":case"unshift":a=t;break;case"splice":a=t.slice(2)}return a&&i.observeArray(a),i.dep.notify(),o}))}));var xn=Object.getOwnPropertyNames(kn),En=!0;function Tn(n){En=n}var wn=function(n){this.value=n,this.dep=new pn,this.vmCount=0,$(n,"__ob__",this),Array.isArray(n)?(J?function(n,e){n.__proto__=e}(n,kn):function(n,e,t){for(var r=0,a=t.length;r<a;r++){var o=t[r];$(n,o,e[o])}}(n,kn,xn),this.observeArray(n)):this.walk(n)};function Cn(n,e){var t;if(c(n)&&!(n instanceof gn))return S(n,"__ob__")&&n.__ob__ instanceof wn?t=n.__ob__:En&&!rn()&&(Array.isArray(n)||u(n))&&Object.isExtensible(n)&&!n._isVue&&(t=new wn(n)),e&&t&&t.vmCount++,t}function Dn(n,e,t,r,a){var o=new pn,i=Object.getOwnPropertyDescriptor(n,e);if(!i||!1!==i.configurable){var s=i&&i.get,c=i&&i.set;s&&!c||2!==arguments.length||(t=n[e]);var l=!a&&Cn(t);Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=s?s.call(n):t;return pn.target&&(o.depend(),l&&(l.dep.depend(),Array.isArray(e)&&Rn(e))),e},set:function(e){var r=s?s.call(n):t;e===r||e!=e&&r!=r||s&&!c||(c?c.call(n,e):t=e,l=!a&&Cn(e),o.notify())}})}}function On(n,e,t){if(Array.isArray(n)&&d(e))return n.length=Math.max(n.length,e),n.splice(e,1,t),t;if(e in n&&!(e in Object.prototype))return n[e]=t,t;var r=n.__ob__;return n._isVue||r&&r.vmCount?t:r?(Dn(r.value,e,t),r.dep.notify(),t):(n[e]=t,t)}function Ln(n,e){if(Array.isArray(n)&&d(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||S(n,e)&&(delete n[e],t&&t.dep.notify())}}function Rn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),Array.isArray(e)&&Rn(e)}wn.prototype.walk=function(n){for(var e=Object.keys(n),t=0;t<e.length;t++)Dn(n,e[t])},wn.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Cn(n[e])};var _n=B.optionMergeStrategies;function An(n,e){if(!e)return n;for(var t,r,a,o=cn?Reflect.ownKeys(e):Object.keys(e),i=0;i<o.length;i++)"__ob__"!==(t=o[i])&&(r=n[t],a=e[t],S(n,t)?r!==a&&u(r)&&u(a)&&An(r,a):On(n,t,a));return n}function In(n,e,t){return t?function(){var r="function"==typeof e?e.call(t,t):e,a="function"==typeof n?n.call(t,t):n;return r?An(r,a):a}:e?n?function(){return An("function"==typeof e?e.call(this,this):e,"function"==typeof n?n.call(this,this):n)}:e:n}function Mn(n,e){var t=e?n?n.concat(e):Array.isArray(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Fn(n,e,t,r){var a=Object.create(n||null);return e?L(a,e):a}_n.data=function(n,e,t){return t?In(n,e,t):e&&"function"!=typeof e?n:In(n,e)},H.forEach((function(n){_n[n]=Mn})),N.forEach((function(n){_n[n+"s"]=Fn})),_n.watch=function(n,e,t,r){if(n===nn&&(n=void 0),e===nn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var a={};for(var o in L(a,n),e){var i=a[o],s=e[o];i&&!Array.isArray(i)&&(i=[i]),a[o]=i?i.concat(s):Array.isArray(s)?s:[s]}return a},_n.props=_n.methods=_n.inject=_n.computed=function(n,e,t,r){if(!n)return e;var a=Object.create(null);return L(a,n),e&&L(a,e),a},_n.provide=In;var Pn=function(n,e){return void 0===e?n:e};function Nn(n,e,t){if("function"==typeof e&&(e=e.options),function(n,e){var t=n.props;if(t){var r,a,o={};if(Array.isArray(t))for(r=t.length;r--;)"string"==typeof(a=t[r])&&(o[E(a)]={type:null});else if(u(t))for(var i in t)a=t[i],o[E(i)]=u(a)?a:{type:a};else 0;n.props=o}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(Array.isArray(t))for(var a=0;a<t.length;a++)r[t[a]]={from:t[a]};else if(u(t))for(var o in t){var i=t[o];r[o]=u(i)?L({from:o},i):{from:i}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];"function"==typeof r&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Nn(n,e.extends,t)),e.mixins))for(var r=0,a=e.mixins.length;r<a;r++)n=Nn(n,e.mixins[r],t);var o,i={};for(o in n)s(o);for(o in e)S(n,o)||s(o);function s(r){var a=_n[r]||Pn;i[r]=a(n[r],e[r],t,r)}return i}function Hn(n,e,t,r){if("string"==typeof t){var a=n[e];if(S(a,t))return a[t];var o=E(t);if(S(a,o))return a[o];var i=T(o);return S(a,i)?a[i]:a[t]||a[o]||a[i]}}function Bn(n,e,t,r){var a=e[n],o=!S(t,n),i=t[n],s=Wn(Boolean,a.type);if(s>-1)if(o&&!S(a,"default"))i=!1;else if(""===i||i===C(n)){var c=Wn(String,a.type);(c<0||s<c)&&(i=!0)}if(void 0===i){i=function(n,e,t){if(!S(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return"function"==typeof r&&"Function"!==$n(e.type)?r.call(n):r}(r,a,n);var l=En;Tn(!0),Cn(i),Tn(l)}return i}var jn=/^\s*function (\w+)/;function $n(n){var e=n&&n.toString().match(jn);return e?e[1]:""}function Un(n,e){return $n(n)===$n(e)}function Wn(n,e){if(!Array.isArray(e))return Un(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Un(e[t],n))return t;return-1}function Jn(n,e,t){mn();try{if(e)for(var r=e;r=r.$parent;){var a=r.$options.errorCaptured;if(a)for(var o=0;o<a.length;o++)try{if(!1===a[o].call(r,n,e,t))return}catch(n){Kn(n,r,"errorCaptured hook")}}Kn(n,e,t)}finally{fn()}}function Vn(n,e,t,r,a){var o;try{(o=t?n.apply(e,t):n.call(e))&&!o._isVue&&m(o)&&!o._handled&&(o.catch((function(n){return Jn(n,r,a+" (Promise/async)")})),o._handled=!0)}catch(n){Jn(n,r,a)}return o}function Kn(n,e,t){if(B.errorHandler)try{return B.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Gn(e,null,"config.errorHandler")}Gn(n,e,t)}function Gn(n,e,t){if(!V&&!K||"undefined"==typeof console)throw n;console.error(n)}var zn,qn=!1,Yn=[],Qn=!1;function Xn(){Qn=!1;var n=Yn.slice(0);Yn.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&on(Promise)){var Zn=Promise.resolve();zn=function(){Zn.then(Xn),X&&setTimeout(_)},qn=!0}else if(q||"undefined"==typeof MutationObserver||!on(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())zn="undefined"!=typeof setImmediate&&on(setImmediate)?function(){setImmediate(Xn)}:function(){setTimeout(Xn,0)};else{var ne=1,ee=new MutationObserver(Xn),te=document.createTextNode(String(ne));ee.observe(te,{characterData:!0}),zn=function(){ne=(ne+1)%2,te.data=String(ne)},qn=!0}function re(n,e){var t;if(Yn.push((function(){if(n)try{n.call(e)}catch(n){Jn(n,e,"nextTick")}else t&&t(e)})),Qn||(Qn=!0,zn()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}var ae=new sn;function oe(n){!function n(e,t){var r,a,o=Array.isArray(e);if(!o&&!c(e)||Object.isFrozen(e)||e instanceof gn)return;if(e.__ob__){var i=e.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(o)for(r=e.length;r--;)n(e[r],t);else for(a=Object.keys(e),r=a.length;r--;)n(e[a[r]],t)}(n,ae),ae.clear()}var ie=k((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function se(n,e){function t(){var n=arguments,r=t.fns;if(!Array.isArray(r))return Vn(r,null,arguments,e,"v-on handler");for(var a=r.slice(),o=0;o<a.length;o++)Vn(a[o],null,n,e,"v-on handler")}return t.fns=n,t}function ce(n,e,t,r,o,s){var c,l,u,p;for(c in n)l=n[c],u=e[c],p=ie(c),a(l)||(a(u)?(a(l.fns)&&(l=n[c]=se(l,s)),i(p.once)&&(l=n[c]=o(p.name,l,p.capture)),t(p.name,l,p.capture,p.passive,p.params)):l!==u&&(u.fns=l,n[c]=u));for(c in e)a(n[c])&&r((p=ie(c)).name,e[c],p.capture)}function le(n,e,t){var r;n instanceof gn&&(n=n.data.hook||(n.data.hook={}));var s=n[e];function c(){t.apply(this,arguments),y(r.fns,c)}a(s)?r=se([c]):o(s.fns)&&i(s.merged)?(r=s).fns.push(c):r=se([s,c]),r.merged=!0,n[e]=r}function ue(n,e,t,r,a){if(o(e)){if(S(e,t))return n[t]=e[t],a||delete e[t],!0;if(S(e,r))return n[t]=e[r],a||delete e[r],!0}return!1}function pe(n){return s(n)?[yn(n)]:Array.isArray(n)?function n(e,t){var r,c,l,u,p=[];for(r=0;r<e.length;r++)a(c=e[r])||"boolean"==typeof c||(l=p.length-1,u=p[l],Array.isArray(c)?c.length>0&&(de((c=n(c,(t||"")+"_"+r))[0])&&de(u)&&(p[l]=yn(u.text+c[0].text),c.shift()),p.push.apply(p,c)):s(c)?de(u)?p[l]=yn(u.text+c):""!==c&&p.push(yn(c)):de(c)&&de(u)?p[l]=yn(u.text+c.text):(i(e._isVList)&&o(c.tag)&&a(c.key)&&o(t)&&(c.key="__vlist"+t+"_"+r+"__"),p.push(c)));return p}(n):void 0}function de(n){return o(n)&&o(n.text)&&!1===n.isComment}function me(n,e){if(n){for(var t=Object.create(null),r=cn?Reflect.ownKeys(n):Object.keys(n),a=0;a<r.length;a++){var o=r[a];if("__ob__"!==o){for(var i=n[o].from,s=e;s;){if(s._provided&&S(s._provided,i)){t[o]=s._provided[i];break}s=s.$parent}if(!s)if("default"in n[o]){var c=n[o].default;t[o]="function"==typeof c?c.call(e):c}else 0}}return t}}function fe(n,e){if(!n||!n.length)return{};for(var t={},r=0,a=n.length;r<a;r++){var o=n[r],i=o.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,o.context!==e&&o.fnContext!==e||!i||null==i.slot)(t.default||(t.default=[])).push(o);else{var s=i.slot,c=t[s]||(t[s]=[]);"template"===o.tag?c.push.apply(c,o.children||[]):c.push(o)}}for(var l in t)t[l].every(ge)&&delete t[l];return t}function ge(n){return n.isComment&&!n.asyncFactory||" "===n.text}function he(n){return n.isComment&&n.asyncFactory}function ve(n,e,t){var a,o=Object.keys(e).length>0,i=n?!!n.$stable:!o,s=n&&n.$key;if(n){if(n._normalized)return n._normalized;if(i&&t&&t!==r&&s===t.$key&&!o&&!t.$hasNormal)return t;for(var c in a={},n)n[c]&&"$"!==c[0]&&(a[c]=ye(e,c,n[c]))}else a={};for(var l in e)l in a||(a[l]=be(e,l));return n&&Object.isExtensible(n)&&(n._normalized=a),$(a,"$stable",i),$(a,"$key",s),$(a,"$hasNormal",o),a}function ye(n,e,t){var r=function(){var n=arguments.length?t.apply(null,arguments):t({}),e=(n=n&&"object"==typeof n&&!Array.isArray(n)?[n]:pe(n))&&n[0];return n&&(!e||1===n.length&&e.isComment&&!he(e))?void 0:n};return t.proxy&&Object.defineProperty(n,e,{get:r,enumerable:!0,configurable:!0}),r}function be(n,e){return function(){return n[e]}}function Se(n,e){var t,r,a,i,s;if(Array.isArray(n)||"string"==typeof n)for(t=new Array(n.length),r=0,a=n.length;r<a;r++)t[r]=e(n[r],r);else if("number"==typeof n)for(t=new Array(n),r=0;r<n;r++)t[r]=e(r+1,r);else if(c(n))if(cn&&n[Symbol.iterator]){t=[];for(var l=n[Symbol.iterator](),u=l.next();!u.done;)t.push(e(u.value,t.length)),u=l.next()}else for(i=Object.keys(n),t=new Array(i.length),r=0,a=i.length;r<a;r++)s=i[r],t[r]=e(n[s],s,r);return o(t)||(t=[]),t._isVList=!0,t}function ke(n,e,t,r){var a,o=this.$scopedSlots[n];o?(t=t||{},r&&(t=L(L({},r),t)),a=o(t)||("function"==typeof e?e():e)):a=this.$slots[n]||("function"==typeof e?e():e);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},a):a}function xe(n){return Hn(this.$options,"filters",n)||I}function Ee(n,e){return Array.isArray(n)?-1===n.indexOf(e):n!==e}function Te(n,e,t,r,a){var o=B.keyCodes[e]||t;return a&&r&&!B.keyCodes[e]?Ee(a,r):o?Ee(o,n):r?C(r)!==e:void 0===n}function we(n,e,t,r,a){if(t)if(c(t)){var o;Array.isArray(t)&&(t=R(t));var i=function(i){if("class"===i||"style"===i||v(i))o=n;else{var s=n.attrs&&n.attrs.type;o=r||B.mustUseProp(e,s,i)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var c=E(i),l=C(i);c in o||l in o||(o[i]=t[i],a&&((n.on||(n.on={}))["update:"+i]=function(n){t[i]=n}))};for(var s in t)i(s)}else;return n}function Ce(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||Oe(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,null,this),"__static__"+n,!1),r}function De(n,e,t){return Oe(n,"__once__"+e+(t?"_"+t:""),!0),n}function Oe(n,e,t){if(Array.isArray(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&Le(n[r],e+"_"+r,t);else Le(n,e,t)}function Le(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function Re(n,e){if(e)if(u(e)){var t=n.on=n.on?L({},n.on):{};for(var r in e){var a=t[r],o=e[r];t[r]=a?[].concat(a,o):o}}else;return n}function _e(n,e,t,r){e=e||{$stable:!t};for(var a=0;a<n.length;a++){var o=n[a];Array.isArray(o)?_e(o,e,t):o&&(o.proxy&&(o.fn.proxy=!0),e[o.key]=o.fn)}return r&&(e.$key=r),e}function Ae(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function Ie(n,e){return"string"==typeof n?e+n:n}function Me(n){n._o=De,n._n=g,n._s=f,n._l=Se,n._t=ke,n._q=M,n._i=F,n._m=Ce,n._f=xe,n._k=Te,n._b=we,n._v=yn,n._e=vn,n._u=_e,n._g=Re,n._d=Ae,n._p=Ie}function Fe(n,e,t,a,o){var s,c=this,l=o.options;S(a,"_uid")?(s=Object.create(a))._original=a:(s=a,a=a._original);var u=i(l._compiled),p=!u;this.data=n,this.props=e,this.children=t,this.parent=a,this.listeners=n.on||r,this.injections=me(l.inject,a),this.slots=function(){return c.$slots||ve(n.scopedSlots,c.$slots=fe(t,a)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ve(n.scopedSlots,this.slots())}}),u&&(this.$options=l,this.$slots=this.slots(),this.$scopedSlots=ve(n.scopedSlots,this.$slots)),l._scopeId?this._c=function(n,e,t,r){var o=Ue(s,n,e,t,r,p);return o&&!Array.isArray(o)&&(o.fnScopeId=l._scopeId,o.fnContext=a),o}:this._c=function(n,e,t,r){return Ue(s,n,e,t,r,p)}}function Pe(n,e,t,r,a){var o=bn(n);return o.fnContext=t,o.fnOptions=r,e.slot&&((o.data||(o.data={})).slot=e.slot),o}function Ne(n,e){for(var t in e)n[E(t)]=e[t]}Me(Fe.prototype);var He={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;He.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;o(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Qe)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,a,o){0;var i=a.data.scopedSlots,s=n.$scopedSlots,c=!!(i&&!i.$stable||s!==r&&!s.$stable||i&&n.$scopedSlots.$key!==i.$key||!i&&n.$scopedSlots.$key),l=!!(o||n.$options._renderChildren||c);n.$options._parentVnode=a,n.$vnode=a,n._vnode&&(n._vnode.parent=a);if(n.$options._renderChildren=o,n.$attrs=a.data.attrs||r,n.$listeners=t||r,e&&n.$options.props){Tn(!1);for(var u=n._props,p=n.$options._propKeys||[],d=0;d<p.length;d++){var m=p[d],f=n.$options.props;u[m]=Bn(m,f,e,n)}Tn(!0),n.$options.propsData=e}t=t||r;var g=n.$options._parentListeners;n.$options._parentListeners=t,Ye(n,t,g),l&&(n.$slots=fe(o,a.context),n.$forceUpdate());0}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,et(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,rt.push(e)):nt(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(t&&(e._directInactive=!0,Ze(e)))return;if(!e._inactive){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);et(e,"deactivated")}}(e,!0):e.$destroy())}},Be=Object.keys(He);function je(n,e,t,s,l){if(!a(n)){var u=t.$options._base;if(c(n)&&(n=u.extend(n)),"function"==typeof n){var p;if(a(n.cid)&&void 0===(n=function(n,e){if(i(n.error)&&o(n.errorComp))return n.errorComp;if(o(n.resolved))return n.resolved;var t=Je;t&&o(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t);if(i(n.loading)&&o(n.loadingComp))return n.loadingComp;if(t&&!o(n.owners)){var r=n.owners=[t],s=!0,l=null,u=null;t.$on("hook:destroyed",(function(){return y(r,t)}));var p=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==l&&(clearTimeout(l),l=null),null!==u&&(clearTimeout(u),u=null))},d=P((function(t){n.resolved=Ve(t,e),s?r.length=0:p(!0)})),f=P((function(e){o(n.errorComp)&&(n.error=!0,p(!0))})),g=n(d,f);return c(g)&&(m(g)?a(n.resolved)&&g.then(d,f):m(g.component)&&(g.component.then(d,f),o(g.error)&&(n.errorComp=Ve(g.error,e)),o(g.loading)&&(n.loadingComp=Ve(g.loading,e),0===g.delay?n.loading=!0:l=setTimeout((function(){l=null,a(n.resolved)&&a(n.error)&&(n.loading=!0,p(!1))}),g.delay||200)),o(g.timeout)&&(u=setTimeout((function(){u=null,a(n.resolved)&&f(null)}),g.timeout)))),s=!1,n.loading?n.loadingComp:n.resolved}}(p=n,u)))return function(n,e,t,r,a){var o=vn();return o.asyncFactory=n,o.asyncMeta={data:e,context:t,children:r,tag:a},o}(p,e,t,s,l);e=e||{},Et(n),o(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var a=e.on||(e.on={}),i=a[r],s=e.model.callback;o(i)?(Array.isArray(i)?-1===i.indexOf(s):i!==s)&&(a[r]=[s].concat(i)):a[r]=s}(n.options,e);var d=function(n,e,t){var r=e.options.props;if(!a(r)){var i={},s=n.attrs,c=n.props;if(o(s)||o(c))for(var l in r){var u=C(l);ue(i,c,l,u,!0)||ue(i,s,l,u,!1)}return i}}(e,n);if(i(n.options.functional))return function(n,e,t,a,i){var s=n.options,c={},l=s.props;if(o(l))for(var u in l)c[u]=Bn(u,l,e||r);else o(t.attrs)&&Ne(c,t.attrs),o(t.props)&&Ne(c,t.props);var p=new Fe(t,c,i,a,n),d=s.render.call(null,p._c,p);if(d instanceof gn)return Pe(d,t,p.parent,s,p);if(Array.isArray(d)){for(var m=pe(d)||[],f=new Array(m.length),g=0;g<m.length;g++)f[g]=Pe(m[g],t,p.parent,s,p);return f}}(n,d,e,t,s);var f=e.on;if(e.on=e.nativeOn,i(n.options.abstract)){var g=e.slot;e={},g&&(e.slot=g)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<Be.length;t++){var r=Be[t],a=e[r],o=He[r];a===o||a&&a._merged||(e[r]=a?$e(o,a):o)}}(e);var h=n.options.name||l;return new gn("vue-component-"+n.cid+(h?"-"+h:""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:d,listeners:f,tag:l,children:s},p)}}}function $e(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}function Ue(n,e,t,r,l,u){return(Array.isArray(t)||s(t))&&(l=r,r=t,t=void 0),i(u)&&(l=2),function(n,e,t,r,s){if(o(t)&&o(t.__ob__))return vn();o(t)&&o(t.is)&&(e=t.is);if(!e)return vn();0;Array.isArray(r)&&"function"==typeof r[0]&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===s?r=pe(r):1===s&&(r=function(n){for(var e=0;e<n.length;e++)if(Array.isArray(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var l,u;if("string"==typeof e){var p;u=n.$vnode&&n.$vnode.ns||B.getTagNamespace(e),l=B.isReservedTag(e)?new gn(B.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!o(p=Hn(n.$options,"components",e))?new gn(e,t,r,void 0,void 0,n):je(p,t,n,r,e)}else l=je(e,t,n,r);return Array.isArray(l)?l:o(l)?(o(u)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(o(e.children))for(var s=0,c=e.children.length;s<c;s++){var l=e.children[s];o(l.tag)&&(a(l.ns)||i(r)&&"svg"!==l.tag)&&n(l,t,r)}}(l,u),o(t)&&function(n){c(n.style)&&oe(n.style);c(n.class)&&oe(n.class)}(t),l):vn()}(n,e,t,r,l)}var We,Je=null;function Ve(n,e){return(n.__esModule||cn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),c(n)?e.extend(n):n}function Ke(n){if(Array.isArray(n))for(var e=0;e<n.length;e++){var t=n[e];if(o(t)&&(o(t.componentOptions)||he(t)))return t}}function Ge(n,e){We.$on(n,e)}function ze(n,e){We.$off(n,e)}function qe(n,e){var t=We;return function r(){var a=e.apply(null,arguments);null!==a&&t.$off(n,r)}}function Ye(n,e,t){We=n,ce(e,t||{},Ge,ze,qe,n),We=void 0}var Qe=null;function Xe(n){var e=Qe;return Qe=n,function(){Qe=e}}function Ze(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function nt(n,e){if(e){if(n._directInactive=!1,Ze(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)nt(n.$children[t]);et(n,"activated")}}function et(n,e){mn();var t=n.$options[e],r=e+" hook";if(t)for(var a=0,o=t.length;a<o;a++)Vn(t[a],n,null,n,r);n._hasHookEvent&&n.$emit("hook:"+e),fn()}var tt=[],rt=[],at={},ot=!1,it=!1,st=0;var ct=0,lt=Date.now;if(V&&!q){var ut=window.performance;ut&&"function"==typeof ut.now&&lt()>document.createEvent("Event").timeStamp&&(lt=function(){return ut.now()})}function pt(){var n,e;for(ct=lt(),it=!0,tt.sort((function(n,e){return n.id-e.id})),st=0;st<tt.length;st++)(n=tt[st]).before&&n.before(),e=n.id,at[e]=null,n.run();var t=rt.slice(),r=tt.slice();st=tt.length=rt.length=0,at={},ot=it=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,nt(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r._watcher===t&&r._isMounted&&!r._isDestroyed&&et(r,"updated")}}(r),an&&B.devtools&&an.emit("flush")}var dt=0,mt=function(n,e,t,r,a){this.vm=n,a&&(n._watcher=this),n._watchers.push(this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++dt,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new sn,this.newDepIds=new sn,this.expression="","function"==typeof e?this.getter=e:(this.getter=function(n){if(!U.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=_)),this.value=this.lazy?void 0:this.get()};mt.prototype.get=function(){var n;mn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Jn(n,e,'getter for watcher "'+this.expression+'"')}finally{this.deep&&oe(n),fn(),this.cleanupDeps()}return n},mt.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},mt.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},mt.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(n){var e=n.id;if(null==at[e]){if(at[e]=!0,it){for(var t=tt.length-1;t>st&&tt[t].id>n.id;)t--;tt.splice(t+1,0,n)}else tt.push(n);ot||(ot=!0,re(pt))}}(this)},mt.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||c(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'+this.expression+'"';Vn(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},mt.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},mt.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},mt.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||y(this.vm._watchers,this);for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1}};var ft={enumerable:!0,configurable:!0,get:_,set:_};function gt(n,e,t){ft.get=function(){return this[e][t]},ft.set=function(n){this[e][t]=n},Object.defineProperty(n,t,ft)}function ht(n){n._watchers=[];var e=n.$options;e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props={},a=n.$options._propKeys=[];n.$parent&&Tn(!1);var o=function(o){a.push(o);var i=Bn(o,e,t,n);Dn(r,o,i),o in n||gt(n,"_props",o)};for(var i in e)o(i);Tn(!0)}(n,e.props),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?_:D(e[t],n)}(n,e.methods),e.data?function(n){var e=n.$options.data;u(e=n._data="function"==typeof e?function(n,e){mn();try{return n.call(e,e)}catch(n){return Jn(n,e,"data()"),{}}finally{fn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,a=(n.$options.methods,t.length);for(;a--;){var o=t[a];0,r&&S(r,o)||(i=void 0,36!==(i=(o+"").charCodeAt(0))&&95!==i&&gt(n,"_data",o))}var i;Cn(e,!0)}(n):Cn(n._data={},!0),e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=rn();for(var a in e){var o=e[a],i="function"==typeof o?o:o.get;0,r||(t[a]=new mt(n,i||_,_,vt)),a in n||yt(n,a,o)}}(n,e.computed),e.watch&&e.watch!==nn&&function(n,e){for(var t in e){var r=e[t];if(Array.isArray(r))for(var a=0;a<r.length;a++)kt(n,t,r[a]);else kt(n,t,r)}}(n,e.watch)}var vt={lazy:!0};function yt(n,e,t){var r=!rn();"function"==typeof t?(ft.get=r?bt(e):St(t),ft.set=_):(ft.get=t.get?r&&!1!==t.cache?bt(e):St(t.get):_,ft.set=t.set||_),Object.defineProperty(n,e,ft)}function bt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),pn.target&&e.depend(),e.value}}function St(n){return function(){return n.call(this,this)}}function kt(n,e,t,r){return u(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var xt=0;function Et(n){var e=n.options;if(n.super){var t=Et(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var a in t)t[a]!==r[a]&&(e||(e={}),e[a]=t[a]);return e}(n);r&&L(n.extendOptions,r),(e=n.options=Nn(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Tt(n){this._init(n)}function wt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,a=n._Ctor||(n._Ctor={});if(a[r])return a[r];var o=n.name||t.options.name;var i=function(n){this._init(n)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=e++,i.options=Nn(t.options,n),i.super=t,i.options.props&&function(n){var e=n.options.props;for(var t in e)gt(n.prototype,"_props",t)}(i),i.options.computed&&function(n){var e=n.options.computed;for(var t in e)yt(n.prototype,t,e[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,N.forEach((function(n){i[n]=t[n]})),o&&(i.options.components[o]=i),i.superOptions=t.options,i.extendOptions=n,i.sealedOptions=L({},i.options),a[r]=i,i}}function Ct(n){return n&&(n.Ctor.options.name||n.tag)}function Dt(n,e){return Array.isArray(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!p(n)&&n.test(e)}function Ot(n,e){var t=n.cache,r=n.keys,a=n._vnode;for(var o in t){var i=t[o];if(i){var s=i.name;s&&!e(s)&&Lt(t,o,r,a)}}}function Lt(n,e,t,r){var a=n[e];!a||r&&a.tag===r.tag||a.componentInstance.$destroy(),n[e]=null,y(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=xt++,e._isVue=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var a=r.componentOptions;t.propsData=a.propsData,t._parentListeners=a.listeners,t._renderChildren=a.children,t._componentTag=a.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Nn(Et(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ye(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,a=t&&t.context;n.$slots=fe(e._renderChildren,a),n.$scopedSlots=r,n._c=function(e,t,r,a){return Ue(n,e,t,r,a,!1)},n.$createElement=function(e,t,r,a){return Ue(n,e,t,r,a,!0)};var o=t&&t.data;Dn(n,"$attrs",o&&o.attrs||r,null,!0),Dn(n,"$listeners",e._parentListeners||r,null,!0)}(e),et(e,"beforeCreate"),function(n){var e=me(n.$options.inject,n);e&&(Tn(!1),Object.keys(e).forEach((function(t){Dn(n,t,e[t])})),Tn(!0))}(e),ht(e),function(n){var e=n.$options.provide;e&&(n._provided="function"==typeof e?e.call(n):e)}(e),et(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Tt),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=On,n.prototype.$delete=Ln,n.prototype.$watch=function(n,e,t){if(u(e))return kt(this,n,e,t);(t=t||{}).user=!0;var r=new mt(this,n,e,t);if(t.immediate){var a='callback for immediate watcher "'+r.expression+'"';mn(),Vn(e,this,[r.value],this,a),fn()}return function(){r.teardown()}}}(Tt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(Array.isArray(n))for(var a=0,o=n.length;a<o;a++)r.$on(n[a],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(Array.isArray(n)){for(var r=0,a=n.length;r<a;r++)t.$off(n[r],e);return t}var o,i=t._events[n];if(!i)return t;if(!e)return t._events[n]=null,t;for(var s=i.length;s--;)if((o=i[s])===e||o.fn===e){i.splice(s,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?O(t):t;for(var r=O(arguments,1),a='event handler for "'+n+'"',o=0,i=t.length;o<i;o++)Vn(t[o],e,r,e,a)}return e}}(Tt),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,a=t._vnode,o=Xe(t);t._vnode=n,t.$el=a?t.__patch__(a,n):t.__patch__(t.$el,n,e,!1),o(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){et(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||y(e.$children,n),n._watcher&&n._watcher.teardown();for(var t=n._watchers.length;t--;)n._watchers[t].teardown();n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),et(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Tt),function(n){Me(n.prototype),n.prototype.$nextTick=function(n){return re(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,a=t._parentVnode;a&&(e.$scopedSlots=ve(a.data.scopedSlots,e.$slots,e.$scopedSlots)),e.$vnode=a;try{Je=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){Jn(t,e,"render"),n=e._vnode}finally{Je=null}return Array.isArray(n)&&1===n.length&&(n=n[0]),n instanceof gn||(n=vn()),n.parent=a,n}}(Tt);var Rt=[String,RegExp,Array],_t={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Rt,exclude:Rt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var a=t.tag,o=t.componentInstance,i=t.componentOptions;n[r]={name:Ct(i),tag:a,componentInstance:o},e.push(r),this.max&&e.length>parseInt(this.max)&&Lt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Lt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Ot(n,(function(n){return Dt(e,n)}))})),this.$watch("exclude",(function(e){Ot(n,(function(n){return!Dt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ke(n),t=e&&e.componentOptions;if(t){var r=Ct(t),a=this.include,o=this.exclude;if(a&&(!r||!Dt(a,r))||o&&r&&Dt(o,r))return e;var i=this.cache,s=this.keys,c=null==e.key?t.Ctor.cid+(t.tag?"::"+t.tag:""):e.key;i[c]?(e.componentInstance=i[c].componentInstance,y(s,c),s.push(c)):(this.vnodeToCache=e,this.keyToCache=c),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return B}};Object.defineProperty(n,"config",e),n.util={warn:ln,extend:L,mergeOptions:Nn,defineReactive:Dn},n.set=On,n.delete=Ln,n.nextTick=re,n.observable=function(n){return Cn(n),n},n.options=Object.create(null),N.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,L(n.options.components,_t),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=O(arguments,1);return t.unshift(this),"function"==typeof n.install?n.install.apply(n,t):"function"==typeof n&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Nn(this.options,n),this}}(n),wt(n),function(n){N.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&u(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&"function"==typeof t&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Tt),Object.defineProperty(Tt.prototype,"$isServer",{get:rn}),Object.defineProperty(Tt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Tt,"FunctionalRenderContext",{value:Fe}),Tt.version="2.6.14";var At=h("style,class"),It=h("input,textarea,option,select,progress"),Mt=h("contenteditable,draggable,spellcheck"),Ft=h("events,caret,typing,plaintext-only"),Pt=h("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),Nt="http://www.w3.org/1999/xlink",Ht=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},Bt=function(n){return Ht(n)?n.slice(6,n.length):""},jt=function(n){return null==n||!1===n};function $t(n){for(var e=n.data,t=n,r=n;o(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=Ut(r.data,e));for(;o(t=t.parent);)t&&t.data&&(e=Ut(e,t.data));return function(n,e){if(o(n)||o(e))return Wt(n,Jt(e));return""}(e.staticClass,e.class)}function Ut(n,e){return{staticClass:Wt(n.staticClass,e.staticClass),class:o(n.class)?[n.class,e.class]:e.class}}function Wt(n,e){return n?e?n+" "+e:n:e||""}function Jt(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,a=n.length;r<a;r++)o(e=Jt(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):c(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var Vt={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Kt=h("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Gt=h("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),zt=function(n){return Kt(n)||Gt(n)};var qt=Object.create(null);var Yt=h("text,number,password,search,email,tel,url");var Qt=Object.freeze({createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(Vt[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),Xt={create:function(n,e){Zt(e)},update:function(n,e){n.data.ref!==e.data.ref&&(Zt(n,!0),Zt(e))},destroy:function(n){Zt(n,!0)}};function Zt(n,e){var t=n.data.ref;if(o(t)){var r=n.context,a=n.componentInstance||n.elm,i=r.$refs;e?Array.isArray(i[t])?y(i[t],a):i[t]===a&&(i[t]=void 0):n.data.refInFor?Array.isArray(i[t])?i[t].indexOf(a)<0&&i[t].push(a):i[t]=[a]:i[t]=a}}var nr=new gn("",{},[]),er=["create","activate","update","remove","destroy"];function tr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&o(n.data)===o(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=o(t=n.data)&&o(t=t.attrs)&&t.type,a=o(t=e.data)&&o(t=t.attrs)&&t.type;return r===a||Yt(r)&&Yt(a)}(n,e)||i(n.isAsyncPlaceholder)&&a(e.asyncFactory.error))}function rr(n,e,t){var r,a,i={};for(r=e;r<=t;++r)o(a=n[r].key)&&(i[a]=r);return i}var ar={create:or,update:or,destroy:function(n){or(n,nr)}};function or(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,a,o=n===nr,i=e===nr,s=sr(n.data.directives,n.context),c=sr(e.data.directives,e.context),l=[],u=[];for(t in c)r=s[t],a=c[t],r?(a.oldValue=r.value,a.oldArg=r.arg,lr(a,"update",e,n),a.def&&a.def.componentUpdated&&u.push(a)):(lr(a,"bind",e,n),a.def&&a.def.inserted&&l.push(a));if(l.length){var p=function(){for(var t=0;t<l.length;t++)lr(l[t],"inserted",e,n)};o?le(e,"insert",p):p()}u.length&&le(e,"postpatch",(function(){for(var t=0;t<u.length;t++)lr(u[t],"componentUpdated",e,n)}));if(!o)for(t in s)c[t]||lr(s[t],"unbind",n,n,i)}(n,e)}var ir=Object.create(null);function sr(n,e){var t,r,a=Object.create(null);if(!n)return a;for(t=0;t<n.length;t++)(r=n[t]).modifiers||(r.modifiers=ir),a[cr(r)]=r,r.def=Hn(e.$options,"directives",r.name);return a}function cr(n){return n.rawName||n.name+"."+Object.keys(n.modifiers||{}).join(".")}function lr(n,e,t,r,a){var o=n.def&&n.def[e];if(o)try{o(t.elm,n,t,r,a)}catch(r){Jn(r,t.context,"directive "+n.name+" "+e+" hook")}}var ur=[Xt,ar];function pr(n,e){var t=e.componentOptions;if(!(o(t)&&!1===t.Ctor.options.inheritAttrs||a(n.data.attrs)&&a(e.data.attrs))){var r,i,s=e.elm,c=n.data.attrs||{},l=e.data.attrs||{};for(r in o(l.__ob__)&&(l=e.data.attrs=L({},l)),l)i=l[r],c[r]!==i&&dr(s,r,i,e.data.pre);for(r in(q||Q)&&l.value!==c.value&&dr(s,"value",l.value),c)a(l[r])&&(Ht(r)?s.removeAttributeNS(Nt,Bt(r)):Mt(r)||s.removeAttribute(r))}}function dr(n,e,t,r){r||n.tagName.indexOf("-")>-1?mr(n,e,t):Pt(e)?jt(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):Mt(e)?n.setAttribute(e,function(n,e){return jt(e)||"false"===e?"false":"contenteditable"===n&&Ft(e)?e:"true"}(e,t)):Ht(e)?jt(t)?n.removeAttributeNS(Nt,Bt(e)):n.setAttributeNS(Nt,e,t):mr(n,e,t)}function mr(n,e,t){if(jt(t))n.removeAttribute(e);else{if(q&&!Y&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var fr={create:pr,update:pr};function gr(n,e){var t=e.elm,r=e.data,i=n.data;if(!(a(r.staticClass)&&a(r.class)&&(a(i)||a(i.staticClass)&&a(i.class)))){var s=$t(e),c=t._transitionClasses;o(c)&&(s=Wt(s,Jt(c))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var hr,vr={create:gr,update:gr};function yr(n,e,t){var r=hr;return function a(){var o=e.apply(null,arguments);null!==o&&kr(n,a,t,r)}}var br=qn&&!(Z&&Number(Z[1])<=53);function Sr(n,e,t,r){if(br){var a=ct,o=e;e=o._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=a||n.timeStamp<=0||n.target.ownerDocument!==document)return o.apply(this,arguments)}}hr.addEventListener(n,e,en?{capture:t,passive:r}:t)}function kr(n,e,t,r){(r||hr).removeEventListener(n,e._wrapper||e,t)}function xr(n,e){if(!a(n.data.on)||!a(e.data.on)){var t=e.data.on||{},r=n.data.on||{};hr=e.elm,function(n){if(o(n.__r)){var e=q?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}o(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),ce(t,r,Sr,kr,yr,e.context),hr=void 0}}var Er,Tr={create:xr,update:xr};function wr(n,e){if(!a(n.data.domProps)||!a(e.data.domProps)){var t,r,i=e.elm,s=n.data.domProps||{},c=e.data.domProps||{};for(t in o(c.__ob__)&&(c=e.data.domProps=L({},c)),s)t in c||(i[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===s[t])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===t&&"PROGRESS"!==i.tagName){i._value=r;var l=a(r)?"":String(r);Cr(i,l)&&(i.value=l)}else if("innerHTML"===t&&Gt(i.tagName)&&a(i.innerHTML)){(Er=Er||document.createElement("div")).innerHTML="<svg>"+r+"</svg>";for(var u=Er.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;u.firstChild;)i.appendChild(u.firstChild)}else if(r!==s[t])try{i[t]=r}catch(n){}}}}function Cr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(o(r)){if(r.number)return g(t)!==g(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Dr={create:wr,update:wr},Or=k((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Lr(n){var e=Rr(n.style);return n.staticStyle?L(n.staticStyle,e):e}function Rr(n){return Array.isArray(n)?R(n):"string"==typeof n?Or(n):n}var _r,Ar=/^--/,Ir=/\s*!important$/,Mr=function(n,e,t){if(Ar.test(e))n.style.setProperty(e,t);else if(Ir.test(t))n.style.setProperty(C(e),t.replace(Ir,""),"important");else{var r=Pr(e);if(Array.isArray(t))for(var a=0,o=t.length;a<o;a++)n.style[r]=t[a];else n.style[r]=t}},Fr=["Webkit","Moz","ms"],Pr=k((function(n){if(_r=_r||document.createElement("div").style,"filter"!==(n=E(n))&&n in _r)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<Fr.length;t++){var r=Fr[t]+e;if(r in _r)return r}}));function Nr(n,e){var t=e.data,r=n.data;if(!(a(t.staticStyle)&&a(t.style)&&a(r.staticStyle)&&a(r.style))){var i,s,c=e.elm,l=r.staticStyle,u=r.normalizedStyle||r.style||{},p=l||u,d=Rr(e.data.style)||{};e.data.normalizedStyle=o(d.__ob__)?L({},d):d;var m=function(n,e){var t,r={};if(e)for(var a=n;a.componentInstance;)(a=a.componentInstance._vnode)&&a.data&&(t=Lr(a.data))&&L(r,t);(t=Lr(n.data))&&L(r,t);for(var o=n;o=o.parent;)o.data&&(t=Lr(o.data))&&L(r,t);return r}(e,!0);for(s in p)a(m[s])&&Mr(c,s,"");for(s in m)(i=m[s])!==p[s]&&Mr(c,s,null==i?"":i)}}var Hr={create:Nr,update:Nr},Br=/\s+/;function jr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Br).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" "+(n.getAttribute("class")||"")+" ";t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function $r(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Br).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" "+(n.getAttribute("class")||"")+" ",r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function Ur(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&L(e,Wr(n.name||"v")),L(e,n),e}return"string"==typeof n?Wr(n):void 0}}var Wr=k((function(n){return{enterClass:n+"-enter",enterToClass:n+"-enter-to",enterActiveClass:n+"-enter-active",leaveClass:n+"-leave",leaveToClass:n+"-leave-to",leaveActiveClass:n+"-leave-active"}})),Jr=V&&!Y,Vr="transition",Kr="transitionend",Gr="animation",zr="animationend";Jr&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(Vr="WebkitTransition",Kr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Gr="WebkitAnimation",zr="webkitAnimationEnd"));var qr=V?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function Yr(n){qr((function(){qr(n)}))}function Qr(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),jr(n,e))}function Xr(n,e){n._transitionClasses&&y(n._transitionClasses,e),$r(n,e)}function Zr(n,e,t){var r=ea(n,e),a=r.type,o=r.timeout,i=r.propCount;if(!a)return t();var s="transition"===a?Kr:zr,c=0,l=function(){n.removeEventListener(s,u),t()},u=function(e){e.target===n&&++c>=i&&l()};setTimeout((function(){c<i&&l()}),o+1),n.addEventListener(s,u)}var na=/\b(transform|all)(,|$)/;function ea(n,e){var t,r=window.getComputedStyle(n),a=(r[Vr+"Delay"]||"").split(", "),o=(r[Vr+"Duration"]||"").split(", "),i=ta(a,o),s=(r[Gr+"Delay"]||"").split(", "),c=(r[Gr+"Duration"]||"").split(", "),l=ta(s,c),u=0,p=0;return"transition"===e?i>0&&(t="transition",u=i,p=o.length):"animation"===e?l>0&&(t="animation",u=l,p=c.length):p=(t=(u=Math.max(i,l))>0?i>l?"transition":"animation":null)?"transition"===t?o.length:c.length:0,{type:t,timeout:u,propCount:p,hasTransform:"transition"===t&&na.test(r[Vr+"Property"])}}function ta(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return ra(e)+ra(n[t])})))}function ra(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function aa(n,e){var t=n.elm;o(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=Ur(n.data.transition);if(!a(r)&&!o(t._enterCb)&&1===t.nodeType){for(var i=r.css,s=r.type,l=r.enterClass,u=r.enterToClass,p=r.enterActiveClass,d=r.appearClass,m=r.appearToClass,f=r.appearActiveClass,h=r.beforeEnter,v=r.enter,y=r.afterEnter,b=r.enterCancelled,S=r.beforeAppear,k=r.appear,x=r.afterAppear,E=r.appearCancelled,T=r.duration,w=Qe,C=Qe.$vnode;C&&C.parent;)w=C.context,C=C.parent;var D=!w._isMounted||!n.isRootInsert;if(!D||k||""===k){var O=D&&d?d:l,L=D&&f?f:p,R=D&&m?m:u,_=D&&S||h,A=D&&"function"==typeof k?k:v,I=D&&x||y,M=D&&E||b,F=g(c(T)?T.enter:T);0;var N=!1!==i&&!Y,H=sa(A),B=t._enterCb=P((function(){N&&(Xr(t,R),Xr(t,L)),B.cancelled?(N&&Xr(t,O),M&&M(t)):I&&I(t),t._enterCb=null}));n.data.show||le(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),A&&A(t,B)})),_&&_(t),N&&(Qr(t,O),Qr(t,L),Yr((function(){Xr(t,O),B.cancelled||(Qr(t,R),H||(ia(F)?setTimeout(B,F):Zr(t,s,B)))}))),n.data.show&&(e&&e(),A&&A(t,B)),N||H||B()}}}function oa(n,e){var t=n.elm;o(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=Ur(n.data.transition);if(a(r)||1!==t.nodeType)return e();if(!o(t._leaveCb)){var i=r.css,s=r.type,l=r.leaveClass,u=r.leaveToClass,p=r.leaveActiveClass,d=r.beforeLeave,m=r.leave,f=r.afterLeave,h=r.leaveCancelled,v=r.delayLeave,y=r.duration,b=!1!==i&&!Y,S=sa(m),k=g(c(y)?y.leave:y);0;var x=t._leaveCb=P((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),b&&(Xr(t,u),Xr(t,p)),x.cancelled?(b&&Xr(t,l),h&&h(t)):(e(),f&&f(t)),t._leaveCb=null}));v?v(E):E()}function E(){x.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),d&&d(t),b&&(Qr(t,l),Qr(t,p),Yr((function(){Xr(t,l),x.cancelled||(Qr(t,u),S||(ia(k)?setTimeout(x,k):Zr(t,s,x)))}))),m&&m(t,x),b||S||x())}}function ia(n){return"number"==typeof n&&!isNaN(n)}function sa(n){if(a(n))return!1;var e=n.fns;return o(e)?sa(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function ca(n,e){!0!==e.data.show&&aa(e)}var la=function(n){var e,t,r={},c=n.modules,l=n.nodeOps;for(e=0;e<er.length;++e)for(r[er[e]]=[],t=0;t<c.length;++t)o(c[t][er[e]])&&r[er[e]].push(c[t][er[e]]);function u(n){var e=l.parentNode(n);o(e)&&l.removeChild(e,n)}function p(n,e,t,a,s,c,u){if(o(n.elm)&&o(c)&&(n=c[u]=bn(n)),n.isRootInsert=!s,!function(n,e,t,a){var s=n.data;if(o(s)){var c=o(n.componentInstance)&&s.keepAlive;if(o(s=s.hook)&&o(s=s.init)&&s(n,!1),o(n.componentInstance))return d(n,e),m(t,n.elm,a),i(c)&&function(n,e,t,a){var i,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,o(i=s.data)&&o(i=i.transition)){for(i=0;i<r.activate.length;++i)r.activate[i](nr,s);e.push(s);break}m(t,n.elm,a)}(n,e,t,a),!0}}(n,e,t,a)){var p=n.data,g=n.children,h=n.tag;o(h)?(n.elm=n.ns?l.createElementNS(n.ns,h):l.createElement(h,n),y(n),f(n,g,e),o(p)&&v(n,e),m(t,n.elm,a)):i(n.isComment)?(n.elm=l.createComment(n.text),m(t,n.elm,a)):(n.elm=l.createTextNode(n.text),m(t,n.elm,a))}}function d(n,e){o(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,g(n)?(v(n,e),y(n)):(Zt(n),e.push(n))}function m(n,e,t){o(n)&&(o(t)?l.parentNode(t)===n&&l.insertBefore(n,e,t):l.appendChild(n,e))}function f(n,e,t){if(Array.isArray(e)){0;for(var r=0;r<e.length;++r)p(e[r],t,n.elm,null,!0,e,r)}else s(n.text)&&l.appendChild(n.elm,l.createTextNode(String(n.text)))}function g(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return o(n.tag)}function v(n,t){for(var a=0;a<r.create.length;++a)r.create[a](nr,n);o(e=n.data.hook)&&(o(e.create)&&e.create(nr,n),o(e.insert)&&t.push(n))}function y(n){var e;if(o(e=n.fnScopeId))l.setStyleScope(n.elm,e);else for(var t=n;t;)o(e=t.context)&&o(e=e.$options._scopeId)&&l.setStyleScope(n.elm,e),t=t.parent;o(e=Qe)&&e!==n.context&&e!==n.fnContext&&o(e=e.$options._scopeId)&&l.setStyleScope(n.elm,e)}function b(n,e,t,r,a,o){for(;r<=a;++r)p(t[r],o,n,e,!1,t,r)}function S(n){var e,t,a=n.data;if(o(a))for(o(e=a.hook)&&o(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(o(e=n.children))for(t=0;t<n.children.length;++t)S(n.children[t])}function k(n,e,t){for(;e<=t;++e){var r=n[e];o(r)&&(o(r.tag)?(x(r),S(r)):u(r.elm))}}function x(n,e){if(o(e)||o(n.data)){var t,a=r.remove.length+1;for(o(e)?e.listeners+=a:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,a),o(t=n.componentInstance)&&o(t=t._vnode)&&o(t.data)&&x(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);o(t=n.data.hook)&&o(t=t.remove)?t(n,e):e()}else u(n.elm)}function E(n,e,t,r){for(var a=t;a<r;a++){var i=e[a];if(o(i)&&tr(n,i))return a}}function T(n,e,t,s,c,u){if(n!==e){o(e.elm)&&o(s)&&(e=s[c]=bn(e));var d=e.elm=n.elm;if(i(n.isAsyncPlaceholder))o(e.asyncFactory.resolved)?D(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(i(e.isStatic)&&i(n.isStatic)&&e.key===n.key&&(i(e.isCloned)||i(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,f=e.data;o(f)&&o(m=f.hook)&&o(m=m.prepatch)&&m(n,e);var h=n.children,v=e.children;if(o(f)&&g(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);o(m=f.hook)&&o(m=m.update)&&m(n,e)}a(e.text)?o(h)&&o(v)?h!==v&&function(n,e,t,r,i){var s,c,u,d=0,m=0,f=e.length-1,g=e[0],h=e[f],v=t.length-1,y=t[0],S=t[v],x=!i;for(0;d<=f&&m<=v;)a(g)?g=e[++d]:a(h)?h=e[--f]:tr(g,y)?(T(g,y,r,t,m),g=e[++d],y=t[++m]):tr(h,S)?(T(h,S,r,t,v),h=e[--f],S=t[--v]):tr(g,S)?(T(g,S,r,t,v),x&&l.insertBefore(n,g.elm,l.nextSibling(h.elm)),g=e[++d],S=t[--v]):tr(h,y)?(T(h,y,r,t,m),x&&l.insertBefore(n,h.elm,g.elm),h=e[--f],y=t[++m]):(a(s)&&(s=rr(e,d,f)),a(c=o(y.key)?s[y.key]:E(y,e,d,f))?p(y,r,n,g.elm,!1,t,m):tr(u=e[c],y)?(T(u,y,r,t,m),e[c]=void 0,x&&l.insertBefore(n,u.elm,g.elm)):p(y,r,n,g.elm,!1,t,m),y=t[++m]);d>f?b(n,a(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&k(e,d,f)}(d,h,v,t,u):o(v)?(o(n.text)&&l.setTextContent(d,""),b(d,null,v,0,v.length-1,t)):o(h)?k(h,0,h.length-1):o(n.text)&&l.setTextContent(d,""):n.text!==e.text&&l.setTextContent(d,e.text),o(f)&&o(m=f.hook)&&o(m=m.postpatch)&&m(n,e)}}}function w(n,e,t){if(i(t)&&o(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var C=h("attrs,class,staticClass,staticStyle,key");function D(n,e,t,r){var a,s=e.tag,c=e.data,l=e.children;if(r=r||c&&c.pre,e.elm=n,i(e.isComment)&&o(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(o(c)&&(o(a=c.hook)&&o(a=a.init)&&a(e,!0),o(a=e.componentInstance)))return d(e,t),!0;if(o(s)){if(o(l))if(n.hasChildNodes())if(o(a=c)&&o(a=a.domProps)&&o(a=a.innerHTML)){if(a!==n.innerHTML)return!1}else{for(var u=!0,p=n.firstChild,m=0;m<l.length;m++){if(!p||!D(p,l[m],t,r)){u=!1;break}p=p.nextSibling}if(!u||p)return!1}else f(e,l,t);if(o(c)){var g=!1;for(var h in c)if(!C(h)){g=!0,v(e,t);break}!g&&c.class&&oe(c.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,s){if(!a(e)){var c,u=!1,d=[];if(a(n))u=!0,p(e,d);else{var m=o(n.nodeType);if(!m&&tr(n,e))T(n,e,d,null,null,s);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),i(t)&&D(n,e,d))return w(e,d,!0),n;c=n,n=new gn(l.tagName(c).toLowerCase(),{},[],void 0,c)}var f=n.elm,h=l.parentNode(f);if(p(e,d,f._leaveCb?null:h,l.nextSibling(f)),o(e.parent))for(var v=e.parent,y=g(e);v;){for(var b=0;b<r.destroy.length;++b)r.destroy[b](v);if(v.elm=e.elm,y){for(var x=0;x<r.create.length;++x)r.create[x](nr,v);var E=v.data.hook.insert;if(E.merged)for(var C=1;C<E.fns.length;C++)E.fns[C]()}else Zt(v);v=v.parent}o(h)?k([n],0,0):o(n.tag)&&S(n)}}return w(e,d,u),e.elm}o(n)&&S(n)}}({nodeOps:Qt,modules:[fr,vr,Tr,Dr,Hr,V?{create:ca,activate:ca,remove:function(n,e){!0!==n.data.show?oa(n,e):e()}}:{}].concat(ur)});Y&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&va(n,"input")}));var ua={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?le(t,"postpatch",(function(){ua.componentUpdated(n,e,t)})):pa(n,e,t.context),n._vOptions=[].map.call(n.options,fa)):("textarea"===t.tag||Yt(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",ga),n.addEventListener("compositionend",ha),n.addEventListener("change",ha),Y&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){pa(n,e,t.context);var r=n._vOptions,a=n._vOptions=[].map.call(n.options,fa);if(a.some((function(n,e){return!M(n,r[e])})))(n.multiple?e.value.some((function(n){return ma(n,a)})):e.value!==e.oldValue&&ma(e.value,a))&&va(n,"change")}}};function pa(n,e,t){da(n,e,t),(q||Q)&&setTimeout((function(){da(n,e,t)}),0)}function da(n,e,t){var r=e.value,a=n.multiple;if(!a||Array.isArray(r)){for(var o,i,s=0,c=n.options.length;s<c;s++)if(i=n.options[s],a)o=F(r,fa(i))>-1,i.selected!==o&&(i.selected=o);else if(M(fa(i),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));a||(n.selectedIndex=-1)}}function ma(n,e){return e.every((function(e){return!M(e,n)}))}function fa(n){return"_value"in n?n._value:n.value}function ga(n){n.target.composing=!0}function ha(n){n.target.composing&&(n.target.composing=!1,va(n.target,"input"))}function va(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function ya(n){return!n.componentInstance||n.data&&n.data.transition?n:ya(n.componentInstance._vnode)}var ba={model:ua,show:{bind:function(n,e,t){var r=e.value,a=(t=ya(t)).data&&t.data.transition,o=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&a?(t.data.show=!0,aa(t,(function(){n.style.display=o}))):n.style.display=r?o:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=ya(t)).data&&t.data.transition?(t.data.show=!0,r?aa(t,(function(){n.style.display=n.__vOriginalDisplay})):oa(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,a){a||(n.style.display=n.__vOriginalDisplay)}}},Sa={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function ka(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?ka(Ke(e.children)):n}function xa(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var a=t._parentListeners;for(var o in a)e[E(o)]=a[o];return e}function Ea(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Ta=function(n){return n.tag||he(n)},wa=function(n){return"show"===n.name},Ca={name:"transition",props:Sa,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Ta)).length){0;var r=this.mode;0;var a=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return a;var o=ka(a);if(!o)return a;if(this._leaving)return Ea(n,a);var i="__transition-"+this._uid+"-";o.key=null==o.key?o.isComment?i+"comment":i+o.tag:s(o.key)?0===String(o.key).indexOf(i)?o.key:i+o.key:o.key;var c=(o.data||(o.data={})).transition=xa(this),l=this._vnode,u=ka(l);if(o.data.directives&&o.data.directives.some(wa)&&(o.data.show=!0),u&&u.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(o,u)&&!he(u)&&(!u.componentInstance||!u.componentInstance._vnode.isComment)){var p=u.data.transition=L({},c);if("out-in"===r)return this._leaving=!0,le(p,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Ea(n,a);if("in-out"===r){if(he(o))return l;var d,m=function(){d()};le(c,"afterEnter",m),le(c,"enterCancelled",m),le(p,"delayLeave",(function(n){d=n}))}}return a}}},Da=L({tag:String,moveClass:String},Sa);function Oa(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function La(n){n.data.newPos=n.elm.getBoundingClientRect()}function Ra(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,a=e.top-t.top;if(r||a){n.data.moved=!0;var o=n.elm.style;o.transform=o.WebkitTransform="translate("+r+"px,"+a+"px)",o.transitionDuration="0s"}}delete Da.mode;var _a={Transition:Ca,TransitionGroup:{props:Da,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var a=Xe(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,a(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,a=this.$slots.default||[],o=this.children=[],i=xa(this),s=0;s<a.length;s++){var c=a[s];if(c.tag)if(null!=c.key&&0!==String(c.key).indexOf("__vlist"))o.push(c),t[c.key]=c,(c.data||(c.data={})).transition=i;else;}if(r){for(var l=[],u=[],p=0;p<r.length;p++){var d=r[p];d.data.transition=i,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):u.push(d)}this.kept=n(e,null,l),this.removed=u}return n(e,null,o)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Oa),n.forEach(La),n.forEach(Ra),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;Qr(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(Kr,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(Kr,n),t._moveCb=null,Xr(t,e))})}})))},methods:{hasMove:function(n,e){if(!Jr)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){$r(t,n)})),jr(t,e),t.style.display="none",this.$el.appendChild(t);var r=ea(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};Tt.config.mustUseProp=function(n,e,t){return"value"===t&&It(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Tt.config.isReservedTag=zt,Tt.config.isReservedAttr=At,Tt.config.getTagNamespace=function(n){return Gt(n)?"svg":"math"===n?"math":void 0},Tt.config.isUnknownElement=function(n){if(!V)return!0;if(zt(n))return!1;if(n=n.toLowerCase(),null!=qt[n])return qt[n];var e=document.createElement(n);return n.indexOf("-")>-1?qt[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:qt[n]=/HTMLUnknownElement/.test(e.toString())},L(Tt.options.directives,ba),L(Tt.options.components,_a),Tt.prototype.__patch__=V?la:_,Tt.prototype.$mount=function(n,e){return function(n,e,t){var r;return n.$el=e,n.$options.render||(n.$options.render=vn),et(n,"beforeMount"),r=function(){n._update(n._render(),t)},new mt(n,r,_,{before:function(){n._isMounted&&!n._isDestroyed&&et(n,"beforeUpdate")}},!0),t=!1,null==n.$vnode&&(n._isMounted=!0,et(n,"mounted")),n}(this,n=n&&V?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},V&&setTimeout((function(){B.devtools&&an&&an.emit("init",Tt)}),0),e.a=Tt},function(n,e,t){"use strict";function r(n,e,t,r,a,o,i,s){var c,l="function"==typeof n?n.options:n;if(e&&(l.render=e,l.staticRenderFns=t,l._compiled=!0),r&&(l.functional=!0),o&&(l._scopeId="data-v-"+o),i?(c=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),a&&a.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(i)},l._ssrRegister=c):a&&(c=s?function(){a.call(this,(l.functional?this.parent:this).$root.$options.shadowRoot)}:a),c)if(l.functional){l._injectStyles=c;var u=l.render;l.render=function(n,e){return c.call(e),u(n,e)}}else{var p=l.beforeCreate;l.beforeCreate=p?[].concat(p,c):[c]}return{exports:n,options:l}}t.d(e,"a",(function(){return r}))},function(n,e,t){var r=t(4),a=t(37).f,o=t(23),i=t(17),s=t(98),c=t(151),l=t(69);n.exports=function(n,e){var t,u,p,d,m,f=n.target,g=n.global,h=n.stat;if(t=g?r:h?r[f]||s(f,{}):(r[f]||{}).prototype)for(u in e){if(d=e[u],p=n.noTargetGet?(m=a(t,u))&&m.value:t[u],!l(g?u:f+(h?".":"#")+u,n.forced)&&void 0!==p){if(typeof d==typeof p)continue;c(d,p)}(n.sham||p&&p.sham)&&o(d,"sham",!0),i(t,u,d,n)}}},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e,t){var r=t(4),a=t(71),o=t(14),i=t(72),s=t(99),c=t(145),l=a("wks"),u=r.Symbol,p=c?u:u&&u.withoutSetter||i;n.exports=function(n){return o(l,n)&&(s||"string"==typeof l[n])||(s&&o(u,n)?l[n]=u[n]:l[n]=p("Symbol."+n)),l[n]}},function(n,e,t){var r=t(109),a=t(17),o=t(245);r||a(Object.prototype,"toString",o,{unsafe:!0})},function(n,e){n.exports=function(n){return"object"==typeof n?null!==n:"function"==typeof n}},function(n,e,t){"use strict";var r=t(165).charAt,a=t(16),o=t(39),i=t(104),s=o.set,c=o.getterFor("String Iterator");i(String,"String",(function(n){s(this,{type:"String Iterator",string:a(n),index:0})}),(function(){var n,e=c(this),t=e.string,a=e.index;return a>=t.length?{value:void 0,done:!0}:(n=r(t,a),e.index+=n.length,{value:n,done:!1})}))},function(n,e,t){var r=t(4),a=t(166),o=t(143),i=t(23),s=t(5),c=s("iterator"),l=s("toStringTag"),u=o.values;for(var p in a){var d=r[p],m=d&&d.prototype;if(m){if(m[c]!==u)try{i(m,c,u)}catch(n){m[c]=u}if(m[l]||i(m,l,p),a[p])for(var f in o)if(m[f]!==o[f])try{i(m,f,o[f])}catch(n){m[f]=o[f]}}}},function(n,e,t){var r=t(7);n.exports=function(n){if(!r(n))throw TypeError(String(n)+" is not an object");return n}},function(n,e,t){"use strict";t.d(e,"a",(function(){return i}));t(66);var r=t(63);var a=t(86),o=t(46);function i(n){return function(n){if(Array.isArray(n))return Object(r.a)(n)}(n)||Object(a.a)(n)||Object(o.a)(n)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(n,e,t){var r=t(3);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var r=t(12),a=t(146),o=t(10),i=t(73),s=Object.defineProperty;e.f=r?s:function(n,e,t){if(o(n),e=i(e),o(t),a)try{return s(n,e,t)}catch(n){}if("get"in t||"set"in t)throw TypeError("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(18),a={}.hasOwnProperty;n.exports=Object.hasOwn||function(n,e){return a.call(r(n),e)}},function(n,e,t){"use strict";t.d(e,"a",(function(){return i}));var r=t(87);t(49),t(50),t(6),t(67),t(8),t(9);var a=t(46),o=t(88);function i(n,e){return Object(r.a)(n)||function(n,e){var t=null==n?null:"undefined"!=typeof Symbol&&n[Symbol.iterator]||n["@@iterator"];if(null!=t){var r,a,o=[],i=!0,s=!1;try{for(t=t.call(n);!(i=(r=t.next()).done)&&(o.push(r.value),!e||o.length!==e);i=!0);}catch(n){s=!0,a=n}finally{try{i||null==t.return||t.return()}finally{if(s)throw a}}return o}}(n,e)||Object(a.a)(n,e)||Object(o.a)()}},function(n,e,t){var r=t(55);n.exports=function(n){if(r(n))throw TypeError("Cannot convert a Symbol value to a string");return String(n)}},function(n,e,t){var r=t(4),a=t(23),o=t(14),i=t(98),s=t(103),c=t(39),l=c.get,u=c.enforce,p=String(String).split("String");(n.exports=function(n,e,t,s){var c,l=!!s&&!!s.unsafe,d=!!s&&!!s.enumerable,m=!!s&&!!s.noTargetGet;"function"==typeof t&&("string"!=typeof e||o(t,"name")||a(t,"name",e),(c=u(t)).source||(c.source=p.join("string"==typeof e?e:""))),n!==r?(l?!m&&n[e]&&(d=!0):delete n[e],d?n[e]=t:a(n,e,t)):d?n[e]=t:i(e,t)})(Function.prototype,"toString",(function(){return"function"==typeof this&&l(this).source||s(this)}))},function(n,e,t){var r=t(30);n.exports=function(n){return Object(r(n))}},function(n,e,t){var r=t(68),a=Math.min;n.exports=function(n){return n>0?a(r(n),9007199254740991):0}},function(n,e,t){"use strict";var r=t(2),a=t(80);r({target:"RegExp",proto:!0,forced:/./.exec!==a},{exec:a})},function(n,e,t){"use strict";var r=t(2),a=t(170);r({target:"Array",proto:!0,forced:[].forEach!=a},{forEach:a})},function(n,e,t){var r=t(54),a=t(30);n.exports=function(n){return r(a(n))}},function(n,e,t){var r=t(12),a=t(13),o=t(58);n.exports=r?function(n,e,t){return a.f(n,e,o(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(4),a=function(n){return"function"==typeof n?n:void 0};n.exports=function(n,e){return arguments.length<2?a(r[n]):r[n]&&r[n][e]}},function(n,e,t){var r=t(177),a="object"==typeof self&&self&&self.Object===Object&&self,o=r||a||Function("return this")();n.exports=o},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){"use strict";var r=t(2),a=t(44).map;r({target:"Array",proto:!0,forced:!t(79)("map")},{map:function(n){return a(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(2),a=t(44).filter;r({target:"Array",proto:!0,forced:!t(79)("filter")},{filter:function(n){return a(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(4),a=t(166),o=t(170),i=t(23);for(var s in a){var c=r[s],l=c&&c.prototype;if(l&&l.forEach!==o)try{i(l,"forEach",o)}catch(n){l.forEach=o}}},function(n,e){n.exports=function(n){if(null==n)throw TypeError("Can't call method on "+n);return n}},function(n,e,t){var r=t(2),a=t(4),o=t(32),i=[].slice,s=function(n){return function(e,t){var r=arguments.length>2,a=r?i.call(arguments,2):void 0;return n(r?function(){("function"==typeof e?e:Function(e)).apply(this,a)}:e,t)}};r({global:!0,bind:!0,forced:/MSIE .\./.test(o)},{setTimeout:s(a.setTimeout),setInterval:s(a.setInterval)})},function(n,e,t){var r=t(24);n.exports=r("navigator","userAgent")||""},function(n,e,t){var r,a=t(10),o=t(222),i=t(102),s=t(56),c=t(150),l=t(100),u=t(75),p=u("IE_PROTO"),d=function(){},m=function(n){return"<script>"+n+"<\/script>"},f=function(n){n.write(m("")),n.close();var e=n.parentWindow.Object;return n=null,e},g=function(){try{r=new ActiveXObject("htmlfile")}catch(n){}g=document.domain&&r?f(r):function(){var n,e=l("iframe");if(e.style)return e.style.display="none",c.appendChild(e),e.src=String("javascript:"),(n=e.contentWindow.document).open(),n.write(m("document.F=Object")),n.close(),n.F}()||f(r);for(var n=i.length;n--;)delete g.prototype[i[n]];return g()};s[p]=!0,n.exports=Object.create||function(n,e){var t;return null!==n?(d.prototype=a(n),t=new d,d.prototype=null,t[p]=n):t=g(),void 0===e?t:o(t,e)}},function(n,e){n.exports=function(n){if("function"!=typeof n)throw TypeError(String(n)+" is not a function");return n}},function(n,e,t){"use strict";var r=t(130),a=t(3),o=t(10),i=t(68),s=t(19),c=t(16),l=t(30),u=t(139),p=t(252),d=t(131),m=t(5)("replace"),f=Math.max,g=Math.min,h="$0"==="a".replace(/./,"$0"),v=!!/./[m]&&""===/./[m]("a","$0");r("replace",(function(n,e,t){var r=v?"$":"$0";return[function(n,t){var r=l(this),a=null==n?void 0:n[m];return void 0!==a?a.call(n,r,t):e.call(c(r),n,t)},function(n,a){var l=o(this),m=c(n);if("string"==typeof a&&-1===a.indexOf(r)&&-1===a.indexOf("$<")){var h=t(e,l,m,a);if(h.done)return h.value}var v="function"==typeof a;v||(a=c(a));var y=l.global;if(y){var b=l.unicode;l.lastIndex=0}for(var S=[];;){var k=d(l,m);if(null===k)break;if(S.push(k),!y)break;""===c(k[0])&&(l.lastIndex=u(m,s(l.lastIndex),b))}for(var x,E="",T=0,w=0;w<S.length;w++){k=S[w];for(var C=c(k[0]),D=f(g(i(k.index),m.length),0),O=[],L=1;L<k.length;L++)O.push(void 0===(x=k[L])?x:String(x));var R=k.groups;if(v){var _=[C].concat(O,D,m);void 0!==R&&_.push(R);var A=c(a.apply(void 0,_))}else A=p(C,m,D,O,R,a);D>=T&&(E+=m.slice(T,D)+A,T=D+C.length)}return E+m.slice(T)}]}),!!a((function(){var n=/./;return n.exec=function(){var n=[];return n.groups={a:"7"},n},"7"!=="".replace(n,"$<a>")}))||!h||v)},function(n,e,t){"use strict";var r=t(2),a=t(7),o=t(53),i=t(149),s=t(19),c=t(22),l=t(70),u=t(5),p=t(79)("slice"),d=u("species"),m=[].slice,f=Math.max;r({target:"Array",proto:!0,forced:!p},{slice:function(n,e){var t,r,u,p=c(this),g=s(p.length),h=i(n,g),v=i(void 0===e?g:e,g);if(o(p)&&("function"!=typeof(t=p.constructor)||t!==Array&&!o(t.prototype)?a(t)&&null===(t=t[d])&&(t=void 0):t=void 0,t===Array||void 0===t))return m.call(p,h,v);for(r=new(void 0===t?Array:t)(f(v-h,0)),u=0;h<v;h++,u++)h in p&&l(r,u,p[h]);return r.length=u,r}})},function(n,e,t){var r=t(12),a=t(105),o=t(58),i=t(22),s=t(73),c=t(14),l=t(146),u=Object.getOwnPropertyDescriptor;e.f=r?u:function(n,e){if(n=i(n),e=s(e),l)try{return u(n,e)}catch(n){}if(c(n,e))return o(!a.f.call(n,e),n[e])}},function(n,e){n.exports=!1},function(n,e,t){var r,a,o,i=t(232),s=t(4),c=t(7),l=t(23),u=t(14),p=t(97),d=t(75),m=t(56),f=s.WeakMap;if(i||p.state){var g=p.state||(p.state=new f),h=g.get,v=g.has,y=g.set;r=function(n,e){if(v.call(g,n))throw new TypeError("Object already initialized");return e.facade=n,y.call(g,n,e),e},a=function(n){return h.call(g,n)||{}},o=function(n){return v.call(g,n)}}else{var b=d("state");m[b]=!0,r=function(n,e){if(u(n,b))throw new TypeError("Object already initialized");return e.facade=n,l(n,b,e),e},a=function(n){return u(n,b)?n[b]:{}},o=function(n){return u(n,b)}}n.exports={set:r,get:a,has:o,enforce:function(n){return o(n)?a(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!c(e)||(t=a(e)).type!==n)throw TypeError("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){throw 1},1)}))}},function(n,e){var t={}.toString;n.exports=function(n){return t.call(n).slice(8,-1)}},function(n,e,t){var r=t(271),a=t(274);n.exports=function(n,e){var t=a(n,e);return r(t)?t:void 0}},function(n,e,t){var r,a,o=t(4),i=t(32),s=o.process,c=o.Deno,l=s&&s.versions||c&&c.version,u=l&&l.v8;u?a=(r=u.split("."))[0]<4?1:r[0]+r[1]:i&&(!(r=i.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=i.match(/Chrome\/(\d+)/))&&(a=r[1]),n.exports=a&&+a},function(n,e,t){var r=t(60),a=t(54),o=t(18),i=t(19),s=t(167),c=[].push,l=function(n){var e=1==n,t=2==n,l=3==n,u=4==n,p=6==n,d=7==n,m=5==n||p;return function(f,g,h,v){for(var y,b,S=o(f),k=a(S),x=r(g,h,3),E=i(k.length),T=0,w=v||s,C=e?w(f,E):t||d?w(f,0):void 0;E>T;T++)if((m||T in k)&&(b=x(y=k[T],T,S),n))if(e)C[T]=b;else if(b)switch(n){case 3:return!0;case 5:return y;case 6:return T;case 2:c.call(C,y)}else switch(n){case 4:return!1;case 7:c.call(C,y)}return p?-1:l||u?u:C}};n.exports={forEach:l(0),map:l(1),filter:l(2),some:l(3),every:l(4),find:l(5),findIndex:l(6),filterReject:l(7)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){"use strict";t.d(e,"a",(function(){return a}));t(36),t(6),t(94),t(51),t(8);var r=t(63);function a(n,e){if(n){if("string"==typeof n)return Object(r.a)(n,e);var t=Object.prototype.toString.call(n).slice(8,-1);return"Object"===t&&n.constructor&&(t=n.constructor.name),"Map"===t||"Set"===t?Array.from(n):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?Object(r.a)(n,e):void 0}}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,a=/^0b[01]+$/i,o=/^0o[0-7]+$/i,i=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,c="object"==typeof self&&self&&self.Object===Object&&self,l=s||c||Function("return this")(),u=Object.prototype.toString,p=Math.max,d=Math.min,m=function(){return l.Date.now()};function f(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function g(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==u.call(n)}(n))return NaN;if(f(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=f(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=a.test(n);return s||o.test(n)?i(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,a,o,i,s,c,l=0,u=!1,h=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function y(e){var t=r,o=a;return r=a=void 0,l=e,i=n.apply(o,t)}function b(n){return l=n,s=setTimeout(k,e),u?y(n):i}function S(n){var t=n-c;return void 0===c||t>=e||t<0||h&&n-l>=o}function k(){var n=m();if(S(n))return x(n);s=setTimeout(k,function(n){var t=e-(n-c);return h?d(t,o-(n-l)):t}(n))}function x(n){return s=void 0,v&&r?y(n):(r=a=void 0,i)}function E(){var n=m(),t=S(n);if(r=arguments,a=this,c=n,t){if(void 0===s)return b(c);if(h)return s=setTimeout(k,e),y(c)}return void 0===s&&(s=setTimeout(k,e)),i}return e=g(e)||0,f(t)&&(u=!!t.leading,o=(h="maxWait"in t)?p(g(t.maxWait)||0,e):o,v="trailing"in t?!!t.trailing:v),E.cancel=function(){void 0!==s&&clearTimeout(s),l=0,r=c=a=s=void 0},E.flush=function(){return void 0===s?i:x(m())},E}},function(n,e,t){var r=t(2),a=t(18),o=t(74);r({target:"Object",stat:!0,forced:t(3)((function(){o(1)}))},{keys:function(n){return o(a(n))}})},function(n,e,t){"use strict";var r=t(2),a=t(4),o=t(24),i=t(38),s=t(12),c=t(99),l=t(3),u=t(14),p=t(53),d=t(7),m=t(55),f=t(10),g=t(18),h=t(22),v=t(73),y=t(16),b=t(58),S=t(33),k=t(74),x=t(52),E=t(172),T=t(106),w=t(37),C=t(13),D=t(105),O=t(23),L=t(17),R=t(71),_=t(75),A=t(56),I=t(72),M=t(5),F=t(173),P=t(174),N=t(59),H=t(39),B=t(44).forEach,j=_("hidden"),$=M("toPrimitive"),U=H.set,W=H.getterFor("Symbol"),J=Object.prototype,V=a.Symbol,K=o("JSON","stringify"),G=w.f,z=C.f,q=E.f,Y=D.f,Q=R("symbols"),X=R("op-symbols"),Z=R("string-to-symbol-registry"),nn=R("symbol-to-string-registry"),en=R("wks"),tn=a.QObject,rn=!tn||!tn.prototype||!tn.prototype.findChild,an=s&&l((function(){return 7!=S(z({},"a",{get:function(){return z(this,"a",{value:7}).a}})).a}))?function(n,e,t){var r=G(J,e);r&&delete J[e],z(n,e,t),r&&n!==J&&z(J,e,r)}:z,on=function(n,e){var t=Q[n]=S(V.prototype);return U(t,{type:"Symbol",tag:n,description:e}),s||(t.description=e),t},sn=function(n,e,t){n===J&&sn(X,e,t),f(n);var r=v(e);return f(t),u(Q,r)?(t.enumerable?(u(n,j)&&n[j][r]&&(n[j][r]=!1),t=S(t,{enumerable:b(0,!1)})):(u(n,j)||z(n,j,b(1,{})),n[j][r]=!0),an(n,r,t)):z(n,r,t)},cn=function(n,e){f(n);var t=h(e),r=k(t).concat(dn(t));return B(r,(function(e){s&&!ln.call(t,e)||sn(n,e,t[e])})),n},ln=function(n){var e=v(n),t=Y.call(this,e);return!(this===J&&u(Q,e)&&!u(X,e))&&(!(t||!u(this,e)||!u(Q,e)||u(this,j)&&this[j][e])||t)},un=function(n,e){var t=h(n),r=v(e);if(t!==J||!u(Q,r)||u(X,r)){var a=G(t,r);return!a||!u(Q,r)||u(t,j)&&t[j][r]||(a.enumerable=!0),a}},pn=function(n){var e=q(h(n)),t=[];return B(e,(function(n){u(Q,n)||u(A,n)||t.push(n)})),t},dn=function(n){var e=n===J,t=q(e?X:h(n)),r=[];return B(t,(function(n){!u(Q,n)||e&&!u(J,n)||r.push(Q[n])})),r};(c||(L((V=function(){if(this instanceof V)throw TypeError("Symbol is not a constructor");var n=arguments.length&&void 0!==arguments[0]?y(arguments[0]):void 0,e=I(n),t=function(n){this===J&&t.call(X,n),u(this,j)&&u(this[j],e)&&(this[j][e]=!1),an(this,e,b(1,n))};return s&&rn&&an(J,e,{configurable:!0,set:t}),on(e,n)}).prototype,"toString",(function(){return W(this).tag})),L(V,"withoutSetter",(function(n){return on(I(n),n)})),D.f=ln,C.f=sn,w.f=un,x.f=E.f=pn,T.f=dn,F.f=function(n){return on(M(n),n)},s&&(z(V.prototype,"description",{configurable:!0,get:function(){return W(this).description}}),i||L(J,"propertyIsEnumerable",ln,{unsafe:!0}))),r({global:!0,wrap:!0,forced:!c,sham:!c},{Symbol:V}),B(k(en),(function(n){P(n)})),r({target:"Symbol",stat:!0,forced:!c},{for:function(n){var e=y(n);if(u(Z,e))return Z[e];var t=V(e);return Z[e]=t,nn[t]=e,t},keyFor:function(n){if(!m(n))throw TypeError(n+" is not a symbol");if(u(nn,n))return nn[n]},useSetter:function(){rn=!0},useSimple:function(){rn=!1}}),r({target:"Object",stat:!0,forced:!c,sham:!s},{create:function(n,e){return void 0===e?S(n):cn(S(n),e)},defineProperty:sn,defineProperties:cn,getOwnPropertyDescriptor:un}),r({target:"Object",stat:!0,forced:!c},{getOwnPropertyNames:pn,getOwnPropertySymbols:dn}),r({target:"Object",stat:!0,forced:l((function(){T.f(1)}))},{getOwnPropertySymbols:function(n){return T.f(g(n))}}),K)&&r({target:"JSON",stat:!0,forced:!c||l((function(){var n=V();return"[null]"!=K([n])||"{}"!=K({a:n})||"{}"!=K(Object(n))}))},{stringify:function(n,e,t){for(var r,a=[n],o=1;arguments.length>o;)a.push(arguments[o++]);if(r=e,(d(e)||void 0!==n)&&!m(n))return p(e)||(e=function(n,e){if("function"==typeof r&&(e=r.call(this,n,e)),!m(e))return e}),a[1]=e,K.apply(null,a)}});V.prototype[$]||O(V.prototype,$,V.prototype.valueOf),N(V,"Symbol"),A[j]=!0},function(n,e,t){"use strict";var r=t(2),a=t(12),o=t(4),i=t(14),s=t(7),c=t(13).f,l=t(151),u=o.Symbol;if(a&&"function"==typeof u&&(!("description"in u.prototype)||void 0!==u().description)){var p={},d=function(){var n=arguments.length<1||void 0===arguments[0]?void 0:String(arguments[0]),e=this instanceof d?new u(n):void 0===n?u():u(n);return""===n&&(p[e]=!0),e};l(d,u);var m=d.prototype=u.prototype;m.constructor=d;var f=m.toString,g="Symbol(test)"==String(u("test")),h=/^Symbol\((.*)\)[^)]+$/;c(m,"description",{configurable:!0,get:function(){var n=s(this)?this.valueOf():this,e=f.call(n);if(i(p,n))return"";var t=g?e.slice(7,-1):e.replace(h,"$1");return""===t?void 0:t}}),r({global:!0,forced:!0},{Symbol:d})}},function(n,e,t){var r=t(2),a=t(250);r({target:"Array",stat:!0,forced:!t(110)((function(n){Array.from(n)}))},{from:a})},function(n,e,t){var r=t(148),a=t(102).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,a)}},function(n,e,t){var r=t(41);n.exports=Array.isArray||function(n){return"Array"==r(n)}},function(n,e,t){var r=t(3),a=t(41),o="".split;n.exports=r((function(){return!Object("z").propertyIsEnumerable(0)}))?function(n){return"String"==a(n)?o.call(n,""):Object(n)}:Object},function(n,e,t){var r=t(24),a=t(145);n.exports=a?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return"function"==typeof e&&Object(n)instanceof e}},function(n,e){n.exports={}},function(n,e){n.exports={}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var r=t(13).f,a=t(14),o=t(5)("toStringTag");n.exports=function(n,e,t){n&&!a(n=t?n:n.prototype,o)&&r(n,o,{configurable:!0,value:e})}},function(n,e,t){var r=t(34);n.exports=function(n,e,t){if(r(n),void 0===e)return n;switch(t){case 0:return function(){return n.call(e)};case 1:return function(t){return n.call(e,t)};case 2:return function(t,r){return n.call(e,t,r)};case 3:return function(t,r,a){return n.call(e,t,r,a)}}return function(){return n.apply(e,arguments)}}},function(n,e,t){var r=t(25).Symbol;n.exports=r},function(n,e,t){var r=t(61),a=t(256),o=t(257),i=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":i&&i in Object(n)?a(n):o(n)}},function(n,e,t){"use strict";function r(n,e){(null==e||e>n.length)&&(e=n.length);for(var t=0,r=new Array(e);t<e;t++)r[t]=n[t];return r}t.d(e,"a",(function(){return r}))},function(n,e,t){
/*!
* screenfull
* v5.2.0 - 2021-11-03
* (c) Sindre Sorhus; MIT License
*/
!function(){"use strict";var e="undefined"!=typeof window&&void 0!==window.document?window.document:{},t=n.exports,r=function(){for(var n,t=[["requestFullscreen","exitFullscreen","fullscreenElement","fullscreenEnabled","fullscreenchange","fullscreenerror"],["webkitRequestFullscreen","webkitExitFullscreen","webkitFullscreenElement","webkitFullscreenEnabled","webkitfullscreenchange","webkitfullscreenerror"],["webkitRequestFullScreen","webkitCancelFullScreen","webkitCurrentFullScreenElement","webkitCancelFullScreen","webkitfullscreenchange","webkitfullscreenerror"],["mozRequestFullScreen","mozCancelFullScreen","mozFullScreenElement","mozFullScreenEnabled","mozfullscreenchange","mozfullscreenerror"],["msRequestFullscreen","msExitFullscreen","msFullscreenElement","msFullscreenEnabled","MSFullscreenChange","MSFullscreenError"]],r=0,a=t.length,o={};r<a;r++)if((n=t[r])&&n[1]in e){for(r=0;r<n.length;r++)o[t[0][r]]=n[r];return o}return!1}(),a={change:r.fullscreenchange,error:r.fullscreenerror},o={request:function(n,t){return new Promise(function(a,o){var i=function(){this.off("change",i),a()}.bind(this);this.on("change",i);var s=(n=n||e.documentElement)[r.requestFullscreen](t);s instanceof Promise&&s.then(i).catch(o)}.bind(this))},exit:function(){return new Promise(function(n,t){if(this.isFullscreen){var a=function(){this.off("change",a),n()}.bind(this);this.on("change",a);var o=e[r.exitFullscreen]();o instanceof Promise&&o.then(a).catch(t)}else n()}.bind(this))},toggle:function(n,e){return this.isFullscreen?this.exit():this.request(n,e)},onchange:function(n){this.on("change",n)},onerror:function(n){this.on("error",n)},on:function(n,t){var r=a[n];r&&e.addEventListener(r,t,!1)},off:function(n,t){var r=a[n];r&&e.removeEventListener(r,t,!1)},raw:r};r?(Object.defineProperties(o,{isFullscreen:{get:function(){return Boolean(e[r.fullscreenElement])}},element:{enumerable:!0,get:function(){return e[r.fullscreenElement]}},isEnabled:{enumerable:!0,get:function(){return Boolean(e[r.fullscreenEnabled])}}}),t?n.exports=o:window.screenfull=o):t?n.exports={isEnabled:!1}:window.screenfull={isEnabled:!1}}()},function(n,e,t){"use strict";var r=t(2),a=t(3),o=t(53),i=t(7),s=t(18),c=t(19),l=t(70),u=t(167),p=t(79),d=t(5),m=t(43),f=d("isConcatSpreadable"),g=m>=51||!a((function(){var n=[];return n[f]=!1,n.concat()[0]!==n})),h=p("concat"),v=function(n){if(!i(n))return!1;var e=n[f];return void 0!==e?!!e:o(n)};r({target:"Array",proto:!0,forced:!g||!h},{concat:function(n){var e,t,r,a,o,i=s(this),p=u(i,0),d=0;for(e=-1,r=arguments.length;e<r;e++)if(v(o=-1===e?i:arguments[e])){if(d+(a=c(o.length))>9007199254740991)throw TypeError("Maximum allowed index exceeded");for(t=0;t<a;t++,d++)t in o&&l(p,d,o[t])}else{if(d>=9007199254740991)throw TypeError("Maximum allowed index exceeded");l(p,d++,o)}return p.length=d,p}})},function(n,e,t){t(2)({target:"Array",stat:!0},{isArray:t(53)})},function(n,e,t){t(174)("iterator")},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=function(n){return isNaN(n=+n)?0:(n>0?r:t)(n)}},function(n,e,t){var r=t(3),a=/#|\.prototype\./,o=function(n,e){var t=s[i(n)];return t==l||t!=c&&("function"==typeof e?r(e):!!e)},i=o.normalize=function(n){return String(n).replace(a,".").toLowerCase()},s=o.data={},c=o.NATIVE="N",l=o.POLYFILL="P";n.exports=o},function(n,e,t){"use strict";var r=t(73),a=t(13),o=t(58);n.exports=function(n,e,t){var i=r(e);i in n?a.f(n,i,o(0,t)):n[i]=t}},function(n,e,t){var r=t(38),a=t(97);(n.exports=function(n,e){return a[n]||(a[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.16.1",mode:r?"pure":"global",copyright:"© 2021 Denis Pushkarev (zloirock.ru)"})},function(n,e){var t=0,r=Math.random();n.exports=function(n){return"Symbol("+String(void 0===n?"":n)+")_"+(++t+r).toString(36)}},function(n,e,t){var r=t(147),a=t(55);n.exports=function(n){var e=r(n,"string");return a(e)?e:String(e)}},function(n,e,t){var r=t(148),a=t(102);n.exports=Object.keys||function(n){return r(n,a)}},function(n,e,t){var r=t(71),a=t(72),o=r("keys");n.exports=function(n){return o[n]||(o[n]=a(n))}},function(n,e,t){var r=t(10),a=t(234);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set).call(t,[]),e=t instanceof Array}catch(n){}return function(t,o){return r(t),a(o),e?n.call(t,o):t.__proto__=o,t}}():void 0)},function(n,e,t){var r=t(41),a=t(4);n.exports="process"==r(a.process)},function(n,e,t){var r=function(n){"use strict";var e=Object.prototype,t=e.hasOwnProperty,r="function"==typeof Symbol?Symbol:{},a=r.iterator||"@@iterator",o=r.asyncIterator||"@@asyncIterator",i=r.toStringTag||"@@toStringTag";function s(n,e,t){return Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}),n[e]}try{s({},"")}catch(n){s=function(n,e,t){return n[e]=t}}function c(n,e,t,r){var a=e&&e.prototype instanceof p?e:p,o=Object.create(a.prototype),i=new E(r||[]);return o._invoke=function(n,e,t){var r="suspendedStart";return function(a,o){if("executing"===r)throw new Error("Generator is already running");if("completed"===r){if("throw"===a)throw o;return w()}for(t.method=a,t.arg=o;;){var i=t.delegate;if(i){var s=S(i,t);if(s){if(s===u)continue;return s}}if("next"===t.method)t.sent=t._sent=t.arg;else if("throw"===t.method){if("suspendedStart"===r)throw r="completed",t.arg;t.dispatchException(t.arg)}else"return"===t.method&&t.abrupt("return",t.arg);r="executing";var c=l(n,e,t);if("normal"===c.type){if(r=t.done?"completed":"suspendedYield",c.arg===u)continue;return{value:c.arg,done:t.done}}"throw"===c.type&&(r="completed",t.method="throw",t.arg=c.arg)}}}(n,t,i),o}function l(n,e,t){try{return{type:"normal",arg:n.call(e,t)}}catch(n){return{type:"throw",arg:n}}}n.wrap=c;var u={};function p(){}function d(){}function m(){}var f={};s(f,a,(function(){return this}));var g=Object.getPrototypeOf,h=g&&g(g(T([])));h&&h!==e&&t.call(h,a)&&(f=h);var v=m.prototype=p.prototype=Object.create(f);function y(n){["next","throw","return"].forEach((function(e){s(n,e,(function(n){return this._invoke(e,n)}))}))}function b(n,e){var r;this._invoke=function(a,o){function i(){return new e((function(r,i){!function r(a,o,i,s){var c=l(n[a],n,o);if("throw"!==c.type){var u=c.arg,p=u.value;return p&&"object"==typeof p&&t.call(p,"__await")?e.resolve(p.__await).then((function(n){r("next",n,i,s)}),(function(n){r("throw",n,i,s)})):e.resolve(p).then((function(n){u.value=n,i(u)}),(function(n){return r("throw",n,i,s)}))}s(c.arg)}(a,o,r,i)}))}return r=r?r.then(i,i):i()}}function S(n,e){var t=n.iterator[e.method];if(void 0===t){if(e.delegate=null,"throw"===e.method){if(n.iterator.return&&(e.method="return",e.arg=void 0,S(n,e),"throw"===e.method))return u;e.method="throw",e.arg=new TypeError("The iterator does not provide a 'throw' method")}return u}var r=l(t,n.iterator,e.arg);if("throw"===r.type)return e.method="throw",e.arg=r.arg,e.delegate=null,u;var a=r.arg;return a?a.done?(e[n.resultName]=a.value,e.next=n.nextLoc,"return"!==e.method&&(e.method="next",e.arg=void 0),e.delegate=null,u):a:(e.method="throw",e.arg=new TypeError("iterator result is not an object"),e.delegate=null,u)}function k(n){var e={tryLoc:n[0]};1 in n&&(e.catchLoc=n[1]),2 in n&&(e.finallyLoc=n[2],e.afterLoc=n[3]),this.tryEntries.push(e)}function x(n){var e=n.completion||{};e.type="normal",delete e.arg,n.completion=e}function E(n){this.tryEntries=[{tryLoc:"root"}],n.forEach(k,this),this.reset(!0)}function T(n){if(n){var e=n[a];if(e)return e.call(n);if("function"==typeof n.next)return n;if(!isNaN(n.length)){var r=-1,o=function e(){for(;++r<n.length;)if(t.call(n,r))return e.value=n[r],e.done=!1,e;return e.value=void 0,e.done=!0,e};return o.next=o}}return{next:w}}function w(){return{value:void 0,done:!0}}return d.prototype=m,s(v,"constructor",m),s(m,"constructor",d),d.displayName=s(m,i,"GeneratorFunction"),n.isGeneratorFunction=function(n){var e="function"==typeof n&&n.constructor;return!!e&&(e===d||"GeneratorFunction"===(e.displayName||e.name))},n.mark=function(n){return Object.setPrototypeOf?Object.setPrototypeOf(n,m):(n.__proto__=m,s(n,i,"GeneratorFunction")),n.prototype=Object.create(v),n},n.awrap=function(n){return{__await:n}},y(b.prototype),s(b.prototype,o,(function(){return this})),n.AsyncIterator=b,n.async=function(e,t,r,a,o){void 0===o&&(o=Promise);var i=new b(c(e,t,r,a),o);return n.isGeneratorFunction(t)?i:i.next().then((function(n){return n.done?n.value:i.next()}))},y(v),s(v,i,"Generator"),s(v,a,(function(){return this})),s(v,"toString",(function(){return"[object Generator]"})),n.keys=function(n){var e=[];for(var t in n)e.push(t);return e.reverse(),function t(){for(;e.length;){var r=e.pop();if(r in n)return t.value=r,t.done=!1,t}return t.done=!0,t}},n.values=T,E.prototype={constructor:E,reset:function(n){if(this.prev=0,this.next=0,this.sent=this._sent=void 0,this.done=!1,this.delegate=null,this.method="next",this.arg=void 0,this.tryEntries.forEach(x),!n)for(var e in this)"t"===e.charAt(0)&&t.call(this,e)&&!isNaN(+e.slice(1))&&(this[e]=void 0)},stop:function(){this.done=!0;var n=this.tryEntries[0].completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(n){if(this.done)throw n;var e=this;function r(t,r){return i.type="throw",i.arg=n,e.next=t,r&&(e.method="next",e.arg=void 0),!!r}for(var a=this.tryEntries.length-1;a>=0;--a){var o=this.tryEntries[a],i=o.completion;if("root"===o.tryLoc)return r("end");if(o.tryLoc<=this.prev){var s=t.call(o,"catchLoc"),c=t.call(o,"finallyLoc");if(s&&c){if(this.prev<o.catchLoc)return r(o.catchLoc,!0);if(this.prev<o.finallyLoc)return r(o.finallyLoc)}else if(s){if(this.prev<o.catchLoc)return r(o.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<o.finallyLoc)return r(o.finallyLoc)}}}},abrupt:function(n,e){for(var r=this.tryEntries.length-1;r>=0;--r){var a=this.tryEntries[r];if(a.tryLoc<=this.prev&&t.call(a,"finallyLoc")&&this.prev<a.finallyLoc){var o=a;break}}o&&("break"===n||"continue"===n)&&o.tryLoc<=e&&e<=o.finallyLoc&&(o=null);var i=o?o.completion:{};return i.type=n,i.arg=e,o?(this.method="next",this.next=o.finallyLoc,u):this.complete(i)},complete:function(n,e){if("throw"===n.type)throw n.arg;return"break"===n.type||"continue"===n.type?this.next=n.arg:"return"===n.type?(this.rval=this.arg=n.arg,this.method="return",this.next="end"):"normal"===n.type&&e&&(this.next=e),u},finish:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.finallyLoc===n)return this.complete(t.completion,t.afterLoc),x(t),u}},catch:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.tryLoc===n){var r=t.completion;if("throw"===r.type){var a=r.arg;x(t)}return a}}throw new Error("illegal catch attempt")},delegateYield:function(n,e,t){return this.delegate={iterator:T(n),resultName:e,nextLoc:t},"next"===this.method&&(this.arg=void 0),u}},n}(n.exports);try{regeneratorRuntime=r}catch(n){"object"==typeof globalThis?globalThis.regeneratorRuntime=r:Function("r","regeneratorRuntime = r")(r)}},function(n,e,t){var r=t(3),a=t(5),o=t(43),i=a("species");n.exports=function(n){return o>=51||!r((function(){var e=[];return(e.constructor={})[i]=function(){return{foo:1}},1!==e[n](Boolean).foo}))}},function(n,e,t){"use strict";var r,a,o=t(16),i=t(137),s=t(138),c=t(71),l=t(33),u=t(39).get,p=t(224),d=t(225),m=RegExp.prototype.exec,f=c("native-string-replace",String.prototype.replace),g=m,h=(r=/a/,a=/b*/g,m.call(r,"a"),m.call(a,"a"),0!==r.lastIndex||0!==a.lastIndex),v=s.UNSUPPORTED_Y||s.BROKEN_CARET,y=void 0!==/()??/.exec("")[1];(h||y||v||p||d)&&(g=function(n){var e,t,r,a,s,c,p,d=this,b=u(d),S=o(n),k=b.raw;if(k)return k.lastIndex=d.lastIndex,e=g.call(k,S),d.lastIndex=k.lastIndex,e;var x=b.groups,E=v&&d.sticky,T=i.call(d),w=d.source,C=0,D=S;if(E&&(-1===(T=T.replace("y","")).indexOf("g")&&(T+="g"),D=S.slice(d.lastIndex),d.lastIndex>0&&(!d.multiline||d.multiline&&"\n"!==S.charAt(d.lastIndex-1))&&(w="(?: "+w+")",D=" "+D,C++),t=new RegExp("^(?:"+w+")",T)),y&&(t=new RegExp("^"+w+"$(?!\\s)",T)),h&&(r=d.lastIndex),a=m.call(E?t:d,D),E?a?(a.input=a.input.slice(C),a[0]=a[0].slice(C),a.index=d.lastIndex,d.lastIndex+=a[0].length):d.lastIndex=0:h&&a&&(d.lastIndex=d.global?a.index+a[0].length:r),y&&a&&a.length>1&&f.call(a[0],t,(function(){for(s=1;s<arguments.length-2;s++)void 0===arguments[s]&&(a[s]=void 0)})),a&&x)for(a.groups=c=l(null),s=0;s<x.length;s++)c[(p=x[s])[0]]=a[p[1]];return a}),n.exports=g},function(n,e,t){var r=t(261),a=t(262),o=t(263),i=t(264),s=t(265);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(179);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(42)(Object,"create");n.exports=r},function(n,e,t){var r=t(283);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(120);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));t(49),t(50),t(6),t(67),t(8),t(9),t(51);function r(n){if("undefined"!=typeof Symbol&&null!=n[Symbol.iterator]||null!=n["@@iterator"])return Array.from(n)}},function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));t(66);function r(n){if(Array.isArray(n))return n}},function(n,e,t){"use strict";function r(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}t.d(e,"a",(function(){return r}))},function(n,e,t){var r,a;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(a="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function a(n,e,t){return n<e?e:n>t?t:n}function o(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=a(n,r.minimum,1),t.status=1===n?null:n;var c=t.render(!e),l=c.querySelector(r.barSelector),u=r.speed,p=r.easing;return c.offsetWidth,i((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(l,function(n,e,t){var a;return(a="translate3d"===r.positionUsing?{transform:"translate3d("+o(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+o(n)+"%,0)"}:{"margin-left":o(n)+"%"}).transition="all "+e+"ms "+t,a}(n,u,p)),1===n?(s(c,{transition:"none",opacity:1}),c.offsetWidth,setTimeout((function(){s(c,{transition:"all "+u+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),u)}),u)):setTimeout(e,u)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*a(Math.random()*e,.1,.95)),e=a(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");l(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var a,i=e.querySelector(r.barSelector),c=n?"-100":o(t.status||0),u=document.querySelector(r.parent);return s(i,{transition:"all 0 linear",transform:"translate3d("+c+"%,0,0)"}),r.showSpinner||(a=e.querySelector(r.spinnerSelector))&&d(a),u!=document.body&&l(u,"nprogress-custom-parent"),u.appendChild(e),e},t.remove=function(){u(document.documentElement,"nprogress-busy"),u(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&d(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var i=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,a=n.length,o=e.charAt(0).toUpperCase()+e.slice(1);a--;)if((r=n[a]+o)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,a,o=arguments;if(2==o.length)for(t in e)void 0!==(a=e[t])&&e.hasOwnProperty(t)&&r(n,t,a);else r(n,o[1],o[2])}}();function c(n,e){return("string"==typeof n?n:p(n)).indexOf(" "+e+" ")>=0}function l(n,e){var t=p(n),r=t+e;c(t,e)||(n.className=r.substring(1))}function u(n,e){var t,r=p(n);c(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function p(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function d(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=a)},function(n,e,t){"use strict";var r=t(2),a=t(44).some;r({target:"Array",proto:!0,forced:!t(40)("some")},{some:function(n){return a(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(2),a=t(101).includes,o=t(144);r({target:"Array",proto:!0},{includes:function(n){return a(this,n,arguments.length>1?arguments[1]:void 0)}}),o("includes")},function(n,e,t){"use strict";var r=t(12),a=t(4),o=t(69),i=t(17),s=t(14),c=t(41),l=t(140),u=t(55),p=t(147),d=t(3),m=t(33),f=t(52).f,g=t(37).f,h=t(13).f,v=t(122).trim,y=a.Number,b=y.prototype,S="Number"==c(m(b)),k=function(n){if(u(n))throw TypeError("Cannot convert a Symbol value to a number");var e,t,r,a,o,i,s,c,l=p(n,"number");if("string"==typeof l&&l.length>2)if(43===(e=(l=v(l)).charCodeAt(0))||45===e){if(88===(t=l.charCodeAt(2))||120===t)return NaN}else if(48===e){switch(l.charCodeAt(1)){case 66:case 98:r=2,a=49;break;case 79:case 111:r=8,a=55;break;default:return+l}for(i=(o=l.slice(2)).length,s=0;s<i;s++)if((c=o.charCodeAt(s))<48||c>a)return NaN;return parseInt(o,r)}return+l};if(o("Number",!y(" 0o1")||!y("0b1")||y("+0x1"))){for(var x,E=function(n){var e=arguments.length<1?0:n,t=this;return t instanceof E&&(S?d((function(){b.valueOf.call(t)})):"Number"!=c(t))?l(new y(k(e)),t,E):k(e)},T=r?f(y):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger,fromString,range".split(","),w=0;T.length>w;w++)s(y,x=T[w])&&!s(E,x)&&h(E,x,g(y,x));E.prototype=b,b.constructor=E,i(a,"Number",E)}},function(n,e,t){"use strict";var r=t(2),a=t(134),o=t(30),i=t(16);r({target:"String",proto:!0,forced:!t(136)("includes")},{includes:function(n){return!!~i(o(this)).indexOf(i(a(n)),arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(12),a=t(13).f,o=Function.prototype,i=o.toString,s=/^\s*function ([^ (]*)/;r&&!("name"in o)&&a(o,"name",{configurable:!0,get:function(){try{return i.call(this).match(s)[1]}catch(n){return""}}})},function(n,e,t){var r=t(10),a=t(157),o=t(19),i=t(60),s=t(158),c=t(160),l=function(n,e){this.stopped=n,this.result=e};n.exports=function(n,e,t){var u,p,d,m,f,g,h,v=t&&t.that,y=!(!t||!t.AS_ENTRIES),b=!(!t||!t.IS_ITERATOR),S=!(!t||!t.INTERRUPTED),k=i(e,v,1+y+S),x=function(n){return u&&c(u),new l(!0,n)},E=function(n){return y?(r(n),S?k(n[0],n[1],x):k(n[0],n[1])):S?k(n,x):k(n)};if(b)u=n;else{if("function"!=typeof(p=s(n)))throw TypeError("Target is not iterable");if(a(p)){for(d=0,m=o(n.length);m>d;d++)if((f=E(n[d]))&&f instanceof l)return f;return new l(!1)}u=p.call(n)}for(g=u.next;!(h=g.call(u)).done;){try{f=E(h.value)}catch(n){throw c(u),n}if("object"==typeof f&&f&&f instanceof l)return f}return new l(!1)}},function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));t(141);function r(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}},function(n,e,t){var r=t(4),a=t(98),o=r["__core-js_shared__"]||a("__core-js_shared__",{});n.exports=o},function(n,e,t){var r=t(4);n.exports=function(n,e){try{Object.defineProperty(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(43),a=t(3);n.exports=!!Object.getOwnPropertySymbols&&!a((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r=t(4),a=t(7),o=r.document,i=a(o)&&a(o.createElement);n.exports=function(n){return i?o.createElement(n):{}}},function(n,e,t){var r=t(22),a=t(19),o=t(149),i=function(n){return function(e,t,i){var s,c=r(e),l=a(c.length),u=o(i,l);if(n&&t!=t){for(;l>u;)if((s=c[u++])!=s)return!0}else for(;l>u;u++)if((n||u in c)&&c[u]===t)return n||u||0;return!n&&-1}};n.exports={includes:i(!0),indexOf:i(!1)}},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var r=t(97),a=Function.toString;"function"!=typeof r.inspectSource&&(r.inspectSource=function(n){return a.call(n)}),n.exports=r.inspectSource},function(n,e,t){"use strict";var r=t(2),a=t(233),o=t(107),i=t(76),s=t(59),c=t(23),l=t(17),u=t(5),p=t(38),d=t(57),m=t(153),f=m.IteratorPrototype,g=m.BUGGY_SAFARI_ITERATORS,h=u("iterator"),v=function(){return this};n.exports=function(n,e,t,u,m,y,b){a(t,e,u);var S,k,x,E=function(n){if(n===m&&O)return O;if(!g&&n in C)return C[n];switch(n){case"keys":case"values":case"entries":return function(){return new t(this,n)}}return function(){return new t(this)}},T=e+" Iterator",w=!1,C=n.prototype,D=C[h]||C["@@iterator"]||m&&C[m],O=!g&&D||E(m),L="Array"==e&&C.entries||D;if(L&&(S=o(L.call(new n)),f!==Object.prototype&&S.next&&(p||o(S)===f||(i?i(S,f):"function"!=typeof S[h]&&c(S,h,v)),s(S,T,!0,!0),p&&(d[T]=v))),"values"==m&&D&&"values"!==D.name&&(w=!0,O=function(){return D.call(this)}),p&&!b||C[h]===O||c(C,h,O),d[e]=O,m)if(k={values:E("values"),keys:y?O:E("keys"),entries:E("entries")},b)for(x in k)(g||w||!(x in C))&&l(C,x,k[x]);else r({target:e,proto:!0,forced:g||w},k);return k}},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,a=Object.getOwnPropertyDescriptor,o=a&&!r.call({1:2},1);e.f=o?function(n){var e=a(this,n);return!!e&&e.enumerable}:r},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(14),a=t(18),o=t(75),i=t(154),s=o("IE_PROTO"),c=Object.prototype;n.exports=i?Object.getPrototypeOf:function(n){return n=a(n),r(n,s)?n[s]:"function"==typeof n.constructor&&n instanceof n.constructor?n.constructor.prototype:n instanceof Object?c:null}},function(n,e){n.exports=function(n,e,t){if(!(n instanceof e))throw TypeError("Incorrect "+(t?t+" ":"")+"invocation");return n}},function(n,e,t){var r={};r[t(5)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(5)("iterator"),a=!1;try{var o=0,i={next:function(){return{done:!!o++}},return:function(){a=!0}};i[r]=function(){return this},Array.from(i,(function(){throw 2}))}catch(n){}n.exports=function(n,e){if(!e&&!a)return!1;var t=!1;try{var o={};o[r]=function(){return{next:function(){return{done:t=!0}}}},n(o)}catch(n){}return t}},function(n,e,t){var r=t(10),a=t(34),o=t(5)("species");n.exports=function(n,e){var t,i=r(n).constructor;return void 0===i||null==(t=r(i)[o])?e:a(t)}},function(n,e,t){var r=t(2),a=t(56),o=t(7),i=t(14),s=t(13).f,c=t(52),l=t(172),u=t(72),p=t(171),d=!1,m=u("meta"),f=0,g=Object.isExtensible||function(){return!0},h=function(n){s(n,m,{value:{objectID:"O"+f++,weakData:{}}})},v=n.exports={enable:function(){v.enable=function(){},d=!0;var n=c.f,e=[].splice,t={};t[m]=1,n(t).length&&(c.f=function(t){for(var r=n(t),a=0,o=r.length;a<o;a++)if(r[a]===m){e.call(r,a,1);break}return r},r({target:"Object",stat:!0,forced:!0},{getOwnPropertyNames:l.f}))},fastKey:function(n,e){if(!o(n))return"symbol"==typeof n?n:("string"==typeof n?"S":"P")+n;if(!i(n,m)){if(!g(n))return"F";if(!e)return"E";h(n)}return n[m].objectID},getWeakData:function(n,e){if(!i(n,m)){if(!g(n))return!0;if(!e)return!1;h(n)}return n[m].weakData},onFreeze:function(n){return p&&d&&g(n)&&!i(n,m)&&h(n),n}};a[m]=!0},function(n,e,t){var r=t(255),a=t(45),o=Object.prototype,i=o.hasOwnProperty,s=o.propertyIsEnumerable,c=r(function(){return arguments}())?r:function(n){return a(n)&&i.call(n,"callee")&&!s.call(n,"callee")};n.exports=c},function(n,e,t){var r=t(42)(t(25),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(275),a=t(282),o=t(284),i=t(285),s=t(286);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(26),a=t(120),o=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!a(n))||(i.test(n)||!o.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(62),a=t(45);n.exports=function(n){return"symbol"==typeof n||a(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(30),a=t(16),o="["+t(123)+"]",i=RegExp("^"+o+o+"*"),s=RegExp(o+o+"*$"),c=function(n){return function(e){var t=a(r(e));return 1&n&&(t=t.replace(i,"")),2&n&&(t=t.replace(s,"")),t}};n.exports={start:c(1),end:c(2),trim:c(3)}},function(n,e){n.exports="\t\n\v\f\r                　\u2028\u2029\ufeff"},function(n,e,t){t(2)({target:"Function",proto:!0},{bind:t(196)})},function(n,e,t){var r=t(17),a=Date.prototype,o=a.toString,i=a.getTime;"Invalid Date"!=String(new Date(NaN))&&r(a,"toString",(function(){var n=i.call(this);return n==n?o.call(this):"Invalid Date"}))},function(n,e,t){"use strict";var r=t(17),a=t(10),o=t(16),i=t(3),s=t(137),c=RegExp.prototype,l=c.toString,u=i((function(){return"/a/b"!=l.call({source:"a",flags:"b"})})),p="toString"!=l.name;(u||p)&&r(RegExp.prototype,"toString",(function(){var n=a(this),e=o(n.source),t=n.flags;return"/"+e+"/"+o(void 0===t&&n instanceof RegExp&&!("flags"in c)?s.call(n):t)}),{unsafe:!0})},function(n,e,t){"use strict";var r=t(2),a=t(101).indexOf,o=t(40),i=[].indexOf,s=!!i&&1/[1].indexOf(1,-0)<0,c=o("indexOf");r({target:"Array",proto:!0,forced:s||!c},{indexOf:function(n){return s?i.apply(this,arguments)||0:a(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));t(49),t(50),t(6),t(67),t(8),t(9);function r(n){return(r="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n})(n)}},function(n,e,t){"use strict";t(20);var r=t(17),a=t(80),o=t(3),i=t(5),s=t(23),c=i("species"),l=RegExp.prototype;n.exports=function(n,e,t,u){var p=i(n),d=!o((function(){var e={};return e[p]=function(){return 7},7!=""[n](e)})),m=d&&!o((function(){var e=!1,t=/a/;return"split"===n&&((t={}).constructor={},t.constructor[c]=function(){return t},t.flags="",t[p]=/./[p]),t.exec=function(){return e=!0,null},t[p](""),!e}));if(!d||!m||t){var f=/./[p],g=e(p,""[n],(function(n,e,t,r,o){var i=e.exec;return i===a||i===l.exec?d&&!o?{done:!0,value:f.call(e,t,r)}:{done:!0,value:n.call(t,e,r)}:{done:!1}}));r(String.prototype,n,g[0]),r(l,p,g[1])}u&&s(l[p],"sham",!0)}},function(n,e,t){var r=t(41),a=t(80);n.exports=function(n,e){var t=n.exec;if("function"==typeof t){var o=t.call(n,e);if("object"!=typeof o)throw TypeError("RegExp exec method returned something other than an Object or null");return o}if("RegExp"!==r(n))throw TypeError("RegExp#exec called on incompatible receiver");return a.call(n,e)}},function(n,e,t){"use strict";var r=t(2),a=t(54),o=t(22),i=t(40),s=[].join,c=a!=Object,l=i("join",",");r({target:"Array",proto:!0,forced:c||!l},{join:function(n){return s.call(o(this),void 0===n?",":n)}})},function(n,e,t){"use strict";var r=t(24),a=t(13),o=t(5),i=t(12),s=o("species");n.exports=function(n){var e=r(n),t=a.f;i&&e&&!e[s]&&t(e,s,{configurable:!0,get:function(){return this}})}},function(n,e,t){var r=t(135);n.exports=function(n){if(r(n))throw TypeError("The method doesn't accept regular expressions");return n}},function(n,e,t){var r=t(7),a=t(41),o=t(5)("match");n.exports=function(n){var e;return r(n)&&(void 0!==(e=n[o])?!!e:"RegExp"==a(n))}},function(n,e,t){var r=t(5)("match");n.exports=function(n){var e=/./;try{"/./"[n](e)}catch(t){try{return e[r]=!1,"/./"[n](e)}catch(n){}}return!1}},function(n,e,t){"use strict";var r=t(10);n.exports=function(){var n=r(this),e="";return n.global&&(e+="g"),n.ignoreCase&&(e+="i"),n.multiline&&(e+="m"),n.dotAll&&(e+="s"),n.unicode&&(e+="u"),n.sticky&&(e+="y"),e}},function(n,e,t){var r=t(3),a=function(n,e){return RegExp(n,e)};e.UNSUPPORTED_Y=r((function(){var n=a("a","y");return n.lastIndex=2,null!=n.exec("abcd")})),e.BROKEN_CARET=r((function(){var n=a("^r","gy");return n.lastIndex=2,null!=n.exec("str")}))},function(n,e,t){"use strict";var r=t(165).charAt;n.exports=function(n,e,t){return e+(t?r(n,e).length:1)}},function(n,e,t){var r=t(7),a=t(76);n.exports=function(n,e,t){var o,i;return a&&"function"==typeof(o=e.constructor)&&o!==t&&r(i=o.prototype)&&i!==t.prototype&&a(n,i),n}},function(n,e,t){var r=t(2),a=t(12);r({target:"Object",stat:!0,forced:!a,sham:!a},{defineProperty:t(13).f})},function(n,e,t){n.exports=function(){"use strict";var n=6e4,e=36e5,t="millisecond",r="second",a="minute",o="hour",i="day",s="week",c="month",l="quarter",u="year",p="date",d="Invalid Date",m=/^(\d{4})[-/]?(\d{1,2})?[-/]?(\d{0,2})[Tt\s]*(\d{1,2})?:?(\d{1,2})?:?(\d{1,2})?[.:]?(\d+)?$/,f=/\[([^\]]+)]|Y{1,4}|M{1,4}|D{1,2}|d{1,4}|H{1,2}|h{1,2}|a|A|m{1,2}|s{1,2}|Z{1,2}|SSS/g,g={name:"en",weekdays:"Sunday_Monday_Tuesday_Wednesday_Thursday_Friday_Saturday".split("_"),months:"January_February_March_April_May_June_July_August_September_October_November_December".split("_")},h=function(n,e,t){var r=String(n);return!r||r.length>=e?n:""+Array(e+1-r.length).join(t)+n},v={s:h,z:function(n){var e=-n.utcOffset(),t=Math.abs(e),r=Math.floor(t/60),a=t%60;return(e<=0?"+":"-")+h(r,2,"0")+":"+h(a,2,"0")},m:function n(e,t){if(e.date()<t.date())return-n(t,e);var r=12*(t.year()-e.year())+(t.month()-e.month()),a=e.clone().add(r,c),o=t-a<0,i=e.clone().add(r+(o?-1:1),c);return+(-(r+(t-a)/(o?a-i:i-a))||0)},a:function(n){return n<0?Math.ceil(n)||0:Math.floor(n)},p:function(n){return{M:c,y:u,w:s,d:i,D:p,h:o,m:a,s:r,ms:t,Q:l}[n]||String(n||"").toLowerCase().replace(/s$/,"")},u:function(n){return void 0===n}},y="en",b={};b[y]=g;var S=function(n){return n instanceof T},k=function(n,e,t){var r;if(!n)return y;if("string"==typeof n)b[n]&&(r=n),e&&(b[n]=e,r=n);else{var a=n.name;b[a]=n,r=a}return!t&&r&&(y=r),r||!t&&y},x=function(n,e){if(S(n))return n.clone();var t="object"==typeof e?e:{};return t.date=n,t.args=arguments,new T(t)},E=v;E.l=k,E.i=S,E.w=function(n,e){return x(n,{locale:e.$L,utc:e.$u,x:e.$x,$offset:e.$offset})};var T=function(){function g(n){this.$L=k(n.locale,null,!0),this.parse(n)}var h=g.prototype;return h.parse=function(n){this.$d=function(n){var e=n.date,t=n.utc;if(null===e)return new Date(NaN);if(E.u(e))return new Date;if(e instanceof Date)return new Date(e);if("string"==typeof e&&!/Z$/i.test(e)){var r=e.match(m);if(r){var a=r[2]-1||0,o=(r[7]||"0").substring(0,3);return t?new Date(Date.UTC(r[1],a,r[3]||1,r[4]||0,r[5]||0,r[6]||0,o)):new Date(r[1],a,r[3]||1,r[4]||0,r[5]||0,r[6]||0,o)}}return new Date(e)}(n),this.$x=n.x||{},this.init()},h.init=function(){var n=this.$d;this.$y=n.getFullYear(),this.$M=n.getMonth(),this.$D=n.getDate(),this.$W=n.getDay(),this.$H=n.getHours(),this.$m=n.getMinutes(),this.$s=n.getSeconds(),this.$ms=n.getMilliseconds()},h.$utils=function(){return E},h.isValid=function(){return!(this.$d.toString()===d)},h.isSame=function(n,e){var t=x(n);return this.startOf(e)<=t&&t<=this.endOf(e)},h.isAfter=function(n,e){return x(n)<this.startOf(e)},h.isBefore=function(n,e){return this.endOf(e)<x(n)},h.$g=function(n,e,t){return E.u(n)?this[e]:this.set(t,n)},h.unix=function(){return Math.floor(this.valueOf()/1e3)},h.valueOf=function(){return this.$d.getTime()},h.startOf=function(n,e){var t=this,l=!!E.u(e)||e,d=E.p(n),m=function(n,e){var r=E.w(t.$u?Date.UTC(t.$y,e,n):new Date(t.$y,e,n),t);return l?r:r.endOf(i)},f=function(n,e){return E.w(t.toDate()[n].apply(t.toDate("s"),(l?[0,0,0,0]:[23,59,59,999]).slice(e)),t)},g=this.$W,h=this.$M,v=this.$D,y="set"+(this.$u?"UTC":"");switch(d){case u:return l?m(1,0):m(31,11);case c:return l?m(1,h):m(0,h+1);case s:var b=this.$locale().weekStart||0,S=(g<b?g+7:g)-b;return m(l?v-S:v+(6-S),h);case i:case p:return f(y+"Hours",0);case o:return f(y+"Minutes",1);case a:return f(y+"Seconds",2);case r:return f(y+"Milliseconds",3);default:return this.clone()}},h.endOf=function(n){return this.startOf(n,!1)},h.$set=function(n,e){var s,l=E.p(n),d="set"+(this.$u?"UTC":""),m=(s={},s[i]=d+"Date",s[p]=d+"Date",s[c]=d+"Month",s[u]=d+"FullYear",s[o]=d+"Hours",s[a]=d+"Minutes",s[r]=d+"Seconds",s[t]=d+"Milliseconds",s)[l],f=l===i?this.$D+(e-this.$W):e;if(l===c||l===u){var g=this.clone().set(p,1);g.$d[m](f),g.init(),this.$d=g.set(p,Math.min(this.$D,g.daysInMonth())).$d}else m&&this.$d[m](f);return this.init(),this},h.set=function(n,e){return this.clone().$set(n,e)},h.get=function(n){return this[E.p(n)]()},h.add=function(t,l){var p,d=this;t=Number(t);var m=E.p(l),f=function(n){var e=x(d);return E.w(e.date(e.date()+Math.round(n*t)),d)};if(m===c)return this.set(c,this.$M+t);if(m===u)return this.set(u,this.$y+t);if(m===i)return f(1);if(m===s)return f(7);var g=(p={},p[a]=n,p[o]=e,p[r]=1e3,p)[m]||1,h=this.$d.getTime()+t*g;return E.w(h,this)},h.subtract=function(n,e){return this.add(-1*n,e)},h.format=function(n){var e=this,t=this.$locale();if(!this.isValid())return t.invalidDate||d;var r=n||"YYYY-MM-DDTHH:mm:ssZ",a=E.z(this),o=this.$H,i=this.$m,s=this.$M,c=t.weekdays,l=t.months,u=function(n,t,a,o){return n&&(n[t]||n(e,r))||a[t].substr(0,o)},p=function(n){return E.s(o%12||12,n,"0")},m=t.meridiem||function(n,e,t){var r=n<12?"AM":"PM";return t?r.toLowerCase():r},g={YY:String(this.$y).slice(-2),YYYY:this.$y,M:s+1,MM:E.s(s+1,2,"0"),MMM:u(t.monthsShort,s,l,3),MMMM:u(l,s),D:this.$D,DD:E.s(this.$D,2,"0"),d:String(this.$W),dd:u(t.weekdaysMin,this.$W,c,2),ddd:u(t.weekdaysShort,this.$W,c,3),dddd:c[this.$W],H:String(o),HH:E.s(o,2,"0"),h:p(1),hh:p(2),a:m(o,i,!0),A:m(o,i,!1),m:String(i),mm:E.s(i,2,"0"),s:String(this.$s),ss:E.s(this.$s,2,"0"),SSS:E.s(this.$ms,3,"0"),Z:a};return r.replace(f,(function(n,e){return e||g[n]||a.replace(":","")}))},h.utcOffset=function(){return 15*-Math.round(this.$d.getTimezoneOffset()/15)},h.diff=function(t,p,d){var m,f=E.p(p),g=x(t),h=(g.utcOffset()-this.utcOffset())*n,v=this-g,y=E.m(this,g);return y=(m={},m[u]=y/12,m[c]=y,m[l]=y/3,m[s]=(v-h)/6048e5,m[i]=(v-h)/864e5,m[o]=v/e,m[a]=v/n,m[r]=v/1e3,m)[f]||v,d?y:E.a(y)},h.daysInMonth=function(){return this.endOf(c).$D},h.$locale=function(){return b[this.$L]},h.locale=function(n,e){if(!n)return this.$L;var t=this.clone(),r=k(n,e,!0);return r&&(t.$L=r),t},h.clone=function(){return E.w(this.$d,this)},h.toDate=function(){return new Date(this.valueOf())},h.toJSON=function(){return this.isValid()?this.toISOString():null},h.toISOString=function(){return this.$d.toISOString()},h.toString=function(){return this.$d.toUTCString()},g}(),w=T.prototype;return x.prototype=w,[["$ms",t],["$s",r],["$m",a],["$H",o],["$W",i],["$M",c],["$y",u],["$D",p]].forEach((function(n){w[n[1]]=function(e){return this.$g(e,n[0],n[1])}})),x.extend=function(n,e){return n.$i||(n(e,T,x),n.$i=!0),x},x.locale=k,x.isDayjs=S,x.unix=function(n){return x(1e3*n)},x.en=b[y],x.Ls=b,x.p={},x}()},function(n,e,t){"use strict";var r=t(22),a=t(144),o=t(57),i=t(39),s=t(104),c=i.set,l=i.getterFor("Array Iterator");n.exports=s(Array,"Array",(function(n,e){c(this,{type:"Array Iterator",target:r(n),index:0,kind:e})}),(function(){var n=l(this),e=n.target,t=n.kind,r=n.index++;return!e||r>=e.length?(n.target=void 0,{value:void 0,done:!0}):"keys"==t?{value:r,done:!1}:"values"==t?{value:e[r],done:!1}:{value:[r,e[r]],done:!1}}),"values"),o.Arguments=o.Array,a("keys"),a("values"),a("entries")},function(n,e,t){var r=t(5),a=t(33),o=t(13),i=r("unscopables"),s=Array.prototype;null==s[i]&&o.f(s,i,{configurable:!0,value:a(null)}),n.exports=function(n){s[i][n]=!0}},function(n,e,t){var r=t(99);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(12),a=t(3),o=t(100);n.exports=!r&&!a((function(){return 7!=Object.defineProperty(o("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(7),a=t(55),o=t(231),i=t(5)("toPrimitive");n.exports=function(n,e){if(!r(n)||a(n))return n;var t,s=n[i];if(void 0!==s){if(void 0===e&&(e="default"),t=s.call(n,e),!r(t)||a(t))return t;throw TypeError("Can't convert object to primitive value")}return void 0===e&&(e="number"),o(n,e)}},function(n,e,t){var r=t(14),a=t(22),o=t(101).indexOf,i=t(56);n.exports=function(n,e){var t,s=a(n),c=0,l=[];for(t in s)!r(i,t)&&r(s,t)&&l.push(t);for(;e.length>c;)r(s,t=e[c++])&&(~o(l,t)||l.push(t));return l}},function(n,e,t){var r=t(68),a=Math.max,o=Math.min;n.exports=function(n,e){var t=r(n);return t<0?a(t+e,0):o(t,e)}},function(n,e,t){var r=t(24);n.exports=r("document","documentElement")},function(n,e,t){var r=t(14),a=t(152),o=t(37),i=t(13);n.exports=function(n,e){for(var t=a(e),s=i.f,c=o.f,l=0;l<t.length;l++){var u=t[l];r(n,u)||s(n,u,c(e,u))}}},function(n,e,t){var r=t(24),a=t(52),o=t(106),i=t(10);n.exports=r("Reflect","ownKeys")||function(n){var e=a.f(i(n)),t=o.f;return t?e.concat(t(n)):e}},function(n,e,t){"use strict";var r,a,o,i=t(3),s=t(107),c=t(23),l=t(14),u=t(5),p=t(38),d=u("iterator"),m=!1;[].keys&&("next"in(o=[].keys())?(a=s(s(o)))!==Object.prototype&&(r=a):m=!0);var f=null==r||i((function(){var n={};return r[d].call(n)!==n}));f&&(r={}),p&&!f||l(r,d)||c(r,d,(function(){return this})),n.exports={IteratorPrototype:r,BUGGY_SAFARI_ITERATORS:m}},function(n,e,t){var r=t(3);n.exports=!r((function(){function n(){}return n.prototype.constructor=null,Object.getPrototypeOf(new n)!==n.prototype}))},function(n,e,t){var r=t(4);n.exports=r.Promise},function(n,e,t){var r=t(17);n.exports=function(n,e,t){for(var a in e)r(n,a,e[a],t);return n}},function(n,e,t){var r=t(5),a=t(57),o=r("iterator"),i=Array.prototype;n.exports=function(n){return void 0!==n&&(a.Array===n||i[o]===n)}},function(n,e,t){var r=t(159),a=t(57),o=t(5)("iterator");n.exports=function(n){if(null!=n)return n[o]||n["@@iterator"]||a[r(n)]}},function(n,e,t){var r=t(109),a=t(41),o=t(5)("toStringTag"),i="Arguments"==a(function(){return arguments}());n.exports=r?a:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=Object(n),o))?t:i?a(e):"Object"==(r=a(e))&&"function"==typeof e.callee?"Arguments":r}},function(n,e,t){var r=t(10);n.exports=function(n){var e=n.return;if(void 0!==e)return r(e.call(n)).value}},function(n,e,t){var r,a,o,i,s=t(4),c=t(3),l=t(60),u=t(150),p=t(100),d=t(162),m=t(77),f=s.setImmediate,g=s.clearImmediate,h=s.process,v=s.MessageChannel,y=s.Dispatch,b=0,S={};try{r=s.location}catch(n){}var k=function(n){if(S.hasOwnProperty(n)){var e=S[n];delete S[n],e()}},x=function(n){return function(){k(n)}},E=function(n){k(n.data)},T=function(n){s.postMessage(String(n),r.protocol+"//"+r.host)};f&&g||(f=function(n){for(var e=[],t=arguments.length,r=1;t>r;)e.push(arguments[r++]);return S[++b]=function(){("function"==typeof n?n:Function(n)).apply(void 0,e)},a(b),b},g=function(n){delete S[n]},m?a=function(n){h.nextTick(x(n))}:y&&y.now?a=function(n){y.now(x(n))}:v&&!d?(i=(o=new v).port2,o.port1.onmessage=E,a=l(i.postMessage,i,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts&&r&&"file:"!==r.protocol&&!c(T)?(a=T,s.addEventListener("message",E,!1)):a="onreadystatechange"in p("script")?function(n){u.appendChild(p("script")).onreadystatechange=function(){u.removeChild(this),k(n)}}:function(n){setTimeout(x(n),0)}),n.exports={set:f,clear:g}},function(n,e,t){var r=t(32);n.exports=/(?:iphone|ipod|ipad).*applewebkit/i.test(r)},function(n,e,t){var r=t(10),a=t(7),o=t(164);n.exports=function(n,e){if(r(n),a(e)&&e.constructor===n)return e;var t=o.f(n);return(0,t.resolve)(e),t.promise}},function(n,e,t){"use strict";var r=t(34),a=function(n){var e,t;this.promise=new n((function(n,r){if(void 0!==e||void 0!==t)throw TypeError("Bad Promise constructor");e=n,t=r})),this.resolve=r(e),this.reject=r(t)};n.exports.f=function(n){return new a(n)}},function(n,e,t){var r=t(68),a=t(16),o=t(30),i=function(n){return function(e,t){var i,s,c=a(o(e)),l=r(t),u=c.length;return l<0||l>=u?n?"":void 0:(i=c.charCodeAt(l))<55296||i>56319||l+1===u||(s=c.charCodeAt(l+1))<56320||s>57343?n?c.charAt(l):i:n?c.slice(l,l+2):s-56320+(i-55296<<10)+65536}};n.exports={codeAt:i(!1),charAt:i(!0)}},function(n,e){n.exports={CSSRuleList:0,CSSStyleDeclaration:0,CSSValueList:0,ClientRectList:0,DOMRectList:0,DOMStringList:0,DOMTokenList:1,DataTransferItemList:0,FileList:0,HTMLAllCollection:0,HTMLCollection:0,HTMLFormElement:0,HTMLSelectElement:0,MediaList:0,MimeTypeArray:0,NamedNodeMap:0,NodeList:1,PaintRequestList:0,Plugin:0,PluginArray:0,SVGLengthList:0,SVGNumberList:0,SVGPathSegList:0,SVGPointList:0,SVGStringList:0,SVGTransformList:0,SourceBufferList:0,StyleSheetList:0,TextTrackCueList:0,TextTrackList:0,TouchList:0}},function(n,e,t){var r=t(246);n.exports=function(n,e){return new(r(n))(0===e?0:e)}},function(n,e,t){var r=t(2),a=t(3),o=t(18),i=t(107),s=t(154);r({target:"Object",stat:!0,forced:a((function(){i(1)})),sham:!s},{getPrototypeOf:function(n){return i(o(n))}})},function(n,e,t){"use strict";var r=t(2),a=t(247).left,o=t(40),i=t(43),s=t(77);r({target:"Array",proto:!0,forced:!o("reduce")||!s&&i>79&&i<83},{reduce:function(n){return a(this,n,arguments.length,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(44).forEach,a=t(40)("forEach");n.exports=a?[].forEach:function(n){return r(this,n,arguments.length>1?arguments[1]:void 0)}},function(n,e,t){var r=t(3);n.exports=!r((function(){return Object.isExtensible(Object.preventExtensions({}))}))},function(n,e,t){var r=t(22),a=t(52).f,o={}.toString,i="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[];n.exports.f=function(n){return i&&"[object Window]"==o.call(n)?function(n){try{return a(n)}catch(n){return i.slice()}}(n):a(r(n))}},function(n,e,t){var r=t(5);e.f=r},function(n,e,t){var r=t(249),a=t(14),o=t(173),i=t(13).f;n.exports=function(n){var e=r.Symbol||(r.Symbol={});a(e,n)||i(e,n,{value:o.f(n)})}},function(n,e,t){t(2)({target:"Object",stat:!0,sham:!t(12)},{create:t(33)})},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,a=n.length;++t<r;)n[a+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(81),a=t(266),o=t(267),i=t(268),s=t(269),c=t(270);function l(n){var e=this.__data__=new r(n);this.size=e.size}l.prototype.clear=a,l.prototype.delete=o,l.prototype.get=i,l.prototype.has=s,l.prototype.set=c,n.exports=l},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(62),a=t(115);n.exports=function(n){if(!a(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(287),a=t(45);n.exports=function n(e,t,o,i,s){return e===t||(null==e||null==t||!a(e)&&!a(t)?e!=e&&t!=t:r(e,t,o,i,n,s))}},function(n,e,t){var r=t(184),a=t(290),o=t(185);n.exports=function(n,e,t,i,s,c){var l=1&t,u=n.length,p=e.length;if(u!=p&&!(l&&p>u))return!1;var d=c.get(n),m=c.get(e);if(d&&m)return d==e&&m==n;var f=-1,g=!0,h=2&t?new r:void 0;for(c.set(n,e),c.set(e,n);++f<u;){var v=n[f],y=e[f];if(i)var b=l?i(y,v,f,e,n,c):i(v,y,f,n,e,c);if(void 0!==b){if(b)continue;g=!1;break}if(h){if(!a(e,(function(n,e){if(!o(h,e)&&(v===n||s(v,n,t,i,c)))return h.push(e)}))){g=!1;break}}else if(v!==y&&!s(v,y,t,i,c)){g=!1;break}}return c.delete(n),c.delete(e),g}},function(n,e,t){var r=t(116),a=t(288),o=t(289);function i(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}i.prototype.add=i.prototype.push=a,i.prototype.has=o,n.exports=i},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(300),a=t(306),o=t(190);n.exports=function(n){return o(n)?r(n):a(n)}},function(n,e,t){(function(n){var r=t(25),a=t(302),o=e&&!e.nodeType&&e,i=o&&"object"==typeof n&&n&&!n.nodeType&&n,s=i&&i.exports===o?r.Buffer:void 0,c=(s?s.isBuffer:void 0)||a;n.exports=c}).call(this,t(128)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(303),a=t(304),o=t(305),i=o&&o.isTypedArray,s=i?a(i):r;n.exports=s},function(n,e,t){var r=t(180),a=t(118);n.exports=function(n){return null!=n&&a(n.length)&&!r(n)}},function(n,e,t){var r=t(42)(t(25),"Set");n.exports=r},function(n,e,t){var r=t(115);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(195),a=t(85);n.exports=function(n,e){for(var t=0,o=(e=r(e,n)).length;null!=n&&t<o;)n=n[a(e[t++])];return t&&t==o?n:void 0}},function(n,e,t){var r=t(26),a=t(119),o=t(316),i=t(319);n.exports=function(n,e){return r(n)?n:a(n,e)?[n]:o(i(n))}},function(n,e,t){"use strict";var r=t(34),a=t(7),o=[].slice,i={},s=function(n,e,t){if(!(e in i)){for(var r=[],a=0;a<e;a++)r[a]="a["+a+"]";i[e]=Function("C,a","return new C("+r.join(",")+")")}return i[e](n,t)};n.exports=Function.bind||function(n){var e=r(this),t=o.call(arguments,1),i=function(){var r=t.concat(o.call(arguments));return this instanceof i?s(e,r.length,r):e.apply(n,r)};return a(e.prototype)&&(i.prototype=e.prototype),i}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){t(2)({target:"Object",stat:!0},{setPrototypeOf:t(76)})},function(n,e,t){var r=t(2),a=t(24),o=t(34),i=t(10),s=t(7),c=t(33),l=t(196),u=t(3),p=a("Reflect","construct"),d=u((function(){function n(){}return!(p((function(){}),[],n)instanceof n)})),m=!u((function(){p((function(){}))})),f=d||m;r({target:"Reflect",stat:!0,forced:f,sham:f},{construct:function(n,e){o(n),i(e);var t=arguments.length<3?n:o(arguments[2]);if(m&&!d)return p(n,e,t);if(n==t){switch(e.length){case 0:return new n;case 1:return new n(e[0]);case 2:return new n(e[0],e[1]);case 3:return new n(e[0],e[1],e[2]);case 4:return new n(e[0],e[1],e[2],e[3])}var r=[null];return r.push.apply(r,e),new(l.apply(n,r))}var a=t.prototype,u=c(s(a)?a:Object.prototype),f=Function.apply.call(n,u,e);return s(f)?f:u}})},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(253),a=t(258),o=t(328),i=t(336),s=t(345),c=t(346),l=o((function(n){var e=c(n);return s(e)&&(e=void 0),i(r(n,1,s,!0),a(e,2))}));n.exports=l},function(n,e,t){function r(){var n;try{n=e.storage.debug}catch(n){}return!n&&"undefined"!=typeof process&&"env"in process&&(n=process.env.DEBUG),n}(e=n.exports=t(370)).log=function(){return"object"==typeof console&&console.log&&Function.prototype.apply.call(console.log,console,arguments)},e.formatArgs=function(n){var t=this.useColors;if(n[0]=(t?"%c":"")+this.namespace+(t?" %c":" ")+n[0]+(t?"%c ":" ")+"+"+e.humanize(this.diff),!t)return;var r="color: "+this.color;n.splice(1,0,r,"color: inherit");var a=0,o=0;n[0].replace(/%[a-zA-Z%]/g,(function(n){"%%"!==n&&(a++,"%c"===n&&(o=a))})),n.splice(o,0,r)},e.save=function(n){try{null==n?e.storage.removeItem("debug"):e.storage.debug=n}catch(n){}},e.load=r,e.useColors=function(){if("undefined"!=typeof window&&window.process&&"renderer"===window.process.type)return!0;return"undefined"!=typeof document&&document.documentElement&&document.documentElement.style&&document.documentElement.style.WebkitAppearance||"undefined"!=typeof window&&window.console&&(window.console.firebug||window.console.exception&&window.console.table)||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)&&parseInt(RegExp.$1,10)>=31||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/)},e.storage="undefined"!=typeof chrome&&void 0!==chrome.storage?chrome.storage.local:function(){try{return window.localStorage}catch(n){}}(),e.colors=["lightseagreen","forestgreen","goldenrod","dodgerblue","darkorchid","crimson"],e.formatters.j=function(n){try{return JSON.stringify(n)}catch(n){return"[UnexpectedJSONParseError]: "+n.message}},e.enable(r())},function(n,e,t){function r(e){return"function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?(n.exports=r=function(n){return typeof n},n.exports.default=n.exports,n.exports.__esModule=!0):(n.exports=r=function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},n.exports.default=n.exports,n.exports.__esModule=!0),r(e)}t(49),t(50),t(6),t(67),t(8),t(9),n.exports=r,n.exports.default=n.exports,n.exports.__esModule=!0},function(n,e,t){"use strict";var r=t(130),a=t(135),o=t(10),i=t(30),s=t(111),c=t(139),l=t(19),u=t(16),p=t(131),d=t(80),m=t(138),f=t(3),g=m.UNSUPPORTED_Y,h=[].push,v=Math.min;r("split",(function(n,e,t){var r;return r="c"=="abbc".split(/(b)*/)[1]||4!="test".split(/(?:)/,-1).length||2!="ab".split(/(?:ab)*/).length||4!=".".split(/(.?)(.?)/).length||".".split(/()()/).length>1||"".split(/.?/).length?function(n,t){var r=u(i(this)),o=void 0===t?4294967295:t>>>0;if(0===o)return[];if(void 0===n)return[r];if(!a(n))return e.call(r,n,o);for(var s,c,l,p=[],m=(n.ignoreCase?"i":"")+(n.multiline?"m":"")+(n.unicode?"u":"")+(n.sticky?"y":""),f=0,g=new RegExp(n.source,m+"g");(s=d.call(g,r))&&!((c=g.lastIndex)>f&&(p.push(r.slice(f,s.index)),s.length>1&&s.index<r.length&&h.apply(p,s.slice(1)),l=s[0].length,f=c,p.length>=o));)g.lastIndex===s.index&&g.lastIndex++;return f===r.length?!l&&g.test("")||p.push(""):p.push(r.slice(f)),p.length>o?p.slice(0,o):p}:"0".split(void 0,0).length?function(n,t){return void 0===n&&0===t?[]:e.call(this,n,t)}:e,[function(e,t){var a=i(this),o=null==e?void 0:e[n];return void 0!==o?o.call(e,a,t):r.call(u(a),e,t)},function(n,a){var i=o(this),d=u(n),m=t(r,i,d,a,r!==e);if(m.done)return m.value;var f=s(i,RegExp),h=i.unicode,y=(i.ignoreCase?"i":"")+(i.multiline?"m":"")+(i.unicode?"u":"")+(g?"g":"y"),b=new f(g?"^(?:"+i.source+")":i,y),S=void 0===a?4294967295:a>>>0;if(0===S)return[];if(0===d.length)return null===p(b,d)?[d]:[];for(var k=0,x=0,E=[];x<d.length;){b.lastIndex=g?0:x;var T,w=p(b,g?d.slice(x):d);if(null===w||(T=v(l(b.lastIndex+(g?x:0)),d.length))===k)x=c(d,x,h);else{if(E.push(d.slice(k,x)),E.length===S)return E;for(var C=1;C<=w.length-1;C++)if(E.push(w[C]),E.length===S)return E;x=k=T}}return E.push(d.slice(k)),E}]}),!!f((function(){var n=/(?:)/,e=n.exec;n.exec=function(){return e.apply(this,arguments)};var t="ab".split(n);return 2!==t.length||"a"!==t[0]||"b"!==t[1]})),g)},function(n,e,t){"use strict";var r,a=t(2),o=t(37).f,i=t(19),s=t(16),c=t(134),l=t(30),u=t(136),p=t(38),d="".startsWith,m=Math.min,f=u("startsWith");a({target:"String",proto:!0,forced:!!(p||f||(r=o(String.prototype,"startsWith"),!r||r.writable))&&!f},{startsWith:function(n){var e=s(l(this));c(n);var t=i(m(arguments.length>1?arguments[1]:void 0,e.length)),r=s(n);return d?d.call(e,r,t):e.slice(t,t+r.length)===r}})},function(n,e,t){"use strict";var r=t(2),a=t(122).trim;r({target:"String",proto:!0,forced:t(348)("trim")},{trim:function(){return a(this)}})},function(n,e,t){"use strict";var r=t(2),a=t(44).every;r({target:"Array",proto:!0,forced:!t(40)("every")},{every:function(n){return a(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(2),a=t(34),o=t(18),i=t(19),s=t(16),c=t(3),l=t(366),u=t(40),p=t(367),d=t(368),m=t(43),f=t(369),g=[],h=g.sort,v=c((function(){g.sort(void 0)})),y=c((function(){g.sort(null)})),b=u("sort"),S=!c((function(){if(m)return m<70;if(!(p&&p>3)){if(d)return!0;if(f)return f<603;var n,e,t,r,a="";for(n=65;n<76;n++){switch(e=String.fromCharCode(n),n){case 66:case 69:case 70:case 72:t=3;break;case 68:case 71:t=4;break;default:t=2}for(r=0;r<47;r++)g.push({k:e+r,v:t})}for(g.sort((function(n,e){return e.v-n.v})),r=0;r<g.length;r++)e=g[r].k.charAt(0),a.charAt(a.length-1)!==e&&(a+=e);return"DGBEFHACIJK"!==a}}));r({target:"Array",proto:!0,forced:v||!y||!b||!S},{sort:function(n){void 0!==n&&a(n);var e=o(this);if(S)return void 0===n?h.call(e):h.call(e,n);var t,r,c=[],u=i(e.length);for(r=0;r<u;r++)r in e&&c.push(e[r]);for(t=(c=l(c,function(n){return function(e,t){return void 0===t?-1:void 0===e?1:void 0!==n?+n(e,t)||0:s(e)>s(t)?1:-1}}(n))).length,r=0;r<t;)e[r]=c[r++];for(;r<u;)delete e[r++];return e}})},function(n,e,t){var r=t(12),a=t(13),o=t(10),i=t(74);n.exports=r?Object.defineProperties:function(n,e){o(n);for(var t,r=i(e),s=r.length,c=0;s>c;)a.f(n,t=r[c++],e[t]);return n}},function(n,e,t){var r=t(2),a=t(12),o=t(152),i=t(22),s=t(37),c=t(70);r({target:"Object",stat:!0,sham:!a},{getOwnPropertyDescriptors:function(n){for(var e,t,r=i(n),a=s.f,l=o(r),u={},p=0;l.length>p;)void 0!==(t=a(r,e=l[p++]))&&c(u,e,t);return u}})},function(n,e,t){var r=t(3);n.exports=r((function(){var n=RegExp(".","string".charAt(0));return!(n.dotAll&&n.exec("\n")&&"s"===n.flags)}))},function(n,e,t){var r=t(3);n.exports=r((function(){var n=RegExp("(?<a>b)","string".charAt(5));return"b"!==n.exec("b").groups.a||"bc"!=="b".replace(n,"$<a>c")}))},function(n,e,t){var r=t(194);n.exports=function(n,e,t){var a=null==n?void 0:r(n,e);return void 0===a?t:a}},function(n,e,t){"use strict";var r=t(349),a=t(350);n.exports=r("Set",(function(n){return function(){return n(this,arguments.length?arguments[0]:void 0)}}),a)},function(n,e,t){},function(n,e,t){var r=t(2),a=t(359);r({global:!0,forced:parseInt!=a},{parseInt:a})},function(n,e,t){n.exports=t(380)},function(n,e,t){var r=t(7);n.exports=function(n,e){var t,a;if("string"===e&&"function"==typeof(t=n.toString)&&!r(a=t.call(n)))return a;if("function"==typeof(t=n.valueOf)&&!r(a=t.call(n)))return a;if("string"!==e&&"function"==typeof(t=n.toString)&&!r(a=t.call(n)))return a;throw TypeError("Can't convert object to primitive value")}},function(n,e,t){var r=t(4),a=t(103),o=r.WeakMap;n.exports="function"==typeof o&&/native code/.test(a(o))},function(n,e,t){"use strict";var r=t(153).IteratorPrototype,a=t(33),o=t(58),i=t(59),s=t(57),c=function(){return this};n.exports=function(n,e,t){var l=e+" Iterator";return n.prototype=a(r,{next:o(1,t)}),i(n,l,!1,!0),s[l]=c,n}},function(n,e,t){var r=t(7);n.exports=function(n){if(!r(n)&&null!==n)throw TypeError("Can't set "+String(n)+" as a prototype");return n}},function(n,e,t){"use strict";var r,a,o,i,s=t(2),c=t(38),l=t(4),u=t(24),p=t(155),d=t(17),m=t(156),f=t(76),g=t(59),h=t(133),v=t(7),y=t(34),b=t(108),S=t(103),k=t(95),x=t(110),E=t(111),T=t(161).set,w=t(236),C=t(163),D=t(239),O=t(164),L=t(240),R=t(39),_=t(69),A=t(5),I=t(241),M=t(77),F=t(43),P=A("species"),N="Promise",H=R.get,B=R.set,j=R.getterFor(N),$=p&&p.prototype,U=p,W=$,J=l.TypeError,V=l.document,K=l.process,G=O.f,z=G,q=!!(V&&V.createEvent&&l.dispatchEvent),Y="function"==typeof PromiseRejectionEvent,Q=!1,X=_(N,(function(){var n=S(U),e=n!==String(U);if(!e&&66===F)return!0;if(c&&!W.finally)return!0;if(F>=51&&/native code/.test(n))return!1;var t=new U((function(n){n(1)})),r=function(n){n((function(){}),(function(){}))};return(t.constructor={})[P]=r,!(Q=t.then((function(){}))instanceof r)||!e&&I&&!Y})),Z=X||!x((function(n){U.all(n).catch((function(){}))})),nn=function(n){var e;return!(!v(n)||"function"!=typeof(e=n.then))&&e},en=function(n,e){if(!n.notified){n.notified=!0;var t=n.reactions;w((function(){for(var r=n.value,a=1==n.state,o=0;t.length>o;){var i,s,c,l=t[o++],u=a?l.ok:l.fail,p=l.resolve,d=l.reject,m=l.domain;try{u?(a||(2===n.rejection&&on(n),n.rejection=1),!0===u?i=r:(m&&m.enter(),i=u(r),m&&(m.exit(),c=!0)),i===l.promise?d(J("Promise-chain cycle")):(s=nn(i))?s.call(i,p,d):p(i)):d(r)}catch(n){m&&!c&&m.exit(),d(n)}}n.reactions=[],n.notified=!1,e&&!n.rejection&&rn(n)}))}},tn=function(n,e,t){var r,a;q?((r=V.createEvent("Event")).promise=e,r.reason=t,r.initEvent(n,!1,!0),l.dispatchEvent(r)):r={promise:e,reason:t},!Y&&(a=l["on"+n])?a(r):"unhandledrejection"===n&&D("Unhandled promise rejection",t)},rn=function(n){T.call(l,(function(){var e,t=n.facade,r=n.value;if(an(n)&&(e=L((function(){M?K.emit("unhandledRejection",r,t):tn("unhandledrejection",t,r)})),n.rejection=M||an(n)?2:1,e.error))throw e.value}))},an=function(n){return 1!==n.rejection&&!n.parent},on=function(n){T.call(l,(function(){var e=n.facade;M?K.emit("rejectionHandled",e):tn("rejectionhandled",e,n.value)}))},sn=function(n,e,t){return function(r){n(e,r,t)}},cn=function(n,e,t){n.done||(n.done=!0,t&&(n=t),n.value=e,n.state=2,en(n,!0))},ln=function(n,e,t){if(!n.done){n.done=!0,t&&(n=t);try{if(n.facade===e)throw J("Promise can't be resolved itself");var r=nn(e);r?w((function(){var t={done:!1};try{r.call(e,sn(ln,t,n),sn(cn,t,n))}catch(e){cn(t,e,n)}})):(n.value=e,n.state=1,en(n,!1))}catch(e){cn({done:!1},e,n)}}};if(X&&(W=(U=function(n){b(this,U,N),y(n),r.call(this);var e=H(this);try{n(sn(ln,e),sn(cn,e))}catch(n){cn(e,n)}}).prototype,(r=function(n){B(this,{type:N,done:!1,notified:!1,parent:!1,reactions:[],rejection:!1,state:0,value:void 0})}).prototype=m(W,{then:function(n,e){var t=j(this),r=G(E(this,U));return r.ok="function"!=typeof n||n,r.fail="function"==typeof e&&e,r.domain=M?K.domain:void 0,t.parent=!0,t.reactions.push(r),0!=t.state&&en(t,!1),r.promise},catch:function(n){return this.then(void 0,n)}}),a=function(){var n=new r,e=H(n);this.promise=n,this.resolve=sn(ln,e),this.reject=sn(cn,e)},O.f=G=function(n){return n===U||n===o?new a(n):z(n)},!c&&"function"==typeof p&&$!==Object.prototype)){i=$.then,Q||(d($,"then",(function(n,e){var t=this;return new U((function(n,e){i.call(t,n,e)})).then(n,e)}),{unsafe:!0}),d($,"catch",W.catch,{unsafe:!0}));try{delete $.constructor}catch(n){}f&&f($,W)}s({global:!0,wrap:!0,forced:X},{Promise:U}),g(U,N,!1,!0),h(N),o=u(N),s({target:N,stat:!0,forced:X},{reject:function(n){var e=G(this);return e.reject.call(void 0,n),e.promise}}),s({target:N,stat:!0,forced:c||X},{resolve:function(n){return C(c&&this===o?U:this,n)}}),s({target:N,stat:!0,forced:Z},{all:function(n){var e=this,t=G(e),r=t.resolve,a=t.reject,o=L((function(){var t=y(e.resolve),o=[],i=0,s=1;k(n,(function(n){var c=i++,l=!1;o.push(void 0),s++,t.call(e,n).then((function(n){l||(l=!0,o[c]=n,--s||r(o))}),a)})),--s||r(o)}));return o.error&&a(o.value),t.promise},race:function(n){var e=this,t=G(e),r=t.reject,a=L((function(){var a=y(e.resolve);k(n,(function(n){a.call(e,n).then(t.resolve,r)}))}));return a.error&&r(a.value),t.promise}})},function(n,e,t){var r,a,o,i,s,c,l,u,p=t(4),d=t(37).f,m=t(161).set,f=t(162),g=t(237),h=t(238),v=t(77),y=p.MutationObserver||p.WebKitMutationObserver,b=p.document,S=p.process,k=p.Promise,x=d(p,"queueMicrotask"),E=x&&x.value;E||(r=function(){var n,e;for(v&&(n=S.domain)&&n.exit();a;){e=a.fn,a=a.next;try{e()}catch(n){throw a?i():o=void 0,n}}o=void 0,n&&n.enter()},f||v||h||!y||!b?!g&&k&&k.resolve?((l=k.resolve(void 0)).constructor=k,u=l.then,i=function(){u.call(l,r)}):i=v?function(){S.nextTick(r)}:function(){m.call(p,r)}:(s=!0,c=b.createTextNode(""),new y(r).observe(c,{characterData:!0}),i=function(){c.data=s=!s})),n.exports=E||function(n){var e={fn:n,next:void 0};o&&(o.next=e),a||(a=e,i()),o=e}},function(n,e,t){var r=t(32),a=t(4);n.exports=/iphone|ipod|ipad/i.test(r)&&void 0!==a.Pebble},function(n,e,t){var r=t(32);n.exports=/web0s(?!.*chrome)/i.test(r)},function(n,e,t){var r=t(4);n.exports=function(n,e){var t=r.console;t&&t.error&&(1===arguments.length?t.error(n):t.error(n,e))}},function(n,e){n.exports=function(n){try{return{error:!1,value:n()}}catch(n){return{error:!0,value:n}}}},function(n,e){n.exports="object"==typeof window},function(n,e,t){var r=t(2),a=t(243);r({target:"Object",stat:!0,forced:Object.assign!==a},{assign:a})},function(n,e,t){"use strict";var r=t(12),a=t(3),o=t(74),i=t(106),s=t(105),c=t(18),l=t(54),u=Object.assign,p=Object.defineProperty;n.exports=!u||a((function(){if(r&&1!==u({b:1},u(p({},"a",{enumerable:!0,get:function(){p(this,"b",{value:3,enumerable:!1})}}),{b:2})).b)return!0;var n={},e={},t=Symbol();return n[t]=7,"abcdefghijklmnopqrst".split("").forEach((function(n){e[n]=n})),7!=u({},n)[t]||"abcdefghijklmnopqrst"!=o(u({},e)).join("")}))?function(n,e){for(var t=c(n),a=arguments.length,u=1,p=i.f,d=s.f;a>u;)for(var m,f=l(arguments[u++]),g=p?o(f).concat(p(f)):o(f),h=g.length,v=0;h>v;)m=g[v++],r&&!d.call(f,m)||(t[m]=f[m]);return t}:u},function(n,e,t){"use strict";var r=t(2),a=t(38),o=t(155),i=t(3),s=t(24),c=t(111),l=t(163),u=t(17);if(r({target:"Promise",proto:!0,real:!0,forced:!!o&&i((function(){o.prototype.finally.call({then:function(){}},(function(){}))}))},{finally:function(n){var e=c(this,s("Promise")),t="function"==typeof n;return this.then(t?function(t){return l(e,n()).then((function(){return t}))}:n,t?function(t){return l(e,n()).then((function(){throw t}))}:n)}}),!a&&"function"==typeof o){var p=s("Promise").prototype.finally;o.prototype.finally!==p&&u(o.prototype,"finally",p,{unsafe:!0})}},function(n,e,t){"use strict";var r=t(109),a=t(159);n.exports=r?{}.toString:function(){return"[object "+a(this)+"]"}},function(n,e,t){var r=t(7),a=t(53),o=t(5)("species");n.exports=function(n){var e;return a(n)&&("function"!=typeof(e=n.constructor)||e!==Array&&!a(e.prototype)?r(e)&&null===(e=e[o])&&(e=void 0):e=void 0),void 0===e?Array:e}},function(n,e,t){var r=t(34),a=t(18),o=t(54),i=t(19),s=function(n){return function(e,t,s,c){r(t);var l=a(e),u=o(l),p=i(l.length),d=n?p-1:0,m=n?-1:1;if(s<2)for(;;){if(d in u){c=u[d],d+=m;break}if(d+=m,n?d<0:p<=d)throw TypeError("Reduce of empty array with no initial value")}for(;n?d>=0:p>d;d+=m)d in u&&(c=t(c,u[d],d,l));return c}};n.exports={left:s(!1),right:s(!0)}},function(n,e,t){var r=t(2),a=t(171),o=t(3),i=t(7),s=t(112).onFreeze,c=Object.freeze;r({target:"Object",stat:!0,forced:o((function(){c(1)})),sham:!a},{freeze:function(n){return c&&i(n)?c(s(n)):n}})},function(n,e,t){var r=t(4);n.exports=r},function(n,e,t){"use strict";var r=t(60),a=t(18),o=t(251),i=t(157),s=t(19),c=t(70),l=t(158);n.exports=function(n){var e,t,u,p,d,m,f=a(n),g="function"==typeof this?this:Array,h=arguments.length,v=h>1?arguments[1]:void 0,y=void 0!==v,b=l(f),S=0;if(y&&(v=r(v,h>2?arguments[2]:void 0,2)),null==b||g==Array&&i(b))for(t=new g(e=s(f.length));e>S;S++)m=y?v(f[S],S):f[S],c(t,S,m);else for(d=(p=b.call(f)).next,t=new g;!(u=d.call(p)).done;S++)m=y?o(p,v,[u.value,S],!0):u.value,c(t,S,m);return t.length=S,t}},function(n,e,t){var r=t(10),a=t(160);n.exports=function(n,e,t,o){try{return o?e(r(t)[0],t[1]):e(t)}catch(e){throw a(n),e}}},function(n,e,t){var r=t(18),a=Math.floor,o="".replace,i=/\$([$&'`]|\d{1,2}|<[^>]*>)/g,s=/\$([$&'`]|\d{1,2})/g;n.exports=function(n,e,t,c,l,u){var p=t+n.length,d=c.length,m=s;return void 0!==l&&(l=r(l),m=i),o.call(u,m,(function(r,o){var i;switch(o.charAt(0)){case"$":return"$";case"&":return n;case"`":return e.slice(0,t);case"'":return e.slice(p);case"<":i=l[o.slice(1,-1)];break;default:var s=+o;if(0===s)return r;if(s>d){var u=a(s/10);return 0===u?r:u<=d?void 0===c[u-1]?o.charAt(1):c[u-1]+o.charAt(1):r}i=c[s-1]}return void 0===i?"":i}))}},function(n,e,t){var r=t(176),a=t(254);n.exports=function n(e,t,o,i,s){var c=-1,l=e.length;for(o||(o=a),s||(s=[]);++c<l;){var u=e[c];t>0&&o(u)?t>1?n(u,t-1,o,i,s):r(s,u):i||(s[s.length]=u)}return s}},function(n,e,t){var r=t(61),a=t(113),o=t(26),i=r?r.isConcatSpreadable:void 0;n.exports=function(n){return o(n)||a(n)||!!(i&&n&&n[i])}},function(n,e,t){var r=t(62),a=t(45);n.exports=function(n){return a(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(61),a=Object.prototype,o=a.hasOwnProperty,i=a.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=o.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var a=i.call(n);return r&&(e?n[s]=t:delete n[s]),a}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(259),a=t(315),o=t(121),i=t(26),s=t(325);n.exports=function(n){return"function"==typeof n?n:null==n?o:"object"==typeof n?i(n)?a(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(260),a=t(314),o=t(193);n.exports=function(n){var e=a(n);return 1==e.length&&e[0][2]?o(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(178),a=t(182);n.exports=function(n,e,t,o){var i=t.length,s=i,c=!o;if(null==n)return!s;for(n=Object(n);i--;){var l=t[i];if(c&&l[2]?l[1]!==n[l[0]]:!(l[0]in n))return!1}for(;++i<s;){var u=(l=t[i])[0],p=n[u],d=l[1];if(c&&l[2]){if(void 0===p&&!(u in n))return!1}else{var m=new r;if(o)var f=o(p,d,u,n,e,m);if(!(void 0===f?a(d,p,3,o,m):f))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(82),a=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():a.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(82);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(82);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(82);n.exports=function(n,e){var t=this.__data__,a=r(t,n);return a<0?(++this.size,t.push([n,e])):t[a][1]=e,this}},function(n,e,t){var r=t(81);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(81),a=t(114),o=t(116);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var i=t.__data__;if(!a||i.length<199)return i.push([n,e]),this.size=++t.size,this;t=this.__data__=new o(i)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(180),a=t(272),o=t(115),i=t(181),s=/^\[object .+?Constructor\]$/,c=Function.prototype,l=Object.prototype,u=c.toString,p=l.hasOwnProperty,d=RegExp("^"+u.call(p).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!o(n)||a(n))&&(r(n)?d:s).test(i(n))}},function(n,e,t){var r,a=t(273),o=(r=/[^.]+$/.exec(a&&a.keys&&a.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!o&&o in n}},function(n,e,t){var r=t(25)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(276),a=t(81),o=t(114);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(o||a),string:new r}}},function(n,e,t){var r=t(277),a=t(278),o=t(279),i=t(280),s=t(281);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(83);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(83),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return a.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(83),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:a.call(e,n)}},function(n,e,t){var r=t(83);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(84);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(84);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(84);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(84);n.exports=function(n,e){var t=r(this,n),a=t.size;return t.set(n,e),this.size+=t.size==a?0:1,this}},function(n,e,t){var r=t(178),a=t(183),o=t(291),i=t(294),s=t(310),c=t(26),l=t(187),u=t(189),p="[object Object]",d=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,f,g){var h=c(n),v=c(e),y=h?"[object Array]":s(n),b=v?"[object Array]":s(e),S=(y="[object Arguments]"==y?p:y)==p,k=(b="[object Arguments]"==b?p:b)==p,x=y==b;if(x&&l(n)){if(!l(e))return!1;h=!0,S=!1}if(x&&!S)return g||(g=new r),h||u(n)?a(n,e,t,m,f,g):o(n,e,y,t,m,f,g);if(!(1&t)){var E=S&&d.call(n,"__wrapped__"),T=k&&d.call(e,"__wrapped__");if(E||T){var w=E?n.value():n,C=T?e.value():e;return g||(g=new r),f(w,C,t,m,g)}}return!!x&&(g||(g=new r),i(n,e,t,m,f,g))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(61),a=t(292),o=t(179),i=t(183),s=t(293),c=t(117),l=r?r.prototype:void 0,u=l?l.valueOf:void 0;n.exports=function(n,e,t,r,l,p,d){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!p(new a(n),new a(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return o(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=s;case"[object Set]":var f=1&r;if(m||(m=c),n.size!=e.size&&!f)return!1;var g=d.get(n);if(g)return g==e;r|=2,d.set(n,e);var h=i(m(n),m(e),r,l,p,d);return d.delete(n),h;case"[object Symbol]":if(u)return u.call(n)==u.call(e)}return!1}},function(n,e,t){var r=t(25).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(295),a=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,o,i,s){var c=1&t,l=r(n),u=l.length;if(u!=r(e).length&&!c)return!1;for(var p=u;p--;){var d=l[p];if(!(c?d in e:a.call(e,d)))return!1}var m=s.get(n),f=s.get(e);if(m&&f)return m==e&&f==n;var g=!0;s.set(n,e),s.set(e,n);for(var h=c;++p<u;){var v=n[d=l[p]],y=e[d];if(o)var b=c?o(y,v,d,e,n,s):o(v,y,d,n,e,s);if(!(void 0===b?v===y||i(v,y,t,o,s):b)){g=!1;break}h||(h="constructor"==d)}if(g&&!h){var S=n.constructor,k=e.constructor;S==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof S&&S instanceof S&&"function"==typeof k&&k instanceof k||(g=!1)}return s.delete(n),s.delete(e),g}},function(n,e,t){var r=t(296),a=t(297),o=t(186);n.exports=function(n){return r(n,o,a)}},function(n,e,t){var r=t(176),a=t(26);n.exports=function(n,e,t){var o=e(n);return a(n)?o:r(o,t(n))}},function(n,e,t){var r=t(298),a=t(299),o=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,s=i?function(n){return null==n?[]:(n=Object(n),r(i(n),(function(e){return o.call(n,e)})))}:a;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=0,o=[];++t<r;){var i=n[t];e(i,t,n)&&(o[a++]=i)}return o}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(301),a=t(113),o=t(26),i=t(187),s=t(188),c=t(189),l=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=o(n),u=!t&&a(n),p=!t&&!u&&i(n),d=!t&&!u&&!p&&c(n),m=t||u||p||d,f=m?r(n.length,String):[],g=f.length;for(var h in n)!e&&!l.call(n,h)||m&&("length"==h||p&&("offset"==h||"parent"==h)||d&&("buffer"==h||"byteLength"==h||"byteOffset"==h)||s(h,g))||f.push(h);return f}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(62),a=t(118),o=t(45),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,n.exports=function(n){return o(n)&&a(n.length)&&!!i[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(177),a=e&&!e.nodeType&&e,o=a&&"object"==typeof n&&n&&!n.nodeType&&n,i=o&&o.exports===a&&r.process,s=function(){try{var n=o&&o.require&&o.require("util").types;return n||i&&i.binding&&i.binding("util")}catch(n){}}();n.exports=s}).call(this,t(128)(n))},function(n,e,t){var r=t(307),a=t(308),o=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return a(n);var e=[];for(var t in Object(n))o.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(309)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(311),a=t(114),o=t(312),i=t(191),s=t(313),c=t(62),l=t(181),u=l(r),p=l(a),d=l(o),m=l(i),f=l(s),g=c;(r&&"[object DataView]"!=g(new r(new ArrayBuffer(1)))||a&&"[object Map]"!=g(new a)||o&&"[object Promise]"!=g(o.resolve())||i&&"[object Set]"!=g(new i)||s&&"[object WeakMap]"!=g(new s))&&(g=function(n){var e=c(n),t="[object Object]"==e?n.constructor:void 0,r=t?l(t):"";if(r)switch(r){case u:return"[object DataView]";case p:return"[object Map]";case d:return"[object Promise]";case m:return"[object Set]";case f:return"[object WeakMap]"}return e}),n.exports=g},function(n,e,t){var r=t(42)(t(25),"DataView");n.exports=r},function(n,e,t){var r=t(42)(t(25),"Promise");n.exports=r},function(n,e,t){var r=t(42)(t(25),"WeakMap");n.exports=r},function(n,e,t){var r=t(192),a=t(186);n.exports=function(n){for(var e=a(n),t=e.length;t--;){var o=e[t],i=n[o];e[t]=[o,i,r(i)]}return e}},function(n,e,t){var r=t(182),a=t(226),o=t(322),i=t(119),s=t(192),c=t(193),l=t(85);n.exports=function(n,e){return i(n)&&s(e)?c(l(n),e):function(t){var i=a(t,n);return void 0===i&&i===e?o(t,n):r(e,i,3)}}},function(n,e,t){var r=t(317),a=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,o=/\\(\\)?/g,i=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(a,(function(n,t,r,a){e.push(r?a.replace(o,"$1"):t||n)})),e}));n.exports=i},function(n,e,t){var r=t(318);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(116);function a(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,a=e?e.apply(this,r):r[0],o=t.cache;if(o.has(a))return o.get(a);var i=n.apply(this,r);return t.cache=o.set(a,i)||o,i};return t.cache=new(a.Cache||r),t}a.Cache=r,n.exports=a},function(n,e,t){var r=t(320);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(61),a=t(321),o=t(26),i=t(120),s=r?r.prototype:void 0,c=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(o(e))return a(e,n)+"";if(i(e))return c?c.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=Array(r);++t<r;)a[t]=e(n[t],t,n);return a}},function(n,e,t){var r=t(323),a=t(324);n.exports=function(n,e){return null!=n&&a(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(195),a=t(113),o=t(26),i=t(188),s=t(118),c=t(85);n.exports=function(n,e,t){for(var l=-1,u=(e=r(e,n)).length,p=!1;++l<u;){var d=c(e[l]);if(!(p=null!=n&&t(n,d)))break;n=n[d]}return p||++l!=u?p:!!(u=null==n?0:n.length)&&s(u)&&i(d,u)&&(o(n)||a(n))}},function(n,e,t){var r=t(326),a=t(327),o=t(119),i=t(85);n.exports=function(n){return o(n)?r(i(n)):a(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(194);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(121),a=t(329),o=t(331);n.exports=function(n,e){return o(a(n,e,r),n+"")}},function(n,e,t){var r=t(330),a=Math.max;n.exports=function(n,e,t){return e=a(void 0===e?n.length-1:e,0),function(){for(var o=arguments,i=-1,s=a(o.length-e,0),c=Array(s);++i<s;)c[i]=o[e+i];i=-1;for(var l=Array(e+1);++i<e;)l[i]=o[i];return l[e]=t(c),r(n,this,l)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(332),a=t(335)(r);n.exports=a},function(n,e,t){var r=t(333),a=t(334),o=t(121),i=a?function(n,e){return a(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:o;n.exports=i},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(42),a=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=a},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var a=t(),o=16-(a-r);if(r=a,o>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(184),a=t(337),o=t(342),i=t(185),s=t(343),c=t(117);n.exports=function(n,e,t){var l=-1,u=a,p=n.length,d=!0,m=[],f=m;if(t)d=!1,u=o;else if(p>=200){var g=e?null:s(n);if(g)return c(g);d=!1,u=i,f=new r}else f=e?[]:m;n:for(;++l<p;){var h=n[l],v=e?e(h):h;if(h=t||0!==h?h:0,d&&v==v){for(var y=f.length;y--;)if(f[y]===v)continue n;e&&f.push(v),m.push(h)}else u(f,v,t)||(f!==m&&f.push(v),m.push(h))}return m}},function(n,e,t){var r=t(338);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(339),a=t(340),o=t(341);n.exports=function(n,e,t){return e==e?o(n,e,t):r(n,a,t)}},function(n,e){n.exports=function(n,e,t,r){for(var a=n.length,o=t+(r?1:-1);r?o--:++o<a;)if(e(n[o],o,n))return o;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,a=n.length;++r<a;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,a=null==n?0:n.length;++r<a;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(191),a=t(344),o=t(117),i=r&&1/o(new r([,-0]))[1]==1/0?function(n){return new r(n)}:a;n.exports=i},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(190),a=t(45);n.exports=function(n){return a(n)&&r(n)}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){},function(n,e,t){var r=t(3),a=t(123);n.exports=function(n){return r((function(){return!!a[n]()||"​᠎"!="​᠎"[n]()||a[n].name!==n}))}},function(n,e,t){"use strict";var r=t(2),a=t(4),o=t(69),i=t(17),s=t(112),c=t(95),l=t(108),u=t(7),p=t(3),d=t(110),m=t(59),f=t(140);n.exports=function(n,e,t){var g=-1!==n.indexOf("Map"),h=-1!==n.indexOf("Weak"),v=g?"set":"add",y=a[n],b=y&&y.prototype,S=y,k={},x=function(n){var e=b[n];i(b,n,"add"==n?function(n){return e.call(this,0===n?0:n),this}:"delete"==n?function(n){return!(h&&!u(n))&&e.call(this,0===n?0:n)}:"get"==n?function(n){return h&&!u(n)?void 0:e.call(this,0===n?0:n)}:"has"==n?function(n){return!(h&&!u(n))&&e.call(this,0===n?0:n)}:function(n,t){return e.call(this,0===n?0:n,t),this})};if(o(n,"function"!=typeof y||!(h||b.forEach&&!p((function(){(new y).entries().next()})))))S=t.getConstructor(e,n,g,v),s.enable();else if(o(n,!0)){var E=new S,T=E[v](h?{}:-0,1)!=E,w=p((function(){E.has(1)})),C=d((function(n){new y(n)})),D=!h&&p((function(){for(var n=new y,e=5;e--;)n[v](e,e);return!n.has(-0)}));C||((S=e((function(e,t){l(e,S,n);var r=f(new y,e,S);return null!=t&&c(t,r[v],{that:r,AS_ENTRIES:g}),r}))).prototype=b,b.constructor=S),(w||D)&&(x("delete"),x("has"),g&&x("get")),(D||T)&&x(v),h&&b.clear&&delete b.clear}return k[n]=S,r({global:!0,forced:S!=y},k),m(S,n),h||t.setStrong(S,n,g),S}},function(n,e,t){"use strict";var r=t(13).f,a=t(33),o=t(156),i=t(60),s=t(108),c=t(95),l=t(104),u=t(133),p=t(12),d=t(112).fastKey,m=t(39),f=m.set,g=m.getterFor;n.exports={getConstructor:function(n,e,t,l){var u=n((function(n,r){s(n,u,e),f(n,{type:e,index:a(null),first:void 0,last:void 0,size:0}),p||(n.size=0),null!=r&&c(r,n[l],{that:n,AS_ENTRIES:t})})),m=g(e),h=function(n,e,t){var r,a,o=m(n),i=v(n,e);return i?i.value=t:(o.last=i={index:a=d(e,!0),key:e,value:t,previous:r=o.last,next:void 0,removed:!1},o.first||(o.first=i),r&&(r.next=i),p?o.size++:n.size++,"F"!==a&&(o.index[a]=i)),n},v=function(n,e){var t,r=m(n),a=d(e);if("F"!==a)return r.index[a];for(t=r.first;t;t=t.next)if(t.key==e)return t};return o(u.prototype,{clear:function(){for(var n=m(this),e=n.index,t=n.first;t;)t.removed=!0,t.previous&&(t.previous=t.previous.next=void 0),delete e[t.index],t=t.next;n.first=n.last=void 0,p?n.size=0:this.size=0},delete:function(n){var e=m(this),t=v(this,n);if(t){var r=t.next,a=t.previous;delete e.index[t.index],t.removed=!0,a&&(a.next=r),r&&(r.previous=a),e.first==t&&(e.first=r),e.last==t&&(e.last=a),p?e.size--:this.size--}return!!t},forEach:function(n){for(var e,t=m(this),r=i(n,arguments.length>1?arguments[1]:void 0,3);e=e?e.next:t.first;)for(r(e.value,e.key,this);e&&e.removed;)e=e.previous},has:function(n){return!!v(this,n)}}),o(u.prototype,t?{get:function(n){var e=v(this,n);return e&&e.value},set:function(n,e){return h(this,0===n?0:n,e)}}:{add:function(n){return h(this,n=0===n?0:n,n)}}),p&&r(u.prototype,"size",{get:function(){return m(this).size}}),u},setStrong:function(n,e,t){var r=e+" Iterator",a=g(e),o=g(r);l(n,e,(function(n,e){f(this,{type:r,target:n,state:a(n),kind:e,last:void 0})}),(function(){for(var n=o(this),e=n.kind,t=n.last;t&&t.removed;)t=t.previous;return n.target&&(n.last=t=t?t.next:n.state.first)?"keys"==e?{value:t.key,done:!1}:"values"==e?{value:t.value,done:!1}:{value:[t.key,t.value],done:!1}:(n.target=void 0,{value:void 0,done:!0})}),t?"entries":"values",!t,!0),u(e)}}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(197)},function(n,e,t){"use strict";t(198)},function(n,e,t){"use strict";t(199)},function(n,e,t){"use strict";t(200)},function(n,e,t){"use strict";t(201)},function(n,e,t){var r=t(4),a=t(16),o=t(122).trim,i=t(123),s=r.parseInt,c=/^[+-]?0[Xx]/,l=8!==s(i+"08")||22!==s(i+"0x16");n.exports=l?function(n,e){var t=o(a(n));return s(t,e>>>0||(c.test(t)?16:10))}:s},function(n,e,t){"use strict";t(202)},function(n,e,t){"use strict";t(203)},function(n,e,t){"use strict";t(204)},function(n,e,t){"use strict";t(205)},function(n,e,t){"use strict";t(206)},function(n,e,t){},function(n,e){var t=Math.floor,r=function(n,e){var i=n.length,s=t(i/2);return i<8?a(n,e):o(r(n.slice(0,s),e),r(n.slice(s),e),e)},a=function(n,e){for(var t,r,a=n.length,o=1;o<a;){for(r=o,t=n[o];r&&e(n[r-1],t)>0;)n[r]=n[--r];r!==o++&&(n[r]=t)}return n},o=function(n,e,t){for(var r=n.length,a=e.length,o=0,i=0,s=[];o<r||i<a;)o<r&&i<a?s.push(t(n[o],e[i])<=0?n[o++]:e[i++]):s.push(o<r?n[o++]:e[i++]);return s};n.exports=r},function(n,e,t){var r=t(32).match(/firefox\/(\d+)/i);n.exports=!!r&&+r[1]},function(n,e,t){var r=t(32);n.exports=/MSIE|Trident/.test(r)},function(n,e,t){var r=t(32).match(/AppleWebKit\/(\d+)\./);n.exports=!!r&&+r[1]},function(n,e,t){var r;function a(n){function t(){if(t.enabled){var n=t,a=+new Date,o=a-(r||a);n.diff=o,n.prev=r,n.curr=a,r=a;for(var i=new Array(arguments.length),s=0;s<i.length;s++)i[s]=arguments[s];i[0]=e.coerce(i[0]),"string"!=typeof i[0]&&i.unshift("%O");var c=0;i[0]=i[0].replace(/%([a-zA-Z%])/g,(function(t,r){if("%%"===t)return t;c++;var a=e.formatters[r];if("function"==typeof a){var o=i[c];t=a.call(n,o),i.splice(c,1),c--}return t})),e.formatArgs.call(n,i);var l=t.log||e.log||console.log.bind(console);l.apply(n,i)}}return t.namespace=n,t.enabled=e.enabled(n),t.useColors=e.useColors(),t.color=function(n){var t,r=0;for(t in n)r=(r<<5)-r+n.charCodeAt(t),r|=0;return e.colors[Math.abs(r)%e.colors.length]}(n),"function"==typeof e.init&&e.init(t),t}(e=n.exports=a.debug=a.default=a).coerce=function(n){return n instanceof Error?n.stack||n.message:n},e.disable=function(){e.enable("")},e.enable=function(n){e.save(n),e.names=[],e.skips=[];for(var t=("string"==typeof n?n:"").split(/[\s,]+/),r=t.length,a=0;a<r;a++)t[a]&&("-"===(n=t[a].replace(/\*/g,".*?"))[0]?e.skips.push(new RegExp("^"+n.substr(1)+"$")):e.names.push(new RegExp("^"+n+"$")))},e.enabled=function(n){var t,r;for(t=0,r=e.skips.length;t<r;t++)if(e.skips[t].test(n))return!1;for(t=0,r=e.names.length;t<r;t++)if(e.names[t].test(n))return!0;return!1},e.humanize=t(371),e.names=[],e.skips=[],e.formatters={}},function(n,e){var t=1e3,r=6e4,a=60*r,o=24*a;function i(n,e,t){if(!(n<e))return n<1.5*e?Math.floor(n/e)+" "+t:Math.ceil(n/e)+" "+t+"s"}n.exports=function(n,e){e=e||{};var s,c=typeof n;if("string"===c&&n.length>0)return function(n){if((n=String(n)).length>100)return;var e=/^((?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(n);if(!e)return;var i=parseFloat(e[1]);switch((e[2]||"ms").toLowerCase()){case"years":case"year":case"yrs":case"yr":case"y":return 315576e5*i;case"days":case"day":case"d":return i*o;case"hours":case"hour":case"hrs":case"hr":case"h":return i*a;case"minutes":case"minute":case"mins":case"min":case"m":return i*r;case"seconds":case"second":case"secs":case"sec":case"s":return i*t;case"milliseconds":case"millisecond":case"msecs":case"msec":case"ms":return i;default:return}}(n);if("number"===c&&!1===isNaN(n))return e.long?i(s=n,o,"day")||i(s,a,"hour")||i(s,r,"minute")||i(s,t,"second")||s+" ms":function(n){if(n>=o)return Math.round(n/o)+"d";if(n>=a)return Math.round(n/a)+"h";if(n>=r)return Math.round(n/r)+"m";if(n>=t)return Math.round(n/t)+"s";return n+"ms"}(n);throw new Error("val is not a non-empty string or a valid number. val="+JSON.stringify(n))}},function(n,e,t){},function(n,e,t){"use strict";t(207)},function(n,e,t){},function(n,e,t){"use strict";t(208)},function(n,e,t){},function(n,e,t){"use strict";t(209)},function(n,e,t){"use strict";t(212)},function(n,e,t){"use strict";t(213)},function(n,e,t){"use strict";t.r(e);t(143),t(235),t(242),t(244),t(6);function r(n,e,t,r,a,o,i){try{var s=n[o](i),c=s.value}catch(n){return void t(n)}s.done?e(c):Promise.resolve(c).then(r,a)}function a(n){return function(){var e=this,t=arguments;return new Promise((function(a,o){var i=n.apply(e,t);function s(n){r(i,a,o,s,c,"next",n)}function c(n){r(i,a,o,s,c,"throw",n)}s(void 0)}))}}t(78),t(36),t(8),t(9),t(27),t(28);var o=t(0);function i(n,e){for(var t in e)n[t]=e[t];return n}var s=/[!'()*]/g,c=function(n){return"%"+n.charCodeAt(0).toString(16)},l=/%2C/g,u=function(n){return encodeURIComponent(n).replace(s,c).replace(l,",")};function p(n){try{return decodeURIComponent(n)}catch(n){0}return n}var d=function(n){return null==n||"object"==typeof n?n:String(n)};function m(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=p(t.shift()),a=t.length>0?p(t.join("=")):null;void 0===e[r]?e[r]=a:Array.isArray(e[r])?e[r].push(a):e[r]=[e[r],a]})),e):e}function f(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return u(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(u(e)):r.push(u(e)+"="+u(n)))})),r.join("&")}return u(e)+"="+u(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var g=/\/?$/;function h(n,e,t,r){var a=r&&r.options.stringifyQuery,o=e.query||{};try{o=v(o)}catch(n){}var i={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:o,params:e.params||{},fullPath:S(e,a),matched:n?b(n):[]};return t&&(i.redirectedFrom=S(t,a)),Object.freeze(i)}function v(n){if(Array.isArray(n))return n.map(v);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=v(n[t]);return e}return n}var y=h(null,{path:"/"});function b(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function S(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var a=n.hash;return void 0===a&&(a=""),(t||"/")+(e||f)(r)+a}function k(n,e,t){return e===y?n===e:!!e&&(n.path&&e.path?n.path.replace(g,"")===e.path.replace(g,"")&&(t||n.hash===e.hash&&x(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&x(n.query,e.query)&&x(n.params,e.params))))}function x(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,a){var o=n[t];if(r[a]!==t)return!1;var i=e[t];return null==o||null==i?o===i:"object"==typeof o&&"object"==typeof i?x(o,i):String(o)===String(i)}))}function E(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var a=t.instances[r],o=t.enteredCbs[r];if(a&&o){delete t.enteredCbs[r];for(var i=0;i<o.length;i++)a._isBeingDestroyed||o[i](a)}}}}var T={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,a=e.parent,o=e.data;o.routerView=!0;for(var s=a.$createElement,c=t.name,l=a.$route,u=a._routerViewCache||(a._routerViewCache={}),p=0,d=!1;a&&a._routerRoot!==a;){var m=a.$vnode?a.$vnode.data:{};m.routerView&&p++,m.keepAlive&&a._directInactive&&a._inactive&&(d=!0),a=a.$parent}if(o.routerViewDepth=p,d){var f=u[c],g=f&&f.component;return g?(f.configProps&&w(g,o,f.route,f.configProps),s(g,o,r)):s()}var h=l.matched[p],v=h&&h.components[c];if(!h||!v)return u[c]=null,s();u[c]={component:v},o.registerRouteInstance=function(n,e){var t=h.instances[c];(e&&t!==n||!e&&t===n)&&(h.instances[c]=e)},(o.hook||(o.hook={})).prepatch=function(n,e){h.instances[c]=e.componentInstance},o.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==h.instances[c]&&(h.instances[c]=n.componentInstance),E(l)};var y=h.props&&h.props[c];return y&&(i(u[c],{route:l,configProps:y}),w(v,o,l,y)),s(v,o,r)}};function w(n,e,t,r){var a=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(a){a=e.props=i({},a);var o=e.attrs=e.attrs||{};for(var s in a)n.props&&s in n.props||(o[s]=a[s],delete a[s])}}function C(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var a=e.split("/");t&&a[a.length-1]||a.pop();for(var o=n.replace(/^\//,"").split("/"),i=0;i<o.length;i++){var s=o[i];".."===s?a.pop():"."!==s&&a.push(s)}return""!==a[0]&&a.unshift(""),a.join("/")}function D(n){return n.replace(/\/\//g,"/")}var O=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},L=W,R=F,_=function(n,e){return N(F(n,e),e)},A=N,I=U,M=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function F(n,e){for(var t,r=[],a=0,o=0,i="",s=e&&e.delimiter||"/";null!=(t=M.exec(n));){var c=t[0],l=t[1],u=t.index;if(i+=n.slice(o,u),o=u+c.length,l)i+=l[1];else{var p=n[o],d=t[2],m=t[3],f=t[4],g=t[5],h=t[6],v=t[7];i&&(r.push(i),i="");var y=null!=d&&null!=p&&p!==d,b="+"===h||"*"===h,S="?"===h||"*"===h,k=t[2]||s,x=f||g;r.push({name:m||a++,prefix:d||"",delimiter:k,optional:S,repeat:b,partial:y,asterisk:!!v,pattern:x?B(x):v?".*":"[^"+H(k)+"]+?"})}}return o<n.length&&(i+=n.substr(o)),i&&r.push(i),r}function P(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function N(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",$(e)));return function(e,r){for(var a="",o=e||{},i=(r||{}).pretty?P:encodeURIComponent,s=0;s<n.length;s++){var c=n[s];if("string"!=typeof c){var l,u=o[c.name];if(null==u){if(c.optional){c.partial&&(a+=c.prefix);continue}throw new TypeError('Expected "'+c.name+'" to be defined')}if(O(u)){if(!c.repeat)throw new TypeError('Expected "'+c.name+'" to not repeat, but received `'+JSON.stringify(u)+"`");if(0===u.length){if(c.optional)continue;throw new TypeError('Expected "'+c.name+'" to not be empty')}for(var p=0;p<u.length;p++){if(l=i(u[p]),!t[s].test(l))throw new TypeError('Expected all "'+c.name+'" to match "'+c.pattern+'", but received `'+JSON.stringify(l)+"`");a+=(0===p?c.prefix:c.delimiter)+l}}else{if(l=c.asterisk?encodeURI(u).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):i(u),!t[s].test(l))throw new TypeError('Expected "'+c.name+'" to match "'+c.pattern+'", but received "'+l+'"');a+=c.prefix+l}}else a+=c}return a}}function H(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function B(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function j(n,e){return n.keys=e,n}function $(n){return n&&n.sensitive?"":"i"}function U(n,e,t){O(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,a=!1!==t.end,o="",i=0;i<n.length;i++){var s=n[i];if("string"==typeof s)o+=H(s);else{var c=H(s.prefix),l="(?:"+s.pattern+")";e.push(s),s.repeat&&(l+="(?:"+c+l+")*"),o+=l=s.optional?s.partial?c+"("+l+")?":"(?:"+c+"("+l+"))?":c+"("+l+")"}}var u=H(t.delimiter||"/"),p=o.slice(-u.length)===u;return r||(o=(p?o.slice(0,-u.length):o)+"(?:"+u+"(?=$))?"),o+=a?"$":r&&p?"":"(?="+u+"|$)",j(new RegExp("^"+o,$(t)),e)}function W(n,e,t){return O(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return j(n,e)}(n,e):O(n)?function(n,e,t){for(var r=[],a=0;a<n.length;a++)r.push(W(n[a],e,t).source);return j(new RegExp("(?:"+r.join("|")+")",$(t)),e)}(n,e,t):function(n,e,t){return U(F(n,t),e,t)}(n,e,t)}L.parse=R,L.compile=_,L.tokensToFunction=A,L.tokensToRegExp=I;var J=Object.create(null);function V(n,e,t){e=e||{};try{var r=J[n]||(J[n]=L.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function K(n,e,t,r){var a="string"==typeof n?{path:n}:n;if(a._normalized)return a;if(a.name){var o=(a=i({},n)).params;return o&&"object"==typeof o&&(a.params=i({},o)),a}if(!a.path&&a.params&&e){(a=i({},a))._normalized=!0;var s=i(i({},e.params),a.params);if(e.name)a.name=e.name,a.params=s;else if(e.matched.length){var c=e.matched[e.matched.length-1].path;a.path=V(c,s,e.path)}else 0;return a}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var a=n.indexOf("?");return a>=0&&(t=n.slice(a+1),n=n.slice(0,a)),{path:n,query:t,hash:e}}(a.path||""),u=e&&e.path||"/",p=l.path?C(l.path,u,t||a.append):u,f=function(n,e,t){void 0===e&&(e={});var r,a=t||m;try{r=a(n||"")}catch(n){r={}}for(var o in e){var i=e[o];r[o]=Array.isArray(i)?i.map(d):d(i)}return r}(l.query,a.query,r&&r.options.parseQuery),g=a.hash||l.hash;return g&&"#"!==g.charAt(0)&&(g="#"+g),{_normalized:!0,path:p,query:f,hash:g}}var G,z=function(){},q={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,a=t.resolve(this.to,r,this.append),o=a.location,s=a.route,c=a.href,l={},u=t.options.linkActiveClass,p=t.options.linkExactActiveClass,d=null==u?"router-link-active":u,m=null==p?"router-link-exact-active":p,f=null==this.activeClass?d:this.activeClass,v=null==this.exactActiveClass?m:this.exactActiveClass,y=s.redirectedFrom?h(null,K(s.redirectedFrom),null,t):s;l[v]=k(r,y,this.exactPath),l[f]=this.exact||this.exactPath?l[v]:function(n,e){return 0===n.path.replace(g,"/").indexOf(e.path.replace(g,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,y);var b=l[v]?this.ariaCurrentValue:null,S=function(n){Y(n)&&(e.replace?t.replace(o,z):t.push(o,z))},x={click:Y};Array.isArray(this.event)?this.event.forEach((function(n){x[n]=S})):x[this.event]=S;var E={class:l},T=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:c,route:s,navigate:S,isActive:l[f],isExactActive:l[v]});if(T){if(1===T.length)return T[0];if(T.length>1||!T.length)return 0===T.length?n():n("span",{},T)}if("a"===this.tag)E.on=x,E.attrs={href:c,"aria-current":b};else{var w=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(w){w.isStatic=!1;var C=w.data=i({},w.data);for(var D in C.on=C.on||{},C.on){var O=C.on[D];D in x&&(C.on[D]=Array.isArray(O)?O:[O])}for(var L in x)L in C.on?C.on[L].push(x[L]):C.on[L]=S;var R=w.data.attrs=i({},w.data.attrs);R.href=c,R["aria-current"]=b}else E.on=x}return n(this.tag,E,this.$slots.default)}};function Y(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Q="undefined"!=typeof window;function X(n,e,t,r,a){var o=e||[],i=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,a,o,i){var s=a.path,c=a.name;0;var l=a.pathToRegexpOptions||{},u=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return D(e.path+"/"+n)}(s,o,l.strict);"boolean"==typeof a.caseSensitive&&(l.sensitive=a.caseSensitive);var p={path:u,regex:Z(u,l),components:a.components||{default:a.component},alias:a.alias?"string"==typeof a.alias?[a.alias]:a.alias:[],instances:{},enteredCbs:{},name:c,parent:o,matchAs:i,redirect:a.redirect,beforeEnter:a.beforeEnter,meta:a.meta||{},props:null==a.props?{}:a.components?a.props:{default:a.props}};a.children&&a.children.forEach((function(a){var o=i?D(i+"/"+a.path):void 0;n(e,t,r,a,p,o)}));t[p.path]||(e.push(p.path),t[p.path]=p);if(void 0!==a.alias)for(var d=Array.isArray(a.alias)?a.alias:[a.alias],m=0;m<d.length;++m){0;var f={path:d[m],children:a.children};n(e,t,r,f,o,p.path||"/")}c&&(r[c]||(r[c]=p))}(o,i,s,n,a)}));for(var c=0,l=o.length;c<l;c++)"*"===o[c]&&(o.push(o.splice(c,1)[0]),l--,c--);return{pathList:o,pathMap:i,nameMap:s}}function Z(n,e){return L(n,[],e)}function nn(n,e){var t=X(n),r=t.pathList,a=t.pathMap,o=t.nameMap;function i(n,t,i){var s=K(n,t,!1,e),l=s.name;if(l){var u=o[l];if(!u)return c(null,s);var p=u.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var d in t.params)!(d in s.params)&&p.indexOf(d)>-1&&(s.params[d]=t.params[d]);return s.path=V(u.path,s.params),c(u,s,i)}if(s.path){s.params={};for(var m=0;m<r.length;m++){var f=r[m],g=a[f];if(en(g.regex,s.path,s.params))return c(g,s,i)}}return c(null,s)}function s(n,t){var r=n.redirect,a="function"==typeof r?r(h(n,t,null,e)):r;if("string"==typeof a&&(a={path:a}),!a||"object"!=typeof a)return c(null,t);var s=a,l=s.name,u=s.path,p=t.query,d=t.hash,m=t.params;if(p=s.hasOwnProperty("query")?s.query:p,d=s.hasOwnProperty("hash")?s.hash:d,m=s.hasOwnProperty("params")?s.params:m,l){o[l];return i({_normalized:!0,name:l,query:p,hash:d,params:m},void 0,t)}if(u){var f=function(n,e){return C(n,e.parent?e.parent.path:"/",!0)}(u,n);return i({_normalized:!0,path:V(f,m),query:p,hash:d},void 0,t)}return c(null,t)}function c(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=i({_normalized:!0,path:V(t,e.params)});if(r){var a=r.matched,o=a[a.length-1];return e.params=r.params,c(o,e)}return c(null,e)}(0,t,n.matchAs):h(n,t,r,e)}return{match:i,addRoute:function(n,e){var t="object"!=typeof n?o[n]:void 0;X([e||n],r,a,o,t),t&&t.alias.length&&X(t.alias.map((function(n){return{path:n,children:[e]}})),r,a,o,t)},getRoutes:function(){return r.map((function(n){return a[n]}))},addRoutes:function(n){X(n,r,a,o)}}}function en(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var a=1,o=r.length;a<o;++a){var i=n.keys[a-1];i&&(t[i.name||"pathMatch"]="string"==typeof r[a]?p(r[a]):r[a])}return!0}var tn=Q&&window.performance&&window.performance.now?window.performance:Date;function rn(){return tn.now().toFixed(3)}var an=rn();function on(){return an}function sn(n){return an=n}var cn=Object.create(null);function ln(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=i({},window.history.state);return t.key=on(),window.history.replaceState(t,"",e),window.addEventListener("popstate",dn),function(){window.removeEventListener("popstate",dn)}}function un(n,e,t,r){if(n.app){var a=n.options.scrollBehavior;a&&n.app.$nextTick((function(){var o=function(){var n=on();if(n)return cn[n]}(),i=a.call(n,e,t,r?o:null);i&&("function"==typeof i.then?i.then((function(n){vn(n,o)})).catch((function(n){0})):vn(i,o))}))}}function pn(){var n=on();n&&(cn[n]={x:window.pageXOffset,y:window.pageYOffset})}function dn(n){pn(),n.state&&n.state.key&&sn(n.state.key)}function mn(n){return gn(n.x)||gn(n.y)}function fn(n){return{x:gn(n.x)?n.x:window.pageXOffset,y:gn(n.y)?n.y:window.pageYOffset}}function gn(n){return"number"==typeof n}var hn=/^#\d/;function vn(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var a=hn.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(a){var o=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(a,o={x:gn((t=o).x)?t.x:0,y:gn(t.y)?t.y:0})}else mn(n)&&(e=fn(n))}else r&&mn(n)&&(e=fn(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var yn,bn=Q&&((-1===(yn=window.navigator.userAgent).indexOf("Android 2.")&&-1===yn.indexOf("Android 4.0")||-1===yn.indexOf("Mobile Safari")||-1!==yn.indexOf("Chrome")||-1!==yn.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function Sn(n,e){pn();var t=window.history;try{if(e){var r=i({},t.state);r.key=on(),t.replaceState(r,"",n)}else t.pushState({key:sn(rn())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function kn(n){Sn(n,!0)}function xn(n,e,t){var r=function(a){a>=n.length?t():n[a]?e(n[a],(function(){r(a+1)})):r(a+1)};r(0)}var En={redirected:2,aborted:4,cancelled:8,duplicated:16};function Tn(n,e){return Cn(n,e,En.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return Dn.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function wn(n,e){return Cn(n,e,En.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function Cn(n,e,t,r){var a=new Error(r);return a._isRouter=!0,a.from=n,a.to=e,a.type=t,a}var Dn=["params","query","hash"];function On(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function Ln(n,e){return On(n)&&n._isRouter&&(null==e||n.type===e)}function Rn(n){return function(e,t,r){var a=!1,o=0,i=null;_n(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){a=!0,o++;var c,l=Mn((function(e){var a;((a=e).__esModule||In&&"Module"===a[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:G.extend(e),t.components[s]=e,--o<=0&&r()})),u=Mn((function(n){var e="Failed to resolve async component "+s+": "+n;i||(i=On(n)?n:new Error(e),r(i))}));try{c=n(l,u)}catch(n){u(n)}if(c)if("function"==typeof c.then)c.then(l,u);else{var p=c.component;p&&"function"==typeof p.then&&p.then(l,u)}}})),a||r()}}function _n(n,e){return An(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function An(n){return Array.prototype.concat.apply([],n)}var In="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Mn(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var Fn=function(n,e){this.router=n,this.base=function(n){if(!n)if(Q){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=y,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Pn(n,e,t,r){var a=_n(n,(function(n,r,a,o){var i=function(n,e){"function"!=typeof n&&(n=G.extend(n));return n.options[e]}(n,e);if(i)return Array.isArray(i)?i.map((function(n){return t(n,r,a,o)})):t(i,r,a,o)}));return An(r?a.reverse():a)}function Nn(n,e){if(e)return function(){return n.apply(e,arguments)}}Fn.prototype.listen=function(n){this.cb=n},Fn.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Fn.prototype.onError=function(n){this.errorCbs.push(n)},Fn.prototype.transitionTo=function(n,e,t){var r,a=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var o=this.current;this.confirmTransition(r,(function(){a.updateRoute(r),e&&e(r),a.ensureURL(),a.router.afterHooks.forEach((function(n){n&&n(r,o)})),a.ready||(a.ready=!0,a.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!a.ready&&(Ln(n,En.redirected)&&o===y||(a.ready=!0,a.readyErrorCbs.forEach((function(e){e(n)}))))}))},Fn.prototype.confirmTransition=function(n,e,t){var r=this,a=this.current;this.pending=n;var o,i,s=function(n){!Ln(n)&&On(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},c=n.matched.length-1,l=a.matched.length-1;if(k(n,a)&&c===l&&n.matched[c]===a.matched[l])return this.ensureURL(),s(((i=Cn(o=a,n,En.duplicated,'Avoided redundant navigation to current location: "'+o.fullPath+'".')).name="NavigationDuplicated",i));var u=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),p=u.updated,d=u.deactivated,m=u.activated,f=[].concat(function(n){return Pn(n,"beforeRouteLeave",Nn,!0)}(d),this.router.beforeHooks,function(n){return Pn(n,"beforeRouteUpdate",Nn)}(p),m.map((function(n){return n.beforeEnter})),Rn(m)),g=function(e,t){if(r.pending!==n)return s(wn(a,n));try{e(n,a,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return Cn(n,e,En.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(a,n))):On(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(Tn(a,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};xn(f,g,(function(){xn(function(n){return Pn(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,a,o){return n(r,a,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),o(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),g,(function(){if(r.pending!==n)return s(wn(a,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){E(n)}))}))}))},Fn.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Fn.prototype.setupListeners=function(){},Fn.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=y,this.pending=null};var Hn=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Bn(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=bn&&t;r&&this.listeners.push(ln());var a=function(){var t=n.current,a=Bn(n.base);n.current===y&&a===n._startLocation||n.transitionTo(a,(function(n){r&&un(e,n,t,!0)}))};window.addEventListener("popstate",a),this.listeners.push((function(){window.removeEventListener("popstate",a)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Sn(D(r.base+n.fullPath)),un(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){kn(D(r.base+n.fullPath)),un(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Bn(this.base)!==this.current.fullPath){var e=D(this.base+this.current.fullPath);n?Sn(e):kn(e)}},e.prototype.getCurrentLocation=function(){return Bn(this.base)},e}(Fn);function Bn(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(D(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var jn=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Bn(n);if(!/^\/#/.test(e))return window.location.replace(D(n+"/#"+e)),!0}(this.base)||$n()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=bn&&e;t&&this.listeners.push(ln());var r=function(){var e=n.current;$n()&&n.transitionTo(Un(),(function(r){t&&un(n.router,r,e,!0),bn||Vn(r.fullPath)}))},a=bn?"popstate":"hashchange";window.addEventListener(a,r),this.listeners.push((function(){window.removeEventListener(a,r)}))}},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Jn(n.fullPath),un(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Vn(n.fullPath),un(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Un()!==e&&(n?Jn(e):Vn(e))},e.prototype.getCurrentLocation=function(){return Un()},e}(Fn);function $n(){var n=Un();return"/"===n.charAt(0)||(Vn("/"+n),!1)}function Un(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Wn(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Jn(n){bn?Sn(Wn(n)):window.location.hash=n}function Vn(n){bn?kn(Wn(n)):window.location.replace(Wn(n))}var Kn=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){Ln(n,En.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Fn),Gn=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=nn(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!bn&&!1!==n.fallback,this.fallback&&(e="hash"),Q||(e="abstract"),this.mode=e,e){case"history":this.history=new Hn(this,n.base);break;case"hash":this.history=new jn(this,n.base,this.fallback);break;case"abstract":this.history=new Kn(this,n.base);break;default:0}},zn={currentRoute:{configurable:!0}};function qn(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Gn.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},zn.currentRoute.get=function(){return this.history&&this.history.current},Gn.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Hn||t instanceof jn){var r=function(n){t.setupListeners(),function(n){var r=t.current,a=e.options.scrollBehavior;bn&&a&&"fullPath"in n&&un(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Gn.prototype.beforeEach=function(n){return qn(this.beforeHooks,n)},Gn.prototype.beforeResolve=function(n){return qn(this.resolveHooks,n)},Gn.prototype.afterEach=function(n){return qn(this.afterHooks,n)},Gn.prototype.onReady=function(n,e){this.history.onReady(n,e)},Gn.prototype.onError=function(n){this.history.onError(n)},Gn.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Gn.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Gn.prototype.go=function(n){this.history.go(n)},Gn.prototype.back=function(){this.go(-1)},Gn.prototype.forward=function(){this.go(1)},Gn.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Gn.prototype.resolve=function(n,e,t){var r=K(n,e=e||this.history.current,t,this),a=this.match(r,e),o=a.redirectedFrom||a.fullPath;return{location:r,route:a,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?D(n+"/"+r):r}(this.history.base,o,this.mode),normalizedTo:r,resolved:a}},Gn.prototype.getRoutes=function(){return this.matcher.getRoutes()},Gn.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==y&&this.history.transitionTo(this.history.getCurrentLocation())},Gn.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==y&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Gn.prototype,zn),Gn.install=function n(e){if(!n.installed||G!==e){n.installed=!0,G=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",T),e.component("RouterLink",q);var a=e.config.optionMergeStrategies;a.beforeRouteEnter=a.beforeRouteLeave=a.beforeRouteUpdate=a.created}},Gn.version="3.5.2",Gn.isNavigationFailure=Ln,Gn.NavigationFailureType=En,Gn.START_LOCATION=y,Q&&window.Vue&&window.Vue.use(Gn);var Yn=Gn;t(223),t(168),t(169),t(48),t(218),t(21),t(29),t(248);function Qn(n){n.locales&&Object.keys(n.locales).forEach((function(e){n.locales[e].path=e})),Object.freeze(n)}t(129);var Xn=t(11),Zn=(t(175),t(20),t(35),t(91),t(93),{NotFound:function(){return Promise.all([t.e(0),t.e(1),t.e(5)]).then(t.bind(null,1021))},Blog:function(){return Promise.all([t.e(0),t.e(1),t.e(3)]).then(t.bind(null,1020))},Layout:function(){return Promise.all([t.e(0),t.e(1),t.e(50),t.e(4)]).then(t.bind(null,1019))},Slide:function(){return Promise.all([t.e(0),t.e(6)]).then(t.bind(null,1022))}}),ne={"v-2a4e8730":function(){return t.e(44).then(t.bind(null,1023))},"v-6ce8a11a":function(){return t.e(7).then(t.bind(null,1024))},"v-4af972b2":function(){return t.e(8).then(t.bind(null,1025))},"v-700ad79e":function(){return t.e(45).then(t.bind(null,1026))},"v-59db6648":function(){return t.e(46).then(t.bind(null,1027))},"v-3619c21a":function(){return t.e(47).then(t.bind(null,1028))},"v-cdbd9150":function(){return t.e(48).then(t.bind(null,1029))},"v-16ce3220":function(){return t.e(9).then(t.bind(null,1030))},"v-192fb65e":function(){return t.e(10).then(t.bind(null,1031))},"v-0d4b1bdc":function(){return t.e(34).then(t.bind(null,1032))},"v-58e0fb48":function(){return t.e(28).then(t.bind(null,1033))},"v-1ddb11e8":function(){return t.e(27).then(t.bind(null,1034))},"v-15ed21e8":function(){return t.e(43).then(t.bind(null,1035))},"v-d83236b0":function(){return t.e(29).then(t.bind(null,1036))},"v-8af45558":function(){return t.e(33).then(t.bind(null,1037))},"v-2436b22c":function(){return t.e(35).then(t.bind(null,1038))},"v-2dfdfd20":function(){return t.e(15).then(t.bind(null,1039))},"v-1d1a5ab0":function(){return t.e(36).then(t.bind(null,1040))},"v-15fe0334":function(){return t.e(37).then(t.bind(null,1041))},"v-0ee1abb8":function(){return t.e(38).then(t.bind(null,1042))},"v-08950870":function(){return t.e(39).then(t.bind(null,1043))},"v-6c4d9170":function(){return t.e(11).then(t.bind(null,1044))},"v-16441730":function(){return t.e(12).then(t.bind(null,1045))},"v-1fe2b188":function(){return t.e(13).then(t.bind(null,1046))},"v-13d1b368":function(){return t.e(16).then(t.bind(null,1047))},"v-521bf728":function(){return t.e(14).then(t.bind(null,1048))},"v-3ed67088":function(){return t.e(17).then(t.bind(null,1049))},"v-12defbfc":function(){return t.e(18).then(t.bind(null,1050))},"v-0e1bf380":function(){return t.e(19).then(t.bind(null,1051))},"v-0958eb04":function(){return t.e(20).then(t.bind(null,1052))},"v-0495e288":function(){return t.e(21).then(t.bind(null,1053))},"v-7c98df2c":function(){return t.e(22).then(t.bind(null,1054))},"v-61a49f28":function(){return t.e(24).then(t.bind(null,1055))},"v-542a7f26":function(){return t.e(25).then(t.bind(null,1056))},"v-6f1ebf2a":function(){return t.e(23).then(t.bind(null,1057))},"v-0f870848":function(){return t.e(32).then(t.bind(null,1058))},"v-46b05f24":function(){return t.e(26).then(t.bind(null,1059))},"v-8d04e3f0":function(){return t.e(30).then(t.bind(null,1060))},"v-36fb69b0":function(){return t.e(31).then(t.bind(null,1061))},"v-3ee237e8":function(){return t.e(40).then(t.bind(null,1062))},"v-6ed3dbc8":function(){return t.e(42).then(t.bind(null,1063))},"v-69e6f508":function(){return t.e(41).then(t.bind(null,1064))}};function ee(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var te=/-(\w)/g,re=ee((function(n){return n.replace(te,(function(n,e){return e?e.toUpperCase():""}))})),ae=/\B([A-Z])/g,oe=ee((function(n){return n.replace(ae,"-$1").toLowerCase()})),ie=ee((function(n){return n.charAt(0).toUpperCase()+n.slice(1)}));function se(n,e){if(e)return n(e)?n(e):e.includes("-")?n(ie(re(e))):n(ie(e))||n(oe(e))}var ce=Object.assign({},Zn,ne),le=function(n){return ce[n]},ue=function(n){return ne[n]},pe=function(n){return Zn[n]},de=function(n){return o.a.component(n)};function me(n){return se(ue,n)}function fe(n){return se(pe,n)}function ge(n){return se(le,n)}function he(n){return se(de,n)}function ve(){for(var n=arguments.length,e=new Array(n),t=0;t<n;t++)e[t]=arguments[t];return Promise.all(e.filter((function(n){return n})).map(function(){var n=a(regeneratorRuntime.mark((function n(e){var t;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:if(he(e)||!ge(e)){n.next=5;break}return n.next=3,ge(e)();case 3:t=n.sent,o.a.component(e,t.default);case 5:case"end":return n.stop()}}),n)})));return function(e){return n.apply(this,arguments)}}()))}function ye(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var be=t(15),Se=(t(132),t(65),t(214)),ke=t.n(Se),xe={created:function(){if(this.siteMeta=this.$site.headTags.filter((function(n){return"meta"===Object(be.a)(n,1)[0]})).map((function(n){var e=Object(be.a)(n,2);e[0];return e[1]})),this.$ssrContext){var n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map((function(n){var e="<meta";return Object.keys(n).forEach((function(t){e+=" ".concat(t,'="').concat(n[t],'"')})),e+">"})).join("\n    "):"",this.$ssrContext.canonicalLink=Te(this.$canonicalUrl)}var e},mounted:function(){this.currentMetaTags=Object(Xn.a)(document.querySelectorAll("meta")),this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta:function(){document.title=this.$title,document.documentElement.lang=this.$lang;var n=this.getMergedMetaTags();this.currentMetaTags=we(n,this.currentMetaTags)},getMergedMetaTags:function(){var n=this.$page.frontmatter.meta||[];return ke()([{name:"description",content:this.$description}],n,this.siteMeta,Ce)},updateCanonicalLink:function(){Ee(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",Te(this.$canonicalUrl))}},watch:{$page:function(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy:function(){we(null,this.currentMetaTags),Ee()}};function Ee(){var n=document.querySelector("link[rel='canonical']");n&&n.remove()}function Te(){var n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"";return n?'<link href="'.concat(n,'" rel="canonical" />'):""}function we(n,e){if(e&&Object(Xn.a)(e).filter((function(n){return n.parentNode===document.head})).forEach((function(n){return document.head.removeChild(n)})),n)return n.map((function(n){var e=document.createElement("meta");return Object.keys(n).forEach((function(t){e.setAttribute(t,n[t])})),document.head.appendChild(e),e}))}function Ce(n){for(var e=0,t=["name","property","itemprop"];e<t.length;e++){var r=t[e];if(n.hasOwnProperty(r))return n[r]+r}return JSON.stringify(n)}t(94);var De,Oe=t(89),Le=t.n(Oe),Re={mounted:function(){var n=this;Le.a.configure({showSpinner:!1}),this.$router.beforeEach((function(n,e,t){n.path===e.path||o.a.component(n.name)||Le.a.start(),t()})),this.$router.afterEach((function(){Le.a.done(),n.isSidebarOpen=!1}))}},_e=(t(51),t(90),t(47)),Ae=t.n(_e),Ie=o.a.extend({mounted:function(){var n=this;De=Ae()((function(){n.setActiveHash()}),300),window.addEventListener("scroll",De)},beforeDestroy:function(){window.removeEventListener("scroll",De)},methods:{setActiveHash:function(){var n=this,e=Array.from(document.querySelectorAll(".sidebar-link")),t=Array.from(document.querySelectorAll(".header-anchor")).filter((function(n){return 0===e.length||e.some((function(e){return e.hash===n.hash}))})),r=document.querySelector(".theme-default-content").offsetTop,a=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),o=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),i=window.innerHeight+a,s=decodeURIComponent(this.$route.hash),c=function(e,r){if(i===o)for(var a=r+1;a<t.length;a++)if(s===decodeURIComponent(t[a].hash))return;n.$vuepress.$set("disableScrollBehavior",!0),n.$router.replace(decodeURIComponent(e),(function(){n.$nextTick((function(){n.$vuepress.$set("disableScrollBehavior",!1)}))}))};if(a-r<0&&s)c("#",-1);else for(var l=0;l<t.length;l++){var u=t[l],p=t[l+1];if(a-r>=u.parentElement.offsetTop+0&&(!p||a-r<p.parentElement.offsetTop+0)&&s!==decodeURIComponent(u.hash))return void c(u.hash,l)}}}}),Me=(t(31),t(347),t(219),t(127),t(227),t(220),{useBabel:!1,jsLib:[],cssLib:[],codepenLayout:"left",codepenEditors:"101",babel:"https://cdn.jsdelivr.net/npm/@babel/standalone/babel.min.js",vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"}),Fe={html:{types:["html","slim","haml","md","markdown","vue"],map:{html:"none",vue:"none",md:"markdown"}},js:{types:["js","javascript","coffee","coffeescript","ts","typescript","ls","livescript"],map:{js:"none",javascript:"none",coffee:"coffeescript",ls:"livescript",ts:"typescript"}},css:{types:["css","less","sass","scss","stylus","styl"],map:{css:"none",styl:"stylus"}}},Pe=function(n,e,t){var r=document.createElement(n);return e&&Object.keys(e).forEach((function(n){if(n.indexOf("data"))r[n]=e[n];else{var t=n.replace("data","");r.dataset[t]=e[n]}})),t&&t.forEach((function(n){r.appendChild(n)})),r},Ne=function(n){return Object.assign(Object.assign(Object.assign({},Me),n),{jsLib:Array.from(new Set([].concat(Object(Xn.a)(Me.jsLib||[]),Object(Xn.a)(n.jsLib||[])))),cssLib:Array.from(new Set([].concat(Object(Xn.a)(Me.cssLib||[]),Object(Xn.a)(n.cssLib||[]))))})},He=function(n,e){if(void 0!==n[e])return n[e];var t=new Promise((function(n){var t=document.createElement("script");t.src=e,document.getElementsByTagName("body")[0].appendChild(t),t.onload=function(){n()}}));return n[e]=t,t},Be=function(n){return n.replace(/<br \/>/g,"<br>").replace(/<((\S+)[^<]*?)\s+\/>/g,"<$1></$2>")},je=function(n){return'<div id="app">\n'.concat(Be(n),"\n</div>")},$e=function(n){return"".concat(n.replace("export default ","const $reactApp = ").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),';\nReactDOM.render(React.createElement($reactApp), document.getElementById("app"))')},Ue=function(n){return"new Vue({ el: '#app', ".concat(n.replace(/export[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+default[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\{(\n*(?:[\0-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])*)\n*\}[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*;?$/,"$1").replace(/export[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+default[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*Vue\.extend[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\([\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\{(\n*(?:[\0-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])*)\n*\}[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\)[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*;?$/,"$1").trim()," })")},We=function(n){return"(function(exports){var module={};module.exports=exports;".concat(n,";return module.exports.__esModule?module.exports.default:module.exports;})({})")},Je=(t(124),function(n,e){return Array.from(n.querySelectorAll(".".concat(e)))}),Ve=function(n,e,t,r){var a=n.classList.contains("down");e.style.height=a?"".concat(t.clientHeight+13.8,"px"):"0",a?(r.classList.add("show-link"),n.classList.remove("down")):(r.classList.remove("show-link"),n.classList.add("down"))},Ke=function(n,e){var t=n.html,r=n.js,a=n.css,o=n.jsLib,i=n.cssLib,s=n.codepenEditors,c=n.codepenLayout;return Pe("form",{className:"code-demo-codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[Pe("input",{type:"hidden",name:"data",value:JSON.stringify({html:t,js:r,css:a,js_external:o.join(";"),css_external:i.join(";"),layout:c,html_pre_processor:e?e.html[1]:"none",js_pre_processor:e?e.js[1]:"none",css_pre_processor:e?e.css[1]:"none",editors:s})}),Pe("button",{type:"submit",innerHTML:'<svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="200" height="200"><defs><style/></defs><path d="M123.429 668L468 897.714V692.571L277.143 565.143zM88 585.714L198.286 512 88 438.286v147.428zm468 312L900.571 668 746.857 565.143 556 692.57v205.143zM512 616l155.429-104L512 408 356.571 512zM277.143 458.857L468 331.43V126.286L123.429 356zM825.714 512L936 585.714V438.286zm-78.857-53.143L900.571 356 556 126.286v205.143zM1024 356v312q0 23.429-19.429 36.571l-468 312Q524.571 1024 512 1024t-24.571-7.429l-468-312Q0 691.43 0 668V356q0-23.429 19.429-36.571l468-312Q499.429 0 512 0t24.571 7.429l468 312Q1024 332.57 1024 356z"/></svg>',className:"button",datatip:"Codepen"})])},Ge=function(n){var e,t,r,a,o,i,s=n.code,c=n.codeType,l=n.container,u=n.innerHTML,p=void 0!==u&&u,d=l.id,m=Je(l,"demo-wrapper")[0],f=Je(l,"code-wrapper")[0],g=Je(l,"code")[0],h=Je(l,"code-demo-footer")[0],v=decodeURIComponent(l.dataset.title||""),y=m.attachShadow({mode:"open"}),b=document.createElement("div");if(b.classList.add("code-demo-app"),y.appendChild(b),s.isLegal){p&&(b.innerHTML=s.html),function(n,e){if(e.css&&Array.from(n.childNodes).every((function(n){return"STYLE"!==n.nodeName}))){var t=Pe("style",{innerHTML:e.css});n.appendChild(t)}}(y,s),function(n,e,t){var r=t.getScript();if(r&&Array.from(e.childNodes).every((function(n){return"SCRIPT"!==n.nodeName}))){var a=document.createElement("script");a.appendChild(document.createTextNode("{const document=window.document.querySelector('#".concat(n," .demo-wrapper').shadowRoot;\n").concat(r,"}"))),e.appendChild(a)}}(d,y,s);var S=Pe("button",{className:"expand down"});h.appendChild(S),h.appendChild(Pe("span",{className:"title",innerHTML:v})),S.addEventListener("click",Ve.bind(null,S,f,g,h)),f.style.height="0",!1!==s.jsfiddle&&h.appendChild((t=(e=s).html,r=e.js,a=e.css,o=e.jsLib,i=e.cssLib,Pe("form",{className:"code-demo-jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[Pe("input",{type:"hidden",name:"html",value:t}),Pe("input",{type:"hidden",name:"js",value:r}),Pe("input",{type:"hidden",name:"css",value:a}),Pe("input",{type:"hidden",name:"wrap",value:"1"}),Pe("input",{type:"hidden",name:"panel_js",value:"3"}),Pe("input",{type:"hidden",name:"resources",value:[].concat(Object(Xn.a)(i),Object(Xn.a)(o)).join(",")}),Pe("button",{type:"submit",className:"button",innerHTML:'<svg class="icon" viewBox="0 0 1170 1024" xmlns="http://www.w3.org/2000/svg" width="228.516" height="200"><defs><style/></defs><path d="M1028.571 441.143q63.429 26.286 102.572 83.143t39.143 126.571q0 93.714-67.429 160.286T940 877.714q-2.286 0-6.571-.285t-6-.286H232q-97.143-5.714-164.571-71.714T0 645.143q0-62.857 31.429-116t84-84q-6.858-22.286-6.858-46.857 0-65.715 46.858-112T269.143 240q54.286 0 98.286 33.143 42.857-88 127.142-141.714t186.572-53.715q94.857 0 174.857 46t126.571 124.857 46.572 172q0 3.429-.286 10.286t-.286 10.286zm-761.142 152q0 69.714 48 110.286T434.286 744q78.285 0 137.143-56.571-9.143-11.429-27.143-32.286t-24.857-28.857q-38.286 37.143-82.286 37.143-31.429 0-53.429-19.143t-22-50q0-30.286 22-49.715T436 525.143q25.143 0 48.286 12T526 568.57t37.143 42.858 39.428 46.857 44 42.857T702 732.57t69.429 12q69.142 0 116.857-40.857T936 594.857q0-69.143-48-109.714T769.714 444.57Q688 444.571 632 500l53.143 61.714q37.714-36.571 81.143-36.571 29.714 0 52.571 18.857t22.857 48q0 32.571-21.143 52.286T766.857 664q-24.571 0-47.143-12t-41.143-31.429-37.428-42.857-39.714-46.857T557.143 488 502 456.571t-67.714-12q-69.715 0-118.286 40.286t-48.571 108.286z"/></svg>',datatip:"JSFiddle"})]))),!1!==s.codepen&&h.appendChild(Ke(s))}else m.style.display="none",f.style.height="auto",h.appendChild(Ke(s,c)),h.style.height="40px";l.setAttribute("demo-inited","")},ze=function(){var n=Je(document,"code-demo-wrapper"),e={};return Promise.all(n.map((function(n){if(n.hasAttribute("demo-inited"))return Promise.resolve();var t=decodeURIComponent(n.dataset.type||"normal"),r=JSON.parse(decodeURIComponent(n.dataset.config||"{}")),a=function(n){var e=Object.keys(n),t={html:[],js:[],css:[],isLegal:!1};return["html","js","css"].forEach((function(r){var a=e.filter((function(n){return Fe[r].types.includes(n)}));if(a.length){var o=a[0];t[r]=[n[o].replace(/^\n|\n$/g,""),Fe[r].map[o]||o]}})),t.isLegal=!(t.html.length&&"none"!==t.html[1]||t.js.length&&"none"!==t.js[1]||t.css.length&&"none"!==t.css[1]),t}(JSON.parse(decodeURIComponent(n.dataset.code||"{}")));switch(t){case"react":var o=function(n,e){var t=Ne(e);return Object.assign(Object.assign({},t),{html:je(""),js:$e(n.js[0]||""),css:n.css[0]||(n.js[0]?n.js[0].replace(/App\.__style__(?:\s*)=(?:\s*)`([\s\S]*)?`/,"$1").trim():""),isLegal:n.isLegal,jsLib:[t.react,t.reactDOM].concat(Object(Xn.a)(t.jsLib)),getScript:function(){var e,t,r=(null===(t=null===(e=window.Babel)||void 0===e?void 0:e.transform(n.js[0]||"",{presets:["es2015","react"]}))||void 0===t?void 0:t.code)||"";return"window.ReactDOM.render(window.React.createElement(".concat(We(r),"), document.firstElementChild)")}})}(a,r);return Promise.all([He(e,o.babel),He(e,o.react),He(e,o.reactDOM)]).then((function(){return Ge({code:o,codeType:a,container:n})}));case"vue":var i=function(n,e){var t=Ne(e),r=n.html[0]||"",a=/<template>((?:[\0-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])+)<\/template>/.exec(r),o=/<script([\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*lang=(["'])((?:[\0-\t\x0B\f\x0E-\u2027\u202A-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])*?)\2)?>((?:[\0-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])+)<\/script>/.exec(r),i=/<style([\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*lang=(["'])((?:[\0-\t\x0B\f\x0E-\u2027\u202A-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])*?)\2)?[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*(?:scoped)?>((?:[\0-\uD7FF\uE000-\uFFFF]|[\uD800-\uDBFF][\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF])+)<\/style>/.exec(r),s=a?a[1].replace(/^\n|\n$/g,""):"",c=o?[o[4].replace(/^\n|\n$/g,""),o[3]]:[],l=Object(be.a)(c,2),u=l[0],p=void 0===u?"":u,d=l[1],m=void 0===d?"":d,f=i?[i[4].replace(/^\n|\n$/g,""),i[3]]:[],g=Object(be.a)(f,2),h=g[0],v=void 0===h?"":h,y=g[1],b=void 0===y?"":y,S=""===m&&(""===b||"css"===b);return Object.assign(Object.assign({},t),{html:je(s),js:Ue(p),css:v,isLegal:S,jsLib:[t.vue].concat(Object(Xn.a)(t.jsLib)),getScript:function(){var n,t,r=e.useBabel?(null===(t=null===(n=window.Babel)||void 0===n?void 0:n.transform(p,{presets:["es2015"]}))||void 0===t?void 0:t.code)||"":p.replace(/export[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+default/,"return");return"const appOptions=".concat(We(r),";appOptions.template=`").concat(s.replace("`",'\\`"'),"`;document.firstElementChild.appendChild(new (window.Vue.extend(appOptions))().$mount().$el);")}})}(a,r),s=[He(e,i.vue)];return i.useBabel&&s.push(He(e,i.babel)),Promise.all(s).then((function(){return Ge({code:i,codeType:a,container:n})}));default:var c=function(n,e){var t=Ne(e),r=n.js[0]||"";return Object.assign(Object.assign({},t),{html:Be(n.html[0]||""),js:r,css:n.css[0]||"",isLegal:n.isLegal,getScript:function(){var n;return t.useBabel?(null===(n=window.Babel.transform(r,{presets:["es2015"]}))||void 0===n?void 0:n.code)||"":r}})}(a,r);return(c.useBabel?He(e,c.babel):Promise.resolve()).then((function(){return Ge({code:c,codeType:a,container:n,innerHTML:!0})}))}})))},qe={mounted:function(){setTimeout((function(){ze()}),1e3)},updated:function(){setTimeout((function(){ze()}),1e3)}};t(66);function Ye(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}t(141);function Qe(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}function Xe(n,e,t){return e&&Qe(n.prototype,e),t&&Qe(n,t),n}t(351);var Ze,nt=function(){function n(){Ye(this,n);var e=document.getElementById("message-container");e?this.containerElement=e:(this.containerElement=document.createElement("div"),this.containerElement.id="message-container",document.body.appendChild(this.containerElement))}return Xe(n,[{key:"pop",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:2e3,r=document.createElement("div");r.className="message move-in",r.innerHTML='<svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#06a35a"><path d="M822.812 824.618c-83.076 81.992-188.546 124.614-316.05 127.865-122.085-3.251-223.943-45.873-305.935-127.865S76.213 640.406 72.962 518.682c3.251-127.503 45.873-232.973 127.865-316.05 81.992-83.075 184.211-126.058 305.936-129.309 127.503 3.251 232.973 46.234 316.049 129.31 83.076 83.076 126.059 188.546 129.31 316.05-2.89 121.723-46.234 223.943-129.31 305.935zM432.717 684.111c3.973 3.974 8.307 5.78 13.364 6.14 5.057.362 9.753-1.444 13.365-5.417l292.57-287.515c3.974-3.973 5.78-8.307 5.78-13.364s-1.806-9.753-5.78-13.365l1.807 1.806c-3.973-3.973-8.669-5.779-14.087-6.14-5.418-.361-10.475 1.445-14.809 5.418L460.529 592.006c-3.973 3.25-8.669 4.695-14.448 4.695-5.78 0-10.836-1.445-15.531-3.973l-94.273-72.962c-4.335-3.251-9.392-4.335-14.448-3.973s-9.392 3.25-12.642 7.585l-2.89 3.973c-3.25 4.334-4.334 9.391-3.973 14.81.722 5.417 2.528 10.113 5.779 14.086L432.717 684.11z"/></svg><span>'.concat(n,"</span>"),this.containerElement.appendChild(r),t>0&&setTimeout((function(){e.close(r)}),t)}},{key:"close",value:function(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",(function(){n.remove()}))}}]),n}(),et=(t(352),t(228),{"/":{copy:"Copied successfully 🎉",hint:"Copy code"}}),tt={},rt=function(){return!!navigator&&/Android|webO[S\u017F]|iPhone|iPad|iPod|Blac[k\u212A]Berry|IEMobile|Opera Mini/i.test(navigator.userAgent)},at=[xe,Re,Ie,qe,o.a.extend({mounted:function(){Ze=new nt,rt()&&!tt.showInMobile||this.genCopyButton()},updated:function(){rt()&&!tt.showInMobile||this.genCopyButton()},methods:{genCopyButton:function(){var n=this,e=tt.selector||'.theme-default-content div[class*="language-"] pre';setTimeout((function(){"string"==typeof e?document.querySelectorAll(e).forEach(n.insertCopyButton.bind(n)):Array.isArray(e)&&e.forEach((function(e){document.querySelectorAll(e).forEach(n.insertCopyButton.bind(n))}))}),1e3)},insertCopyButton:function(n){var e=this;if(!n.hasAttribute("copy-code-registerd")){var t=document.createElement("button");t.className="copy-code-button",t.innerHTML='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" class="icon-copy-code"><path fill="currentColor" d="M384 112v352c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V112c0-26.51 21.49-48 48-48h80c0-35.29 28.71-64 64-64s64 28.71 64 64h80c26.51 0 48 21.49 48 48zM192 40c-13.255 0-24 10.745-24 24s10.745 24 24 24 24-10.745 24-24-10.745-24-24-24m96 114v-20a6 6 0 00-6-6H102a6 6 0 00-6 6v20a6 6 0 006 6h180a6 6 0 006-6z" /></svg>',t.addEventListener("click",(function(){e.copyToClipboard(n.innerText)})),t.setAttribute("aria-label",et[this.$localePath||"/"].hint),t.setAttribute("data-balloon-pos","left"),n.parentElement&&n.parentElement.insertBefore(t,n),n.setAttribute("copy-code-registerd","")}},copyToClipboard:function(n){var e=document.getSelection(),t=!!(e&&e.rangeCount>0)&&e.getRangeAt(0),r=document.createElement("textarea");r.value=n,r.setAttribute("readonly",""),r.style.position="absolute",r.style.top="-9999px",document.body.appendChild(r),r.select(),document.execCommand("copy"),0!==tt.duration&&Ze.pop(et[this.$localePath||"/"].copy,tt.duration),document.body.removeChild(r),t&&e&&(e.removeAllRanges(),e.addRange(t))}}})],ot={name:"GlobalLayout",computed:{layout:function(){var n=this.getLayout();return ye("layout",n),o.a.component(n)}},methods:{getLayout:function(){if(this.$page.path){var n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},it=t(1),st=Object(it.a)(ot,(function(){var n=this.$createElement;return(this._self._c||n)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){var r;switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),(r=n[e]).push.apply(r,Object(Xn.a)(t));break;default:throw new Error("Unknown option name.")}}(st,"mixins",at);var ct,lt,ut,pt,dt=[{name:"v-2a4e8730",path:"/about/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-2a4e8730").then(t)}},{path:"/about/index.html",redirect:"/about/"},{path:"/About.html",redirect:"/about/"},{name:"v-6ce8a11a",path:"/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-6ce8a11a").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-4af972b2",path:"/backend/Concurrent/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-4af972b2").then(t)}},{path:"/backend/Concurrent/part1/index.html",redirect:"/backend/Concurrent/part1/"},{path:"/backend/Concurrent/part1.html",redirect:"/backend/Concurrent/part1/"},{name:"v-700ad79e",path:"/backend/DesignPatterns/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-700ad79e").then(t)}},{path:"/backend/DesignPatterns/part1/index.html",redirect:"/backend/DesignPatterns/part1/"},{path:"/backend/DesignPatterns/part1.html",redirect:"/backend/DesignPatterns/part1/"},{name:"v-59db6648",path:"/backend/DesignPatterns/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-59db6648").then(t)}},{path:"/backend/DesignPatterns/part2/index.html",redirect:"/backend/DesignPatterns/part2/"},{path:"/backend/DesignPatterns/part2.html",redirect:"/backend/DesignPatterns/part2/"},{name:"v-3619c21a",path:"/backend/DesignPatterns/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-3619c21a").then(t)}},{path:"/backend/DesignPatterns/part3/index.html",redirect:"/backend/DesignPatterns/part3/"},{path:"/backend/DesignPatterns/part3.html",redirect:"/backend/DesignPatterns/part3/"},{name:"v-cdbd9150",path:"/backend/DesignPatterns/part4/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-cdbd9150").then(t)}},{path:"/backend/DesignPatterns/part4/index.html",redirect:"/backend/DesignPatterns/part4/"},{path:"/backend/DesignPatterns/part4.html",redirect:"/backend/DesignPatterns/part4/"},{name:"v-16ce3220",path:"/backend/Docker/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-16ce3220").then(t)}},{path:"/backend/Docker/part1/index.html",redirect:"/backend/Docker/part1/"},{path:"/backend/Docker/part1.html",redirect:"/backend/Docker/part1/"},{name:"v-192fb65e",path:"/backend/Docker/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-192fb65e").then(t)}},{path:"/backend/Docker/part2/index.html",redirect:"/backend/Docker/part2/"},{path:"/backend/Docker/part2.html",redirect:"/backend/Docker/part2/"},{name:"v-0d4b1bdc",path:"/backend/Kubernetes/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0d4b1bdc").then(t)}},{path:"/backend/Kubernetes/part2/index.html",redirect:"/backend/Kubernetes/part2/"},{path:"/backend/Kubernetes/part2.html",redirect:"/backend/Kubernetes/part2/"},{name:"v-58e0fb48",path:"/backend/JVM/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-58e0fb48").then(t)}},{path:"/backend/JVM/part2/index.html",redirect:"/backend/JVM/part2/"},{path:"/backend/JVM/part2.html",redirect:"/backend/JVM/part2/"},{name:"v-1ddb11e8",path:"/backend/JVM/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-1ddb11e8").then(t)}},{path:"/backend/JVM/part1/index.html",redirect:"/backend/JVM/part1/"},{path:"/backend/JVM/part1.html",redirect:"/backend/JVM/part1/"},{name:"v-15ed21e8",path:"/base/Algorithms/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-15ed21e8").then(t)}},{path:"/base/Algorithms/part1/index.html",redirect:"/base/Algorithms/part1/"},{path:"/base/Algorithms/part1.html",redirect:"/base/Algorithms/part1/"},{name:"v-d83236b0",path:"/backend/JVM/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-d83236b0").then(t)}},{path:"/backend/JVM/part3/index.html",redirect:"/backend/JVM/part3/"},{path:"/backend/JVM/part3.html",redirect:"/backend/JVM/part3/"},{name:"v-8af45558",path:"/backend/Kubernetes/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-8af45558").then(t)}},{path:"/backend/Kubernetes/part1/index.html",redirect:"/backend/Kubernetes/part1/"},{path:"/backend/Kubernetes/part1.html",redirect:"/backend/Kubernetes/part1/"},{name:"v-2436b22c",path:"/base/Linux/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-2436b22c").then(t)}},{path:"/base/Linux/part1/index.html",redirect:"/base/Linux/part1/"},{path:"/base/Linux/part1.html",redirect:"/base/Linux/part1/"},{name:"v-2dfdfd20",path:"/base/Git/part0/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-2dfdfd20").then(t)}},{path:"/base/Git/part0/index.html",redirect:"/base/Git/part0/"},{path:"/base/Git/part0.html",redirect:"/base/Git/part0/"},{name:"v-1d1a5ab0",path:"/base/Linux/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-1d1a5ab0").then(t)}},{path:"/base/Linux/part2/index.html",redirect:"/base/Linux/part2/"},{path:"/base/Linux/part2.html",redirect:"/base/Linux/part2/"},{name:"v-15fe0334",path:"/base/Linux/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-15fe0334").then(t)}},{path:"/base/Linux/part3/index.html",redirect:"/base/Linux/part3/"},{path:"/base/Linux/part3.html",redirect:"/base/Linux/part3/"},{name:"v-0ee1abb8",path:"/base/Linux/part4/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0ee1abb8").then(t)}},{path:"/base/Linux/part4/index.html",redirect:"/base/Linux/part4/"},{path:"/base/Linux/part4.html",redirect:"/base/Linux/part4/"},{name:"v-08950870",path:"/base/LinuxProxy/linux-proxy/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-08950870").then(t)}},{path:"/base/LinuxProxy/linux-proxy/index.html",redirect:"/base/LinuxProxy/linux-proxy/"},{path:"/base/LinuxProxy/linux-proxy.html",redirect:"/base/LinuxProxy/linux-proxy/"},{name:"v-6c4d9170",path:"/bigdata/Flink/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-6c4d9170").then(t)}},{path:"/bigdata/Flink/part1/index.html",redirect:"/bigdata/Flink/part1/"},{path:"/bigdata/Flink/part1.html",redirect:"/bigdata/Flink/part1/"},{name:"v-16441730",path:"/bigdata/Flink/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-16441730").then(t)}},{path:"/bigdata/Flink/part2/index.html",redirect:"/bigdata/Flink/part2/"},{path:"/bigdata/Flink/part2.html",redirect:"/bigdata/Flink/part2/"},{name:"v-1fe2b188",path:"/bigdata/Flink/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-1fe2b188").then(t)}},{path:"/bigdata/Flink/part3/index.html",redirect:"/bigdata/Flink/part3/"},{path:"/bigdata/Flink/part3.html",redirect:"/bigdata/Flink/part3/"},{name:"v-13d1b368",path:"/bigdata/HBase/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-13d1b368").then(t)}},{path:"/bigdata/HBase/part1/index.html",redirect:"/bigdata/HBase/part1/"},{path:"/bigdata/HBase/part1.html",redirect:"/bigdata/HBase/part1/"},{name:"v-521bf728",path:"/bigdata/Flume/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-521bf728").then(t)}},{path:"/bigdata/Flume/part1/index.html",redirect:"/bigdata/Flume/part1/"},{path:"/bigdata/Flume/part1.html",redirect:"/bigdata/Flume/part1/"},{name:"v-3ed67088",path:"/bigdata/HBase/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-3ed67088").then(t)}},{path:"/bigdata/HBase/part2/index.html",redirect:"/bigdata/HBase/part2/"},{path:"/bigdata/HBase/part2.html",redirect:"/bigdata/HBase/part2/"},{name:"v-12defbfc",path:"/bigdata/Hadoop/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-12defbfc").then(t)}},{path:"/bigdata/Hadoop/part1/index.html",redirect:"/bigdata/Hadoop/part1/"},{path:"/bigdata/Hadoop/part1.html",redirect:"/bigdata/Hadoop/part1/"},{name:"v-0e1bf380",path:"/bigdata/Hadoop/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0e1bf380").then(t)}},{path:"/bigdata/Hadoop/part2/index.html",redirect:"/bigdata/Hadoop/part2/"},{path:"/bigdata/Hadoop/part2.html",redirect:"/bigdata/Hadoop/part2/"},{name:"v-0958eb04",path:"/bigdata/Hadoop/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0958eb04").then(t)}},{path:"/bigdata/Hadoop/part3/index.html",redirect:"/bigdata/Hadoop/part3/"},{path:"/bigdata/Hadoop/part3.html",redirect:"/bigdata/Hadoop/part3/"},{name:"v-0495e288",path:"/bigdata/Hadoop/part4/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0495e288").then(t)}},{path:"/bigdata/Hadoop/part4/index.html",redirect:"/bigdata/Hadoop/part4/"},{path:"/bigdata/Hadoop/part4.html",redirect:"/bigdata/Hadoop/part4/"},{name:"v-7c98df2c",path:"/bigdata/Hive/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-7c98df2c").then(t)}},{path:"/bigdata/Hive/part1/index.html",redirect:"/bigdata/Hive/part1/"},{path:"/bigdata/Hive/part1.html",redirect:"/bigdata/Hive/part1/"},{name:"v-61a49f28",path:"/bigdata/Hive/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-61a49f28").then(t)}},{path:"/bigdata/Hive/part3/index.html",redirect:"/bigdata/Hive/part3/"},{path:"/bigdata/Hive/part3.html",redirect:"/bigdata/Hive/part3/"},{name:"v-542a7f26",path:"/bigdata/Hive/part4/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-542a7f26").then(t)}},{path:"/bigdata/Hive/part4/index.html",redirect:"/bigdata/Hive/part4/"},{path:"/bigdata/Hive/part4.html",redirect:"/bigdata/Hive/part4/"},{name:"v-6f1ebf2a",path:"/bigdata/Hive/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-6f1ebf2a").then(t)}},{path:"/bigdata/Hive/part2/index.html",redirect:"/bigdata/Hive/part2/"},{path:"/bigdata/Hive/part2.html",redirect:"/bigdata/Hive/part2/"},{name:"v-0f870848",path:"/bigdata/Kafka/part3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-0f870848").then(t)}},{path:"/bigdata/Kafka/part3/index.html",redirect:"/bigdata/Kafka/part3/"},{path:"/bigdata/Kafka/part3.html",redirect:"/bigdata/Kafka/part3/"},{name:"v-46b05f24",path:"/bigdata/Hive/part5/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-46b05f24").then(t)}},{path:"/bigdata/Hive/part5/index.html",redirect:"/bigdata/Hive/part5/"},{path:"/bigdata/Hive/part5.html",redirect:"/bigdata/Hive/part5/"},{name:"v-8d04e3f0",path:"/bigdata/Kafka/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-8d04e3f0").then(t)}},{path:"/bigdata/Kafka/part1/index.html",redirect:"/bigdata/Kafka/part1/"},{path:"/bigdata/Kafka/part1.html",redirect:"/bigdata/Kafka/part1/"},{name:"v-36fb69b0",path:"/bigdata/Kafka/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-36fb69b0").then(t)}},{path:"/bigdata/Kafka/part2/index.html",redirect:"/bigdata/Kafka/part2/"},{path:"/bigdata/Kafka/part2.html",redirect:"/bigdata/Kafka/part2/"},{name:"v-3ee237e8",path:"/bigdata/Spark/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-3ee237e8").then(t)}},{path:"/bigdata/Spark/part1/index.html",redirect:"/bigdata/Spark/part1/"},{path:"/bigdata/Spark/part1.html",redirect:"/bigdata/Spark/part1/"},{name:"v-6ed3dbc8",path:"/bigdata/Zookeeper/part1/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-6ed3dbc8").then(t)}},{path:"/bigdata/Zookeeper/part1/index.html",redirect:"/bigdata/Zookeeper/part1/"},{path:"/bigdata/Zookeeper/part1.html",redirect:"/bigdata/Zookeeper/part1/"},{name:"v-69e6f508",path:"/bigdata/Spark/part2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-69e6f508").then(t)}},{path:"/bigdata/Spark/part2/index.html",redirect:"/bigdata/Spark/part2/"},{path:"/bigdata/Spark/part2.html",redirect:"/bigdata/Spark/part2/"},{name:"v-6453f364",path:"/article/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-6453f364").then(t)}},{path:"/article/index.html",redirect:"/article/"},{name:"v-4340f7e8",path:"/star/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-4340f7e8").then(t)}},{path:"/star/index.html",redirect:"/star/"},{name:"v-7d484ebf",path:"/encrypt/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-7d484ebf").then(t)}},{path:"/encrypt/index.html",redirect:"/encrypt/"},{name:"v-2470be33",path:"/slide/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-2470be33").then(t)}},{path:"/slide/index.html",redirect:"/slide/"},{name:"v-6319eb4e",path:"/timeline/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-6319eb4e").then(t)}},{path:"/timeline/index.html",redirect:"/timeline/"},{name:"v-b1564aac",path:"/tag/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-b1564aac").then(t)},meta:{pid:"tag",id:"tag"}},{path:"/tag/index.html",redirect:"/tag/"},{name:"v-28e6393c",path:"/category/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-28e6393c").then(t)},meta:{pid:"category",id:"category"}},{path:"/category/index.html",redirect:"/category/"},{name:"v-1218ef24",path:"/tag/concurrent/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-1218ef24").then(t)},meta:{pid:"tag",id:"concurrent"}},{path:"/tag/concurrent/index.html",redirect:"/tag/concurrent/"},{name:"v-203905a4",path:"/tag/designPatterns/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-203905a4").then(t)},meta:{pid:"tag",id:"designPatterns"}},{path:"/tag/designPatterns/index.html",redirect:"/tag/designPatterns/"},{name:"v-5ae80825",path:"/tag/docker/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-5ae80825").then(t)},meta:{pid:"tag",id:"docker"}},{path:"/tag/docker/index.html",redirect:"/tag/docker/"},{name:"v-32360c9a",path:"/tag/k8s/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-32360c9a").then(t)},meta:{pid:"tag",id:"k8s"}},{path:"/tag/k8s/index.html",redirect:"/tag/k8s/"},{name:"v-32352550",path:"/tag/jvm/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-32352550").then(t)},meta:{pid:"tag",id:"jvm"}},{path:"/tag/jvm/index.html",redirect:"/tag/jvm/"},{name:"v-130c19e1",path:"/tag/algorithms/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-130c19e1").then(t)},meta:{pid:"tag",id:"algorithms"}},{path:"/tag/algorithms/index.html",redirect:"/tag/algorithms/"},{name:"v-7418fe36",path:"/tag/linux/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-7418fe36").then(t)},meta:{pid:"tag",id:"linux"}},{path:"/tag/linux/index.html",redirect:"/tag/linux/"},{name:"v-32383f72",path:"/tag/git/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-32383f72").then(t)},meta:{pid:"tag",id:"git"}},{path:"/tag/git/index.html",redirect:"/tag/git/"},{name:"v-657392aa",path:"/tag/proxy/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-657392aa").then(t)},meta:{pid:"tag",id:"proxy"}},{path:"/tag/proxy/index.html",redirect:"/tag/proxy/"},{name:"v-88435c0e",path:"/tag/flink/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-88435c0e").then(t)},meta:{pid:"tag",id:"flink"}},{path:"/tag/flink/index.html",redirect:"/tag/flink/"},{name:"v-8290f180",path:"/tag/hbase/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-8290f180").then(t)},meta:{pid:"tag",id:"hbase"}},{path:"/tag/hbase/index.html",redirect:"/tag/hbase/"},{name:"v-88387c1c",path:"/tag/flume/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-88387c1c").then(t)},meta:{pid:"tag",id:"flume"}},{path:"/tag/flume/index.html",redirect:"/tag/flume/"},{name:"v-16ad2ac0",path:"/tag/hadoop/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-16ad2ac0").then(t)},meta:{pid:"tag",id:"hadoop"}},{path:"/tag/hadoop/index.html",redirect:"/tag/hadoop/"},{name:"v-14b36356",path:"/tag/hive/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-14b36356").then(t)},meta:{pid:"tag",id:"hive"}},{path:"/tag/hive/index.html",redirect:"/tag/hive/"},{name:"v-786bbe1a",path:"/tag/kafka/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-786bbe1a").then(t)},meta:{pid:"tag",id:"kafka"}},{path:"/tag/kafka/index.html",redirect:"/tag/kafka/"},{name:"v-5b7bc7c8",path:"/tag/spark/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-5b7bc7c8").then(t)},meta:{pid:"tag",id:"spark"}},{path:"/tag/spark/index.html",redirect:"/tag/spark/"},{name:"v-87dcfee6",path:"/tag/zookeeper/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-87dcfee6").then(t)},meta:{pid:"tag",id:"zookeeper"}},{path:"/tag/zookeeper/index.html",redirect:"/tag/zookeeper/"},{name:"v-5e1a0957",path:"/category/backend/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-5e1a0957").then(t)},meta:{pid:"category",id:"backend"}},{path:"/category/backend/index.html",redirect:"/category/backend/"},{name:"v-270affc2",path:"/category/base/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-270affc2").then(t)},meta:{pid:"category",id:"base"}},{path:"/category/base/index.html",redirect:"/category/base/"},{name:"v-0bbae601",path:"/category/bigdata/",component:st,beforeEnter:function(n,e,t){ve("Blog","v-0bbae601").then(t)},meta:{pid:"category",id:"bigdata"}},{path:"/category/bigdata/index.html",redirect:"/category/bigdata/"},{name:"v-78da2c86",path:"/category/backend/page/2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-78da2c86").then(t)},meta:{pid:"category",id:"backend"}},{path:"/category/backend/page/2/index.html",redirect:"/category/backend/page/2/"},{name:"v-955cc6c8",path:"/category/bigdata/page/2/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-955cc6c8").then(t)},meta:{pid:"category",id:"bigdata"}},{path:"/category/bigdata/page/2/index.html",redirect:"/category/bigdata/page/2/"},{name:"v-955cc68a",path:"/category/bigdata/page/3/",component:st,beforeEnter:function(n,e,t){ve("Layout","v-955cc68a").then(t)},meta:{pid:"category",id:"bigdata"}},{path:"/category/bigdata/page/3/index.html",redirect:"/category/bigdata/page/3/"},{path:"*",component:st}],mt={title:"知识库",description:"",base:"/",headTags:[["link",{rel:"manifest",href:"/manifest.webmanifest",crossorigin:"use-credentials"}],["meta",{name:"theme-color",content:"#46bd87"}],["meta",{name:"viewport",content:"width=device-width, initial-scale=1.0, viewport-fit=cover"}]],pages:[{title:"注意事项",frontmatter:{title:"注意事项",actions:null,author:"causes",permalink:"/about",sticky:1,summary:"使用到的技术点 GitLab GitLab 提供代码的托管机制。 CI 用到的 CI 是 GitLab 自带的 CI，主要的实现方式就是文件 .gitlab-ci.yml + Runner。 公用的 Runner 需要填写银行卡信息，所以你们想要自己实现 CI 的时候最好自己搭一个。 因为腾讯云服务器只有 1Mbps（128KB） 的速度，所以 CI 有可能",meta:[{property:"og:url",content:"/about/"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"注意事项"},{property:"og:description",content:"使用到的技术点 GitLab GitLab 提供代码的托管机制。 CI 用到的 CI 是 GitLab 自带的 CI，主要的实现方式就是文件 .gitlab-ci.yml + Runner。 公用的 Runner 需要填写银行卡信息，所以你们想要自己实现 CI 的时候最好自己搭一个。 因为腾讯云服务器只有 1Mbps（128KB） 的速度，所以 CI 有可能"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"}]},regularPath:"/About.html",relativePath:"About.md",key:"v-2a4e8730",path:"/about/",headers:[{level:2,title:"使用到的技术点",slug:"使用到的技术点"},{level:2,title:"现在的问题",slug:"现在的问题"}],readingTime:{minutes:1.02,words:305},content:" 使用到的技术点 \n GitLab \n GitLab 提供代码的托管机制。 \n CI \n 用到的 CI 是 GitLab 自带的 CI，主要的实现方式就是文件  .gitlab-ci.yml + Runner 。 \n 公用的 Runner 需要填写银行卡信息，所以你们想要自己实现 CI 的时候最好自己搭一个。 \n Tips \n 因为腾讯云服务器只有 1Mbps（128KB） 的速度，所以 CI 有可能因为网络原因（或者其他灵异事件）失败，重启一下试试。 \n \n VuePress \n 生成静态博客的技术驱动。 \n 同类型的有很多，比如 Hexo，Hugo 等，选择 VuePress 的考虑是使用 Vue 开发的，如果想自己搞一个什么页面都可以。 \n 现在的问题 \n Warning \n 文章中图片的引用使用相对路径，例如引用  ./images/1.png ，不可以写为  /images/1.png ，因为这样写会找到公共文件夹下的  images  文件夹。 \n \n Warning \n 主题使用的是  vuepress-theme-hope ，里面使用了 yarn format 作为配置，所以在写文章之前需要首先看一下基本的书写规则，其实主要就是看一下如何在文章页面给文章填写题目、分类、标签。 \n \n",updateTime:"March 19, 2022 22:20",updateTimeStamp:164769963e4,createTime:"August 14, 2021 16:59",createTimeStamp:1628931592e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"causes",email:"2592716753@qq.com",commits:1},{name:"王宏照",email:"2592716753@qq.com",commits:1}]},{frontmatter:{blog:!0,heroText:"团队博客",heroImage:"/team.jpg",heroImageStyle:{maxHeight:"200px",display:"block",borderRadius:"50%",boxShadow:"0 5px 18px rgba(0,0,0,0.2)"},permalink:"/",summary:"",meta:[{property:"og:url",content:"/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/",relativePath:"README.md",key:"v-6ce8a11a",path:"/",readingTime:{minutes:0,words:0},content:"",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 13, 2021 12:46",createTimeStamp:1628829981e3,contributors:[{name:"causes",email:"2592716753@qq.com",commits:3},{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"王宏照",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Concurrent-01-基础",frontmatter:{title:"Concurrent-01-基础",categories:["backend"],tags:["concurrent"],author:"causes",summary:"简介 需要操作系统和 JVM 的一些基础知识，否则可能会看的很吃力。 参考书籍 《Java 并发编程实战》 现代计算机支持多个进程（每个进程中包含至少一个线程），操作系统分配资源是以进程为单位，但是分配 CPU 是以线程为单位的，所以 CPU 也叫做轻量级处理器。 线程在一个系统中有着巨大的优势，例如可以保证多任务的并发执行，充分发挥多处理器的性能，但是线程",meta:[{property:"og:url",content:"/backend/Concurrent/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Concurrent-01-基础"},{property:"og:description",content:"简介 需要操作系统和 JVM 的一些基础知识，否则可能会看的很吃力。 参考书籍 《Java 并发编程实战》 现代计算机支持多个进程（每个进程中包含至少一个线程），操作系统分配资源是以进程为单位，但是分配 CPU 是以线程为单位的，所以 CPU 也叫做轻量级处理器。 线程在一个系统中有着巨大的优势，例如可以保证多任务的并发执行，充分发挥多处理器的性能，但是线程"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"concurrent"}]},regularPath:"/backend/Concurrent/part1.html",relativePath:"backend/Concurrent/part1.md",key:"v-4af972b2",path:"/backend/Concurrent/part1/",headers:[{level:2,title:"简介",slug:"简介"},{level:2,title:"线程安全性",slug:"线程安全性"}],readingTime:{minutes:4.83,words:1448},content:' 简介 \n Tips \n 需要操作系统和 JVM 的一些基础知识，否则可能会看的很吃力。\n参考书籍 《Java 并发编程实战》 \n \n 现代计算机支持多个进程（每个进程中包含至少一个线程），操作系统分配资源是以进程为单位，但是分配 CPU 是以线程为单位的，所以 CPU 也叫做轻量级处理器。 \n 线程在一个系统中有着巨大的优势，例如可以保证多任务的并发执行，充分发挥多处理器的性能，但是线程实质上是一把双刃剑，它在带来便利的同时同样存在着风险。 \n 安全性问题 \n // 线程不安全 \n class   Unsafe   { \n   private   int  value ; \n\n   public   int   getNext ( )   { \n     return  value ++ ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 表面上看起来这个类是一个返回  value++  的操作，但其实它包含了以下三个步骤： \n \n 读取 value 的值。 \n value + 1 \n 写 value 的值。 \n \n 在 Java 中，多个线程虽然有自己独立的栈空间，但是堆空间是进程中的线程共享的，所以在多线程模式下很有可能会获取相同的值，这是非常危险的。 \n 活跃性问题 \n 简单来讲，活跃性问题就是后面的操作无法继续执行，在单线程模式下最常见的活跃性问题是无限循环。而在多线程模式下则更多（例如死锁、饥饿、活锁）。 \n 性能问题 \n 事实上多线程往往会带来性能问题，CPU 在挂起一个活跃线程而转而运行另一个线程时，就会频繁出现上下文切换操作，这种情况会带来更多的运行时开销，并且 CPU 的时间花费在线程调度的时间上更多了，也就意味着在线程运行上花费的时间更少了。 \n 线程安全性 \n 在构建稳定的并发程序时，我们经常会使用到线程和锁，但是这些终究是一种机制，要编写线程安全的代码，最终还是要对**共享（Shared）、可变（Mutable）**的状态进行管理。 \n 假如某个变量属于线程私有的，那么无论我们怎么去改变，也不会产生并发问题，我们真正需要注意的是那些可以被多个线程共享的，并且是可变的变量。 \n public   class   Demo   { \n   public   static   void   main ( String [ ]  args )   { \n     SafeCount  safeCount  =   new   SafeCount ( ) ; \n\n     new   Thread ( safeCount ) . start ( ) ; \n     new   Thread ( safeCount ) . start ( ) ; \n   } \n } \n\n class   SafeCount   implements   Runnable   { \n   @Override \n   public   void   run ( )   { \n     int  count  =   10 ; \n     try   { \n       Thread . sleep ( 1000 ) ; \n       while   ( count  >   0 )   { \n        count -- ; \n         System . out . printf ( "%s --\x3e %s\\n" ,   Thread . currentThread ( ) . getName ( ) ,  count ) ; \n       } \n     }   catch   ( InterruptedException  e )   { \n      e . printStackTrace ( ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 这个例子中，count 属于线程私有变量，无论执行多少次，我们都不需要担心同步问题。 \n class   SafeCount   implements   Runnable   { \n   final   Integer  count  =   10 ; \n\n   @Override \n   public   void   run ( )   { \n     try   { \n       Thread . sleep ( 1000 ) ; \n       System . out . printf ( "%s --\x3e %s\\n" ,   Thread . currentThread ( ) . getName ( ) ,  count ) ; \n     }   catch   ( InterruptedException  e )   { \n      e . printStackTrace ( ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 虽然 count 可以被多个线程共享，但是没有修改的情况，这也是线程安全的。 \n public   class   Demo   { \n   public   static   void   main ( String [ ]  args )   { \n     UnSafeCount  unSafeCount  =   new   UnSafeCount ( ) ; \n\n     new   Thread ( unSafeCount ) . start ( ) ; \n     new   Thread ( unSafeCount ) . start ( ) ; \n   } \n } \n\n class   UnSafeCount   implements   Runnable   { \n   int  count  =   10 ; \n\n   @Override \n   public   void   run ( )   { \n     try   { \n       Thread . sleep ( 1000 ) ; \n       while   ( count  >   0 )   { \n        count -- ; \n         System . out . printf ( "%s --\x3e %s\\n" ,   Thread . currentThread ( ) . getName ( ) ,  count ) ; \n       } \n     }   catch   ( InterruptedException  e )   { \n      e . printStackTrace ( ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 这个类变得不再安全，这是因为线程私有的 count 已经被多个线程共享，并且可以随时修改。 \n 其实本质上来说，这个类在多线程下不安全的原因是  count--  这个操作并非是原子性操作，表面上看  count--  虽然只有一步，但是它其实包含了三个步骤： \n \n 读取 count 的值。 \n 将值减少 1。 \n 写入 count 的值。 \n \n 在并发状态下，很有可能有 A、B 两个线程同时读取到 count 的值（这个时候 count 是相同的，例如是 9），那么它们就会同时执行后面的两步操作，导致 count 本来应当减少两次变成了减少一次。两个线程拿到的值也是相同的。 \n 对于不恰当的执行顺序导致的并发安全性问题，我们有一个专业术语：竞态条件。 \n 最常见的竞态条件就是：先检查后执行。也就是上面的例子，上面的例子首先会检查 count 的值，之后根据检查的返回结果做下一步的处理。 \n 另一个先检查后执行的例子是懒汉式单例模式，如果不加同步机制，懒汉式单例在多线程状态下是线程不安全的。 \n public   class   Singleton   { \n   private   Singleton ( )   { \n   } \n\n   private   static   Singleton  instance ; \n\n   public   static   Singleton   getInstance ( )   { \n     if   ( instance  !=   null )   { \n      instance  =   new   Singleton ( ) ; \n     } \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 所以这种复合操作必须为原子操作才可以避免竞态条件，注意，即使使用  AtomicInteger  也不能完全避免，因为  AtomicInteger  保护的只有它自己那一部分为原子操作，而不是整个方法为原子操作。最好的办法就是加锁。 \n 重入 \n 加锁其实是对一个线程加锁，而不是对一个操作加锁，举个例子： \n class   SafeCount   implements   Runnable   { \n   @Override \n   public   synchronized   void   run ( )   { \n     . . . \n   } \n } \n\n class   SafeChild   extends   SafeCount   { \n   @Override \n   public   void   run ( )   { \n     . . . \n     super . run ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 在这个例子中，假如  synchronized  保护的只有  SafeCount  中的 run，那么子类去调用父类的操作时是获取不到的，所以加锁保护的是这一整个线程，而不是仅仅某一个方法，这个概念叫做锁的重入。 \n 活跃性和性能问题 \n 尽管锁十分方便，但是不要依赖使用，锁在带来并发安全的同时也带来的是性能问题。要分清楚什么时候需要锁控制并发，什么时候不需要。尤其是对于耗时比较长的操作（网络、I/O）一定不要持有锁。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"September 15, 2021 08:08",createTimeStamp:1631664485e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1}]},{title:"设计模式-01-介绍",frontmatter:{title:"设计模式-01-介绍",categories:["backend"],tags:["designPatterns"],author:"causes",summary:"前言 参考资料： 黑马程序员设计模式; 《HeadFirst 设计模式》; 设计模式概述 设计模式最开始出现在建筑领域的设计中，建筑设计的基本模式高达253种，后来进入到软件的世界中，收入了23种设计模式。 软件设计模式，也叫做设计模式，它是被反复使用的经验总结，是被总结出来的一些套路，用于解决一些反复出现的问题，有一定的普适性。 --- 设计模式的本质是对",meta:[{property:"og:url",content:"/backend/DesignPatterns/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"设计模式-01-介绍"},{property:"og:description",content:"前言 参考资料： 黑马程序员设计模式; 《HeadFirst 设计模式》; 设计模式概述 设计模式最开始出现在建筑领域的设计中，建筑设计的基本模式高达253种，后来进入到软件的世界中，收入了23种设计模式。 软件设计模式，也叫做设计模式，它是被反复使用的经验总结，是被总结出来的一些套路，用于解决一些反复出现的问题，有一定的普适性。 --- 设计模式的本质是对"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"designPatterns"}]},regularPath:"/backend/DesignPatterns/part1.html",relativePath:"backend/DesignPatterns/part1.md",key:"v-700ad79e",path:"/backend/DesignPatterns/part1/",headers:[{level:2,title:"前言",slug:"前言"},{level:2,title:"设计模式概述",slug:"设计模式概述"},{level:2,title:"UML 类图",slug:"uml-类图"},{level:3,title:"类图的表现方式",slug:"类图的表现方式"},{level:3,title:"类和类/接口之间关系的表示方式",slug:"类和类-接口之间关系的表示方式"},{level:2,title:"软件设计原则",slug:"软件设计原则"},{level:3,title:"开闭原则",slug:"开闭原则"},{level:3,title:"里氏替换原则",slug:"里氏替换原则"},{level:3,title:"依赖倒转原则",slug:"依赖倒转原则"},{level:3,title:"接口隔离原则",slug:"接口隔离原则"},{level:3,title:"迪米特法则",slug:"迪米特法则"},{level:3,title:"合成复用",slug:"合成复用"}],readingTime:{minutes:10.22,words:3065},content:' 前言 \n 参考资料： \n \n 黑马程序员设计模式 \n 《HeadFirst 设计模式》 \n 设计模式概述 \n 设计模式最开始出现在建筑领域的设计中，建筑设计的基本模式高达 253 种，后来进入到软件的世界中，收入了 23种设计模式 。 \n 软件设计模式，也叫做设计模式，它是被反复使用的 经验总结 ，是被总结出来的一些套路，用于解决一些反复出现的问题，有一定的普适性。 \n \n 设计模式的本质是对类的封装、继承、多态，以及类的关联关系和组合关系的充分理解。 \n 正确使用设计模式具有以下优点： \n \n 提高程序员的思维能力，编程能力， 设计能力 。 \n 使程序设计更加标准化，代码编制更加工程化，使软件开发效率大大增加，从而缩短软件的开发周期。 \n 代码的可读性、重用性、可靠性高，灵活性、可维护性强。 \n \n \n 设计模式分类： \n \n \n 创建型模式 \n 用于描述如何创建对象，主要特点就是将对象的创建和使用分离。经典设计模式中有 单例、原型、工厂、抽象工厂、建造者 五种。 \n \n \n 结构型模式 \n 描述如何将类/对象按照某种布局组成更大的结构。经典设计模式中有 代理、适配器、桥接、装饰、外观、享元、组合 七种。 \n \n \n 行为型模式 \n 用于描述类或者对象之间如何相互协作共同完成单个对象无法完成的任务，以及如何分配职责。经典设计模式中有 模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器 十一种。 \n UML 类图 \n 统一建模语言（Unified Language，UML）是用来设计软件的可视化建模语言，特点是简单、统一、图形化、能表达软件设计中的动态和静态信息。 \n UML 从目标系统的不同角度出发，定义了用例图、类图、对象图、状态图、活动图、时序图、协作图、构件图、部署图。 \n 我们主要了解的就是 UML 类图，类图主要体现的就是静态信息。UML 类图是显示了模型的静态结构（类的内部结构、类与类的关系）。 \n 类图的表现方式 \n 类使用包含类、属性（field）、方法（method）并且带有分割线的矩形表示。比如下图的  Employee ，包含  name 、 age 、 address  三个属性和  work  方法。 \n \n UML 中的符号有三种： \n \n - ：表示  private 。 \n + ：表示  public 。 \n：表示  protected 。 \n \n 属性的完整表达方式为： 可见性 名称: 类型[ = 缺省值] \n 方法的完整表达方式为： 可见性 名称(参数列表) [ ： 返回类型] \n 注意： \n \n 中括号中的内容是可选的。 \n 也有将类型放在变量名前边，返回值类型放在方法名前面的写法。 \n 类和类/接口之间关系的表示方式 \n 关联关系 \n 关联关系是对象之间的一种引用关系。分为一般关联关系、聚合关系、组合关系。 \n 一般关联关系 \n 单向关联 \n \n 上图就是单向关联关系，使用一个带箭头的实线表示关系， Customer  引用  Address 。 \n 双向关联 \n \n 上图就是双向关联关系，使用不带箭头的实现表示关系， Customer  和  Product  相互引用，但是顾客可以购买多个商品，所以在  Customer  中显示的是  List 。 \n 自关联 \n \n 自关联用到的其实就是自己包含自己类型的变量。 \n 聚合关系 \n 聚合关系是整体对象（整体）和成员对象（部分）之间的关系。 \n 比如学校和老师，学校中包含老师，老师作为学校的一部分存在。 \n 但是成员对象也可以脱离整体对象存在。比如学校停办了，老师仍然存在，可以去其他的学校任职。 \n \n 聚合关系可以使用带空心菱形的实线表示，菱形的一方指向整体。 \n 组合关系 \n 组合关系表示类之间整体和部分之间的关系，但他是一种更加强烈的聚合关系。 \n 在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也就不存在了，部分对象不可以脱离整体而存在，例如头和嘴的关系，头没了嘴也不可能独立存在。 \n \n 组合关系使用带实心菱形的实线表示，菱形的一方指向整体。 \n 依赖关系 \n 依赖关系是一种使用关系，它是对象之间耦合度最弱的一种关联关系，是临时性的关联。比如在代码中，某一个类的方法通过局部变量、方法的参数，或者通过静态对象的方式访问另一个类（被依赖的类）的某些方法来完成一些职责。 \n \n 依赖关系使用带箭头的虚线表示，箭头从使用类开始，指向被依赖（被使用）的类。也就是  Driver  依赖于  Car 。 \n 继承关系 \n 继承关系是对象之间耦合度最大的一种关系。在类图中，继承关系也叫做泛化关系。 \n \n 继承关系使用带空心三角箭头的实线表示，箭头从子类开始，指向父类。 \n 实现关系 \n 实现关系是接口和类之间的关系。 \n \n 实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。 \n 软件设计原则 \n 开闭原则 \n 对扩展开放，对修改关闭 。也就是说在程序需要进行扩展的时候，不能修改原有代码，要实现热插拔的效果。简而言之，是为了程序的更好的扩张和升级。 \n 要想要达到这种的效果，我们需要使用到接口和抽象类。 \n 因为抽象类灵活性好，适应性广，只要抽象地比较合理，基本可以保持软件架构的稳定性。而软件易变的细节可以通过抽象类的派生类来实现，就相当于是定义规范。 \n 例如：搜狗输入法的皮肤，我们就可以看做是一个抽象类，皮肤可以随意更换，其实就是基于皮肤这种规则来进行的代码实现。 \n /**\n * 抽象皮肤类，只要继承抽象皮肤类就可以无限扩展\n */ \n public   abstract   class   AbstractSkin   { \n\n     // 显示的方法 \n     public   abstract   void   display ( ) ; \n } \n\n /**\n * 默认皮肤类\n */ \n public   class   DefaultSkin   extends   AbstractSkin { \n     @Override \n     public   void   display ( )   { \n         System . out . println ( "默认皮肤" ) ; \n     } \n } \n\n /**\n * 黑马皮肤类\n */ \n public   class   HeimaSkin   extends   AbstractSkin   { \n     @Override \n     public   void   display ( )   { \n         System . out . println ( "黑马程序员皮肤" ) ; \n     } \n } \n\n /**\n * 搜狗输入法\n */ \n public   class   SougouInput   { \n     private   AbstractSkin  skin ; \n\n     public   void   setSkin ( AbstractSkin  skin )   { \n         this . skin  =  skin ; \n     } \n\n     // 搜狗输入法展示 \n     public   void   display ( ) { \n        skin . display ( ) ; \n     } \n } \n\n public   class   Client   { \n     public   static   void   main ( String [ ]  args )   { \n         SougouInput  input  =   new   SougouInput ( ) ; \n         // 创建皮肤对象，想要什么皮肤就 new 什么皮肤 \n         DefaultSkin  skin  =   new   DefaultSkin ( ) ; \n        input . setSkin ( skin ) ; \n        input . display ( ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #  里氏替换原则 \n 任何基类可以出现的地方，子类一定可以出现 。通俗的说，子类可以扩展父类的功能，但是不能更改父类原来的功能。所以说，子类尽量不要重写父类的方法，这样会让重用性变差，新加功能会更好。 \n 正方形是长方形，而长方形不是正方形，所以针对于这种情况，正方形继承长方形不是个好选择，更好的方法是抽象出一个四边形类，两者去继承四边形。 \n /**\n * 四边形接口\n */ \n public   interface   Quadrilateral   { \n     double   getHeight ( ) ; \n\n     double   getWidth ( ) ; \n } \n\n /**\n * 长方形类\n */ \n @AllArgsConstructor \n public   class   Rectangle   implements   Quadrilateral { \n     private   double  width ; \n     private   double  height ; \n\n     @Override \n     public   double   getHeight ( )   { \n         return  height ; \n     } \n\n     @Override \n     public   double   getWidth ( )   { \n         return  width ; \n     } \n } \n\n /**\n * 正方形类\n */ \n @AllArgsConstructor \n public   class   Square   implements   Quadrilateral   { \n     private   double  side ; \n\n     @Override \n     public   double   getHeight ( )   { \n         return  side ; \n     } \n\n     @Override \n     public   double   getWidth ( )   { \n         return  side ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #  依赖倒转原则 \n 高层模块不应该依赖于低层模块，两者都应该依赖于低层模块的抽象。简单来说就是对抽象编程，具体实现是细节问题。 \n 现在有 A 类、B 类，其中 A 类用到了 B 类中的内容，这个时候 A 类叫做高层模块，B 类叫做低层模块。那么 A 类不应该依赖于 B 类，而应该依赖于 B 类的抽象。 \n 举个例子： \n 现在我们有一台电脑（高层模块），有各个配件（低层模块）：主板、CPU、散热器、内存条、显卡、电源……。 \n 组装电脑的精髓就是在于挑选各个配件进行组合，挑选出出电脑的最高性价比，也就是说你的各个配件不能是固定的品牌。以 CPU 举例子，我只知道我需要一个 CPU，而具体是 Intel 的还是 AMD 的，具体是什么型号的，这些不是在一开始要去操心的，这是细节问题。 \n \n 上面的图片就表示了这样一种关系，为了简单，我只写了电脑由 CPU、硬盘、内存构成，但是只是指出了他们的组成没有具体的实现，而具体的实现是具体的细节实现。 \n 假如用代码来展示，是这样的： \n @Data \n @AllArgsConstructor \n @NoArgsConstructor \n public   class   Computer   { \n   private   CPU  cpu ; \n   private   Disk  disk ; \n   private   Memory  memory ; \n } \n \n 1 2 3 4 5 6 7 8 public   interface  CPU  { \n } \n\n public   class  AMD  implements  CPU { \n } \n\n public   class   Intel   implements  CPU { \n } \n \n 1 2 3 4 5 6 7 8 public   interface   Disk   { \n } \n\n public   class   Xishu   implements   Disk { \n } \n \n 1 2 3 4 5 public   interface   Memory   { \n } \n\n public   class   WeiGang   implements   Memory { \n } \n \n 1 2 3 4 5 /**\n * 依赖倒转\n */ \n public   class   RelyOnReverse   { \n   public   static   void   main ( String [ ]  args )   { \n     Computer  computer  =   new   Computer ( ) ; \n    computer . setCpu ( new   AMD ( ) ) ; \n    computer . setDisk ( new   Xishu ( ) ) ; \n    computer . setMemory ( new   WeiGang ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 #  接口隔离原则 \n 简单来讲就是实现最小的接口。 \n 比如接口 A 有方法 1 和 方法 2，但是类 B 只需要实现方法 1 的功能，那么它去实现接口 A 就多余了方法 2，这样就违背了接口隔离原则。 \n 迪米特法则 \n 如果两个实体之间不需要直接的通信，那么就不需要直接的调用，而是可以通过第三方的转发来进行调用。目的就是为了降低耦合，提高模块之间的独立性。 \n 比如说，如果要租房，找的其实是中介而不是房东。如果要做软件，找的应该是软件公司而不是具体的工程师。 \n 合成复用 \n 类的复用通常来说分为：继承复用、合成复用。 \n 合成复用的意思是指：尽量优先使用组合或者聚合的关联关系来实现操作，其次才考虑使用继承关系来实现。 \n 我们首先要考虑合成复用而不是继承复用，因为继承复用虽然实现起来简单，但是存在以下缺点： \n \n 继承复用破坏了类的封装性，因为继承会将实现细节暴露给子类。父类对子类是透明的，所以继承复用又被称为白箱复用。 \n 子类和父类的耦合度高，父类的任何实现改变都会改变子类，这不利于类的扩展和维护。 \n 限制了复用的灵活性，因为从父类继承来的实现是静态的，在编译时就已经定义了，所以在运行时不可能发生变化。 \n \n 采用组合或者聚合复用时，可以将已有对象纳入到新的对象中，成为新对象的一部分，新对象可以调用原有对象，这有以下好处： \n \n 维持了类的封装性，因为类的内部实现细节不会对新对象开放。 \n 对象之间的耦合度低。 \n 这样可以在类的成员位置声明为抽象，复用的灵活性更高，这样的复用可以在运行时动态进行，新对象可以动态引用类型相同的对象。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 14, 2021 23:48",createTimeStamp:1628956128e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1}]},{title:"设计模式-02-创建者模式",frontmatter:{title:"设计模式-02-创建者模式",categories:["backend"],tags:["designPatterns"],author:"causes",summary:"创建者模式 创建者模式关注点是如何创建对象，它的主要特点就是将对象的创建和使用相分离。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节。 创建者模式分为以下几种： 单例模式。; 工厂方法模式。; 抽象工厂模式。; 原型模式。; 建造者模式。; 单例模式 单例模式介绍 单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一，",meta:[{property:"og:url",content:"/backend/DesignPatterns/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"设计模式-02-创建者模式"},{property:"og:description",content:"创建者模式 创建者模式关注点是如何创建对象，它的主要特点就是将对象的创建和使用相分离。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节。 创建者模式分为以下几种： 单例模式。; 工厂方法模式。; 抽象工厂模式。; 原型模式。; 建造者模式。; 单例模式 单例模式介绍 单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一，"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"designPatterns"}]},regularPath:"/backend/DesignPatterns/part2.html",relativePath:"backend/DesignPatterns/part2.md",key:"v-59db6648",path:"/backend/DesignPatterns/part2/",headers:[{level:2,title:"创建者模式",slug:"创建者模式"},{level:2,title:"单例模式",slug:"单例模式"},{level:3,title:"单例模式介绍",slug:"单例模式介绍"},{level:3,title:"单例模式实现",slug:"单例模式实现"},{level:2,title:"工厂模式",slug:"工厂模式"},{level:3,title:"简单工厂模式",slug:"简单工厂模式"},{level:3,title:"工厂方法模式",slug:"工厂方法模式"},{level:3,title:"抽象工厂模式",slug:"抽象工厂模式"},{level:3,title:"工厂模式扩展",slug:"工厂模式扩展"},{level:2,title:"原型模式",slug:"原型模式"},{level:2,title:"建造者模式",slug:"建造者模式"},{level:2,title:"创建者模式的对比",slug:"创建者模式的对比"}],readingTime:{minutes:19.08,words:5723},content:' 创建者模式 \n 创建者模式关注点是如何创建对象，它的主要特点就是将对象的创建和使用相分离。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节。 \n 创建者模式分为以下几种： \n \n 单例模式。 \n 工厂方法模式。 \n 抽象工厂模式。 \n 原型模式。 \n 建造者模式。 \n 单例模式 \n 单例模式介绍 \n 单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一，这种类型的设计模式属于创建者模式。这种模式涉及到一个类，这个类创建自己的对象，并且保证只有一个对象被创建，再次创建则复用上一次创建的对象，所以叫做单例对象。 \n 在对象创建之后，对外界提供一个唯一的访问对象的方式，可以直接访问，不需要实例化该类的对象。 \n 单例模式分为两类： \n \n 饿汉式：类加载就会创建对象。 \n 懒汉式：只有使用到对应的类才会创建对象。 \n 单例模式实现 \n 饿汉式： \n 方式一：使用静态变量的方式 \n /**\n* 饿汉式单例模式，静态变量的方式\n*/ \n public   class   Singleton   { \n\n   // 1. 私有构造方法。 \n   private   Singleton ( )   { \n   } \n\n   // 2. 在本类中创建本类对象。 \n   private   static   Singleton  instance  =   new   Singleton ( ) ; \n\n   // 3. 提供一个公共的访问方式让外界获取该对象、 \n   public   static   Singleton   getInstance ( )   { \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Singleton  instance  =   Singleton . getInstance ( ) ; \n     Singleton  instance2  =   Singleton . getInstance ( ) ; \n     // 比较地址 \n     System . out . println ( instance  ==  instance2 ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 方式二：使用静态代码块的方式 \n /**\n* 饿汉式单例模式：使用静态代码块的方式\n*/ \n public   class   Singleton   { \n   // 1. 私有构造方法 \n   private   Singleton ( )   { \n   } \n\n   private   static   Singleton  instance ; \n\n   // 2. 静态代码块进行赋值 \n   static   { \n    instance  =   new   Singleton ( ) ; \n   } \n\n   public   static   Singleton   getInstance ( )   { \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 总结：无论是使用静态变量还是静态代码块的方式，都是在类加载的时候就初始化了，所以会出现浪费内存的问题。 \n 方式三：枚举类加载方式 \n /**\n* 饿汉式单例模式，枚举类方式\n*/ \n public   enum   Singleton   { \n  INSTANCE ; \n } \n \n 1 2 3 4 5 6 枚举类方式同样属于饿汉式单例模式，因为枚举类是线程安全的，并且只会装载一次。枚举的写法十分简单，并且枚举类型是唯一一种不会被破坏的单例模式。所以在不考虑浪费空间的情况下，优先选择枚举类的单例模式。 \n 懒汉式 \n 方式一：线程不安全 \n public   class   Singleton   { \n   // 1. 私有化构造方法 \n   private   Singleton ( )   { \n   } \n\n   private   static   Singleton  instance ; \n\n   // 2. 首次使用类创建，其余返回已有的 \n   public   static   Singleton   getInstance ( )   { \n     if   ( instance  ==   null )   { \n      instance  =   new   Singleton ( ) ; \n     } \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 这种方式其实是有问题的，在多线程状况下很有可能破坏我们想要的单例模式。 \n 方式二：线程安全 \n public   class   Singleton   { \n   private   Singleton ( )   { \n   } \n\n   private   static   Singleton  instance ; \n   // 解决线程问题，其实只需要加上一个 synchronized 关键字即可，可以保证同一时间只有一个线程使用此方法。 \n   public   static   synchronized   Singleton   getInstance ( )   { \n     if   ( instance  !=   null )   { \n      instance  =   new   Singleton ( ) ; \n     } \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 使用关键字  synchronized  虽然可以解决线程不安全的问题，但是同样会引起性能问题，因为只有第一次执行此方法的时候，变量  instance  才会执行赋值操作，其余的时间都是在执行获取  instance  的操作，而获取 instance 本身就是安全的。 \n 方式三：双重检测锁 \n package   com . maple . pattern . singleton . demo4 ; \n\n public   class   Singleton   { \n\n   private   Singleton ( )   { \n   } \n\n   // 多线程模式下可能会出现空指针问题，原因是 JVM 在实例化对象的时候可能会被 CPU 进行指令重排操作（有兴趣可以去看并发编程），所以使用 volatile 能保证可见性和有序性。 \n   private   static   volatile   Singleton  instance ; \n\n   public   static   Singleton   getInstance ( )   { \n     // 首次判断，假如 instance 不为 null，则直接返回对象，提升效率，但是这仍然挡不住线程问题 \n     if   ( instance  ==   null )   { \n       // 使用同步代码块锁当前类，挡住线程问题 \n       synchronized   ( Singleton . class )   { \n         // 第二次判断 \n         if   ( instance == null ) { \n          instance  =   new   Singleton ( ) ; \n         } \n       } \n     } \n     return  instance ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 双重检测锁模式仅仅锁住了赋值的操作也就是写操作，提升了性能。并且使用  volatile  来保证了可见性和有序性。我们推荐使用双重检查锁模式。 \n 方式四：静态内部类方式 \n public   class   Singleton   { \n   private   Singleton ( )   { \n   } \n\n   private   static   class   SingletonHolder { \n     private   static   final   Singleton  INSTANCE  =   new   Singleton ( ) ; \n   } \n\n   private   static   Singleton   getInstance ( ) { \n     return   SingletonHolder . INSTANCE ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 JVM 在加载外部类的时候并不会加载内部类，只有内部类的属性/方法被调用的时候才会被加载，并且初始化其静态属性。静态属性由于被 static 修饰，保证只实例化一次，并且严格保证执行顺序（解决指令重排）。 \n 静态内部类是一种极其优秀的单例模式，是开源项目中比较常用的一种方式。在没有加任何锁的情况下，保证了多线程下的安全，并且没有任何的性能和空间的浪费。 \n \n 在 JDK 中，有大量的类都使用到了单例模式，比如  Runtime 。 \n 工厂模式 \n 在 Java 中，万物皆对象，这些对象都需要去创建。如果在创建的时候都去 new 对象，那么其实和对应的类耦合度会很高。比如像我们之前使用的多态，虽然比较方便，但是耦合度其实也是比较高的。如果我们需要更换对象，那么所有需要使用到该对象的地方都需要更改代码，这显然违反了开闭原则（对修改关闭）。 \n 假如我们使用工厂来生产对象，那么我们要更换对象的时候只需要更改工厂的内容即可。达到了与对象解耦的目的（耦合不可能完全解除，我们要做的只是降低耦合度）。 \n 下面我们进行三种工厂模式的讲解： \n \n 简单工厂模式（其实它不属于 23 种设计模式之一，反而像变成习惯，但是在平时使用中太多了）。 \n 工厂方法模式。 \n 抽象工厂模式。 \n 简单工厂模式 \n 简单工厂模式其实不是 23 种设计模式之一，但是因为它在平时使用太多了，所以讲一下。 \n 简单工厂模式包含以下角色： \n \n 抽象产品：定义了产品的规范，描述了产品的主要功能和特性。 \n 具体产品：实现或者继承了抽象产品的子类。 \n 具体工厂：提供了创建产品的方法，调用者通过该方法来创建产品。 \n \n \n 类图如上图，分为抽象产品（Coffee）、具体产品（AmericanCoffee、LatteCoffee）、具体工厂（SimpleCoffeeFactory）、测试类（CoffeeStore）。 \n 简单工厂模式实现 \n /**\n * 抽象类\n */ \n public   abstract   class   Coffee   { \n\n   abstract   String   getName ( ) ; \n\n   String   getMilk ( ) { \n     return   "加奶" ; \n   } ; \n   String   getSugar ( ) { \n     return   "加糖" ; \n   } ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /**\n * 美式咖啡\n */ \n public   class   AmericanCoffee   extends   Coffee { \n   @Override \n   String   getName ( )   { \n     return   "美式咖啡" ; \n   } \n } \n\n /**\n * 拿铁咖啡\n */ \n public   class   LatteCoffee   extends   Coffee { \n   @Override \n   String   getName ( )   { \n     return   "拿铁咖啡" ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public   class   SimpleCoffeeFactory   { \n\n   public   Coffee   createCoffee ( String  type ) { \n     Coffee  coffee  =   null ; \n\n     switch   ( type ) { \n       case   "American" : \n         return   new   AmericanCoffee ( ) ; \n       case   "Lattee" : \n         return   new   LatteCoffee ( ) ; \n     } \n\n     return  coffee ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public   class   CoffeeStore   { \n   public   static   void   main ( String [ ]  args )   { \n     SimpleCoffeeFactory  factory  =   new   SimpleCoffeeFactory ( ) ; \n     AmericanCoffee  americanCoffee  =   ( AmericanCoffee )  factory . createCoffee ( "American" ) ; \n     System . out . println ( americanCoffee . getName ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 简单工厂模式的优缺点 \n 优点： \n \n 封装了创建对象的过程，可以通过参数直接获得对象，将对象的创建和业务逻辑层分离。降低了使用和创建的耦合，更容易维护。 \n \n 缺点： \n \n 增减产品还是需要修改工厂类的代码，其实还是违反了开闭原则。这也是为什么没有收录到 23 种设计模式中的原因之一。 \n \n 扩展：静态工厂 \n 其实在开发中，还是有一部分人将工厂类中的创建功能定义为静态的，这也不是 23 种设计模式中的一种，代码如下： \n public   class   SimpleCoffeeFactory   { \n\n   public   static   Coffee   createCoffee ( String  type ) { \n     Coffee  coffee  =   null ; \n     switch   ( type ) { \n       case   "American" : \n         return   new   AmericanCoffee ( ) ; \n       case   "Lattee" : \n         return   new   LatteCoffee ( ) ; \n     } \n     return  coffee ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 #  工厂方法模式 \n 简单工厂模式其实还是违背了开闭原则，假如我们使用工厂方法模式就可以解决这个问题。它的思想就是定义一个用于创建对象的接口，让子类去决定实例化哪一个产品类对象。 \n 工厂方法模式的主要角色 \n \n 抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它来访问具体工厂的工厂方法来创建产品。 \n 具体工厂（Concrete Factory）：实现了抽象工厂中的抽象方法，完成具体产品的创建。 \n 抽象产品（Product）：定义了产品规范，描述产品的主要功能和特性。 \n 具体产品（Concrete Product）：实现了抽象产品角色所定义的接口，由具体工厂创建，和具体工厂之间一一对应。 \n \n 实现 \n \n 上面的类图描述的就是工厂方法模式中的角色关系： \n \n \n 右边的部分： \n 首先就是 Coffee 接口，其中具体的实现类有 AmericanCoffee，LatteCoffee。 \n \n \n 中间的部分： \n 中间的 Coffee Store 是咖啡店，拥有点咖啡的功能。\n它依赖于 Coffee，也就是依赖于抽象不依赖于具体实现，符合我们之前说的依赖倒转原则。 \n \n \n 左边的部分： \n 首先有一个 CoffeeFactory 的接口，拥有 createCoffee 方法。\n具体的实现类有 AmericanCoffeeFactory（生产美式咖啡），LatteCoffeeFactory（生产拿铁咖啡）。 \n \n \n public   abstract   class   Coffee   { \n   abstract   String   getName ( ) ; \n\n   String   addMilk ( ) { \n     return   "加奶" ; \n   } \n\n   String   addSuger ( ) { \n     return   "加糖" ; \n   } \n } \n\n public   class   AmericanCoffee   extends   Coffee { \n   @Override \n   String   getName ( )   { \n     return   "美式咖啡" ; \n   } \n } \n\n public   class   LatteCoffee   extends   Coffee { \n   @Override \n   String   getName ( )   { \n     return   "拿铁咖啡" ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public   interface   CoffeeFactory   { \n   Coffee   createCoffee ( ) ; \n } \n\n public   class   AmericanCoffeeFactory   implements   CoffeeFactory { \n   @Override \n   public   Coffee   createCoffee ( )   { \n     return   new   AmericanCoffee ( ) ; \n   } \n } \n\n public   class   LatteCoffeeFactory   implements   CoffeeFactory { \n   @Override \n   public   Coffee   createCoffee ( )   { \n     return   new   LatteCoffee ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Data \n @AllArgsConstructor \n public   class   CoffeeStore   { \n\n   private   CoffeeFactory  factory ; \n\n   Coffee   orderCoffee ( ) { \n     Coffee  coffee  =  factory . createCoffee ( ) ; \n    coffee . addMilk ( ) ; \n    coffee . addSuger ( ) ; \n     return  coffee ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     AmericanCoffeeFactory  factory  =   new   AmericanCoffeeFactory ( ) ; \n     CoffeeStore  coffeeStore  =   new   CoffeeStore ( factory ) ; \n     System . out . println ( coffeeStore . orderCoffee ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 工厂方法模式的优缺点 \n 优点： \n \n 首先工厂方法模式完全符合开闭原则（对扩展开放，对修改关闭）。 \n 用户获取产品只需要知道具体的工厂，无需知道具体的创建过程。 \n \n 缺点： \n \n 要增加内容的时候需要增加工厂和对应的产品，创建的对象有点多，增加了系统的复杂性。 \n 抽象工厂模式 \n 抽象工厂模式介绍 \n \n 上面我们讲的工厂方法模式只是生产同一类的产品，比如说 CoffeeFactory 只会生产咖啡，不管是什么品牌的咖啡都可以生产。这种情况我们叫做 只生产同一级别的产品 。 \n 苹果厂商可以生产苹果手机，也可以生产苹果电脑，但是不关生产什么，都是同一个品牌，这个情况叫做 生产同一个产品族的产品 。 \n 抽象工厂模式就是可以 获取同一个产品组的产品 的设计模式，比如说，利用抽象工厂模式获得某一个品牌的衣服和裤子。 \n 抽象工厂的角色如下： \n \n 抽象工厂（Abstract Factory）：提供了创建产品的接口，定义了同一个产品族的不同等级的产品。 \n 具体工厂（Concrete Factory）：完成具体产品的创建。 \n 抽象产品（Abstract Product）：定义产品规范，描述产品主要功能特性。 \n 具体产品（Concrete Product）：实现抽象产品的接口，和具体工厂一一对应。 \n \n 实现 \n 我们之前举的例子都是咖啡类，现在我们仍然以咖啡举例，不过咖啡店的业务现在发生了改变，除了生产咖啡还要生产甜点。\n现在有：咖啡（美式咖啡、拿铁咖啡），甜点（提拉米苏，抹茶慕斯） \n public   abstract   class   Coffee   { \n   abstract   String   getName ( ) ; \n\n   String   addMilk ( ) { \n     return   "加奶" ; \n   } \n\n   String   addSuger ( ) { \n     return   "加糖" ; \n   } \n } \n\n public   class   AmericanCoffee   extends   Coffee   { \n   @Override \n   String   getName ( )   { \n     return   "美式咖啡" ; \n   } \n } \n\n public   class   LatteCoffee   extends   Coffee   { \n   @Override \n   String   getName ( )   { \n     return   "拿铁咖啡" ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /**\n * 甜品抽象类\n */ \n public   abstract   class   Dessert   { \n   public   abstract   String   show ( ) ; \n } \n\n public   class   Trimisu   extends   Dessert { \n   @Override \n   public   String   show ( )   { \n     return   "提拉米苏" ; \n   } \n } \n\n public   class   MatchaMousse   extends   Dessert   { \n   @Override \n   public   String   show ( )   { \n     return   "抹茶慕斯" ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public   interface   DessertFactory   { \n\n   Coffee   createCoffee ( ) ; \n\n   Dessert   createDessert ( ) ; \n } \n\n /**\n * 美式风味工厂\n */ \n public   class   AmericanDessertFactory   implements   DessertFactory { \n   @Override \n   public   Coffee   createCoffee ( )   { \n     return   new   AmericanCoffee ( ) ; \n   } \n\n   @Override \n   public   Dessert   createDessert ( )   { \n     return   new   MatchaMousse ( ) ; \n   } \n } \n\n /**\n * 意大利风味工厂\n */ \n public   class   ItalyDessertFactory   implements   DessertFactory { \n   @Override \n   public   Coffee   createCoffee ( )   { \n     return   new   LatteCoffee ( ) ; \n   } \n\n   @Override \n   public   Dessert   createDessert ( )   { \n     return   new   MatchaMousse ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     AmericanDessertFactory  americanDessertFactory  =   new   AmericanDessertFactory ( ) ; \n     Coffee  coffee  =  americanDessertFactory . createCoffee ( ) ; \n     Dessert  dessert  =  americanDessertFactory . createDessert ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 抽象工厂模式优缺点和使用场景 \n 优点： \n \n 当一个产品族中的多个对象被设计成一起工作时，能够保证客户端始终使用一个产品组中的对象。 \n \n 缺点： \n \n 当产品组需要新加一类新的产品时，所有的工厂类都需要进行修改。（比如现在是只有甜品和咖啡，但是如果想要再加一类饮料，就要修改所有的代码）。 \n \n 使用场景： \n \n 当需要创建的对象是一系列相关的或者相互依赖的产品时，可以使用抽象工厂模式。 \n 系统中有多个产品族，但是每次只使用其中一个产品族中的产品，比如某人只喜欢穿一个品牌的衣服裤子。 \n 工厂模式扩展 \n 在实际的应用中，经常有一种固定的写法：配置文件 + 反射的方式，来进行类的创建： \n \n \n 在  resources/bean.properties  下，编写类的全路径： \n public   abstract class Coffee { \n   abstract   String getName(); \n\n   String   addMilk(){ \n     return   "加奶"; \n  }\n\n   String   addSuger(){ \n     return   "加糖"; \n  }\n}\n\n public   class LatteCoffee extends Coffee { \n  @Override\n   String   getName() { \n     return   "拿铁咖啡"; \n  }\n}\n\n public   class AmericanCoffee extends Coffee { \n  @Override\n   String   getName() { \n     return   "美式咖啡"; \n  }\n}\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \n \n 使用反射的方式直接创建对象： \n public   class   CoffeeFactory   { \n   private   static   Map < String ,   Coffee >  factory  =   new   HashMap < > ( ) ; \n\n   static   { \n     Properties  properties  =   new   Properties ( ) ; \n     InputStream  inputStream  =   CoffeeFactory . class . getClassLoader ( ) . getResourceAsStream ( "bean.properties" ) ; \n     try   { \n      properties . load ( inputStream ) ; \n       for   ( Object  key  :  properties . keySet ( ) )   { \n         String  className  =  properties . getProperty ( ( String )  key ) ; \n         Coffee  coffee  =   ( Coffee )   Class . forName ( className ) . newInstance ( ) ; \n        factory . put ( ( String )  key , coffee ) ; \n       } \n     }   catch   ( Exception  e )   { \n      e . printStackTrace ( ) ; \n     } \n   } \n\n   public   static   Coffee   createCoffee ( String  coffee ) { \n     return  factory . get ( coffee ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n \n 测试： \n public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Coffee  coffee  =   CoffeeFactory . createCoffee ( "american" ) ; \n     System . out . println ( coffee . getName ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 \n 原型模式 \n 类似克隆羊，使用一个已经创建的实例作为原型，通过复制将该原型对象来创建一个和原型对象相同的新对象。 \n 原型模式包含以下角色： \n \n 抽象原型类：规定了具体原型对象必须实现的  clone()  方法。 \n 具体原型类：实现了抽象原型类的  clone()  方法，它是可以被复制的对象。 \n 访问类：使用具体原型类中的  clone()  方法来复制新的对象。 \n \n 原型模式的克隆分为浅克隆和深克隆： \n \n 浅克隆：创建一个新对象，新对象的属性和原来的对象完全相同，但是对于非基本类型，指向的是原对象的地址值。 \n 深克隆：创建一个新对象，新对象的属性（无论是基本类型还是非基本类型）都会被克隆。 \n \n 原型模式（浅克隆）实现 \n Java 中的 Object 类提供了  clone  方法来实现浅克隆， Cloneable  接口是上面类图中的抽象原型类，而实现了接口  Cloneable  的就是具体的原型类。所以直接写具体原型类即可。 \n /**\n * 浅克隆\n */ \n public   class   Realizetype   implements   Cloneable { \n   @Override \n   public   Realizetype   clone ( )   throws   CloneNotSupportedException   { \n     return   ( Realizetype )   super . clone ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   throws   CloneNotSupportedException   { \n     Realizetype  realizetype  =   new   Realizetype ( ) ; \n     Realizetype  clone  =  realizetype . clone ( ) ; \n     System . out . println ( realizetype  ==  clone ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 原型模式（深克隆）实现 \n 下面我们做一个奖状类，实现奖状类的克隆。但是奖状是属于学生的，所以奖状类中要有学生，这就可以实现深克隆。 \n 假如要实现深克隆，就要使用到对象流。它的思想就是将对象序列化到磁盘上，然后再次读取的时候就会创建一个新的对象。 \n @Data \n @AllArgsConstructor \n public   class   Student   implements   Serializable   { \n   private   String  name ; \n } \n \n 1 2 3 4 5 @Data \n public   class   Citation   implements   Cloneable ,   Serializable   { \n\n   private   Student  student ; \n\n   public   void   show ( ) { \n     System . out . println ( student . getName ( )   +   "同学得到奖状" ) ; \n   } \n\n   @Override \n   protected   Citation   clone ( )   throws   CloneNotSupportedException   { \n     return   ( Citation )   super . clone ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   throws   CloneNotSupportedException ,   IOException ,   ClassNotFoundException   { \n     // 原型 \n     Citation  citation  =   new   Citation ( ) ; \n    citation . setStudent ( new   Student ( "张三" ) ) ; \n\n     // 克隆 \n     ObjectOutputStream  oos  =   new   ObjectOutputStream ( new   FileOutputStream ( "D:/Utils/a.txt" ) ) ; \n    oos . writeObject ( citation ) ; \n    oos . close ( ) ; \n\n     ObjectInput  ois  =   new   ObjectInputStream ( new   FileInputStream ( "D:/Utils/a.txt" ) ) ; \n     Citation  clone  =   ( Citation )  ois . readObject ( ) ; \n    ois . close ( ) ; \n\n    clone . setStudent ( new   Student ( "李四" ) ) ; \n\n    citation . show ( ) ; \n    clone . show ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 注意必须实现序列化接口，否则就会抛出异常。 \n 建造者模式 \n 建造者模式其实就是将构建和装配两部分相互分离，让同样的构建过程有可能会创建不同的表示的设计模式。 \n \n 如上图，现在有一台电脑，它的组件如左边的部分，它的组成如右边的部分： \n \n 部件的构造就是形成左边部分的组件内容。 \n 部件的装配就是左边组装成右边电脑的过程。 \n \n 对于用户来说，他不需要去关心左边的组件是怎么样的，他只关心右边电脑的成品，也就是说只需要知道右边产品的类型，就可以通过建造者模式将成品组装起来。 \n 由于实现了构建和装配的解耦合，所以不同的组件，即使使用相同的构建过程最终产生的产品也不相同。同样的，即使使用相同的组件，构建过程相同最终的产品也有可能不同（这一点在上图没有体现，不过确实存在这种情况）。 \n 我们现在将这些组件的构造交给 Builder 去负责，将组件的构建过程交给 Director 负责，所以建造者模式存在以下角色： \n \n 抽象建造者类（Builder）：这个接口/抽象类规定了要实现复杂对象的哪些部分的创建，不涉及具体部件的创建。 \n 具体建造者类（ConcreteBuilder）：实现 Builder 接口，完成复杂产品中各个部件的创建。 \n 指挥者类（Director）：完成复杂对象各个部件的组装，不涉及具体的产品信息，只负责保证组件的组装过程，形成最终的产品类。 \n 产品类（Product）：要最终完成的产品。 \n \n 实现 \n 使用自行车来练习建造者模式，一个具体的自行车包含车架、车座等部件，而车架有各种分类（铝合金的、碳纤维的），车座也有各种分类（橡胶的、真皮的）。 \n 对于自行车来说，产品 Product 就是 Bike，抽象建造者是 Builder，具体建造者是 MobikeBuilder 和 OfoBuilder，指挥者是 Director。 \n /**\n * 自行车\n */ \n @Data \n @AllArgsConstructor \n @NoArgsConstructor \n public   class   Bike   { \n   private   String  frame ; \n   private   String  seat ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 /**\n * 建造者抽象类\n */ \n public   abstract   class   Builder   { \n\n   protected   Bike  bike  =   new   Bike ( ) ; \n\n   public   abstract   void   buildFrame ( ) ; \n\n   public   abstract   void   buildSeat ( ) ; \n\n   // 构建自行车的方法 \n   public   abstract   Bike   createBike ( ) ; \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /**\n * Mobile 单车\n */ \n public   class   MobileBuilder   extends   Builder { \n   @Override \n   public   void   buildFrame ( )   { \n    bike . setFrame ( "碳纤维车架" ) ; \n   } \n\n   @Override \n   public   void   buildSeat ( )   { \n    bike . setSeat ( "真皮车座" ) ; \n   } \n\n   @Override \n   public   Bike   createBike ( )   { \n     return  bike ; \n   } \n } \n\n /**\n * Ofo 单车\n */ \n public   class   OfoBuilder   extends   Builder { \n   @Override \n   public   void   buildFrame ( )   { \n    bike . setFrame ( "铝合金车架" ) ; \n   } \n\n   @Override \n   public   void   buildSeat ( )   { \n    bike . setSeat ( "橡胶车座" ) ; \n   } \n\n   @Override \n   public   Bike   createBike ( )   { \n     return  bike ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /**\n * 指挥者\n */ \n @AllArgsConstructor \n public   class   Director   { \n\n   private   Builder  builder ; \n\n   /**\n   * 组装自行车，设置构建顺序（首先是车架，然后是车座）\n   * @return 自行车\n   */ \n   public   Bike   constructor ( ) { \n    builder . buildFrame ( ) ; \n    builder . buildSeat ( ) ; \n     return  builder . createBike ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Bike  bike  =   new   Director ( new   MobileBuilder ( ) ) . constructor ( ) ; \n     System . out . println ( bike . toString ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 注意 \n 上面的实例是 Builder 模式的标准用法，但是看起来系统结构比较复杂，所以很多时候我们就会将此系统进行简化，也就是将指挥者 Director 和抽象建造者 Builder 进行结合，如下： \n public   abstract   class   Builder   { \n\n   protected   Bike  bike  =   new   Bike ( ) ; \n\n   public   abstract   void   buildFrame ( ) ; \n\n   public   abstract   void   buildSeat ( ) ; \n\n   // 构建自行车的方法 \n   public   abstract   Bike   createBike ( ) ; \n\n   public   Bike   builde ( ) { \n     return   this . createBike ( ) ; \n   } \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Bike  bike  =   new   MobileBuilder ( ) . builde ( ) ; \n     System . out . println ( bike . toString ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 虽然这样做确实是简化了系统结构，但是同样也加重了抽象建造者模式的职责，不太符合单一职责原则，假如抽象产品的组装过程确实复杂，建议还是抽出来一层指挥者 Director 来实现组装过程。 \n 建造者模式的优缺点和使用场景 \n 优点： \n \n 建造者模式的封装性很好，假如有新的需求，那么新加一个建造者即可。假如组装的过程经常变更，那么只需要更改指挥者 Director 即可。 \n 可以更精细地控制组装的过程。 \n \n 缺点： \n \n 建造者模式创建的产品一般有较多的共同点，也就是说组成结构相似，假如产品之间的差异过大，那么不太适合使用建造者模式。 \n \n 使用场景： \n \n 建造者模式的产品中各个部分经常面临剧烈变化，但是将它们组合到一起的算法相对稳定。所以可以根据这个特点来进行选择。 \n \n 扩展 \n 假如一个类需要非常多的参数（而且参数不固定，可能是一个参数有多个选择）才可创建，可读性较查，这个时候我们就可以使用建造者模式来进行重构。 \n 重构之前（用四个参数做个例子）： \n @Data \n @AllArgsConstructor \n @NoArgsConstructor \n public   class   Phone   { \n\n   private   String  cpu ; \n   private   String  screen ; \n   private   String  memory ; \n   private   String  mainboard ; \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 重构之后： \n public   class   Phone   { \n\n   private   String  cpu ; \n   private   String  screen ; \n   private   String  memory ; \n   private   String  mainboard ; \n\n   @Override \n   public   String   toString ( )   { \n     return   "Phone{"   + \n         "cpu=\'"   +  cpu  +   \'\\\'\'   + \n         ", screen=\'"   +  screen  +   \'\\\'\'   + \n         ", memory=\'"   +  memory  +   \'\\\'\'   + \n         ", mainboard=\'"   +  mainboard  +   \'\\\'\'   + \n         \'}\' ; \n   } \n\n   private   Phone ( Builder  builder ) { \n     this . cpu  =  builder . cpu ; \n     this . screen  =  builder . screen ; \n     this . memory  =  builder . memory ; \n     this . mainboard  =  builder . mainboard ; \n   } \n\n   public   static   final   class   Builder   { \n     private   String  cpu ; \n     private   String  screen ; \n     private   String  memory ; \n     private   String  mainboard ; \n\n     public   Builder   cpu ( String  cpu )   { \n       this . cpu  =  cpu ; \n       return   this ; \n     } \n\n     public   Builder   screen ( String  screen )   { \n       this . screen  =  screen ; \n       return   this ; \n     } \n\n     public   Builder   memory ( String  memory )   { \n       this . memory  =  memory ; \n       return   this ; \n     } \n\n     public   Builder   mainboard ( String  mainboard )   { \n       this . mainboard  =  mainboard ; \n       return   this ; \n     } \n\n     public   Phone   build ( ) { \n       return   new   Phone ( this ) ; \n     } \n   } \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Phone  phone  =   new   Phone . Builder ( ) \n         . cpu ( "intel" ) \n         . screen ( "三星" ) \n         . mainboard ( "金士顿" ) \n         . mainboard ( "华硕" ) \n         . build ( ) ; \n     System . out . println ( phone ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 这种虽然设计起来比较复杂，但是使用起来异常方便。 \n 创建者模式的对比 \n 工厂方法模式 vs 建造者模式： \n \n 工厂方法模式注重的是整体对象的创建方式。 \n 建造者模式注重的是部件构建的过程。 \n \n 抽象工厂模式 vs 建造者模式： \n \n 抽象工厂模式实现对产品家族的创建，比如说相同品牌的不同产品。 \n 建造者模式要求按照指定的蓝图即按照产品，它的主要目的是通过组装零配件产生一个新的产品。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 14, 2021 23:48",createTimeStamp:1628956128e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"causes",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"设计模式-03-结构型模式",frontmatter:{title:"设计模式-03-结构型模式",categories:["backend"],tags:["designPatterns"],author:"causes",summary:"结构型模式 结构型模式强调的是结构，如何将对象或者类按照某种更大的布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者采用组合/聚合来组合对象。 由于组合/聚合关系的耦合度比继承关系的耦合度低，满足合成复用原则，所以对象结构型模式比类结构型模式有更大的灵活性。 结构型模式分为以下七种： 代理模式。; 适配器模式。; 装",meta:[{property:"og:url",content:"/backend/DesignPatterns/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"设计模式-03-结构型模式"},{property:"og:description",content:"结构型模式 结构型模式强调的是结构，如何将对象或者类按照某种更大的布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者采用组合/聚合来组合对象。 由于组合/聚合关系的耦合度比继承关系的耦合度低，满足合成复用原则，所以对象结构型模式比类结构型模式有更大的灵活性。 结构型模式分为以下七种： 代理模式。; 适配器模式。; 装"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"designPatterns"}]},regularPath:"/backend/DesignPatterns/part3.html",relativePath:"backend/DesignPatterns/part3.md",key:"v-3619c21a",path:"/backend/DesignPatterns/part3/",headers:[{level:2,title:"结构型模式",slug:"结构型模式"},{level:2,title:"代理模式",slug:"代理模式"},{level:3,title:"静态代理",slug:"静态代理"},{level:3,title:"动态代理",slug:"动态代理"},{level:2,title:"适配器模式",slug:"适配器模式"},{level:2,title:"装饰者模式",slug:"装饰者模式"},{level:2,title:"桥接模式",slug:"桥接模式"},{level:2,title:"外观模式",slug:"外观模式"},{level:2,title:"组合模式",slug:"组合模式"},{level:2,title:"享元模式",slug:"享元模式"}],readingTime:{minutes:22.83,words:6850},content:' 结构型模式 \n 结构型模式强调的是结构，如何将对象或者类按照某种更大的布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者采用组合/聚合来组合对象。 \n 由于组合/聚合关系的耦合度比继承关系的耦合度低，满足合成复用原则，所以对象结构型模式比类结构型模式有更大的灵活性。 \n 结构型模式分为以下七种： \n \n 代理模式。 \n 适配器模式。 \n 装饰者模式。 \n 桥接模式。 \n 外观模式。 \n 组合模式。 \n 享元模式。 \n 代理模式 \n 如果我们想要买房的话，找的是中介而不是房产公司。假如我们想要买电脑，找的是地方代理商而不是具体公司。 \n 所以这就是代理模式，通过一个代理来实现最终的目标，代理模式是一样，访问对象不能直接引用目标对象，而是通过一个中介来访问对应的目标对象。 \n Java 中的代理按照代理生成的时机不同又分为静态代理和动态代理。静态代理在编译期就已经生成，动态代理则是在 Java 运行时动态生成。动态代理又分为 JDK 代理和 CGLib 代理。 \n \n 静态代理：编译期生成代理对象。 \n 动态代理：Java 运行期间动态生成。\n \n JDK 代理。 \n CGLib 代理。 \n \n \n \n 代理 Proxy 又分为三种角色： \n \n 抽象主题 Subject：通过接口/抽象类声明真实主题和代理对象实现的业务方法。 \n 真实主题 Real Subject：实现了抽象类主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。 \n 代理 Proxy：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。 \n 静态代理 \n 假如我们买火车站，需要坐车到火车站买票，显然比较麻烦。而火车站在多个位置都有代售点，我们到达代售点买票显然要比火车站买票简单的多。 \n 这其实就是典型的代理模式，火车站是目标对象，代售点是代理对象。 \n public   interface   SellTickets   { \n   public   void   sell ( ) ; \n } \n \n 1 2 3 public   class   TrainStation   implements   SellTickets { \n   @Override \n   public   void   sell ( )   { \n     System . out . println ( "卖票" ) ; \n   } \n } \n \n 1 2 3 4 5 6 public   class   ProxyPoint   implements   SellTickets { \n\n   // 声明火车站类对象 \n   private   TrainStation  station  =   new   TrainStation ( ) ; \n\n   @Override \n   public   void   sell ( )   { \n     System . out . println ( "代售点做功能增强" ) ; \n    station . sell ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     ProxyPoint  proxyPoint  =   new   ProxyPoint ( ) ; \n    proxyPoint . sell ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 Tips \n 注意，代理其实最终还是调用的目标对象的方法，只不过做了一些增强。 \n 动态代理 \n JDK 动态代理 \n 下面使用动态代理，首先进行 JDK 动态代理。Java 中提供了一个动态代理类 Proxy，Proxy 并不是我们上述所说的代理对象的类，而是提供了一个创建代理对象的静态方法（new ProxyInstance）来获取代理对象。 \n public   interface   SellTickets   { \n   public   void   sell ( ) ; \n } \n\n public   class   TrainStation   implements   SellTickets   { \n   @Override \n   public   void   sell ( )   { \n     System . out . println ( "卖票" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 /**\n * 获取代理对象的工厂类\n */ \n public   class   ProxyFactory   { \n\n   // 声明目标对象 \n   private   TrainStation  station  =   new   TrainStation ( ) ; \n\n   /**\n   * 获取代理对象\n   *\n   * @return 代理对象\n   */ \n   public   SellTickets   getProxyObject ( )   { \n     /*\n      newProxyInstance 参数说明：\n          - ClassLoader：目标对象的类加载器\n          - interfaces：目标对象实现的接口的字节码\n          - InvocationHandler：代理对象的调用处理程序\n     */ \n     SellTickets  proxyObject  =   ( SellTickets )   Proxy . newProxyInstance ( \n        station . getClass ( ) . getClassLoader ( ) , \n        station . getClass ( ) . getInterfaces ( ) , \n         new   InvocationHandler ( )   { \n           /**\n           * invoke 参数说明\n           *\n           * @param proxy  代理对象，和 proxyObjecy 是一个对象\n           * @param method 对接口中的方法进行封装的 method，比如封装了 sell() 和其他的方法\n           * @param args   调用方法的实际参数，调用什么方法就会传递对应的参数，比如这里调用 sell() 没有参数，那么 args 就没有\n           * @return 调用方法的返回值，比如说调用了 sell()，sell 没有返回值，那么这里就是 null\n           */ \n           @Override \n           public   Object   invoke ( Object  proxy ,   Method  method ,   Object [ ]  args )   throws   Throwable   { \n             System . out . println ( "invoke 增强，JDK 动态代理" ) ; \n             // 执行目标对象的方法 \n             Object  invoke  =  method . invoke ( station ,  args ) ; \n             return  invoke ; \n           } \n         } ) ; \n     return  proxyObject ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     ProxyFactory  factory  =   new   ProxyFactory ( ) ; \n     SellTickets  proxyObject  =  factory . getProxyObject ( ) ; \n    proxyObject . sell ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 Tips \n ProxyFactory 其实并不是代理类，它是一个工厂类，它提供的方法可以生成代理对象，也不是代理类。而代理类是在程序运行过程中，动态在内存中生成的类。 \n 我们可以通过阿里巴巴开源的 Java 诊断工具  Arthas  来查看代理类的结构。 \n \n public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     ProxyFactory  factory  =   new   ProxyFactory ( ) ; \n     SellTickets  proxyObject  =  factory . getProxyObject ( ) ; \n    proxyObject . sell ( ) ; \n\n     // 获取代理类全类名，让 Arthas 从内存中读取 \n     System . out . println ( proxyObject . getClass ( ) ) ; \n     // 让程序一直运行，让我们方便查看 \n     while   ( true ) { } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 /**\n * 使用 Arthas 从内存中读取出来的动态代理类（通过 jad 来反编译）\n */ \n public   final   class  $ Proxy0   extends   Proxy   implements   SellTickets   { \n\n     private   static   Method  m3 ; \n\n     // 这个 invocationHanlder 就是我们在 ProxyFactory 中定义的 InvocationHandler \n     public  $ Proxy0 ( InvocationHandler  invocationHandler )   { \n         // 直接使用了父类 Proxy 的内容，这里其实就是 protected InvocationHandler h; \n         super ( invocationHandler ) ; \n     } \n\n     static   { \n       // SellTicketes 的方法 sell() 赋值给了 m3，所以 m3 就是 sell() \n      m3  =   Class . forName ( "com.maple.pattern.proxy.jdk_proxy.SellTickets" ) . getMethod ( "sell" ,   new   Class [ 0 ] ) ; \n     } \n\n     public   final   void   sell ( )   { \n       /*\n        调用父类中的 invoke 方法，这里的 h 是我们ProxyFactory 中定义的 InvocationHandler\n        那么执行 invoke 其实就是执行 ProxyFactory 中，getProxyObject 中定义的 invoke 方法。\n      */ \n       this . h . invoke ( this ,  m3 ,   null ) ; \n       return ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public   class   Proxy   implements   java . io . Serializable   { \n   protected   InvocationHandler  h ; \n } \n \n 1 2 3 JDK 动态代理的执行流程如下： \n \n 在测试类中通过代理对象调用 sell() 方法。 \n 根据多态的特性，执行的是代理类 $Proxy0 中的 sell() 方法。 \n 代理类 $Proxy0 中的 sell() 方法中又调用了 InvocationHandler 接口的子实现类对象 invoke 方法。 \n invoke 通过反射执行了真正的 TrainStation 中的 sell() 方法。 \n CGLIB 动态代理 \n JDK 动态代理要求必须定义接口，对接口进行代理，那么如果没有定义接口，只定义了对应的类，那么 JDK 动态代理就不能使用了。 \n CGLIB 没有实现接口的动态代理，实现的是子类的动态代理。它为 JDK 的动态代理提供了很好的实现。CGLIB 是一个第三方的包，所以需要引入 jar。 \n < dependency > \n     < groupId > cglib </ groupId > \n     < artifactId > cglib </ artifactId > \n     < version > 2.2.2 </ version > \n </ dependency > \n \n 1 2 3 4 5 public   class   TrainStation   { \n\n   public   void   sell ( )   { \n     System . out . println ( "卖票" ) ; \n   } \n } \n \n 1 2 3 4 5 6 /**\n * 代理对象工厂，用于获取代理对象\n */ \n public   class   ProxyFactory   implements   MethodInterceptor   { \n\n   private   TrainStation  station  =   new   TrainStation ( ) ; \n\n   /**\n   * CGLIB 是基于子类进行的动态代理\n   *\n   * @return 目标对象的子类对象\n   */ \n   public   TrainStation   getProxyObject ( )   { \n     // 1. 创建 Enhancer 对象，类似 JDK 中的 Proxy 类 \n     Enhancer  enhancer  =   new   Enhancer ( ) ; \n     // 2. 因为 CGLIB 是基于子类进行的动态代理，所以这里设置父类的字节码对象，也就是目标对象 \n    enhancer . setSuperclass ( TrainStation . class ) ; \n     // 3. 设置回调函数，这里应该是 MethodInterceptor 中子实现类的对象，那么这里实现了 MethodInterceptor，传递 this 即可 \n    enhancer . setCallback ( this ) ; \n     // 4. 创建代理对象 \n     TrainStation  proxyObject  =   ( TrainStation )  enhancer . create ( ) ; \n     return  proxyObject ; \n   } \n\n\n   /**\n   * 这个回调函数其实就是 proxyObject 在调用对应的方法时，执行的回调函数\n   *\n   * @param o 代理对象\n   * @param method 对应的调用方法\n   * @param objects 对应的调用方法的参数\n   * @param methodProxy\n   * @return 返回值\n   */ \n   @Override \n   public   Object   intercept ( Object  o ,   Method  method ,   Object [ ]  objects ,   MethodProxy  methodProxy )   throws   Throwable   { \n     System . out . println ( "CGLIB 动态代理" ) ; \n     Object  invoke  =  method . invoke ( station ,  objects ) ; \n     return  invoke ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     ProxyFactory  factory  =   new   ProxyFactory ( ) ; \n     // 这里获取的对象是 TranStation 的子类对象 \n     TrainStation  proxyObject  =  factory . getProxyObject ( ) ; \n    proxyObject . sell ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 #  三种代理对比 \n \n \n JDK 和 CGLIB 代理： \n 使用 CGLIB 动态代理，CGLIB 底层采用 ASM 字节码生成框架。 \n 注意，因为 CGLIB 是基于子类的动态代理，所以代理不了声明为 final 的类或者方法。 \n CGLIB 在 JDK1.6 之前比 Java 反射效率高，但是在 JDK1.7、JDK1.8 对 JDK 动态代理优化之后，在调用次数少的情况下，JDK 动态代理远高于 CGLIB。只有在大量调用的时候，JDK1.6 和 JDK1.7 比 CGLIB 效率低一点。 \n JDK1.8 之后，JDK 动态代理远高于 CGLIB，所以有接口时，优先使用 JDK 动态代理。 \n \n \n 动态代理和静态代理： \n 区别很明显，动态代理将所有的方法都转移到了一个集中的方法进行处理。这样在接口方法数量比较多的时候，我们可以灵活处理，而不是像静态代理那样每一个方法进行中转。 \n \n \n 优缺点： \n \n 优点：\n \n 代理模式在客户端与目标对象起到了一个中介作用和保护作用。 \n 代理对象可以扩展目标对象的功能。 \n 代理模式可以将客户端与目标对象分离，在一定程度上降低了系统的耦合度。 \n \n \n 缺点：增加了系统的复杂性。 \n 适配器模式 \n 国外的插头插座和我们国家的插头插座是不一样的，所以使用国外的插头向我们的插座插的时候，需要一个转换器，我们首先插入到转换器中，然后转换器插入到插座上。 \n 适配器模式就是这个意思，他可以将一个类的接口转换为客户希望的一个接口，让原本由于接口不兼容而不能共同工作的类可以共同工作。 \n 适配器模式分为两类： \n \n 类适配器模式，使用的是继承的模式，耦合度高一些。 \n 对象适配器模式，使用到的是组合的模式，耦合度更低一些。 \n \n 适配器模式中的角色： \n \n 目标接口（Target）：中国插头。 \n 适配者类（Adaptee）：例如外国插头。 \n 适配器类（Adapter）：转接头。 \n 类适配器模式 \n 现在有一台电脑，只能读取 SD 卡，如果我们想要读取 TF 卡那么就要使用适配器模式。 \n 思路是这样的：既然电脑只能读取 SD 卡，那么就创建一个适配器，这个适配器对外（电脑）提供的仍然是 SD 卡的读写操作，但是其实内部读取的是 TF 卡。 \n \n /**\n * 目标接口\n */ \n public   interface   SDCard   { \n\n   String   readSD ( ) ; \n\n   void   writeSD ( String  data ) ; \n } \n\n /**\n * 具体的目标接口\n */ \n public   class   SDCardImpl   implements   SDCard { \n   @Override \n   public   String   readSD ( )   { \n     return   "SD" ; \n   } \n\n   @Override \n   public   void   writeSD ( String  data )   { \n     System . out . println ( "write SD data" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /**\n * 适配者类的接口\n */ \n public   interface   TFCard   { \n\n   // 从 TF 卡中读取数据 \n   String   readTF ( ) ; \n\n   // 向 TF 卡中写数据 \n   void   writeTF ( String  data ) ; \n } \n\n /**\n * 适配者类\n */ \n public   class   TFCardImpl   implements   TFCard { \n   @Override \n   public   String   readTF ( )   { \n     return   "TF" ; \n   } \n\n   @Override \n   public   void   writeTF ( String  data )   { \n     System . out . println ( "write TF data" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /**\n * 注意这里，Computer 其实需要的是 SDCard，但是通过适配器模式，可以将 TFCard 转为 SDCard\n */ \n public   class   Computer   { \n   public   String   readSD ( SDCard  sdCard )   { \n     if   ( sdCard == null ) { \n       throw   new   NullPointerException ( "SDCard must not be null" ) ; \n     } \n     return  sdCard . readSD ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 /**\n * 适配器类\n */ \n public   class   SDAdapterTF   extends   TFCardImpl   implements   SDCard { \n   @Override \n   public   String   readSD ( )   { \n     System . out . println ( "adapter read tf card" ) ; \n     return   readTF ( ) ; \n   } \n\n   @Override \n   public   void   writeSD ( String  data )   { \n     System . out . println ( "adapter write tf card" ) ; \n     writeTF ( data ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Computer  computer  =   new   Computer ( ) ; \n     String  data  =  computer . readSD ( new   SDAdapterTF ( ) ) ; \n     System . out . println ( data ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 Tips \n 类适配器的缺点有二： \n \n 很明显，违背了合成复用原则，类之间的耦合度更高了。 \n 假如客户（电脑）没有提供一个 SDCard 的接口只有一个 SDCardImpl 的规则，那么适配器也不可能去继承 SDCardImpl（因为已经继承了 TFCardImpl）。 \n 对象适配器模式 \n 对象适配器模式进行的改进操作其实就是将适配器的继承 TFCardImpl 改为了在类中使用 TFCard 来聚合，这样做解决了类适配器模式的两个缺点： \n \n 满足了合成复用原则。 \n 假如客户（电脑）没有提供 SDCard 接口，也完全可以继承 SDCardImpl 来实现对应的内容。 \n \n \n @AllArgsConstructor \n public   class   SDAdapterTF   implements   SDCard   { \n\n   private   TFCard  tfCard ; \n\n   @Override \n   public   String   readSD ( )   { \n     System . out . println ( "adapter read tf card" ) ; \n     return  tfCard . readTF ( ) ; \n   } \n\n   @Override \n   public   void   writeSD ( String  data )   { \n     System . out . println ( "adapter write tf card" ) ; \n    tfCard . writeTF ( data ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #  装饰者模式 \n 快餐店中，目前有炒面，炒饭两类，并且炒面和炒饭都可以加鸡蛋、加培根。 \n \n 假如我们使用以往的方式来计算价格，这将是一个非常麻烦的过程，并且扩展性极差，容易发生类爆炸的情况。 \n 此时我们可以使用装饰者模式。装饰者模式的意思是：在不改变原有对象结构的情况下，动态给改对象增加额外的内容。 \n 装饰者模式的角色： \n \n 抽象构件角色：例如上图中的快餐。 \n 具体构件角色：例如上图中的炒面和炒饭。 \n 抽象装饰角色：抽象的，装饰者角色比较特殊，既要继承抽象构件角色也要聚合抽象构件角色。 \n 具体装饰角色：具体的装饰角色，比如上图中的鸡蛋和培根。 \n \n /**\n * 快餐，抽象类，对应抽象构件角色\n */ \n @Data \n @AllArgsConstructor \n public   abstract   class   FastFood   { \n\n   // 价格 \n   private   Float  price ; \n   // 描述 \n   private   String  desc ; \n\n   // 计算价格 \n   public   abstract   Float   cost ( ) ; \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /**\n * 炒饭，对应具体构件角色\n */ \n public   class   FriendRice   extends   FastFood   { \n\n   public   FriendRice ( )   { \n     // 炒饭的价格是 10 元，描述就是炒饭 \n     super ( 10F ,   "炒饭" ) ; \n   } \n\n   @Override \n   public   Float   cost ( )   { \n     // 价格就是 10 元，所以我们只需要调用父类的 getPrice，将 10 返回即可 \n     return   getPrice ( ) ; \n   } \n } \n\n /**\n * 炒面，类似炒饭\n */ \n public   class   FriendNoodles   extends   FastFood   { \n\n   public   FriendNoodles ( )   { \n     super ( 12F ,   "炒面" ) ; \n   } \n\n   @Override \n   public   Float   cost ( )   { \n     return   getPrice ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /**\n * 抽象装饰者类，属于抽象装饰者角色\n */ \n public   abstract   class   Garnish   extends   FastFood   { \n\n   /**\n   * 装饰者类比较特殊，既要继承 FastFood，也要聚合 FastFood\n   */ \n   private   FastFood  fastFood ; \n\n   public   Garnish ( FastFood  fastFood ,   Float  price ,   String  desc )   { \n     super ( price ,  desc ) ; \n     this . fastFood  =  fastFood ; \n   } \n\n   public   FastFood   getFastFood ( )   { \n     return  fastFood ; \n   } \n\n   public   void   setFastFood ( FastFood  fastFood )   { \n     this . fastFood  =  fastFood ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /**\n * 配料，对应的角色是具体的装饰者\n */ \n public   class   Egg   extends   Garnish   { \n\n   public   Egg ( FastFood  fastFood )   { \n     // 这里的内容也是精髓，继承了抽象装饰者，假如鸡蛋的价格是 1，那么就返回 1。 \n     super ( fastFood ,   1F ,   "鸡蛋" ) ; \n   } \n\n   @Override \n   public   Float   cost ( )   { \n     // 第一个 getPrice 是鸡蛋的价格，假如要获取快餐本身的价格只能通过 getFastFood 来获取快餐本身，进而获取价格 \n     return   getPrice ( )   +   getFastFood ( ) . getPrice ( ) ; \n   } \n\n   /**\n   * 重写描述\n   */ \n   @Override \n   public   String   getDesc ( )   { \n     return   super . getDesc ( )   +   getFastFood ( ) . getDesc ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     FastFood  fastfood  =   new   FriendRice ( ) ; \n    fastfood  =   new   Egg ( fastfood ) ; \n     System . out . printf ( "快餐 %s %s 元" ,  fastfood . getDesc ( ) ,  fastfood . cost ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 Tips \n 代理模式和装饰着模式的异同： \n \n 相同点：\n \n 都要实现与目标类相同的业务接口。 \n 在两个类中都要声明目标对象。 \n 都可以在不修改目标类的前提下增强目标方法。 \n \n \n 不同点：\n \n 目的不同，装饰者是为了增强对象，代理是为了保护和隐藏目标。 \n 获取目标对象构建的地方不同，装饰者是由外界传进来，可以使用构造方法传递。静态代理是在代理类内部创建，用来隐藏目标对象。 \n 桥接模式 \n 现在有一个需求，需要创建不同的图形，并且每一个图形都可能会有不同的颜色，假设我们使用继承的方式来设计类的关系，那么就可能发生类爆炸。 \n \n 针对这种情况，我们可以使用桥接模式，将抽象与实现相分离，使它们可以独立变化，它们是以组合关系代理继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 \n 桥接模式（Bridge）主要包含如下角色： \n \n 抽象化角色（Abstraction）：定义抽象类，并且包含一个对实现化对象的引用。 \n 扩展抽象化角色（Refined Abstraction）：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。 \n 实现化（Implementor）角色：定义实现化角色接口，供扩展抽象化角色调用。 \n 具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。 \n \n 案例：现在需要开发一个跨平台的播放器，可以播放多种格式的视频文件。常见的操作系统比如 Windows、Mac、Linux 等。常见的视频格式包含 RMVB、AVI、WMV 等。 \n 此案例拥有两个维度（操作系统、视频格式），适合使用桥接模式。 \n \n /**\n * 视频文件，实现化角色\n */ \n public   interface   VideoFile   { \n   void   decode ( String  fileName ) ; \n } \n\n /**\n * 具体实现化角色\n */ \n public   class   AviFile   implements   VideoFile { \n   @Override \n   public   void   decode ( String  fileName )   { \n     System . out . printf ( "AVI 视频文件 %s" ,  fileName ) ; \n   } \n } \n /**\n * 具体实现化角色\n */ \n public   class   RmvbFile   implements   VideoFile { \n   @Override \n   public   void   decode ( String  fileName )   { \n     System . out . printf ( "RMVB 视频文件 %s" ,  fileName ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /**\n * 抽象的操作系统类，抽象化角色\n */ \n @AllArgsConstructor \n public   abstract   class   OperatingSystem   { \n\n   protected   VideoFile  videoFile ; \n\n   public   abstract   void   play ( String  fileName ) ; \n } \n\n /**\n * 扩展抽象化角色\n */ \n public   class   Windows   extends   OperatingSystem { \n   public   Windows ( VideoFile  videoFile )   { \n     super ( videoFile ) ; \n   } \n\n   @Override \n   public   void   play ( String  fileName )   { \n    videoFile . decode ( fileName ) ; \n   } \n } \n\n /**\n * Mac，扩展抽象化角色\n */ \n public   class   Mac   extends   OperatingSystem { \n   public   Mac ( VideoFile  videoFile )   { \n     super ( videoFile ) ; \n   } \n\n   @Override \n   public   void   play ( String  fileName )   { \n    videoFile . decode ( fileName ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     OperatingSystem  system  =   new   Mac ( new   AviFile ( ) ) ; \n    system . play ( "战狼" ) ; \n   } \n } \n \n 1 2 3 4 5 6 Tips \n 桥接模式的好处就是在两个维度里面，随意扩展都不会影响另外的维度。 \n 外观模式 \n 外观模式又叫做门面模式，具体的作用是为多个复杂系统提供一个统一的对外接口，让这些子系统可以更加容易被访问。 \n 外观模式（Facade）包含以下角色： \n \n 外观（Facade）角色：为多个子系统对外提供一个统一接口。 \n 子系统（Sub System）角色：实现系统功能。 \n \n 案例 \n 通过智能音箱控制智能家电的开关，在这里外观角色就是智能音箱，子系统就是系统（灯、电视、……）。 \n public   class   Light   { \n\n   public   void   on ( )   { \n     System . out . println ( "开灯" ) ; \n   } \n\n   public   void   off ( )   { \n     System . out . println ( "关灯" ) ; \n   } \n } \n\n public   class  TV  { \n   public   void   on ( )   { \n     System . out . println ( "开电视" ) ; \n   } \n\n   public   void   off ( )   { \n     System . out . println ( "关电视" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /**\n * 用户主要和该类对象交互\n */ \n public   class   SmartAppliancesFacade   { \n\n   // 聚合电灯、电视机对象 \n   private   Light  light ; \n   private   TV  tv ; \n\n   public   SmartAppliancesFacade ( )   { \n    light  =   new   Light ( ) ; \n    tv  =   new   TV ( ) ; \n   } \n\n   /**\n   * @param message 语音控制\n   */ \n   public   void   say ( String  message )   { \n     if   ( message . contains ( "打开" ) )   { \n       on ( ) ; \n     }   else   if   ( message . contains ( "关闭" ) )   { \n       off ( ) ; \n     }   else   { \n       System . out . println ( "我还听不懂" ) ; \n     } \n   } \n\n   /**\n   * 一键打开\n   */ \n   private   void   on ( )   { \n    light . on ( ) ; \n    tv . on ( ) ; \n   } \n\n   /**\n   * 一键关闭\n   */ \n   private   void   off ( )   { \n    light . off ( ) ; \n    tv . off ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     SmartAppliancesFacade  facade  =   new   SmartAppliancesFacade ( ) ; \n    facade . say ( "打开家电" ) ; \n    facade . say ( "关闭家电" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 外观模式的特点和使用场景 \n 特点： \n \n 好处：\n \n 降低了子系统和客户端之间的耦合度，使子系统的变化不会影响其他的客户类。 \n 对客户端屏蔽了子系统组件，减少了客户处理的对象数目，使子系统使用起来更容易。 \n \n \n 缺点：\n \n 不符合开闭原则，修改很麻烦。 \n \n \n \n 使用场景： \n \n 分层结构系统构建的时候，使用外观模式定义子系统每层的入口可以简化子系统之间的依赖关系。 \n 当一个复杂系统的子系统很多的时候，外观模式可以为系统设计一个简单的接口供外界访问。 \n 当客户端与多个子系统之间存在很大联系时，引入外观模式可以将他们分离，从而干扰提高子系统的独立性和可移植性。 \n 组合模式 \n 组合模式又叫做部分整体模式，是用于把一组相似的对象当作是一个单一的对象。组合模式依据树形结构来组合对象，用来表示整体和部分的层次关系。 \n \n 上面的这张图片是文件和文件夹之间的关系，其实就是我们数据结构中的树，那么组合模式其实也分为三种角色： \n \n 抽象根节点（Component）：定义系统各个层次之间的共有方法和属性，可以预先定义一些默认行为和属性。 \n 树枝节点（Composite）：定义树枝节点的行为，存储各个子节点，组合树枝节点和叶子节点形成一个树形结构。 \n 叶子节点（Leaf）：叶子节点对象，其下再无分支。 \n \n 案例 \n /**\n * 不论是菜单还是菜单中的组件，都是节点，最终都属于抽象根节点\n */ \n public   abstract   class   MenuComponent   { \n\n   // 不管是菜单还是菜单项，都有名称 \n   protected   String  name ; \n   // 当前菜单节点的层级 \n   protected   Integer  level ; \n\n   /**\n   * 添加子菜单/子菜单项，但是不管是什么菜单节点，都属于抽象根节点\n   * 注意，只有菜单可以添加菜单/菜单项，菜单项是不可以添加的，所以我们默认抛出一个异常\n   * @param menuComponent\n   */ \n   public   void   add ( MenuComponent  menuComponent )   { \n     throw   new   UnsupportedOperationException ( ) ; \n   } \n\n   /**\n   * 移除子菜单/子菜单项，同样的，只有菜单可以移除子菜单/子菜单项，所以我们默认抛出一个异常\n   * @param menuComponent\n   */ \n   public   void   remove ( MenuComponent  menuComponent )   { \n     throw   new   UnsupportedOperationException ( ) ; \n   } \n\n   /**\n   * 获取子菜单/子菜单项，同样的，只有菜单可以得到子菜单/子菜单项，所以我们抛出一个异常\n   * @param index\n   * @return\n   */ \n   public   MenuComponent   getChild ( Integer  index )   { \n     throw   new   UnsupportedOperationException ( ) ; \n   } \n\n   public   String   getName ( )   { \n     return  name ; \n   } \n\n   /**\n   * 打印当前节点名称，因为菜单节点和菜单项节点实现方式不同，所以给一个抽象根节点\n   */ \n   public   abstract   void   print ( ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /**\n * 菜单类，属于树枝节点\n */ \n public   class   Menu   extends   MenuComponent { \n\n   private   List < MenuComponent >  menuComponents  =   new   ArrayList < > ( ) ; \n\n   public   Menu ( String  name ,   Integer  level )   { \n     this . name  =  name ; \n     this . level  =  level ; \n   } \n\n   @Override \n   public   void   add ( MenuComponent  menuComponent )   { \n    menuComponents . add ( menuComponent ) ; \n   } \n\n   @Override \n   public   void   remove ( MenuComponent  menuComponent )   { \n    menuComponents . remove ( menuComponent ) ; \n   } \n\n   @Override \n   public   MenuComponent   getChild ( Integer  index )   { \n     return  menuComponents . get ( index ) ; \n   } \n\n   @Override \n   public   void   print ( )   { \n     for   ( Integer  i  =   0 ;  i  <  level ;  i ++ )   { \n       System . out . printf ( "\\t" ) ; \n     } \n     // 首先打印菜单名称 \n     System . out . println ( name ) ; \n     // 打印子菜单或者子菜单项名称 \n    menuComponents . forEach ( MenuComponent :: print ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /**\n * 菜单项类，属于叶子节点\n */ \n public   class   MenuItem   extends   MenuComponent { \n\n   public   MenuItem ( String  name ,   Integer  level )   { \n     this . name  =  name ; \n     this . level  =  level ; \n   } \n\n   @Override \n   public   void   print ( )   { \n     for   ( Integer  i  =   0 ;  i  <  level ;  i ++ )   { \n       System . out . printf ( "\\t" ) ; \n     } \n     System . out . println ( name ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     MenuComponent  menu  =   new   Menu ( "系统管理" , 1 ) ; \n\n     MenuComponent  menu1  =   new   Menu ( "菜单管理" ,   2 ) ; \n    menu1 . add ( new   MenuItem ( "页面访问" , 3 ) ) ; \n    menu1 . add ( new   MenuItem ( "展开菜单" , 3 ) ) ; \n    menu1 . add ( new   MenuItem ( "编辑菜单" , 3 ) ) ; \n    menu1 . add ( new   MenuItem ( "删除菜单" , 3 ) ) ; \n    menu1 . add ( new   MenuItem ( "新增菜单" , 3 ) ) ; \n\n     MenuComponent  menu2  =   new   Menu ( "权限管理" ,   2 ) ; \n    menu2 . add ( new   MenuItem ( "页面访问" , 3 ) ) ; \n    menu2 . add ( new   MenuItem ( "提交保存" , 3 ) ) ; \n\n     MenuComponent  menu3  =   new   Menu ( "角色管理" ,   2 ) ; \n    menu3 . add ( new   MenuItem ( "页面访问" , 3 ) ) ; \n    menu3 . add ( new   MenuItem ( "页面访问新增角色" , 3 ) ) ; \n    menu3 . add ( new   MenuItem ( "页面访问新增角色修改角色" , 3 ) ) ; \n\n    menu . add ( menu1 ) ; \n    menu . add ( menu2 ) ; \n    menu . add ( menu3 ) ; \n\n    menu . print ( ) ; \n\n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 组合模式分类 \n 在使用组合模式的时候，根据抽象构建类的定义形式，我们将其分为： \n \n 透明组合模式：\n抽象根节点中声明了所有管理成员对象的方法，这样的好处是保证所有的构建类都有相同的接口，透明组合模式也是组合模式的标准形式。\n它的缺点是不够安全，因为叶子对象和容器对象本质上有区别，那么调用某些方法时，假如没有进行对应的错误处理，可能会导致出错。 \n 安全组合模式：\n抽象构件中不声明管理成员对象的方法，而是在树枝节点中声明并实现。他的缺点是不够透明，因此客户端不能完全针对抽象进行编程，必须要区别对待叶子和容器。 \n \n 优点和使用场景 \n 组合模式可以清晰的定义分层次的复杂对象，表示对象的全部或者部分层次，它让客户端忽略了层次的差异，方便对整个层次进行控制。 \n 组合模式应用在树形结构很方便，比如文件目录和多级目录等。 \n 享元模式 \n 简单来说，享元模式就是复用。它通过复用对象来大幅减少需要创建的对象数量，避免大量相似的对象开销，从而提高系统资源的利用率。 \n 在生活中，共享单车就是一个例子，共享单车在不用的时候可以停放交给他人使用，并且从始至终都是一批共享单车，提高资源的利用率。 \n 案例 \n \n 在俄罗斯方块中，每一个方块都是一个实例对象，我们可以将相同种类的方块设置为享元对象，共享一个实例对象。 \n /**\n * 抽象享元角色\n */ \n public   abstract   class   AbstractBox   { \n   // 获取图形 \n   public   abstract   String   getShape ( ) ; \n\n   // 显示图形和颜色 \n   public   void   display ( String  color )   { \n     System . out . printf ( "方块形状 %s 颜色 %s \\n" ,   getShape ( ) ,  color ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 /**\n * 具体享元角色\n */ \n public   class   IBox   extends   AbstractBox   { \n   @Override \n   public   String   getShape ( )   { \n     return   "I" ; \n   } \n } \n\n /**\n * 具体享元角色\n */ \n public   class   LBox   extends   AbstractBox   { \n\n   @Override \n   public   String   getShape ( )   { \n     return   "L" ; \n   } \n } \n\n /**\n * 具体享元角色\n */ \n public   class   OBox   extends   AbstractBox   { \n   @Override \n   public   String   getShape ( )   { \n     return   "O" ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /**\n * 享元工厂，设置为单例\n */ \n public   class   BoxFactory   { \n\n   public   static   BoxFactory  boxFactory  =   new   BoxFactory ( ) ; \n   private   HashMap < String ,   AbstractBox >  map ; \n\n   private   BoxFactory ( )   { \n    map  =   new   HashMap < > ( ) ; \n    map . put ( "I" ,   new   IBox ( ) ) ; \n    map . put ( "L" ,   new   LBox ( ) ) ; \n    map . put ( "O" ,   new   OBox ( ) ) ; \n   } \n\n   public   static   BoxFactory   getInstance ( )   { \n     return  boxFactory ; \n   } \n\n   public   AbstractBox   getShape ( String  name )   { \n     return  map . get ( name ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     BoxFactory  factory  =   BoxFactory . getInstance ( ) ; \n\n     AbstractBox  iBox  =  factory . getShape ( "I" ) ; \n    iBox . display ( "grey" ) ; \n\n     AbstractBox  lBox  =  factory . getShape ( "L" ) ; \n    lBox . display ( "green" ) ; \n\n     AbstractBox  oBox  =  factory . getShape ( "O" ) ; \n    oBox . display ( "red" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 使用场景 \n 享元（Flyweight）模式存在两种状态： \n \n 内部状态，指的是不会随着环境的改变而改变可以共享的部分，比如上面的颜色。 \n 外部状态，指的是随着环境改变而改变的不可以被共享的部分，比如上面的图形。 \n \n 享元模式的实现要领就是区分应用中的这两种状态，并且将外部状态外部化（比如作为方法的形参作为传递）。 \n 享元模式存在以下角色： \n \n 抽象享元角色：通常是一个接口或者是一个和抽象类，在抽象享元类中声明了具体享元公共的方法，这些方法可以向外界提供享元对象的内部数据，同时通过这些方法设置外部数据。 \n 具体享元角色：实现了抽象享元类，为内部状态提供了存储空间。通常可以结合单例模式来设计具体的享元类。 \n 非享元角色：不是所有的抽象享元类的子类都需要被共享，这些不被共享的子类可以设计成为非享元角色。 \n 享元工厂角色：负责创建和管理享元角色。 \n \n 使用场景： \n \n 一个系统拥有大量的相同或者相似的对象，避免造成大内存的浪费。 \n 对象的大部分状态都可以进行外部化，可以将这些外部状态传入对象中。 \n 使用享元模式需要维护一个存储享元对象的享元池，这需要耗费一定的系统资源，所以应该在确认需要多次重复使用享元对象才值得使用享元模式。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 14, 2021 23:48",createTimeStamp:1628956128e3,contributors:[{name:"causes",email:"2592716753@qq.com",commits:2},{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"设计模式-04-行为型模式",frontmatter:{title:"设计模式-04-行为型模式",categories:["backend"],tags:["designPatterns"],author:"causes",summary:"行为型模式 行为型模式分为类行为型模式（使用继承方式）和对象行为型模式（使用组合/聚合方式）。 行为型模式分为： 模板方法模式。; 策略模式。; 命令模式。; 职责链（责任链）模式。; 状态模式。; 观察者模式。; 中介者模式。; 迭代器模式。; 访问者模式。; 备忘录模式。; 解释器模式。; 以上的模式除了模板方法和解释器模式属于类行为型模式，其余都是对象",meta:[{property:"og:url",content:"/backend/DesignPatterns/part4.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"设计模式-04-行为型模式"},{property:"og:description",content:"行为型模式 行为型模式分为类行为型模式（使用继承方式）和对象行为型模式（使用组合/聚合方式）。 行为型模式分为： 模板方法模式。; 策略模式。; 命令模式。; 职责链（责任链）模式。; 状态模式。; 观察者模式。; 中介者模式。; 迭代器模式。; 访问者模式。; 备忘录模式。; 解释器模式。; 以上的模式除了模板方法和解释器模式属于类行为型模式，其余都是对象"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"designPatterns"}]},regularPath:"/backend/DesignPatterns/part4.html",relativePath:"backend/DesignPatterns/part4.md",key:"v-cdbd9150",path:"/backend/DesignPatterns/part4/",headers:[{level:2,title:"行为型模式",slug:"行为型模式"},{level:2,title:"模板方法模式",slug:"模板方法模式"},{level:2,title:"策略模式",slug:"策略模式"},{level:2,title:"命令模式",slug:"命令模式"},{level:2,title:"职责链（责任链）模式",slug:"职责链-责任链-模式"},{level:2,title:"状态模式",slug:"状态模式"},{level:2,title:"观察者模式",slug:"观察者模式"},{level:2,title:"中介者模式",slug:"中介者模式"},{level:2,title:"迭代器模式",slug:"迭代器模式"},{level:2,title:"访问者模式",slug:"访问者模式"},{level:2,title:"备忘录模式",slug:"备忘录模式"},{level:2,title:"解释器模式",slug:"解释器模式"}],readingTime:{minutes:26.98,words:8093},content:' 行为型模式 \n 行为型模式分为类行为型模式（使用继承方式）和对象行为型模式（使用组合/聚合方式）。 \n 行为型模式分为： \n \n 模板方法模式。 \n 策略模式。 \n 命令模式。 \n 职责链（责任链）模式。 \n 状态模式。 \n 观察者模式。 \n 中介者模式。 \n 迭代器模式。 \n 访问者模式。 \n 备忘录模式。 \n 解释器模式。 \n \n 以上的模式除了模板方法和解释器模式属于类行为型模式，其余都是对象行为型模式。 \n 模板方法模式 \n 去银行办理业务有四个步骤：取号 -> 排队 -> 办理业务 -> 对工作人员评分。 \n 其中取号、排队、对工作人员评分这三个步骤对每个人是一样的，但是办理的业务是不一样的。所以办理业务可以为一个抽象，其他的均为具体实现。 \n 并且这四个步骤的先后顺序是一样的，所以步骤执行也可以放到父类中去实现。 \n 那么这就是模板方法模式，首先定义一个算法的具体骨架，并将一些步骤延迟到子类中去实现，让子类可以不改变算法结构的情况下重新定义算法的某些特定步骤。 \n 结构 \n 模板方法（Template Method）模式包含以下角色： \n \n 抽象类（Abstract Class）：负责给出一个算法的骨架。\n \n 模板方法：定义了算法的骨架，按照某种顺序调用其包含的基本方法。 \n 基本方法：实现算法各个步骤的具体方法：\n \n 抽象方法（Abstract Method）：一个抽象方法的声明，具体子类来实现。 \n 具体方法（Concrete Method）：一个具体方法，实现抽象方法，也可以覆盖父类的实现。 \n 钩子方法（Hook Method）：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。一般使用  isxxx  来命名。 \n \n \n \n \n 具体子类：实现抽象类中定义的抽象方法和钩子方法，是一个顶级逻辑的组成步骤。 \n \n 案例 \n 用模板方法模式来模拟炒菜的工作，炒菜步骤：倒油 -> 热油 -> 倒蔬菜 -> 倒调料品 -> 翻炒。 \n 基本方法分为：倒油、热油、倒蔬菜、倒调料品、翻炒。\n基本方法中的抽象方法有：倒蔬菜、倒调料品。 \n /**\n * 抽象类，定义模板方法和基本方法\n */ \n public   abstract   class   AbstractClass   { \n\n   // 模板方法，定义算法骨架，子类不可以改变方法的骨架，所以使用 final 修饰 \n   public   final   void   cookProcess ( )   { \n     pourOil ( ) ; \n     heatOil ( ) ; \n     pourVegetable ( ) ; \n     pourSauce ( ) ; \n     fry ( ) ; \n   } \n\n   // 倒油 \n   public   void   pourOil ( )   { \n     System . out . println ( "倒油" ) ; \n   } \n\n   // 热油 \n   public   void   heatOil ( )   { \n     System . out . println ( "热油" ) ; \n   } \n\n   // 倒蔬菜，蔬菜是不一样的，所以它属于模板方法 \n   public   abstract   void   pourVegetable ( ) ; \n\n   // 倒调料品，调料品也不同 \n   public   abstract   void   pourSauce ( ) ; \n\n   // 翻炒 \n   public   void   fry ( )   { \n     System . out . println ( "翻炒" ) ; \n   } \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /**\n * 炒包菜类\n */ \n public   class   ConcreteClassBaocai   extends   AbstractClass { \n   @Override \n   public   void   pourVegetable ( )   { \n     System . out . println ( "包菜" ) ; \n   } \n\n   @Override \n   public   void   pourSauce ( )   { \n     System . out . println ( "辣椒" ) ; \n   } \n } \n\n /**\n * 炒菜心\n */ \n public   class   ConcreteClassCaixin   extends   AbstractClass { \n   @Override \n   public   void   pourVegetable ( )   { \n     System . out . println ( "菜心" ) ; \n   } \n\n   @Override \n   public   void   pourSauce ( )   { \n     System . out . println ( "蒜蓉" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     ConcreteClassBaocai  baocai  =   new   ConcreteClassBaocai ( ) ; \n    baocai . cookProcess ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 优缺点 \n 优点： \n \n 提高代码复用性。 \n 实现了反向控制（父类调用子类的操作）。 \n \n 缺点： \n \n 对每一个不同的实现都需要定义一个子类，这会导致类的个数增加（但是不会爆炸增加，还好），系统更加庞大，设计也更加抽象。 \n 父类中的抽象方法由子类实现，子类会影响父类的结果，导致了反向控制。优点是反向控制，缺点也是反向控制。 \n 策略模式 \n 策略模式定义了一系列的算法，这些算法可以相互替换，并且替换的变化不会影响到使用这些算法的用户。策略模式属于对象行为模式。 \n 结构 \n 策略模式主要角色如下： \n \n 抽象策略（Strategy）类：抽象角色，通常是接口或者抽象类。 \n 具体策略（Concrete Strategy）类：实现了抽象策略类，提供了具体的算法实现。 \n 环境（Context）类：持有策略类的引用，最终给客户端调用。 \n \n 案例 \n 百货公司做促销活动，针对不同节日推出不同的促销活动。 \n /**\n * 抽象策略类\n */ \n public   interface   Strategy   { \n   public   abstract   void   show ( ) ; \n } \n \n 1 2 3 4 5 6 /**\n * 具体策略类，促销活动 A\n */ \n public   class   StrategyA   implements   Strategy   { \n   @Override \n   public   void   show ( )   { \n     System . out . println ( "买一送一" ) ; \n   } \n } \n\n /**\n * 具体策略类，促销活动 B\n */ \n public   class   StrategyB   implements   Strategy   { \n   @Override \n   public   void   show ( )   { \n     System . out . println ( "满两百减五十" ) ; \n   } \n } \n\n /**\n * 具体策略类，促销活动 C\n */ \n public   class   StrategyC   implements   Strategy   { \n   @Override \n   public   void   show ( )   { \n     System . out . println ( "换购" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /**\n * 环境类，促销员\n */ \n public   class   SalesMan   { \n   private   Strategy  strategy ; \n\n   public   SalesMan ( Strategy  strategy )   { \n     this . strategy  =  strategy ; \n   } \n\n   public   void   salesManShow ( )   { \n    strategy . show ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     SalesMan  salesMan  =   new   SalesMan ( new   StrategyA ( ) ) ; \n    salesMan . salesManShow ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 优缺点和使用场景 \n 优点： \n \n 策略类之间可以互相切换。 \n 易于扩展，符合开闭原则。 \n 避免使用多重条件（if else）。 \n \n 缺点： \n \n 客户端必须知道所有的策略类并且自行选择。 \n 会造成产生很多策略类，可以通过享元模式在一定程度上减少对象数量。 \n \n 使用场景： \n \n 一个系统需要动态地在几种算法中选择一种时。 \n 各个算法相互独立，对客户隐藏具体的细节。 \n 系统中大量的 if else 时。 \n 多个类只是在表现行为不同时，在运行时动态选择具体要执行的行为。 \n 命令模式 \n 命令模式将 请求 封装为了一个对象，让发出请求的责任和执行请求的责任分隔开。这样两者之间通过命令对象进行沟通，方便命令的管理。 \n 结构 \n 命令模式包含以下角色： \n \n 抽象命令（Command）角色：定义命令的接口，声明执行的方法。 \n 具体命令（Concrete Command）角色：具体的命令。通常会持有接收者，并且调用接收者的功能来完成命令操作。 \n 实现者/接受者（Receiver）角色：接收者，真正执行命令的对象。 \n 调用者/请求者（Invoker）角色：要求命令对象执行请求，通常会持有命令对象。 \n \n 案例 \n 日常生活中，点餐有如下场景：客户下单给服务员 --\x3e 服务员拿到订单交给厨师 --\x3e 厨师准备餐点，在这种场景下，女招待和厨师高度耦合，餐厅规模一大就不好沟通。 \n 我们使用命令模式解决问题： \n \n 服务员：调用者，发起命令。 \n 厨师：接收者，执行命令。 \n 订单类。 \n 抽象命令类。 \n 命令类：命令类包含订单类。 \n \n /**\n * 订单类\n */ \n @Data \n public   class   Order   { \n\n   // 餐桌号码 \n   private   Integer  diningTable ; \n\n   // 餐品和份数 \n   private   Map < String ,   Integer >  foodDir  =   new   HashMap < > ( ) ; \n\n   public   void   setFoodDir ( String  name ,   Integer  num )   { \n    foodDir . put ( name ,  num ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /**\n * 实现者，厨师类\n */ \n public   class   SeniorChef   { \n\n   public   void   makeFood ( String  name ,   Integer  num )   { \n     System . out . printf ( "%s 份 %s\\n" ,  name ,  num ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 /**\n * 抽象命令类\n */ \n public   interface   Command   { \n\n   void   execute ( ) ; \n } \n\n /**\n * 具体命令类\n */ \n @AllArgsConstructor \n public   class   OrderCommand   implements   Command   { \n\n   // 具体命令类要持有接收者 \n   private   SeniorChef  receiver ; \n\n   // 具体命令类要持有订单 \n   private   Order  order ; \n\n   @Override \n   public   void   execute ( )   { \n     System . out . printf ( "%s 桌的订单：\\n" ,  order . getDiningTable ( ) ) ; \n     Map < String ,   Integer >  foodDir  =  order . getFoodDir ( ) ; \n    foodDir . keySet ( ) . forEach ( foodName  ->  receiver . makeFood ( foodName ,  foodDir . get ( foodName ) ) ) ; \n     System . out . printf ( "%s 桌的饭准备完毕\\n" ,  order . getDiningTable ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /**\n * 请求者，服务员类\n */ \n public   class   Waitor   { \n\n   // 可以持有多个命令对象 \n   private   List < Command >  commands  =   new   ArrayList < > ( ) ; \n\n   public   void   setCommand ( Command  command )   { \n    commands . add ( command ) ; \n   } \n\n   // 发起命令 \n   public   void   orderUp ( )   { \n     System . out . println ( "订单来了" ) ; \n    commands . forEach ( command  ->   { \n       if   ( Objects . isNull ( command ) )   { \n         return ; \n       } \n      command . execute ( ) ; \n     } ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 创建两个订单 \n     Order  order1  =   new   Order ( ) ; \n    order1 . setDiningTable ( 1 ) ; \n    order1 . setFoodDir ( "西红柿鸡蛋面" ,   1 ) ; \n    order1 . setFoodDir ( "小杯可乐" ,   2 ) ; \n\n     Order  order2  =   new   Order ( ) ; \n    order2 . setDiningTable ( 2 ) ; \n    order2 . setFoodDir ( "尖椒肉丝盖饭" ,   1 ) ; \n    order2 . setFoodDir ( "小杯雪碧" ,   1 ) ; \n\n     // 创建接收者，厨师对象 \n     SeniorChef  receiver  =   new   SeniorChef ( ) ; \n\n     // 创建命令对象 \n     OrderCommand  command1  =   new   OrderCommand ( receiver ,  order1 ) ; \n     OrderCommand  command2  =   new   OrderCommand ( receiver ,  order2 ) ; \n\n     // 创建调用者 \n     Waitor  invoke  =   new   Waitor ( ) ; \n    invoke . setCommand ( command1 ) ; \n    invoke . setCommand ( command2 ) ; \n\n     // 服务员发起命令 \n    invoke . orderUp ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 优缺点和使用场景 \n 优点： \n \n 降低系统耦合度。 \n 增加或者删除命令十分方便，满足开闭原则，对扩展比较灵活。 \n 可以和组合模式结合，将多个命令装配成一个组合命令，也就是宏命令。 \n 方便实现命令的撤销和恢复，也就是 Undo 和 Redo 的操作。 \n \n 缺点： \n \n 系统可能会有很多具体命令类。 \n 结构更加复杂。 \n \n 使用场景： \n \n 系统需要将调用者和请求者进行解耦。 \n 系统需要在不同时间指定请求，将请求排队和执行请求。 \n 需要支持命令的撤销和恢复操作。 \n 职责链（责任链）模式 \n 员工在买器材进行报销的时候，每个领导能够批准的额度不同，员工必须去根据自己的实际情况找不同的领导，这就增加了难度。 \n 责任链模式解决了这个问题，它将所有的请求处理连成了一条线，当上一个处理者处理不了这个问题，就会扔给下一个，直到有对象处理它为止。 \n 责任链模式包含以下角色： \n \n 抽象处理者（Handler）：定义一个处理请求的接口，包含抽象处理方法和一个后继链接。 \n 具体处理者（Concrete Handler）：实现抽象处理者的处理方法，判断能否处理本次请求，可以处理则处理，否则转给后继者。 \n \n 案例 \n /**\n * 请假条\n */ \n @Data \n @AllArgsConstructor \n public   class   LeaveRequest   { \n\n   // 姓名 \n   private   String  name ; \n   // 请假的天数 \n   private   Integer  num ; \n   // 理由 \n   private   String  content ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /**\n * 抽象处理者\n */ \n @Data \n public   abstract   class   Handler   { \n   // 请假天数 \n   protected   static   final   Integer  NUM_ONE  =   1 ; \n   protected   static   final   Integer  NUM_THREE  =   3 ; \n   protected   static   final   Integer  NUM_SEVEN  =   7 ; \n\n   // 该领导可以处理的请假天数区间 \n   private   Integer  numStart ; \n   private   Integer  numEnd ; \n\n   // 后继者 \n   private   Handler  nextHandler ; \n\n   public   Handler ( Integer  numStart )   { \n     this . numStart  =  numStart ; \n   } \n\n   public   Handler ( Integer  numStart ,   Integer  numEnd )   { \n     this . numStart  =  numStart ; \n     this . numEnd  =  numEnd ; \n   } \n\n   // 各级领导处理请假条的方法 \n   protected   abstract   void   handleLeave ( LeaveRequest  leaveRequest ) ; \n\n   // 提交请假条 \n   public   final   void   submit ( LeaveRequest  leave )   { \n     // 领导进行审批 \n     this . handleLeave ( leave ) ; \n     // 假设有上级领导，并且请假天数超过了自己的权限，则交给上级领导，否则流程结束 \n     if   ( Objects . nonNull ( this . nextHandler )   &&  leave . getNum ( )   >   this . numEnd )   { \n       this . nextHandler . submit ( leave ) ; \n     }   else   { \n       System . out . println ( "流程结束" ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /**\n * 小组长类\n */ \n public   class   GroupLeader   extends   Handler   { \n   public   GroupLeader ( )   { \n     // 小组长只有 0 - 1 天的请假权限 \n     super ( 0 ,   Handler . NUM_ONE ) ; \n   } \n\n   @Override \n   protected   void   handleLeave ( LeaveRequest  request )   { \n     System . out . printf ( "%s 请假 %s 天，%s。\\n小组长审批：同意\\n" ,  request . getName ( ) ,  request . getNum ( ) ,  request . getContent ( ) ) ; \n   } \n } \n\n /**\n * 部门经理\n */ \n public   class   Manager   extends   Handler { \n   public   Manager ( )   { \n     // 部门经理可以处理 3 - 7 天的请假内容 \n     super ( Handler . NUM_ONE ,   Handler . NUM_THREE ) ; \n   } \n\n   @Override \n   protected   void   handleLeave ( LeaveRequest  request )   { \n     System . out . printf ( "%s 请假 %s 天，%s。\\n经理审批：同意\\n" ,  request . getName ( ) ,  request . getNum ( ) ,  request . getContent ( ) ) ; \n   } \n } \n\n /**\n * 总经理\n */ \n public   class   GeneralManager   extends   Handler   { \n\n\n   public   GeneralManager ( )   { \n     super ( NUM_THREE ,  NUM_SEVEN ) ; \n   } \n\n   @Override \n   protected   void   handleLeave ( LeaveRequest  request )   { \n     System . out . printf ( "%s 请假 %s 天，%s。\\n总经理审批：同意\\n" ,  request . getName ( ) ,  request . getNum ( ) ,  request . getContent ( ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     LeaveRequest  request  =   new   LeaveRequest ( "小明" ,   1 ,   "身体不适" ) ; \n\n     // 创建各级领导对象 \n     GroupLeader  groupLeader  =   new   GroupLeader ( ) ; \n     Manager  manager  =   new   Manager ( ) ; \n     GeneralManager  generalManager  =   new   GeneralManager ( ) ; \n\n     // 设置处理者链 \n    groupLeader . setNextHandler ( manager ) ; \n    manager . setNextHandler ( generalManager ) ; \n\n     // 提交请假条 \n    groupLeader . submit ( request ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 优缺点 \n 优点： \n \n 降低了请求发送者和接收者之间的耦合度。 \n 可以根据需要增加新的请求处理类，满足开闭原则。 \n 当工作流程发送变化，可以动态改变次序，增加了灵活性。 \n 责任链简化了对象之间的链接，只需要一个指向后继的引用即可。 \n 每个类只需要处理自己该处理的工作，不能处理的传递给下一个对象。 \n \n 缺点： \n \n 不能保证每一个请求一定被处理，可能传递倒链的末端都得不到处理。 \n 对于比较长的责任链，系统性能可能会受到一定影响。 \n 责任链如果设置错误（比如成环）会导致系统出错。 \n 状态模式 \n 例如： \n 现在有一个电梯，电梯有这样几种状态：打开、关闭、运行、停止。电梯的运行和这几种状态有关，如果使用普通的做法，我们可以使用枚举类或者几个静态常量来进行判断，进而编写程序。 \n 但是这种写法太过复杂，状态模式就是为了解决这种问题而出现的，也就是将状态提取到状态对象中，允许状态对象在其内部状态发生改变时改变其行为。 \n 结构 \n 状态模式包含以下主要角色： \n \n 环境（Context）角色：也叫做上下文，定义了客户程序需要的接口，维护一个当前状态，并且将状态有关的操作都委托给当前状态对象处理。 \n 抽象（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为。 \n 具体状态（Concrete State）角色：实现抽象状态所对应的行为。 \n \n 案例 \n 对上面的电梯例子进行改进： \n 首先来判断： \n \n 当电梯门关上时：可以打开电梯门（电梯在静止状态下），可以运行电梯（电梯在静止状态下），可以停止电梯（电梯在运行状态下）。 \n 当电梯停止时：可以打开电梯门（当电梯门关上时），可以关上电梯门（电梯门开启时），可以运行电梯（电梯门关上时）。 \n 当电梯正在运行时：可以停止电梯。 \n \n 那么我们可以得到几种基本动作： \n \n 打开电梯门。 \n 关闭电梯门。 \n 启动电梯。 \n 停止电梯。 \n \n /**\n * 抽象状态类\n */ \n @Data \n public   abstract   class   LiftState   { \n\n   // 环境角色类对象 \n   protected   Context  context ; \n\n   // 电梯门开启操作 \n   public   abstract   void   open ( ) ; \n\n   // 电梯门关闭操作 \n   public   abstract   void   close ( ) ; \n\n   // 电梯运行操作 \n   public   abstract   void   run ( ) ; \n\n   // 电梯停止操作 \n   public   abstract   void   stop ( ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 那么对应这几种操作，电梯有几种状态，而这几种状态可以执行的操作是不同的： \n /**\n * 设置当前状态对象\n */ \n @Data \n public   class   Context   { \n\n   public   final   static   OpeningState  OPENING_STATE  =   new   OpeningState ( ) ; \n   public   final   static   ClosingState  CLOSING_STATE  =   new   ClosingState ( ) ; \n   public   final   static   RunningState  RUNNING_STATE  =   new   RunningState ( ) ; \n   public   final   static   StopingState  STOPING_STATE  =   new   StopingState ( ) ; \n\n   private   LiftState  liftState ; \n\n   public   void   setLiftState ( LiftState  liftState )   { \n     this . liftState  =  liftState ; \n     // 设置当前状态 context 对象 \n     this . liftState . setContext ( this ) ; \n   } \n\n   public   void   open ( )   { \n     this . liftState . open ( ) ; \n   } \n\n   public   void   close ( )   { \n     this . liftState . close ( ) ; \n   } \n\n   public   void   run ( )   { \n     this . liftState . run ( ) ; \n   } \n\n   public   void   stop ( )   { \n     this . liftState . stop ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /**\n * 电梯门开启状态\n */ \n public   class   OpeningState   extends   LiftState   { \n   @Override \n   public   void   open ( )   { \n     System . out . println ( "电梯开启……" ) ; \n   } \n\n   @Override \n   public   void   close ( )   { \n     super . context . setLiftState ( Context . CLOSING_STATE ) ; \n     super . context . close ( ) ; \n   } \n\n   // 电梯门在开启的状态肯定不可以运行 \n   @Override \n   public   void   run ( )   { \n\n   } \n\n   // 电梯门在开启的状态下本身就是停止运行状态 \n   @Override \n   public   void   stop ( )   { \n\n   } \n } \n\n /**\n * 电梯门关闭状态\n */ \n public   class   ClosingState   extends   LiftState { \n   // 电梯门关闭之后再打开也是允许的操作 \n   @Override \n   public   void   open ( )   { \n     super . context . setLiftState ( Context . OPENING_STATE ) ; \n     super . context . open ( ) ; \n   } \n\n   @Override \n   public   void   close ( )   { \n     System . out . println ( "电梯门关闭……" ) ; \n   } \n\n   // 电梯门关闭之后开始运行是允许的 \n   @Override \n   public   void   run ( )   { \n     super . context . setLiftState ( Context . RUNNING_STATE ) ; \n     super . context . run ( ) ; \n   } \n\n   // 电梯门关上之后就停止也是可以发生的 \n   @Override \n   public   void   stop ( )   { \n     super . context . setLiftState ( Context . STOPING_STATE ) ; \n     super . context . stop ( ) ; \n   } \n } \n\n /**\n * 电梯运行状态\n */ \n public   class   RunningState   extends   LiftState { \n   // 电梯在运行状态肯定不可以开门 \n   @Override \n   public   void   open ( )   { \n\n   } \n\n   // 电梯在运行之前肯定已经关门了，所以 RUNNING 状态无需执行 \n   @Override \n   public   void   close ( )   { \n\n   } \n\n   @Override \n   public   void   run ( )   { \n     System . out . println ( "电梯正在运行……" ) ; \n   } \n\n   // 电梯运行完之后肯定是可以停止了，所以停止操作也可以做 \n   @Override \n   public   void   stop ( )   { \n     super . context . setLiftState ( Context . STOPING_STATE ) ; \n     super . context . stop ( ) ; \n   } \n } \n\n /**\n * 电梯停止状态\n */ \n public   class   StopingState   extends   LiftState { \n   // 电梯停止状态肯定是可以开门的 \n   @Override \n   public   void   open ( )   { \n     super . context . setLiftState ( Context . OPENING_STATE ) ; \n     super . context . open ( ) ; \n   } \n\n   // 电梯停止之前肯定执行的是关门的操作，所以这个关门不需要 \n   @Override \n   public   void   close ( )   { \n   } \n\n   // 停止之后可以运行 \n   @Override \n   public   void   run ( )   { \n     super . context . setLiftState ( Context . RUNNING_STATE ) ; \n     super . context . run ( ) ; \n   } \n\n   @Override \n   public   void   stop ( )   { \n     System . out . println ( "电梯停止……" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 最后使用一个客户端来实现效果： \n public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     Context  context  =   new   Context ( ) ; \n     // 首先给一个电梯的状态 \n    context . setLiftState ( new   RunningState ( ) ) ; \n\n     // 分别尝试运行以下电梯的各种状态方法，发现只有运行和停止被执行了，这就说明针对某种状态有不同的操作 \n    context . open ( ) ; \n    context . close ( ) ; \n    context . run ( ) ; \n    context . stop ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 以上的几个类（尤其对于  Context  和  xxxState  来说）混合在一起，相互依赖，不是很好分辨。看起来虽然比较麻烦，但其实内在逻辑是很清晰的。 \n 建议实在看不懂就把代码复制下来，在 IDEA 里面慢慢看一看，点一点就懂了。 \n 优缺点 \n 优点： \n \n 将某个状态有关的行为放到一个类中，并且可以很方便的增加新的状态，只需要改变状态即可改变行为。 \n 允许状态转换和状态行为合成一体，而不是一个巨大的语句块。 \n \n 缺点： \n \n 增加系统类和对象的个数。 \n 状态模式比较复杂，使用不当会导致程序混乱。 \n 对开闭原则支持不太好。 \n 观察者模式 \n 观察者模式也叫发布-订阅模式，它可以让多个观察者对象同时监听某一个主题对象，当这个主题对象发生变化时，观察者会收到消息自动更新。 \n 结构 \n \n Subject：抽象主题角色，将所有观察者放到一个集合中，每隔主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加或者删除观察者对象。 \n ConcreteSubject：具体主题，将所有有关状态存入具体观察者对象，在具体主题内部改变时，给所有注册过的观察者发送通知。 \n Observer：抽象观察者，是观察者的抽象类，定义了一个更新接口，让主题更改时通知自己。 \n ConcreteObserver：具体观察者。 \n \n 案例 \n 微信公众号：在使用微信公众号时，当公众号进行了更新之后，关注此公众号的用户都会受到消息。 \n /**\n * 抽象主题角色类\n */ \n public   interface   Subject   { \n\n   // 添加订阅者（观察者） \n   void   attach ( Observer  observer ) ; \n\n   // 删除订阅者 \n   void   detach ( Observer  observer ) ; \n\n   // 通知订阅者 \n   void   notify ( String  message ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /**\n * 具体主题角色类\n */ \n public   class   SubscriptionSubject   implements   Subject   { \n\n   // 定义一个集合，存储多个观察者对象 \n   private   List < Observer >  userList  =   new   ArrayList < > ( ) ; \n\n   @Override \n   public   void   attach ( Observer  observer )   { \n    userList . add ( observer ) ; \n   } \n\n   @Override \n   public   void   detach ( Observer  observer )   { \n    userList . remove ( observer ) ; \n   } \n\n   @Override \n   public   void   notify ( String  message )   { \n    userList . forEach ( user  ->  user . update ( message ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /**\n * 抽象观察者类\n */ \n public   interface   Observer   { \n\n   // 更新 \n   void   update ( String  message ) ; \n } \n \n 1 2 3 4 5 6 7 8 /**\n * 具体观察者\n */ \n public   class   ObserverUser   implements   Observer   { \n\n   private   String  name ; \n\n   public   ObserverUser ( String  name )   { \n     this . name  =  name ; \n   } \n\n   @Override \n   public   void   update ( String  message )   { \n     System . out . println ( String . format ( "%s - %s" ,  name ,  message ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 创建公众号 \n     SubscriptionSubject  subject  =   new   SubscriptionSubject ( ) ; \n\n     // 订阅公众号 \n    subject . attach ( new   ObserverUser ( "zhangsan" ) ) ; \n    subject . attach ( new   ObserverUser ( "lisi" ) ) ; \n\n     // 公众号更新 \n    subject . notify ( "更新" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 优缺点 \n \n 优点：降低了耦合，可以实现广播机制。 \n 缺点：假如观察者非常多，那么可能会非常耗时。如果被观察者有循环依赖，那么被观察者发送通知会让观察者循环调用，最终系统崩溃。 \n 中介者模式 \n 一般来说，人与人之间的关系是十分复杂的，是一种网状结构，但是引入中介者就可以将关系变动为星型关系。 \n \n 这样就减少了系统的耦合，一个良好的系统不可能在自己的类中维护与其他类之间的关系，而是通过一个中介来进行关系的关联。 \n 结构 \n \n 抽象中介者（Mediator）：中介者的接口，提供了对象注册和转发对象信息的抽象方法。 \n 具体中介者（Concrete Mediator）：实现中介者接口，定义一个 List 来管理对象，协调各个角色之间的交互关系。 \n 抽象对象（Colleague）：定义对象的接口，保存中介者，提供对象交互的抽象方法，实现所有相互影响的对象类的公共功能。 \n 具体对象（Concrete Colleague）：抽象类的实现者，当需要与其他对象交互时，中介者负责后续的交互。 \n \n 案例 \n 使用房屋中介来作为案例，房屋中介充当中介者，房租和租房客为对象。 \n /**\n * 抽象中介类\n */ \n @SuppressWarnings ( "unused" ) \n public   interface   Mediator   { \n\n   void   constact ( String  message ,   Person  person ) ; \n } \n \n 1 2 3 4 5 6 7 8 /**\n * 抽象对象类\n */ \n @AllArgsConstructor \n public   abstract   class   Person   { \n\n   protected   String  name ; \n   protected   Mediator  mediator ; \n } \n \n 1 2 3 4 5 6 7 8 9 /**\n * 具体的对象类\n */ \n public   class   Tenant   extends   Person   { \n\n   public   Tenant ( String  name ,   Mediator  mediator )   { \n     super ( name ,  mediator ) ; \n   } \n\n   /**\n   * 与中介联系的功能\n   */ \n   public   void   constact ( String  message )   { \n    mediator . constact ( message ,   this ) ; \n   } \n\n   /**\n   * 租房者\n   */ \n   public   void   getMessage ( String  message )   { \n     System . out . println ( String . format ( "租房者 %s 获取到的信息是 %s" ,  name ,  message ) ) ; \n   } \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /**\n * 具体的对象类\n */ \n public   class   HouseOwner   extends   Person   { \n\n   public   HouseOwner ( String  name ,   Mediator  mediator )   { \n     super ( name ,  mediator ) ; \n   } \n\n   /**\n   * 与中介联系的功能\n   */ \n   public   void   constact ( String  message )   { \n    mediator . constact ( message ,   this ) ; \n   } \n\n   /**\n   * 房主\n   */ \n   public   void   getMessage ( String  message )   { \n     System . out . println ( String . format ( "房主 %s 获取到的信息是 %s" ,  name ,  message ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /**\n * 具体的中介者\n */ \n @Data \n public   class   MediatorStructure   implements   Mediator   { \n\n   // 聚合具体的房主和租房者对象 \n   private   HouseOwner  houseOwner ; \n   private   Tenant  tenant ; \n\n   @Override \n   public   void   constact ( String  message ,   Person  person )   { \n     if   ( person  ==  houseOwner )   { \n      tenant . getMessage ( message ) ; \n     }   else   if   ( person  ==  tenant )   { \n      houseOwner . getMessage ( message ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 创建中介者 \n     MediatorStructure  mediator  =   new   MediatorStructure ( ) ; \n     // 租客 \n     Tenant  tenant  =   new   Tenant ( "李四" ,  mediator ) ; \n     // 房主 \n     HouseOwner  houseOwner  =   new   HouseOwner ( "张三" ,  mediator ) ; \n\n     // 中介者要知道具体的房主和租客 \n    mediator . setTenant ( tenant ) ; \n    mediator . setHouseOwner ( houseOwner ) ; \n\n     // 房客进行沟通 \n    tenant . constact ( "房客租房" ) ; \n     // 房主沟通 \n    houseOwner . constact ( "可以" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 优缺点 \n \n 优点：松散耦合，集中控制交互，一对多转变为一对一关联。 \n 缺点：同事类太多时，中介者的职责会很大，以至于系统难以维护。 \n \n 使用场景 \n 系统中对象存在复杂的引用关系时，当想创建一个运行于多个类之间的对象，但是又不想生成新的子类时。 \n 迭代器模式 \n 提供一个对象，来访问聚合对象的一系列数据，而不暴露聚合对象的内部。 \n 结构 \n \n 抽象聚合角色（Aggregate）：定义增删查和创建迭代器对象的接口。 \n 具体聚合角色（ConcreteAggregate）：实现抽象聚合类，返回一个具体迭代器实例。 \n 抽象迭代器（Iterator）：定义访问和遍历聚合元素的接口，通常包含  hasNext 、 next  等方法。 \n 具体迭代器（ConcreteIterator）：实现抽象迭代器的方法，完成对聚合对象的遍历、并且记录遍历的位置。 \n \n 案例 \n @Data \n @AllArgsConstructor \n public   class   Student   { \n\n   private   String  name ; \n   private   String  number ; \n } \n \n 1 2 3 4 5 6 7 /**\n * 抽象迭代器接口\n */ \n public   interface   StudentIterator   { \n\n   boolean   hasNext ( ) ; \n\n   Student   next ( ) ; \n } \n\n /**\n * 具体迭代器角色\n */ \n public   class   StudentIteratorImpl   implements   StudentIterator   { \n\n   private   List < Student >  list ; \n   private   int  position  =   0 ; \n\n   public   StudentIteratorImpl ( List < Student >  list )   { \n     this . list  =  list ; \n   } \n\n   @Override \n   public   boolean   hasNext ( )   { \n     return  position  <  list . size ( ) ; \n   } \n\n   @Override \n   public   Student   next ( )   { \n     Student  currentStudent  =  list . get ( position ) ; \n    position ++ ; \n     return  currentStudent ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /**\n * 聚合对象接口\n */ \n public   interface   StudentAggregate   { \n\n   void   addStudent ( Student  student ) ; \n\n   void   removeStudent ( Student  student ) ; \n\n   StudentIterator   getStudentIterator ( ) ; \n } \n\n /**\n * 具体聚合对象\n */ \n public   class   StudentAggregateImpl   implements   StudentAggregate   { \n\n   private   List < Student >  list  =   new   ArrayList < > ( ) ; \n\n   @Override \n   public   void   addStudent ( Student  student )   { \n    list . add ( student ) ; \n   } \n\n   @Override \n   public   void   removeStudent ( Student  student )   { \n    list . remove ( student ) ; \n   } \n\n   @Override \n   public   StudentIterator   getStudentIterator ( )   { \n     return   new   StudentIteratorImpl ( list ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 1. 创建聚合对象 \n     StudentAggregate  aggregate  =   new   StudentAggregateImpl ( ) ; \n     // 2. 测试数据 \n    aggregate . addStudent ( new   Student ( "zhangsan" , "001" ) ) ; \n    aggregate . addStudent ( new   Student ( "lisi" , "002" ) ) ; \n    aggregate . addStudent ( new   Student ( "wangwu" , "003" ) ) ; \n    aggregate . addStudent ( new   Student ( "zhaoliu" , "004" ) ) ; \n     // 3. 获取迭代器 \n     StudentIterator  iterator  =  aggregate . getStudentIterator ( ) ; \n     while   ( iterator . hasNext ( ) )   { \n       System . out . println ( iterator . next ( ) ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 优缺点和使用场景 \n 优点： \n \n 支持多种遍历方式，迭代方式方便更换。 \n 简化了聚合类。 \n 引入了抽象层，满足开闭原则。 \n \n 缺点： \n \n 增加了类的个数。 \n \n 使用场景： \n \n 给聚合对象提供多种遍历方式。 \n 访问者模式 \n 封装了一些作用于某种数据结构中的各元素的操作，可以不改变数据结构前提下定义作用于这些新元素的操作。 \n 结构 \n \n 抽象访问者（Visitor）：定义了对每一个元素访问的行为，参数是可以访问的元素。 \n 具体访问者（ConcreteVisitor）：给出对每一个元素类访问时产生的具体行为。 \n 抽象元素（Element）：定义了一个接受访问者的方法（accept），意义是指，每一个元素都要可以被访问者访问。 \n 具体元素（ConcreteElement）：提供接受访问方法的的具体实现，而这个具体的实现，通常情况下是使用访问者提供的访问该元素类的方法。 \n 对象结构（Object Structure）：定义对象结构，对象结构是一个抽象表述。具体可以理解为一个具有容器性质或者复合对象特征的类，会含有一组元素，并且可以迭代这些元素。 \n \n 案例 \n /**\n * 抽象访问者角色\n */ \n public   interface   Person   { \n\n   // 宠物猫喂食 \n   void   feed ( Cat  cat ) ; \n\n   // 宠物狗喂食 \n   void   feed ( Dog  dog ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 /**\n * 抽象元素类，接受指定访问者访问的功能\n */ \n public   interface   Animal   { \n\n   void   accept ( Person  person ) ; \n } \n\n /**\n * 具体元素角色类，宠物猫\n */ \n public   class   Cat   implements   Animal   { \n\n   @Override \n   public   void   accept ( Person  person )   { \n    person . feed ( this ) ; \n   } \n } \n\n /**\n * 具体元素角色类，宠物狗\n */ \n public   class   Dog   implements   Animal   { \n\n   @Override \n   public   void   accept ( Person  person )   { \n    person . feed ( this ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /**\n * 具体访问者角色类(宠物主)\n */ \n public   class   Owner   implements   Person   { \n\n   @Override \n   public   void   feed ( Cat  cat )   { \n     System . out . println ( "喂食猫" ) ; \n   } \n\n   @Override \n   public   void   feed ( Dog  dog )   { \n     System . out . println ( "喂食狗" ) ; \n   } \n } \n\n /**\n * 具体访问者（其他人）\n */ \n public   class   Someone   implements   Person   { \n\n   @Override \n   public   void   feed ( Cat  cat )   { \n     System . out . println ( "其他人喂食猫" ) ; \n   } \n\n   @Override \n   public   void   feed ( Dog  dog )   { \n     System . out . println ( "其他人喂食狗" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /**\n * 对象结构类\n */ \n public   class   Home   { \n   // 定义一个集合对象，用来存储元素对象 \n   List < Animal >  nodeList  =   new   ArrayList < > ( ) ; \n\n   // 添加元素功能 \n   public   void   add ( Animal  animal )   { \n    nodeList . add ( animal ) ; \n   } \n\n   // 遍历集合，获取每一个元素，让访问者访问每一个元素 \n   public   void   action ( Person  person )   { \n    nodeList . forEach ( animal  ->  animal . accept ( person ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 1. 创建 HOME \n     Home  home  =   new   Home ( ) ; \n    home . add ( new   Dog ( ) ) ; \n    home . add ( new   Cat ( ) ) ; \n\n     // 2. 创建宠物主 \n     Owner  owner  =   new   Owner ( ) ; \n\n     // 3. 主人喂食 \n    home . action ( owner ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 优缺点和使用场景 \n 优点： \n \n 扩展性好。 \n 复用性好。 \n 分离无关行为。 \n \n 缺点： \n \n 对象结构变化困难。 \n 违反了依赖导致原则。 \n \n 使用场景： \n \n 对象结构相对稳定，但是操作算法经常变更。 \n 对象需要提供多种不同且不相关操作，并且要避免让这些操作的变化影响对象的结构。 \n 备忘录模式 \n 提供了一种状态恢复机制，使用户可以方便地恢复到一个历史步骤。 \n 结构 \n \n 发起人（Originator）：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，可以访问备忘录中的所有信息。 \n 备忘录（Memento）：存储发起人的内部状态，需要时提供这些内部状态给发起人。 \n 管理者（Caretaker）：对备忘录进行管理，提供保存和获取备忘录的功能，但其不能对备忘录内部内容进行访问和修改。 \n \n 备忘录有两个等效接口： \n \n 窄接口：管理者和其他发起人之外的任何对象看到的是窄接口，这个窄接口只允许它将备忘录对象传递给其他对象。 \n 宽接口：与管理者看到的窄接口相反，这个宽接口允许读取所有数据，以便于恢复发起人对象的内部状态。 \n \n 白箱备忘录模式案例 \n /**\n * 发起人，游戏角色\n */ \n @Data \n public   class   GameRole   { \n\n   // 生命力 \n   private   int  vit ; \n   // 攻击力 \n   private   int  atk ; \n   // 防御力 \n   private   int  def ; \n\n   // 初始化状态 \n   public   void   initState ( )   { \n     this . vit  =   100 ; \n     this . atk  =   100 ; \n     this . def  =   100 ; \n   } \n\n   // 战斗后 \n   public   void   fight ( )   { \n     this . vit  =   0 ; \n     this . atk  =   0 ; \n     this . def  =   0 ; \n   } \n\n   // 保存角色状态功能 \n   public   RoleStateMemento   saveState ( )   { \n     return   new   RoleStateMemento ( vit ,  atk ,  def ) ; \n   } \n\n   // 恢复之前的状态 \n   public   void   recoverState ( RoleStateMemento  roleStateMemento )   { \n     this . vit  =  roleStateMemento . getVit ( ) ; \n     this . atk  =  roleStateMemento . getAtk ( ) ; \n     this . def  =  roleStateMemento . getDef ( ) ; \n   } \n\n   // 展示状态 \n   public   void   display ( )   { \n     System . out . println ( String . format ( "角色生命力：%s" ,  vit ) ) ; \n     System . out . println ( String . format ( "角色攻击力：%s" ,  atk ) ) ; \n     System . out . println ( String . format ( "角色防御力：%s" ,  def ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 /**\n * 备忘录角色类\n */ \n @Data \n @NoArgsConstructor \n @AllArgsConstructor \n public   class   RoleStateMemento   { \n\n   // 生命力 \n   private   int  vit ; \n   // 攻击力 \n   private   int  atk ; \n   // 防御力 \n   private   int  def ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /**\n * 备忘录管理\n */ \n @Data \n public   class   RoleStateCaretaker   { \n\n   private   RoleStateMemento  roleStateMemento ; \n } \n \n 1 2 3 4 5 6 7 8 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 1. 创建游戏角色 \n     GameRole  gameRole  =   new   GameRole ( ) ; \n     // 2. 初始化 \n    gameRole . initState ( ) ; \n     // 3. 展示 \n    gameRole . display ( ) ; \n     // 4. 备份 \n     RoleStateCaretaker  roleStateCaretaker  =   new   RoleStateCaretaker ( ) ; \n    roleStateCaretaker . setRoleStateMemento ( gameRole . saveState ( ) ) ; \n     // 5. 战斗之后 \n    gameRole . fight ( ) ; \n     // 6. 展示 \n    gameRole . display ( ) ; \n     // 7. 恢复之前的状态 \n    gameRole . recoverState ( roleStateCaretaker . getRoleStateMemento ( ) ) ; \n     // 8. 展示 \n    gameRole . display ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 黑箱备忘录案例 \n 修改内容不多，主要有： \n /**\n * 备忘录接口，对外提供窄接口\n */ \n public   interface   Memento   { \n } \n \n 1 2 3 4 5 /**\n * 发起人，游戏角色\n */ \n @Data \n public   class   GameRole   { \n\n   // 生命力 \n   private   int  vit ; \n   // 攻击力 \n   private   int  atk ; \n   // 防御力 \n   private   int  def ; \n\n   // 初始化状态 \n   public   void   initState ( )   { \n     this . vit  =   100 ; \n     this . atk  =   100 ; \n     this . def  =   100 ; \n   } \n\n   // 战斗后 \n   public   void   fight ( )   { \n     this . vit  =   0 ; \n     this . atk  =   0 ; \n     this . def  =   0 ; \n   } \n\n   // 保存角色状态功能 \n   public   RoleStateMemento   saveState ( )   { \n     return   new   RoleStateMemento ( vit ,  atk ,  def ) ; \n   } \n\n   // 恢复之前的状态 \n   public   void   recoverState ( Memento  memento )   { \n     RoleStateMemento  roleStateMemento  =   ( RoleStateMemento )  memento ; \n     this . vit  =  roleStateMemento . getVit ( ) ; \n     this . atk  =  roleStateMemento . getAtk ( ) ; \n     this . def  =  roleStateMemento . getDef ( ) ; \n   } \n\n   // 展示状态 \n   public   void   display ( )   { \n     System . out . println ( String . format ( "角色生命力：%s" ,  vit ) ) ; \n     System . out . println ( String . format ( "角色攻击力：%s" ,  atk ) ) ; \n     System . out . println ( String . format ( "角色防御力：%s" ,  def ) ) ; \n   } \n\n   @Data \n   @NoArgsConstructor \n   @AllArgsConstructor \n   class   RoleStateMemento   implements   Memento   { \n\n     private   int  vit ; \n     private   int  atk ; \n     private   int  def ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 优缺点和使用场景 \n 优点： \n \n 提供了状态，可以方便的恢复之前的状态。 \n 实现了内部状态的封装。 \n 简化了发起人，发起人不需要保存备份。 \n \n 缺点： \n \n 资源消耗大，假如需要保存的内容较多，则将会占用较大的内存。 \n \n 使用场景： \n \n 需要保存和恢复数据的场景。 \n 解释器模式 \n 将需要解决的问题提出规则，抽象为一种语言，比如运算。 \n 结构 \n \n 抽象表达式（Abstract Expression）：定义解释器接口，约定解释器的解释操作，主要包含方法  interpret \n 终结符表达式（Terminal Expression）：是抽象表达式的子类，用来实现和终结符相关的操作。 \n 非终结符表达式（Nonterminal Expression）：抽象表达式的子类。 \n 环境（Context）：包含各个解释器需要的数据或者是公共的功能，一般用于传递被所有解释器共享的数据。 \n 客户端（Client）：将需要分析的句子或者表达式转换为解释器描述的抽象语法树，然后调用解释器的解释方法。 \n \n 案例 \n /**\n * 抽象表达式类\n */ \n public   abstract   class   AbstractExpression   { \n   public   abstract   int   interpret ( Context  context ) ; \n } \n \n 1 2 3 4 5 6 /**\n * 环境\n */ \n public   class   Context   { \n\n   // 存储变量和对应的值 \n   private   Map < Variable ,   Integer >  map  =   new   HashMap < > ( ) ; \n\n   public   void   assign ( Variable  variable ,   Integer  value )   { \n    map . put ( variable ,  value ) ; \n   } \n\n   public   int   getValue ( Variable  variable )   { \n     return  map . get ( variable ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /**\n * 封装表达式的类\n */ \n @Data \n @AllArgsConstructor \n @NoArgsConstructor \n public   class   Variable   extends   AbstractExpression   { \n\n   // 声明存储变量名的成员变量 \n   private   String  name ; \n\n   @Override \n   public   int   interpret ( Context  context )   { \n     // 直接返回变量的值 \n     return  context . getValue ( this ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /**\n * 加法表达式类\n */ \n @Data \n @AllArgsConstructor \n public   class   Plus   extends   AbstractExpression   { \n\n   // 加号左边的表达式 \n   private   AbstractExpression  left ; \n   // 加号右边的表达式 \n   private   AbstractExpression  right ; \n\n   @Override \n   public   int   interpret ( Context  context )   { \n     return  left . interpret ( context )   +  right . interpret ( context ) ; \n   } \n } \n\n /**\n * 减法表达式类\n */ \n @Data \n @AllArgsConstructor \n public   class   Minus   extends   AbstractExpression   { \n\n   // 减号左边的表达式 \n   private   AbstractExpression  left ; \n   // 减号右边的表达式 \n   private   AbstractExpression  right ; \n\n   @Override \n   public   int   interpret ( Context  context )   { \n     return  left . interpret ( context )   -  right . interpret ( context ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public   class   Client   { \n   public   static   void   main ( String [ ]  args )   { \n     // 1. 创建环境对象 \n     Context  context  =   new   Context ( ) ; \n     // 2. 创建变量对象 \n     Variable  a  =   new   Variable ( "a" ) ; \n     Variable  b  =   new   Variable ( "b" ) ; \n     Variable  c  =   new   Variable ( "c" ) ; \n     Variable  d  =   new   Variable ( "d" ) ; \n     // 3. 存储 \n    context . assign ( a ,   1 ) ; \n    context . assign ( b ,   2 ) ; \n    context . assign ( c ,   3 ) ; \n    context . assign ( d ,   4 ) ; \n     // 4. 获取抽象语法树 \n     AbstractExpression  expression  =   new   Minus ( a ,   new   Plus ( new   Minus ( b ,  c ) ,  d ) ) ; \n     System . out . println ( expression . interpret ( context ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 优缺点和使用场景 \n 优点： \n \n 易于改变和扩展文法。 \n 实现文法较为容易。 \n 增加新的解释表达式比较方法。 \n \n 缺点： \n \n 复杂文法难以维护。 \n 执行效率低。 \n \n 使用场景： \n \n 文法较为简单，并且执行效率不是关键问题时。 \n 问题重复出现，并且可以用一种简单的语言表达时。 \n 语言需要解释执行，并且句子可以表示为一个抽象语法树时。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 14, 2021 23:48",createTimeStamp:1628956128e3,contributors:[{name:"causes",email:"2592716753@qq.com",commits:3},{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Docker-01-基础",frontmatter:{title:"Docker-01-基础",categories:["backend"],tags:["docker"],author:"causes",summary:"概述 docker 和传统的虚拟机不同，传统虚拟机是先虚拟出一套硬件，然后在硬件上运行一个操作系统，之后在操作系统上运行进程。 docker 中的进程直接运行在宿主内核中，容器中没有自己的内核，也没有虚拟的硬件，因此更加轻便，启动速度更快。 Docker 中有几个基本概念： 镜像：没有任何动态数据，可以看成是 Java 中类的概念。; 容器：运行中的实体，可",meta:[{property:"og:url",content:"/backend/Docker/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Docker-01-基础"},{property:"og:description",content:"概述 docker 和传统的虚拟机不同，传统虚拟机是先虚拟出一套硬件，然后在硬件上运行一个操作系统，之后在操作系统上运行进程。 docker 中的进程直接运行在宿主内核中，容器中没有自己的内核，也没有虚拟的硬件，因此更加轻便，启动速度更快。 Docker 中有几个基本概念： 镜像：没有任何动态数据，可以看成是 Java 中类的概念。; 容器：运行中的实体，可"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"docker"}]},regularPath:"/backend/Docker/part1.html",relativePath:"backend/Docker/part1.md",key:"v-16ce3220",path:"/backend/Docker/part1/",headers:[{level:2,title:"概述",slug:"概述"},{level:2,title:"镜像",slug:"镜像"},{level:2,title:"容器",slug:"容器"},{level:2,title:"Dockerfile",slug:"dockerfile"}],readingTime:{minutes:14.65,words:4396},content:' 概述 \n docker 和传统的虚拟机不同，传统虚拟机是先虚拟出一套硬件，然后在硬件上运行一个操作系统，之后在操作系统上运行进程。 \n docker 中的进程直接运行在宿主内核中，容器中没有自己的内核，也没有虚拟的硬件，因此更加轻便，启动速度更快。 \n \n \n Docker 中有几个基本概念： \n \n 镜像：没有任何动态数据，可以看成是 Java 中类的概念。 \n 容器：运行中的实体，可以看成是 Java 中，类实例化之后的对象。 \n 仓库：仓库中包含多个标签，每一个标签赌赢一个镜像。 \n Docker Repository：可以包含多个仓库。本质上是一个集中的存储、分发镜像的服务（最常用的是 Docker 官方推出的 Docker Hub）。 \n 镜像 \n 获取 \n Docker Hub 上有大量的镜像可以用，使用  docker pull [options] [address [:port]/]仓库名称 [:tag] ，具体可以通过  docker pull --help  看到。 \n \n Docker 地址格式为  域名/IP :端口号 ，默认的地址为 Docker Hub（ docker.io ）。 \n 仓库名称格式： 用户名/软件名 ，不指定则为官方镜像  library 。 \n \n 例如： docker pull ubuntu:18.04  ->  docker.io/library/ubuntu:18.04 \n 列出 \n 使用命令  docker image  列出已经下载下来的镜像。 \n [root@bigdata]~# docker images\nREPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/gitea/gitea                         latest              423b8c425d76        4 weeks ago         241 MB\ndocker.io/jgraph/drawio                       latest              71f9c9180be6        8 weeks ago         531 MB\ndocker.io/rocket.chat                         latest              00e7c59a3559        2 months ago        828 MB\nregistry.rocket.chat/rocketchat/rocket.chat   latest              97cd6f80ccc2        2 months ago        879 MB\ndocker.io/diygod/rsshub                       latest              e8c178c7e38e        4 months ago        231 MB\ndocker.io/mongo                               4.0                 e305b5d51c0a        4 months ago        430 MB\ndocker.io/elasticsearch                       7.4.2               b1179d41a7b4        2 years ago         855 MB\ndocker.io/mobz/elasticsearch-head             5                   b19a5c98e43b        5 years ago         824 MB\n \n 1 2 3 4 5 6 7 8 9 10 其中包含了：仓库名称、标签、镜像 ID、创建时间、占用空间。 \n 在这里，占用空间和 Docker Hub 中展示的可能不同，因为 Docker Hub 展示的是压缩之后的体积，在镜像下载和上传过程中是压缩状态。 \n \n 可以通过命令  docker system df  可以查看当前镜像、容器、本地卷的占用空间 \n [root@bigdata]~# docker system df\nTYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE\nImages              8                   7                   4.751 GB            828.5 MB (17%)\nContainers          8                   2                   173.2 MB            106.1 MB (61%)\nLocal Volumes       7                   4                   87.61 MB            87.6 MB (99%)\n \n 1 2 3 4 5 \n 在镜像中，可能会有一些特殊镜像，仓库名和标签都为  <none> ，可能会有很多原因导致（比如 build 失败、官方转移新镜像等），这些叫做虚悬镜像，没什么价值，可以删除。 \n \n 基本操作示例 \n普通的 docker images 显示所有镜像 \n [ root@bigdata ] ~ # docker images \nREPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/gitea/gitea                         latest              423b8c425d76         4  weeks ago          241  MB\ndocker.io/jgraph/drawio                       latest              71f9c9180be6         8  weeks ago          531  MB\ndocker.io/rocket.chat                         latest              00e7c59a3559         2  months ago         828  MB\nregistry.rocket.chat/rocketchat/rocket.chat   latest              97cd6f80ccc2         2  months ago         879  MB\ndocker.io/diygod/rsshub                       latest              e8c178c7e38e         4  months ago         231  MB\ndocker.io/mongo                                4.0                  e305b5d51c0a         4  months ago         430  MB\ndocker.io/elasticsearch                        7.4 .2               b1179d41a7b4         2  years ago          855  MB\ndocker.io/mobz/elasticsearch-head              5                    b19a5c98e43b         5  years ago          824  MB\n可以指定仓库，单独显示某个仓库下的镜像 \n [ root@bigdata ] ~ # docker images rocket.chat \nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/rocket.chat   latest              00e7c59a3559         2  months ago         828  MB\n指定仓库 + 标签显示镜像 \n [ root@bigdata ] ~ # docker images rocket.chat:latest \nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/rocket.chat   latest              00e7c59a3559         2  months ago         828  MB\n展示在 rocket.chat 这个镜像之后的镜像 \n [ root@bigdata ] ~ # docker images -f since=rocket.chat \nREPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/gitea/gitea     latest              423b8c425d76         4  weeks ago          241  MB\ndocker.io/jgraph/drawio   latest              71f9c9180be6         8  weeks ago          531  MB\n ## 展示在 rocket.chat 之前的镜像 \n [ root@bigdata ] ~ # docker images -f before=rocket.chat \nREPOSITORY                                    TAG                 IMAGE ID            CREATED             SIZE\nregistry.rocket.chat/rocketchat/rocket.chat   latest              97cd6f80ccc2         2  months ago         879  MB\ndocker.io/diygod/rsshub                       latest              e8c178c7e38e         4  months ago         231  MB\ndocker.io/mongo                                4.0                  e305b5d51c0a         4  months ago         430  MB\ndocker.io/elasticsearch                        7.4 .2               b1179d41a7b4         2  years ago          855  MB\ndocker.io/mobz/elasticsearch-head              5                    b19a5c98e43b         5  years ago          824  MB\n假如构建时指定了 label，可以通过它来展示镜像 \n [ root@bigdata ] ~ # docker images -f label=latest \nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n只展示镜像 ID \n [ root@bigdata ] ~ # docker images -q \n423b8c425d76\n71f9c9180be6\n00e7c59a3559\n97cd6f80ccc2\ne8c178c7e38e\ne305b5d51c0a\nb1179d41a7b4\nb19a5c98e43b\n根据模板展示镜像，需要用到 Go 的模板语法: https://gohugo.io/templates/introduction/ \n [ root@bigdata ] ~ # docker image ls --format "{{.ID}}: {{.Repository}}" \n423b8c425d76: docker.io/gitea/gitea\n71f9c9180be6: docker.io/jgraph/drawio\n00e7c59a3559: docker.io/rocket.chat\n97cd6f80ccc2: registry.rocket.chat/rocketchat/rocket.chat\ne8c178c7e38e: docker.io/diygod/rsshub\ne305b5d51c0a: docker.io/mongo\nb1179d41a7b4: docker.io/elasticsearch\nb19a5c98e43b: docker.io/mobz/elasticsearch-head\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 \n 删除 \n 使用  docker rmi [options] 镜像1 [镜像2 镜像3 ……] ，其中镜像可以是 ID、名称等。 \n 我们删除镜像时，其实是删除某个标签的镜像，所以首先满足条件的镜像都会取消标签，是  Untagged  操作，之后才会删除镜像。 \n 但是假如一个镜像有多个标签，那么我们这个删除操作可能只是删除了某个标签而已，只有删除了所有的标签，才会触发删除行为。 \n 还有一种情况，就是当一个容器使用这个镜像时，这个镜像不会删除，因为容器正在运行，而且容易以镜像为基础，所以不会删除。 \n 我们也可以使用查询镜像命令来配合删除镜像： docker rm $(docker images) \n 容器 \n 基本操作 \n \n docker run 镜像 ：启动容器。 \n docker stop 容器 ：终止容器。 \n docker start 容器 ：启动已经终止的容器。 \n docker run -it 镜像 /bin/bash ：启动并进入容器，使用 bash 交互。 \n docker run -d 镜像 ：后台运行，会返回容器 id。 \n docker logs 镜像 ：获取容器输出。 \n docker rm 镜像 ：删除镜像。 \n \n 当启动容器时，运行过程包括： \n \n 检查本地是否存在镜像，没有则下载。 \n 利用镜像创建并启动容器。 \n 分配文件系统，并在只读的镜像层外挂载一层可读可写层。 \n 从网桥接口中桥接一个虚拟接口到容器中。 \n 分配 ip 给容器。 \n 执行用户指定的程序。 \n 程序完成后终止。 \n \n 所以可以看到，容器默认是一次性的，任务运行完成即终止，要想让容器不终止，需要一直保持执行状态。 \n 进入运行中的容器 \n docker exec -it 容器ID 终端 ，例如： docker exec -it adca7acf3c41 bash 。 \n 其中  -i  表示即使没有连接，也要保持 STDIN 打开， -t  是分配伪终端。 \n 导入导出 \n \n docker export 容器 > container.tar ：将容器导出为本地文件。 \n docker import container.tar test:1.0 ：将本地文件导入为镜像，也可以指定某个 url 或者目录来导入。 \n Dockerfile \n Docker 镜像是一种分层结构，这种结构的好处是：多个镜像可能会用到某一个相同的层，这样就无需多次 pull。 \n 那么对于镜像来说，即使 DockerHub 中有很多优秀镜像，但是不可能完全解决需求，因此我们需要自定义镜像。 \n Dockerfile 是一个文本文件，其内包含了一条条的 指令（Instruction），每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 \n FROM \n 定制镜像，肯定是以一个镜像为基础，而  FROM  关键字则指定了以哪一个镜像为基础。 \n 有一些镜像可以直接拿来用，比如  nginx 、 redis 、 mongo 、 tomcat  等，也有一些方便开发使用，例如  node 、 openjdk 、 python ，甚至还有一些系统镜像  ubuntu 、 centos 、 debian  等。 \n RUN \n 用于执行命令，有两种格式： \n \n RUN 命令 ： RUN echo \'HELLO WORLD\' \n RUN [\'可执行文件\', \'参数\', \'参数\'] \n \n 每个  RUN  都可以看做是一个新的进程执行环境，所以假如使用 \n RUN  cd  /app\nRUN  echo   "HELLO"   >   "world.txt" \n \n 1 2 其实不会进入到  /app  中去创建文件，结果是失败的。因为在 shell 中，这两条命令是处于同一个环境下的，但是在 docker 中，这是两个环境，第二个明显不会集成第一个。 \n 要解决这个问题，需要使用  WORKDIR 。 \n 构建镜像 \n 下面使用  Dockerfile  文件： \n FROM nginx\nRUN echo \'<h1>HELLO Docker</h1>\' > /usr/share/nginx/html/index.html\n \n 1 2 执行构建镜像命令： docker build -t nginx:test .  代表构建了一个镜像，名称为  nginx ，标签为  test \n 镜像构建时，最后一个点，这个  .  代表的是当前目录，而  Dockerfile  就是当前目录，更确切的说，是在指定上下文环境。 \n 提到上下文，首先要提到的就是 Docker 的架构。Docker = Docker 引擎（服务端守护进程）+ 客户端工具。 \n 我们在执行命令时，本质上是通过客户端发送给 Docker 引擎，然后 Docker 引擎去执行命令。构建镜像的命令也是如此。 \n Docker 客户端会将上下文环境中指定下的所有内容都打包交给 Docker 引擎，然后 Docker 引擎去解析上下文环境中的内容进行构建。 \n 之后我们还会学到  COPY  ，假如指定  COPY ./package.json /app/ ，这条命令的意思是将上下文中的  package.json  放到  app  下，而不是 Dockerfile 文件所在位置或构建命令执行的位置下的  package.json 。 \n 假如我们对上下文环境错误地理解为 Dockerfile 所在的目录，有可能会出现  COPY ../package.json  失败的情况，因为这些路径已经超过了上下文环境的范围。 \n 或者，假如有些人将  Dockerfile  文件直接放到了根目录下，那么就相当于将整个根目录打包送到 Docker 引擎，这样明显是错误的。 \n \n 其实上下文和  Dockerfile  文件的所在位置并没有因果关系。 \n 假如我们不指定 Dockerfile 文件，默认会将  Dockerfile  作为构建镜像的文件，而事实上，我们可以使用  -f ../a.txt  这种方式，手动指定某个文件。并且还可以额外指定上下文，但是上下文中必须能够找到指定的  Dockerfile  文件。 \n 比如： docker build -t nginx:v1 -f hello/a.txt . \n COPY \n COPY ，就是将文件从构建的上下文中拷贝到新的一层的镜像内的目标位置，可以使用 GO 的 通配符 表达式。例如： \n COPY hom* /dir/\n \n 1 特别强调文件构建上下文，这里的上下文和 Dockerfile 所在位置并没有直接关系，只是说上下文中必须可以找到 Dockerfile 文件。 \n 目标路径是容器内的路径，建议使用绝对路径，不过也可以使用相对路径，这个相对路径相对的是工作目录（使用关键字  WORKDIR  指定）。 \n 在使用 COPY 命令时，目标的各种属性都会保留，例如权限、文件变更时间。在进行 GIT 管理的时候很有用。 \n 可以使用  --chown=<user>:<group>  来变更所属用户和组，例如： \n COPY --chown = causes:causes hom* /dir/\n \n 1 假如指定原路径为文件夹，那么不会复制文件夹，而是会将文件夹中的内容复制到目标路径下。 \n ADD \n 类似 COPY，但有所不同。它比 COPY 更加高级，比如原路径可以为一个 URL（下载后权限自动设为 600，更改则需要一层的 RUN 去调整）。 \n 假如原路径为一个 tar 压缩文件，并且压缩格式为  gzip 、 bzip2 、 xz  之一，此命令会自动解压缩到目标路径上。 \n 一般的最佳实践是：多用 COPY，少用 ADD。因为 COPY 功能单一，语义明确。ADD 虽然功能多一些，但是语义不明确，行为也不清晰。并且 ADD 会令镜像构建缓存失效，从而影响构建速度。 \n 我们可以在文件复制时使用 COPY，仅在文件需要自动解压缩时使用 ADD。 \n CMD \n CMD 的目的是在容器启动时指定容器启动程序和程序的参数，可使用两种方式： \nshell 格式，会被解析为 exec 格式，会主动包一层 `sh -c`，变为下面的 exec 格式 \nCMD  "echo HELLO" \nexec 格式，推荐使用，注意一定要使用双引号（因为会被解析为 JSON 数组） \nCMD  [ "sh" ,  "-c" ,  "echo HELLO" ] \n \n 1 2 3 4 注意，Docker 和传统的虚拟机有所不同，容器中的应用没有后台服务的概念，都是在前台执行。容器是为了主进程存在的，主进程退容器就结束运行。 \n 所以假如我们使用  CMD service nginx start ，其实是在执行  CMD ["sh", "-c", "service nginx start"] ，这里的主进程其实是  sh ，并不是  nginx 。 \n 正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行： CMD ["nginx", "-g", "daemon: off;"] 。 \n 我们也说过了，容器内没有后台应用的概念，所以传统守护进程服务  daemon: on  没有意义。在容器中想要运行则必须要一个前台进程。 \n 另外，CMD 命令会被  docker run  带有的参数给覆盖掉，例如： \n FROM ubuntu:18.04\nCMD  [ "sh" ,  "-c" ,  "echo HELLO WORLD" ] \n \n 1 2 构建为  test:test ，运行时  docker run test:test  会输出  HELLO WORLD ，但是参上参数  docker run test:test echo HELLO DOCKER  就会输出  HELLO DOCKER 。 \n 而且哪怕我们在 Dockerfile 中没有指定任何 CMD 命令，只要带上参数，那么就会覆盖为 CMD 命令。 \n ENTRYPOINT \n 目的也和 CMD 一样，在容器启动时指定需要的程序和程序对应的参数，但是指定它之后，CMD 的意义就发生了改变，不再是直接运行命令，而是作为参数传递给  ENTRYPOINT 就是： <ENTRYPOINT> "<CMD>" \n 这样做的好处，就是可以将 CMD 执行后得到的参数再传递给  ENTRYPOINT  进行处理。 \n FROM ubuntu:18.04\nENTRYPOINT  [ "echo" ] \n \n 1 2 当运行  docker run test:test HELLO DOCKER  时， HELLO DOCKER  会作为 CMD 传递给  ENTRYPOINT ，最终输出。 \n ENTRYPOINT  也是可以覆盖的，只需要在  docker run  运行时带上  --entrypoint="echo"  就可以覆盖。 \n 但是不管是哪种方式，最终在  docker ps  查看容器信息时，显示的都是最后运行的命令。 \n ENV \n 设置环境变量，格式有两种： \n ENV  < key >   < value > \nENV  < key 1 > = < value 1 >   < key 2 > = < value 2 >  ……\n \n 1 2 在这里定义之后，其他后面的指令都可以直接使用这里的定义。 \n ARG \n 类似 ENV，但区别是：不会在容器运行时看到这些值。但是不要保存敏感数据，因为  docker history  还是可以看到的。 \n 注意，ARG 参数的生效范围截止到下一个 FROM，在下一个 FROM 之后假如还需要使用，那么必须再次指定。 \n ARG  DOCKER_USERNAME = library\n\nFROM  ${DOCKER_USERNAME} /alpine\n在FROM 之后使用变量，必须在每个阶段分别指定 \nARG  DOCKER_USERNAME = library\n\nRUN  set  -x  ;   echo   ${DOCKER_USERNAME} \n\nFROM  ${DOCKER_USERNAME} /alpine\n在FROM 之后使用变量，必须在每个阶段分别指定 \nARG  DOCKER_USERNAME = library\n\nRUN  set  -x  ;   echo   ${DOCKER_USERNAME} \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 VOLUME \n 容器运行应该是无状态的，假如我们想要保存某些数据，那么就需要链接服务器目录和容器对应的目录（这种操作叫做挂载），这样即使容器挂掉，数据也不会丢失。 \n \n \n Dockerfile 方式： \n FROM ubuntu:18.04\n使用 Dockerfile 文件时，只能指定容器内目录，不能指定宿主机目录，因为不能保证每个宿主机都会存在这种目录 \nVOLUME  [ "/dockerContainerDir" ,  "/dockerContainerDir2" ] \n \n 1 2 3 \n \n 匿名目录挂载： \n 不显示指定宿主机的文件夹，会自动生成在  /var/lib/docker/volumes  下。 \n docker run -it -v <容器内目录> \n 假如出现权限问题，只需要多加  --privileged=true  即可 \n 运行命令可覆盖 Dockerfile 的配置 \n \n \n 具名挂载： \n 显示指定宿主机文件夹 \n docker run -it -v <宿主机目录>:<容器内目录> \n 假如出现权限问题，只需要多加  --privileged=true  即可 \n 运行命令可覆盖 Dockerfile 的配置 \n \n \n EXPOSE \n 声明容器运行时提供服务的端口，但是这只是个声明，不意味着开启这个端口的服务，只是提个醒。 \n 和使用  docker run -p  不同， EXPOSE  不会去主动做映射，只是声明一下。 \n 但是在使用  docker run -P （大写 P）时，会随机将  EXPOSE  的端口随机映射给宿主机端口。 \n 可以使用： \n EXPOSE  80 \nEXPOSE  80 /tcp\nEXPOSE  80 /udp\nEXPOSE  < 端口 > / < 协议 > \n \n 1 2 3 4 WORKDIR \n 指定工作目录（当前目录），格式为  WORKDIR <路径> ，如果不存在，Docker 会自动建立一个。 \n 每个  RUN  都可以看做是一个新的进程执行环境，所以假如使用 \n RUN  cd  /app\nRUN  echo   "HELLO"   >   "world.txt" \n \n 1 2 其实不会进入到  /app  中去创建文件，结果是失败的。因为在 shell 中，这两条命令是处于同一个环境下的，但是在 docker 中，这是两个环境，第二个明显不会集成第一个。 \n 要解决这个问题，需要使用  WORKDIR /app 。 WORKDIER  其实就是改变工作环境，假如执行命令存在相对路径，那么也是相对于  WORKDIR 。 \n USER \n 改变之后命令执行时的身份。注意，这个用户必须是实现建立好的，否则是无法进行切换的。例如： \n增加组 causes，并且修改用户的组 \nRUN  groupadd  -r causes  &&  user -r -g causes causes\n USER  causes\n \n 1 2 3 假如是使用 root 执行的脚本，在这期间希望改变身份，那么不要使用  su 、 sudo 。因为缺少 TTY 可能出错，且需要复杂配置，可以使用  gosu \n LABEL \n 添加一些元数据： \n LABEL  < key >= < value >   < key >= < value >   < key >= < value > \n \n 1 SHELL \n 默认情况下使用  /bin/sh -c ，可以使用 SHELL 来切换，例如： \n SHELL   [ "/bin/sh" ,  "-c" ] \n SHELL   [ "/bin/bash" ,  "-c" ] \n \n 1 2 指定之后，可以切换 CMD、RUN、ENTRYPOINT 使用的 shell。 \n',updateTime:"July 4, 2022 10:47",updateTimeStamp:165690284e4,createTime:"June 14, 2022 15:33",createTimeStamp:1655191993e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2}]},{title:"Docker-02-进阶",frontmatter:{title:"Docker-02-进阶",categories:["backend"],tags:["docker"],author:"causes",summary:"Docker Hub 在 Docker Hub 中存在大量成熟的镜像，可以直接使用。 可以使用 docker search 找寻成熟度的镜像，例如：docker search nginx。有关键字：OFFICIAL（官方创建）。 也可以在登陆之后，使用 docker push 将自己的镜像推送到 docker hub：docker tag : /:。 也可以",meta:[{property:"og:url",content:"/backend/Docker/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Docker-02-进阶"},{property:"og:description",content:"Docker Hub 在 Docker Hub 中存在大量成熟的镜像，可以直接使用。 可以使用 docker search 找寻成熟度的镜像，例如：docker search nginx。有关键字：OFFICIAL（官方创建）。 也可以在登陆之后，使用 docker push 将自己的镜像推送到 docker hub：docker tag : /:。 也可以"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"docker"}]},regularPath:"/backend/Docker/part2.html",relativePath:"backend/Docker/part2.md",key:"v-192fb65e",path:"/backend/Docker/part2/",headers:[{level:2,title:"Docker Hub",slug:"docker-hub"},{level:2,title:"Docker 网络",slug:"docker-网络"},{level:2,title:"Docker Compose",slug:"docker-compose"},{level:3,title:"介绍与安装",slug:"介绍与安装"},{level:3,title:"命令",slug:"命令"},{level:3,title:"模板文件",slug:"模板文件"}],readingTime:{minutes:6.77,words:2031},content:' Docker Hub \n 在  Docker Hub  中存在大量成熟的镜像，可以直接使用。 \n 可以使用  docker search  找寻成熟度的镜像，例如： docker search nginx 。有关键字： OFFICIAL（官方创建） 。 \n 也可以在登陆之后，使用  docker push  将自己的镜像推送到 docker hub： docker tag <推送到docker hub 上的镜像名称>:<标签> <username>/<镜像名称>:<标签> 。 \n 也可以使用  docker-registry  构建私人镜像仓库，使用镜像  registry  即可，或者一步到位，直接使用  nexus  来管理 docker，顺便把 maven、yum、pypi 也管了。 \n Docker 网络 \n Docker 提供网络服务有两种方式： \n \n 外部访问容器（端口映射） \n 容器互联（docker 网络） \n \n 端口映射 \n 端口映射，其实就是将宿主机的端口和 docker 端口链接，进而达到访问宿主机端口直接进入到 docker 容器端口的效果。 \n 在  docker run  时，可以通过  -p  和  -P  来进行端口映射，使用  -p  可以指定需要映射的端口，例如： docker run -p 8080:8888 ，这样宿主机的  8080  就映射到 docker 的  8888 。 \n 还可以直接指定地址和协议，比如： docker run -p 127.0.0.1:8080:8888/tcp ，可以多次使用  -p  绑定多个端口。 \n 映射完成之后，可以使用  docker port ${dockerContainer}  查看配置。 \n 容器互联 \n 可以创建一个 Docker 网络，加入此网络的容器可以相互访问。如果有多个容器互相连接的需求，那么  docker compose  是更好的选择。 \n \n \n 新建 docker 网络： docker network create -d bridge docker-net \n -d  可以指定参数  bridge 、 overlay 。其中  overlay  用于 swarm 这个容器编排工具。 \n \n \n 启动容器，并且将容器加入到 docker 网络中： docker run -d --name nginx1 --network docker-net nginx:latest \n \n \n 列出网络： docker network ls \n docker 会自动创建三个网络： bridge 、 host 、 none \n \n \n \n 网络 \n 说明 \n \n \n \n \n bridge \n 为每个容器分配、设置 IP，并且连接到  docker0  上，是默认模式 \n \n \n host \n 容器将使用宿主机 IP 和端口 \n \n \n none \n 不联网 \n \n \n \n \n \n 查看某网路的详细信息： docker inspect bridge \n Docker Compose \n 介绍与安装 \n Docker Compose ，Docker 官方的容器编排项目，他可以让多个容器互相配合完成任务，比 Dockerfile 更好。 \n 允许用户通过一个单独的文件  docker-compose.yml  来定义一组相互关联的容器作为一个项目。 \n 概念： \n \n service  服务：多个运行相同镜像的容器称为服务。 \n project  项目：一组关联的应用容器组成的完整业务单元。 \n \n docker-compose  可以直接从官方  release  包下载安装。 \n sudo   curl  -L https://download.fastgit.org/docker/compose/releases/download/1.27.4/docker-compose- ` uname  -s ` - ` uname  -m `   >  /usr/local/bin/docker-compose\n sudo   chmod  +x /usr/local/bin/docker-compose\n \n 1 2 Docker 重写了 Docker Compose，称为 Compose V2，之后升级的时候可以使用  docker compose  代替  docker-compose 。 \n 命令 \n help \n 使用  docker-compose [COMMAND] --help  或  docker-compose help [COMMAND]  即可查看某个命令的使用格式。 \n 命令选项 \n \n -f, --file File ：指定使用的 compose 模板文件，默认为  docker-compose.yml 。 \n -p, --project-name [name] ：指定项目名称，默认使用所在目录作为项目名。 \n --verbose ：输出更多调试信息。 \n -v, --version ：打印版本并退出。 \n \n build \n 构建项目中的服务容器，选项： \n \n --force-rm ：删除构建中的临时容器。 \n --no-cache ：构建过程不进行缓存。 \n --pull ：始终尝试获取更新版本的镜像。 \n \n config \n 验证 docker compose 文件格式是否正确，错误显示错误原因，正确显示配置。 \n up \n 自动构建镜像、创建服务、增加网络、关联服务相关容器等操作。 \n \n -d ：后台运行容器。 \n --force-recreate ：强制重新创建容器，不可与  --no-recreate  同时使用。 \n --no-recreate ：容器存在则不创建。 \n --no-build ：不自动构建缺失的镜像。 \n \n down \n 停止  docker compose up  启动的容器，移除网络。 \n version \n 查看版本。 \n exec \n 进入指定容器。 \n images \n 列出 compose 文件中包含的镜像。 \n kill \n docker compose kill [service] \n 强制杀掉容器。 \n logs \n docker compose logs [service] \n 查看服务容器的输出。 \n pause \n docker compose pause [service] \n 暂停一个服务容器。 \n unpause \n 恢复处于暂停状态的服务。 \n port \n docker compose port [service] [port] \n 映射端口。 \n \n --protocol=proto ：指定协议，默认为 tcp。 \n --index=index ：若同一服务有多个容器，则指定命令对象容器的编号，默认为 1。 \n \n ps \n 列出所有容器。 \n pull \n 拉取服务依赖的镜像。 \n push \n 推送服务依赖的镜像到 docker 仓库。 \n rm \n 删除所有停止状态的容器。 \n run \n docker compose run ubuntu ping docker.com \n 在指定服务（没有则启动）上执行一个命令。 \n \n -d ：后台启动。 \n --name [name] ：指定容器名称。 \n --entrypoint [command] ：覆盖默认的容器启动指令。 \n -e [KEY=VAL] ：指定环境变量，可多次指定。 \n -u ：指定运行容器的用户。 \n -p ：映射端口。 \n \n start \n 启动已存在的容器。 \n restart \n docker compose restart [service] \n 重启服务。 \n \n -t，--timeout [timeout] ：指定超时时间，默认 10s。 \n \n stop \n 停止已经运行的容器，但不删除。 \n top \n 查看各个服务容器内运行的进程。 \n 模板文件 \n 模板文件 是核心，有了一个模板文件，大部分命令都可以直接配置，然后一个  docker compose run  启动即可。默认模板文件为  docker-compose.yml 。 \n 每个服务都必须指定镜像，可以使用 image 指令，也可使用 build（需要 Dockerfile） 指定，使用 Dockerfile 时，所有的 CMD、EXPOSE、VOLUME、ENV 等会自动被捕获，不用在  docker-compose.yml  再次指定。 \n 例如： \n version :   "3" \n\n services : \n   webapp : \n     image :  examples/web\n     ports : \n       -   "80:80" \n     volumes : \n       -   "/data" \n \n 1 2 3 4 5 6 7 8 9 或 \n version :   \'3\' \n services : \n   webapp : \n     build :  ./dir\n \n 1 2 3 4 image \n 指定镜像，不存在则会拉取。 \n build \n 使用 build 时，可以指定绝对/相对路径，甚至可以使用  context  指定 Dockerfile 所在文件夹的路径，也可以使用  arg  来指定构建镜像的变量，可以使用  cache_from  指定构建镜像的缓存。 \n version :   \'3\' \n\n services : \n   webapp : \n     build : \n       context :  ./dir\n       dockerfile :  Dockerfile - alternate\n       args : \n         buildno :   1 \n     cache_from : \n       -  alpine : latest\n       -  corp/web_app : 3.14 \n \n 1 2 3 4 5 6 7 8 9 10 11 12 labels \n 指定元数据信息。 \n labels : \n   com.startupteam.description :   "webapp for a startup team" \n   com.startupteam.department :   "devops department" \n   com.startupteam.release :   "rc3 for v1.0" \n \n 1 2 3 4 network_mode \n 设置网络模式。 \n network_mode :   "bridge" \n network_mode :   "host" \n network_mode :   "none" \n network_mode :   "service:[service name]" \n network_mode :   "container:[container name/id]" \n \n 1 2 3 4 5 networks \n 配置容器连接的网络。 \n version :   "3" \n\n services : \n   some-service : \n     networks : \n       -  some - network\n       -  other - network\n\n networks : \n   some-network : \n   other-network : \n \n 1 2 3 4 5 6 7 8 9 10 11 ports \n 暴露端口信息。 \n ports : \n   -   "3000" \n   -   "8000:8000" \n   -   "49100:22" \n   -   "127.0.0.1:8001:8001" \n \n 1 2 3 4 5 volumes \n 指定容器数据卷。 \n volumes : \n  -  /var/lib/mysql\n  -  cache/ : /tmp/cache\n  -  ~/configs : /etc/configs/ : ro\n \n 1 2 3 4 command \n command: echo "HELLO WORLD" \n 覆盖容器启动后默认执行的命令。 \n cgroup_parent \n cgroup_parent: cgroups_1 \n 指定父 cgroup，继承此组资源限制。 \n container_name \n container_name: docker-web-container \n 指定容器名称，默认名称是  项目名称_服务名称_序号 。指定后，此项目无法扩展，因为 Docker 不允许多个容器有相同的名称。 \n 读取变量 \n 将使用系统环境变量和当前目录下的  .env  文件中的变量。 \n version :   "3" \n\n services : \n   db : \n     image :   "mongo:${MONGO_VERSION}" \n \n 1 2 3 4 5 depends_on \n 指定启动顺序，这个例子中会先启动 redis、db，之后启动 web。 \n version :   \'3\' \n\n services : \n   web : \n     build :  .\n     depends_on : \n       -  db\n       -  redis\n\n   redis : \n     image :  redis\n\n   db : \n     image :  postgres\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dns \n 自定义 DNS 服务器，可以是一个值，可以是一个列表。 \n dns :  8.8.8.8\n\n dns : \n   -  8.8.8.8\n   -  114.114.114.114\n \n 1 2 3 4 5 env_file \n 从文件中获取环境变量，若冲突，则后者覆盖前者。 \n env_file :  .env\n\n env_file : \n   -  ./common.env\n   -  ./apps/web.env\n   -  /opt/secrets.env\n \n 1 2 3 4 5 6 环境变量文件： \ncommon.env: Set development environment \n PROG_ENV = development\n \n 1 2 environment \n 声明环境变量，环境变量可自动获取 compose 主机上对应的值，可以避免泄露数据。 \n environment : \n   RACK_ENV :  development\n   SESSION_SECRET : \n\n environment : \n   -  RACK_ENV=development\n   -  SESSION_SECRET\n \n 1 2 3 4 5 6 7 布尔值需要放到引号中，包括： y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF \n expose \n 暴露端口，但不映射到宿主机。 \n expose : \n  -   "3000" \n  -   "8000" \n \n 1 2 3 extends \n 继承其他的文件，必须也符合 docker-compose 文件格式。 \n \n \n docker-compose-common.yml \n version :   \'3\' \n\n services : \n   web :  \n     image :  example/web - common : latest\n \n 1 2 3 4 5 \n \n docker-compose.yml \n version :   \'3\' \n\n services : \n   worker : \n     extends : \n         file :  docker - compose - common.yml\n         service :  web\n \n 1 2 3 4 5 6 7 \n \n',updateTime:"July 4, 2022 10:47",updateTimeStamp:165690284e4,createTime:"July 4, 2022 10:47",createTimeStamp:165690284e4,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"Kubernetes-02-操作",frontmatter:{title:"Kubernetes-02-操作",categories:["backend"],tags:["k8s"],author:"causes",summary:"资源管理 介绍 k8s 实际上就是一个集群系统，可以在这个集群中运行一个个的容器，并将程序跑在容器中，这就叫启动服务了。 k8s 的最小管理单元为 pod，容器将会放到 pod 中，而 k8s 通过 pod 控制器来管理 pod，进而管理容器。 pod 对外提供服务，然而出于单一职责的考虑，pod 不能即管理容器又管理服务访问，所以服务访问交给 servic",meta:[{property:"og:url",content:"/backend/Kubernetes/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Kubernetes-02-操作"},{property:"og:description",content:"资源管理 介绍 k8s 实际上就是一个集群系统，可以在这个集群中运行一个个的容器，并将程序跑在容器中，这就叫启动服务了。 k8s 的最小管理单元为 pod，容器将会放到 pod 中，而 k8s 通过 pod 控制器来管理 pod，进而管理容器。 pod 对外提供服务，然而出于单一职责的考虑，pod 不能即管理容器又管理服务访问，所以服务访问交给 servic"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"k8s"}]},regularPath:"/backend/Kubernetes/part2.html",relativePath:"backend/Kubernetes/part2.md",key:"v-0d4b1bdc",path:"/backend/Kubernetes/part2/",headers:[{level:2,title:"资源管理",slug:"资源管理"},{level:3,title:"介绍",slug:"介绍"},{level:3,title:"集群资源分类",slug:"集群资源分类"},{level:3,title:"资源操作方式",slug:"资源操作方式"},{level:3,title:"资源管理方式",slug:"资源管理方式"},{level:2,title:"资源介绍",slug:"资源介绍"},{level:3,title:"资源简介",slug:"资源简介"}],readingTime:{minutes:7.2,words:2159},content:' 资源管理 \n 介绍 \n k8s 实际上就是一个集群系统，可以在这个集群中运行一个个的容器，并将程序跑在容器中，这就叫启动服务了。 \n k8s 的最小管理单元为 pod，容器将会放到 pod 中，而 k8s 通过 pod 控制器来管理 pod，进而管理容器。 \n pod 对外提供服务，然而出于单一职责的考虑，pod 不能即管理容器又管理服务访问，所以服务访问交给 service 资源来实现功能。 \n 同理，数据持久化的功能交给了存储系统。 \n 学习 k8s，本质上就是学习对 pod、pod 控制器、service、存储等资源的操作。 \n 集群资源分类 \n \n \n \n 资源分类 \n 资源名称 \n 缩写 \n 作用 \n \n \n \n \n 集群级别 \n nodes \n no \n 集群组成部分 \n \n \n \n namespace \n ns \n 隔离 pod \n \n \n pod 资源 \n pods \n po \n 装载容器 \n \n \n pod 控制器 \n replicationcontrollers \n rc \n 控制 pod 资源 \n \n \n \n replicasets \n rs \n 控制 pod 资源 \n \n \n \n deployments \n deploy \n 控制 pod 资源 \n \n \n \n daemonsets \n ds \n 控制 pod 资源 \n \n \n \n jobs \n \n 控制 pod 资源 \n \n \n \n cronjobs \n cj \n 控制pod 资源 \n \n \n \n horizontalpodautoscalers \n hpa \n 控制pod 资源 \n \n \n \n statefulsets \n sts \n 控制pod 资源 \n \n \n 服务发现 \n services \n svc \n 统一 pod 对外接口 \n \n \n \n ingress \n ing \n 统一 pod 对外接口 \n \n \n 存储资源 \n volumeattachments \n \n 存储 \n \n \n \n persistentvolumes \n pv \n 存储 \n \n \n \n persistentvolumeclaims \n pvc \n 存储 \n \n \n 配置资源 \n configmaps \n cm \n 配置 \n \n \n \n secrets \n \n 配置 \n 资源操作方式 \n 资源可以进行多种操作，可以通过  --help  查看详细的操作命令。 \n \n \n \n 分类 \n 命令 \n 作用 \n \n \n \n \n 基础 \n create \n 创建资源 \n \n \n \n edit \n 编辑资源 \n \n \n \n get \n 获取资源 \n \n \n \n patch \n 更新资源 \n \n \n \n delete \n 删除资源 \n \n \n \n explain \n 展示资源文档 \n \n \n 调试运行 \n run \n 集群中运行指定镜像 \n \n \n \n expose \n 暴露资源为 service \n \n \n \n describe \n 显示资源内部信息 \n \n \n \n logs \n 输出容器在 pod 的日志 \n \n \n \n attach \n 进入运行中的容器 \n \n \n \n exec \n 执行容器中的一个命令 \n \n \n \n cp \n pod 内外复制文件 \n \n \n \n rollout \n 管理资源发布 \n \n \n \n scale \n 扩缩 pod 数量 \n \n \n \n autoscale \n 自动调整 pod 数量 \n \n \n 高级 \n apply \n 通过文件对资源进行配置 \n \n \n \n label \n 更新资源标签 \n \n \n 其他 \n cluster-info \n 显示集群信息 \n \n \n \n version \n 展示 server 和 client 版本 \n 资源管理方式 \n k8s 中提供了三种方式：命令式对象管理、命令式对象配置、声明式对象配置。 \n 命令式对象管理，直接使用命令来操作 k8s 资源，这种方式简单，但是只能操作活动对象，对于测试比较方便，但是不适于开发。 \n 命令式对象配置，可使用操作文件的方式来操作 k8s 资源，对于小型服务比较简单，可以用于开发，但是当项目变大、配置文件变多时，操作起来就比较麻烦。 \n 声明式对象配置，可使用操作目录的方式来操作 k8s 资源，对于大型项目友好，但是出现意外情况可能难以调试。 \n 命令式对象管理 \n kubectl [command] [type] [name] [flags] \n \n command：指定操作 \n type：指定资源类型，例如 pod、deployment 等 \n name：指定资源名称，大小写敏感 \n flags：指定额外参数 \n \n ➜  software kubectl create namespace dev\nnamespace/dev created\n\n➜  software kubectl get ns\nNAME                   STATUS   AGE\ndefault                Active   44h\ndev                    Active   6s\nkube-node-lease        Active   44h\nkube-public            Active   44h\nkube-system            Active   44h\nkubernetes-dashboard   Active   44h\n\n➜  software kubectl run pod --image = nginx -n dev  \npod/pod created\n\n➜  software kubectl get pod -n dev -o wide\nNAME   READY   STATUS              RESTARTS   AGE   IP       NODE       NOMINATED NODE   READINESS GATES\npod     0 /1     ContainerCreating    0           17s    < none >    minikube    < none >             < none > \n\n➜  software kubectl delete pod pod -n dev\npod  "pod"  deleted\n\n➜  software kubectl delete ns dev             \nnamespace  "dev"  deleted\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #  命令式对象配置 \n 进行配置，IDEA 中有 kubernetes 插件可以方便地使用 \n apiVersion :  v1\n kind :  Namespace\n metadata : \n   name :  dev\n\n --- \n\n apiVersion :  v1\n kind :  Pod\n metadata : \n   name :  nginxpod\n   namespace :  dev\n spec : \n   containers : \n     -   name :  nginx - containers\n       image :  nginx : 1.17.1\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 根据文件进行配置： \n ➜  k8s kubectl create -f nginxpod.yml\nnamespace/dev created\npod/nginxpod created\n➜  k8s kubectl get -f nginxpod.yml \nNAME            STATUS   AGE\nnamespace/dev   Active   10s\n\nNAME           READY   STATUS              RESTARTS   AGE\npod/nginxpod    0 /1     ContainerCreating    0           10s\n➜  k8s kubectl delete -f nginxpod.yml \nnamespace  "dev"  deleted\npod  "nginxpod"  deleted\n \n 1 2 3 4 5 6 7 8 9 10 11 12 #  声明式对象配置 \n 声明式对象配置只有一个 apply 命令，他的意思是：资源存在则更新（kubectl patch），不存在则创建（kubectl create）。 \n 删除时则只能用  kubectl delete -f  了。 \n 推荐创建/更新使用  kubectl apply -f ，删除用  kubectl delete -f 。 \n 资源介绍 \n 资源简介 \n Namespace \n namespace，命名空间，其实也就是用来实现资源隔离的效果。 \n 在默认情况下，k8s 的各个 pod 均可以相互访问，假如想要实现资源隔离，就可以将不同的 pod 放到不同的 namespace 下。 \n 也可以通过 k8s 的授权机制，将 namespace 交给不同租户管理，这样就实现了多租户的资源隔离。 \n 还可以结合资源配置机制，让不同的租户拥有不同的资源，例如 CPU、内存等，实现租户资源管理。 \n k8s 会默认启动几个 namespace： \n \n default：未指定 namespace 的会默认放到这里。 \n kube-node-lease：集群心跳维护。 \n kube-public：公共空间，可以被所有人访问（包括未认证用户）。 \n kube-system：k8s 集群维护。 \n \n 具体操作： \n \n \n 查看： kubectl get ns \n 可指定 namespace： kubectl get ns default  是查看 default 这个 namespace \n 可指定输出格式： kubectl get ns -o yaml  是以 yaml 形式展示，常用的还有 wide、json \n 查看详情： kubectl describe ns default \n \n \n 创建： kubectl create ns dev \n \n \n 删除： kubectl delete ns dev \n \n \n 使用文件配置： \n apiVersion :  v1\n kind :  Namespace\n metadata : \n name :  dev\n \n 1 2 3 4 之后就可使用  kubectl apply -f 、 kubectl delete -f  操纵了。 \n Pod \n 程序运行在容器中，而容器必须存在于 Pod 中，一个 pod 可放多个容器。pod 是 k8s 中管理的最小单元，集群的各个组件也是以 pod 为单位运行的。 \n k8s 不会单独运行 pod，而是通过 pod 控制器间接控制 pod。 \n \n \n 创建并运行： kubectl run nginx --image=nginx:1.17.1 --port=80 --namespace dev \n --image ：指定镜像。 --port ：指定端口。 --namespace ：指定命名空间。 \n \n \n 查看 pod： kubectl get pods -n dev \n 使用  get pods  或者  get pod  均可，k8s 都支持。 \n \n \n 查看 pod 详情： kubectl describe pod nginx -n dev \n \n \n 删除指定 pod： kubectl delete pod nginx -n dev \n 假如是使用 pod 控制器来进行的创建，那么上面这条命令删除之后，pod 控制器会重新开启一个 pod。 \n 如果想要在 pod 控制器创建之后删除 pod，需要直接删除 pod 控制器。 \n Label \n Label 是个标签，可以在资源上进行标识，便于更好地进行管理。Label 的具体表现是 kv 键值对，可以加到任何对象上去（一个对象也可以有任意数量的 Label）。 \n 常用事例： \n \n 版本标签： version: release 、 version: stable \n 环境标签： env: dev 、 env: pro \n 架构标签： tier: frontend 、 tier: backend \n \n 除了标签之外，还有标签选择器（Label Selector），Label 用于给某个资源对象定义标识，Label Selector 用于查询和筛选拥有某些标签的资源对象。 \n \n \n 命令式： \n给予标签 version=1 \nkubectl label pod nginx  version = 1 \n更新标签 version=2 \nkubectl label pod nginx  version = 2  --overwrite\n带标签查看 pod  \nkubectl get pod nginx --show-labels\n使用标签选择器 \nkubectl get pod -l  version = 2 \nkubectl get pod -l version != 1 \n删除标签 \nkubectl label pod nginx version-\n \n 1 2 3 4 5 6 7 8 9 10 11 \n \n 配置式： \n apiVersion :  v1\n kind :  Pod\n metadata : \n   namespace :  dev\n   name :  nginx\n   labels : \n     version :   "1" \n spec : \n   containers : \n     -   name :  pod\n       image :  nginx : 1.17.1\n       ports : \n         -   containerPort :   80 \n           name :  nginx - port\n           protocol :  TCP\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n Deployment \n 属于 pod 控制器的一种，pod 控制器可以控制 pod，k8s 一般使用 pod 控制器来控制 pod。 \n \n \n 命令方式： \n创建太过繁琐，只说查看、删除 \n查看创建的 deployment \nkubectl get deploy\n查看详细信息 \nkubectl describe deploy nginx\n删除 \nkubectl delete deploy nginx\n \n 1 2 3 4 5 6 7 \n \n 配置方式： \n apiVersion :  apps/v1\n kind :  Deployment\n metadata : \n   name :  nginx\n   namespace :  default\n spec : \n   replicas :   3 \n   selector : \n     matchLabels : \n       run :  nginx\n   template : \n     metadata : \n       labels : \n         run :  nginx\n     spec : \n       containers : \n         -   name :  nginx\n           image :  nginx : 1.17.1\n           ports : \n             -   containerPort :   80 \n               protocol :  TCP\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n Service \n 每个 pod 都会分配一个 pod IP，然而: \n \n pod IP 会根据 pod 重建产生变化。 \n pod IP 仅仅是集群内的，外部无法访问。 \n \n k8s 设计了 service 来解决以上的两个问题。service 可以看成是一组同类 pod 对外访问的接口，可以实现服务发现和负载均衡。 \n \n \n 命令式： \n创建集群内部可访问的 service \nkubectl expose deploy nginx --name = service-nginx --type = ClusterIP --port = 80  --target-port = 80 \n创建集群外部可访问的 service \nkubectl expose deploy nginx --name = service-nginx2 --type = NodePort --port = 80  --target-port = 80 \n \n 1 2 3 4 注意，假如使用的是 minikube，有两个方式可以访问： \n \n 进入 k8s 对应的 docker 容器，然后访问。 \n 使用  minkube service service-nginx2 ，查看对应的 IP 和地址，然后访问。 \n \n \n \n 配置式： \n apiVersion: v1\nkind: Service\nmetadata:\n  namespace: default\n  name: service-nginx\nspec:\n  clusterIP: 10.109.179.231\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 80\n  selector:\n    run: nginx\n  type: ClusterIP\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n \n',updateTime:"July 11, 2022 16:17",updateTimeStamp:1657527473e3,createTime:"July 11, 2022 16:17",createTimeStamp:1657527473e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"JVM-02-类加载子系统",frontmatter:{title:"JVM-02-类加载子系统",categories:["backend"],tags:["jvm"],author:"causes",summary:"类加载器和类的加载过程 类加载子系统的作用主要有： 1. 类加载子系统（类加载器）负责从文件系统/网络中加载 Class 文件： ClassLoader 只负责 Class 文件的加载，至于是否可以运行，则由 Execution Engine（执行引擎）决定。 1. 加载的类信息存放于一块称为方法区的内存空间。除了类的信息之外，方法区还会存放运行时常量池信息",meta:[{property:"og:url",content:"/backend/JVM/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"JVM-02-类加载子系统"},{property:"og:description",content:"类加载器和类的加载过程 类加载子系统的作用主要有： 1. 类加载子系统（类加载器）负责从文件系统/网络中加载 Class 文件： ClassLoader 只负责 Class 文件的加载，至于是否可以运行，则由 Execution Engine（执行引擎）决定。 1. 加载的类信息存放于一块称为方法区的内存空间。除了类的信息之外，方法区还会存放运行时常量池信息"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"jvm"}]},regularPath:"/backend/JVM/part2.html",relativePath:"backend/JVM/part2.md",key:"v-58e0fb48",path:"/backend/JVM/part2/",headers:[{level:2,title:"类加载器和类的加载过程",slug:"类加载器和类的加载过程"},{level:2,title:"类加载器的三个阶段",slug:"类加载器的三个阶段"},{level:2,title:"类加载器",slug:"类加载器"},{level:2,title:"双亲委派机制和沙箱安全机制",slug:"双亲委派机制和沙箱安全机制"},{level:2,title:"类的主动使用和被动使用",slug:"类的主动使用和被动使用"}],readingTime:{minutes:11.15,words:3344},content:' 类加载器和类的加载过程 \n 类加载子系统的作用主要有： \n \n \n 类加载子系统（类加载器）负责从文件系统/网络中加载 Class 文件： \n ClassLoader 只负责 Class 文件的加载，至于是否可以运行，则由 Execution Engine（执行引擎）决定。 \n \n \n 加载的类信息存放于一块称为方法区的内存空间。除了类的信息之外，方法区还会存放运行时常量池信息，可能还包含字符串字面量和数字常量。 \n 类加载器的三个阶段 \n \n 字节码的加载和类加载子系统的加载阶段并不一样，它的加载分为三个部分：加载、链接、初始化。 \n 加载阶段 Loading \n 它有如下步骤： \n \n \n 通过一个类的全限定类名获取这个类的二进制字节流。 \n 有如下方式加载  .class  文件： \n \n 从本地系统中直接加载。 \n 从网络中获取，典型场景是 Web Applet（直接嵌入到 HTML 页面中，由支持 Java 的浏览器解释执行，现在几乎绝迹）。 \n 从 zip 压缩包中获取。 \n 运行时计算生成，典型场景是 JSP 应用。 \n 从加密文件中获取，典型场景是防止 Class 文件被反编译的保护措施。 \n \n \n \n 将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构。 \n 方法区首先只有 Hotspot 虚拟机才有这个概念，并且方法区是一个抽象的概念，而不是具体的实现。在不同的 JDK 版本中有不同的实现。\n比如在 JDK7 及以前，方法区的落地实现为永久代；JDK8 及以后，方法区的落地实现为元空间。\n为了方便称呼，我们不讲方法区的区别时统称方法区。 \n \n \n 在内存中生成一个代表这个类的  java.lang.Class  对象，作为方法区这个类的各种数据的访问入口。 \n 通过反射就可以使用这个 Class。 \n \n \n 链接阶段 Linking \n 链接分为三部分： \n \n \n Verify 验证： \n 主要目的是为了确保 Class 文件是格式正确的，符合虚拟机要求的（比如 Class 文件一律使用  CA FE BA BE  开头），不会损害虚拟机自身安全的。\n这个步骤和之后执行引擎是否可以运行是两码事，首先在这里确保 Class 文件格式正确，之后再交给执行引擎查看是否能够运行。 \n 验证阶段主要包含四种验证：文件格式验证、元数据验证、字节码验证、符号引用验证。 \n 如果需要查看字节码文件： \n \n JClassLib  查看（主要用于类似反编译之后的文件），IDEA 有插件，安装完成之后可以在  View -> Show Bytecode With Jclasslib  中查看，或者直接下载安装包。 \n PXBinaryView：查看 Class 文件的二进制编码。 \n \n \n \n Prepare 准备： \n 为类变量（类中使用 static 修饰的变量）分配内存，并且设置该类变量的默认初始值（即零值）。\n这个零值的意思不是 0，是默认值的意思。 \n 这里不会为 final 修饰的类变量进行初始化，因为 final 早已经在编译时分配了。\n这里不会为实例变量进行初始化，实例变量会随对象一起分配到 Java 堆中。 \n \n \n Resolve 解析： \n \n \n \n \n 将常量池中的符号引用转化为直接引用的过程。 \n 符号引用就是一组符号，来描述所引用的目标。\n直接引用就是直接执行目标的指针、相对偏移量，或者是一个间接定位到目标的句柄。 \n \n \n 解析操作往往伴随着 JVM 在进行初始化之后再执行。 \n \n \n 解析动作主要针对类或者接口、方法、接口方法、字段、方法类型等。对应常量池中的  CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info  等。 \n \n \n 初始化阶段 Initialization \n public   class   Demo   { \n   static   Integer  i  =   1 ; \n\n   static   { \n   i  =   2 ; \n   } \n } \n \n 1 2 3 4 5 6 7 \n <clinit>()  是 class 类构造器，用于对 静态变量和静态代码块进行初始化。 \n 这个方法不需要我们去定义，它是 javac 编译器自动收集类中的所有变量的赋值动作和静态代码块中的语句合并而来。 \n \n 构造器方法中指令按语句在源文件中出现的顺序执行（所以静态变量的赋值和静态代码块的赋值谁在前面谁先执行）。 \n 假如该类具有父类，那么JVM会保证子类的  <clinit>()  执行之前，父类的  <clint>()  已经执行完毕。 \n 虚拟机必须保证一个类的  <clinit>()  方法在多线程下被同步加锁。 \n 假如没有静态的内容，那么不会生成  <clinit>()  这个方法。 \n 虚拟机在加载类的时候仅会执行一次  <clinit>() ，也就是说类的加载仅有一次，所以 Class 模板只有一个。 \n \n 除了  <clinit>()  之外，上图还有一个  <init> ，这其实对应着我们类的实例的构造器，用于对非静态变量进行解析初始化。 \n \n package   com . maple . concurrent ; \n\n public   class   Demo   { \n   static   final   Person  person  =   new   Person ( ) ; \n } \n\n class   Person   { } \n \n 1 2 3 4 5 6 7 \n 类加载子系统的三个阶段：加载、链接、初始化。 \n 在这个 Demo 中，链接中的准备阶段赋值默认值 null，随后在初始化阶段赋值  new Person() 。 \n \n public   class   Demo   { \n     static   { \n        a  =   20 ; \n     } \n     static   int  a  =   10 ; \n\n     public   static   void   main ( String [ ]  args )   { \n         System . out . println ( a ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 这个 Demo 中也类似，首先在链接的准备阶段赋值默认值 0，随后在初始化阶段的静态代码块中赋值为 20，然后在静态变量赋值上赋值 10。 \n 类加载器 \n 类加载器分类 \n JVM 支持两种类加载器： \n \n \n Bootstrap ClassLoader：引导类加载器。 \n \n \n User Defined ClassLoader：自定义类加载器，它又分为： \n \n Extension ClassLoader：扩展类加载器。 \n System ClassLoader（也叫做 Application ClassLoader）：系统类加载器。 \n 自定义的类加载器。 \n \n \n \n \n Tips \n 各个类加载器都没有父子继承关系，可以理解为包含关系。\nBootstrap ClassLoader 包含 Extension ClassLoader，Extension ClassLoader 包含 System ClassLoader ……\n除了 BootStrap ClassLoader 之外，所有类加载器继承 ClassLoader 这个抽象类。 \n \n public   class   Demo1   { \n     public   static   void   main ( String [ ]  args )   { \n         ClassLoader  systemClassLoader  =   ClassLoader . getSystemClassLoader ( ) ; \n         ClassLoader  extensionClassLoader  =  systemClassLoader . getParent ( ) ; \n         // 获取不到属于正常，因为 Bootstrap ClassLoader 用 C++ 写的，属于 JVM 的一部分，并不是 Java 类 \n         ClassLoader  bootstrapClassLoader  =  extensionClassLoader . getParent ( ) ; \n\n         System . out . println ( systemClassLoader ) ; \n         System . out . println ( extensionClassLoader ) ; \n         System . out . println ( bootstrapClassLoader ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 虚拟机自带的类加载器 \n \n \n BootStrap ClassLoader：引导类加载器： \n 使用 C/C++ 编写，没有父加载器。 \n 嵌套在 JVM 内部，用来加载 Java 核心类库（ $JAVA_HOME/jre/lib/rt.jar 、 resources.jar 、 sum.boot.class.path  等路径下的内容），用于提供 JVM 自身所需要的类。 \n 可以加载扩展类和系统类加载器，并且指定它们的父类加载器。 \n 可以使用  URL[] urls = Launcher.getBootstrapClassPath().getURLs();  来获取所有能够加载的路径。 \n 出于安全考虑，BootStrapClassLoader 只加载包名为  java、javax、sun  等开头的类。 \n \n \n Extension ClassLoader：扩展类加载器： \n Java 语言编写。派生自 ClassLoader 类。父类加载器为 BootStrap ClassLoader。 \n 从  java.ext.dirs  系统属性所指定的目录中加载类库，或从 JDK 的安装目录的  jre/lib/ext  子目录（扩展目录）下加载类库。如果用户创建的 jar 放在此目录下，也会自动由扩展类加载器加载。 \n 使用  Arrays.stream(System.getProperty("java.ext.dirs").split(";")).forEach(System.out::println);  获取所有扩展类加载器可以加载的位置。 \n \n \n 用户自定义的类加载器 \n \n \n 什么情况下需要使用到自定义类加载器： \n \n 隔离加载类：例如说，某些情况下我们需要使用到中间件，而中间件之间的类（如类名）相互冲突，这个时候需要人工仲裁，自然需要将类隔离。 \n 修改类加载的方式：除了 BootStrap 之外，其他的类完全可以懒加载，而不是在一开始的时候完全加载进去。 \n 扩展类加载源：类的加载完全可以通过网络、jar、磁盘等等加载，可以自定义类加载器，实现源的扩展。 \n 防止源码泄露：如果 Java 代码缺少反编译，那么字节码很容易被篡改，为了防止被篡改，可以实现一个类加载器去实现加密解密操作。 \n \n \n \n 自定义类加载器的主要步骤： \n \n 继承  java.lang.ClassLoader 。 \n 在 JDK1.2 之前需要重写  loadClass() ，不过之后不建议重写  loadClass() ，而是建议将自定义的类加载逻辑放到  findClass()  中。 \n 如果没有太过复杂的要求，可以直接继承  URLClassLoader ，这样可以避免自己去编写  findClass()  方法和其获取字节码流的方式。 \n 双亲委派机制和沙箱安全机制 \n 双亲委派机制概述 \n Java 虚拟机对 class 文件采用的方式为按需加载的方式，加载某个类的 class 文件时，Java 虚拟机采用双亲委派机制，它是一种任务委派模式。 \n \n 当前代码的结构如上图所示，注意，这里的  java.lang.String  为自己创建的。 \n 我们创建了一个  java.lang.String ： \n package   lang ; \n\n public   class   String   { \n   static   { \n     System . out . println ( "自定义的静态代码块" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 在链接阶段中的初始化阶段中，静态代码块中的内容会执行，但是我们手动  new String  的时候，并不会有这个语句产生。所以从结果上来看，我们初始化的 String 应该是 JDK 的而不是我们定义的。 \n 其实以上就是双亲委派机制的一个例子，它其实十分简单： \n \n 假如一个类加载器接收到了类加载的请求，他不会首先去加载，而是将这个类加载器委托给它的父类的加载器，让那个加载器去加载。 \n 继续第一步，直到到达顶层的启动类加载器。 \n BootStrap ClassLoader 会加载 java、javax 等包下的内容，而 Extension ClassLoader 会加载指定目录下的包。按照刚才的委托来看，BootStrap ClassLoader 可以直接加载 JDK 的 String，那么就不会加载自定义的 String。 \n \n 双亲委派的优势： \n \n 避免类的重复加载。 \n 保证程序的安全性，避免核心 API 被篡改。 \n \n 沙箱安全机制 \n 在前面的双亲委派机制过程中，假如我们这样定义： \n package   java . lang ; \n\n public   class   String   { \n\n     static   { \n         System . out . println ( "自定义的静态代码块" ) ; \n     } \n\n     public   static   void   main ( String [ ]  args )   { \n         System . out . println ( "Hello JVM" ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 假如我们直接在 String 下面定义一个 main 方法，然后执行这个 main 方法，表面上看起来它不得不加载，然而事实上它会直接报错。这种安全防御机制就叫做沙箱安全机制。 \n 类的主动使用和被动使用 \n 在 JVM 中，判断两个对象完全一致需要符合两个条件： \n \n 类的完整名称（包名 + 类名）必须完全一致。 \n 加载这个类的类加载器相同，也就是指 ClassLoader 实例对象完全相同。 \n \n \n ClassLoader 实例对象 \n \n 这个实例对象比较类似类和对象之间的关系，类加载器本身只是一个模板，而真正起作用的是类加载器的实例。引导类加载器是 C++ 编写的，不能获取它的实例地址，但是其他的类加载器可以。只需要判断一下地址值是否相等就可以看出实例对象是否相等。 \n \n 对类加载器的引用： \n JVM 必须知道一个类型是由启动类加载器加载还是由用户类加载器加载的。假如是由用户类加载器加载的，那么 JVM 会将这个类加载器的一个引用作为类型信息的一部分放到方法区中。 \n 也就是说，当前我们的方法区中不仅保存了字节码文件，还保存了当前类加载器的实例。 \n \n 类的主动使用和被动使用： \n Java 会将一个类分为主动使用和被动使用，区别就是：主动使用会导致类的初始化，被动使用不会。 \n \n 主动使用会导致类的初始化 \n \n 这里的初始化指的不是类的构造方法，而是指类的初始化阶段（加载、链接、初始化中的初始化阶段），再简单来讲就是是不是调用了  <clinit>() 。 \n 主动使用分为七种： \n \n 创建类的实例。 \n 访问某个类或者接口的静态变量，或者对静态变量进行赋值。 \n 调用类的静态方法。 \n 反射。 \n 初始化一个类的子类。 \n Java 虚拟机启动时被标记为启动的类。 \n JDK7 开始提供的动态语言支持。 \n java.lang.invoke.MethodHandle  实例的解析结果  REF_getStatic、REF_putStatic、REF_invokeStatic  句柄对应的类没有初始化则进行初始化。 \n \n 除了以上七种情况之外，其余都是类的被动使用。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"September 20, 2021 00:01",createTimeStamp:1632067312e3,contributors:[{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1},{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"JVM-01-概述",frontmatter:{title:"JVM-01-概述",categories:["backend"],tags:["jvm"],author:"causes",summary:"JVM 概述 Java 和 JVM 默认使用 JDK8 讲解，切换版本会有说明。 Java 程序的特性是一处编写，到处运行。这个特性主要靠 Java 虚拟机来实现，Java 程序进行编译之后形成字节码文件，字节码文件放到 Java 虚拟机上运行。 对于每一个操作系统，都有不同的虚拟机，虚拟机去适配操作系统（Windows、Linux、Mac），作为字节码到操",meta:[{property:"og:url",content:"/backend/JVM/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"JVM-01-概述"},{property:"og:description",content:"JVM 概述 Java 和 JVM 默认使用 JDK8 讲解，切换版本会有说明。 Java 程序的特性是一处编写，到处运行。这个特性主要靠 Java 虚拟机来实现，Java 程序进行编译之后形成字节码文件，字节码文件放到 Java 虚拟机上运行。 对于每一个操作系统，都有不同的虚拟机，虚拟机去适配操作系统（Windows、Linux、Mac），作为字节码到操"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"jvm"}]},regularPath:"/backend/JVM/part1.html",relativePath:"backend/JVM/part1.md",key:"v-1ddb11e8",path:"/backend/JVM/part1/",headers:[{level:2,title:"JVM 概述",slug:"jvm-概述"},{level:2,title:"JVM 整体流程",slug:"jvm-整体流程"}],readingTime:{minutes:7.49,words:2246},content:" JVM 概述 \n Java 和 JVM \n 默认使用 JDK8 讲解，切换版本会有说明。 \n Java 程序的特性是一处编写，到处运行。这个特性主要靠 Java 虚拟机来实现，Java 程序进行编译之后形成字节码文件，字节码文件放到 Java 虚拟机上运行。\n对于每一个操作系统，都有不同的虚拟机，虚拟机去适配操作系统（Windows、Linux、Mac），作为字节码到操作系统的一层转换措施，所以字节码文件才可以在所有平台上运行。\n对于现在来说，Java 虚拟机（Java Virtual Machine、JVM）并不仅仅可以运行 Java 程序，只要字节码符合 Java 虚拟机的规范，都可以在它上面运行。 \n \n JVM 字节码 \n 平常我们说的字节码指的是 Java 编译形成的字节码文件，但是现在 JVM 只会读取符合规则的字节码文件，而不仅仅限定于 Java 编译成的字节码文件，所以叫做 JVM 字节码更合适一些。 \n 多语言混合编程 \n 软件开发中渐渐靠拢的一个方向是通过特定领域的语言去解决特定领域的问题。而 JVM 可以支持符合规则的字节码文件，这说明其他语言最后形成符合 JVM 规定的字节码文件之后，JVM 同样会执行。 \n JVM 重大事件 \n \n 2000 年，JDK1.3 发布，同时发布了  Java HotSpot Virtual Machine ，成为了 Java 的默认虚拟机。 \n 2003 年底，Java 平台的 Scala 正式发布，同年 Groovy 也加入了 Java。 \n 2006 年，Java 开源并建立了 OpenJDK。顺理成章，Hotspot 虚拟机也成为了 OpenJDK 中的默认虚拟机。 \n 2007 年，Java 平台迎来了 Clojure（一种运行在 Java 平台上的 Lisp 语言）。 \n 2008 年，Oracle 收购 BEA，得到了  JRockit  虚拟机。 \n 2010 年，Oracle 收购了 Sun，获得了 Java 商标和 Hotspot 虚拟机。 \n 2011 年，JDK7 发布，正式启用了新的垃圾回收器  G1 。 \n 2017 年，JDK9 发布。将 G1 设置为默认 GC，代替了 CMS。IBM 的 J9 开源，形成了 Open J9 的社区。 \n 2018 年，发布了革命性的  ZGC ，调整 JDK 授权许可。 \n 2019 年，JDK12 发布，加入 RedHat 领导开发的  Shenandoah GC 。 \n \n JVM 整体结构 \n \n \n 指令集架构和 JVM 的架构模型 \n 指令集的架构模型分为两种： \n \n \n 基于栈的指令集架构： \n \n 设计和实现更加简单，适用于资源受限的系统。 \n 避开了寄存器的分配难题（一地址或者二、甚至三地址指令），转而采用了零地址指令方式分配。 \n 指令流的大部分指令是零地址指令，执行过程依赖于操作栈，指令集更小，编译器更加容易实现。 \n 不需要硬件支持，可移植性更好。 \n \n \n \n 基于寄存器的指令集架构： \n \n 性能更加优秀，执行更加高效。 \n 花费更少的指令去完成一项操作。 \n 大部分情况下，基于寄存器架构的指令往往都是一地址、二地址甚至三地址。 \n \n \n \n Java 编译器输入的指令流基本上都是一种基于栈的指令集架构。 \n Tips \n 零地址、一地址、二地址、三地址： \n 通常在进行一项操作的时候，往往是 [key - value] 形式，key 就是地址值，value 就是操作数。\n一地址，就是说 key 是一个地址，也就是 key-value。二地址是 [(key1, key2) - value]，……。零地址就是 [ value ]。 \n \n JVM 的生命周期 \n \n \n 虚拟机启动： \n 使用引导类加载器（Bootstrap Class Loader）创建的一个初始类来完成，这个类是由虚拟机的具体实现指定的。 \n \n \n 虚拟机的执行： \n 虚拟机运行起来之后，执行 Java 程序。执行的这个 Java 程序本质上是一个叫做 Java 虚拟机的进程。 \n \n \n 虚拟机的退出（几种情况）： \n \n 程序正常执行结束时，正常退出。 \n 执行过程中遇到了错误，异常终止。 \n 操作系统出现了错误，导致 JVM 进程终止。 \n 某线程调用了 Runtime 类或者 System 中的 exit 方法，或者 Runtime 中的 halt 方法，并且 Java 安全管理器也允许这次操作。 \n JNI（Java Native Interface）规范描述了使用 JNI Invocation API 来加载或者卸载 JVM 的时候，JVM 的退出情况。 \n \n \n \n Tips \n exit 或者 halt 方法其实最终调用的时一个本地方法  halt0() 。 \n JVM 的整体结构有一个叫做运行时数据区的东西（可以理解为运行时环境），Runtime 就是运行时环境对应的类。 \n \n 几款 JVM \n Tips \n JVM 的执行引擎中，存在解释器和即时编译器，他们都可以解析字节码，但是有区别： \n 解释器的缺点时每一行的代码都需要解析，哪怕写了两千次的 for 循环，解释器也会一点不落下。\nJIT 编译器会及时将代码编译为本地指令随后缓存这些指令，这样下次就不需要解释执行了，提高了工作效率。 \n 但是所有的代码全部都编译也不够好，我们想要的是经常使用的代码（我们称为热点代码）缓存起来，只需要用一次的正常解析，所以解释器和即时编译器两者配合才能发挥更好的效果。 \n \n \n \n Sun Classic VM： \n 1996 年的 Java1.0 版本，Sun 公司发布了 Sun Classic VM，也是世界上第一款商用虚拟机，JDK1.4 被淘汰。\n它只能提供解释器，如果使用 JIT 编译器就需要外挂，但是这样一来解释器就不会工作。也就是说解释器和 JIT 编译器不能同时工作。 \n \n \n Exact VM： \n JDK1.2 时，Sun 公司提供。\n准确式内存管理：可以知道内存中的某个位置存放的数据是什么类型。\n具备现代高性能虚拟机的雏形：热点探测、编译器和解释器混合执行。 \n 但是它在 Solaris 短暂使用，其他平台当时仍然是 Classic，最终被 Hotspot 代替。 \n \n \n Hotspot： \n 默认虚拟机，至今仍在使用，绝对的市场地位，原来并不是 Sun 的产品，而是 Longview Techonlogies 公司设计，后来被 Sun 收购。后来 Sun 被 Oracle 收购。\n之后主要说明的就是 Hotspot，相关的机制主要也是介绍 Hotspot 的机制（例如其他两个 JVM 没有方法区的概念）。 \n \n \n JRockit： \n 来自 BEA。专注于服务端应用，不太关心程序的启动时间，没有了解释器，这代表所有的代码都缓存，响应速度起飞（甚至传言 JRockit 是世界上最快的 JVM），但是启动时间拉长。\n一般用于延迟敏感性应用的解决方案，比如军事指挥，电信网络。 \n \n \n J9： \n 来自 IBM，全程 IBM Technology for Java Virtual Machine，见车过 IT4J，内部代号 J9。\n定位类似 Hotspot，自封为世界上最快的 Java 虚拟机。2017 年 IBM 开源了 J9，命名为 OpenJ9，交给 Eclipse 基金会管理，也成为 Eclipse OpenJ9。 \n \n \n Taobao： \n 基于 OpenJDK 开发了 AlibabaJDK，简称 AJDK，是整个阿里 Java 的基石。\n基于 OpenJDK Hotspot VM 发布的国内第一个优化，深度定制并且开源的高性能服务器版 Java 虚拟机。 \n JVM 整体流程 \n 在进行讲解之前，最好先有一个大体的印象。 \n \n \n 字节码文件进入到类加载子系统之后，有三个步骤： \n \n \n Loading：加载： \n 加载阶段是为了将字节码加载到内存中，需要用到类加载器，有几种典型的类加载器： \n \n BootStrapClassLoader：引导类加载器。 \n ExtensionClassLoader：扩展类加载器。 \n ApplicationClassLoader：系统类加载器。 \n \n \n \n Linking：链接，链接有三个步骤： \n \n 验证。 \n 准备。 \n 解析。 \n \n \n \n Initialization：初始化。 \n \n \n \n 字节码文件经过了类加载子系统之后，进入了运行时数据区，运行时数据区包含： \n \n PC Register：PC 寄存器（程序计数器），每一个线程都有一个。 \n Stack Area：虚拟机栈，每一个线程一份，每一个线程中的一个一个结构称为栈帧，栈帧也有内部结构，等到之后详细展开。 \n Native Method Stack：本地方法栈，和虚拟机栈的区别是涉及到了本地方法的调用。 \n heap：堆，最大的一块区域，也是 GC 主要考虑的一块空间。堆是线程间共享空间。 \n Method Area：方法区，存放类的信息，一些域的信息，只有 Hotspot 存在方法区这个概念。 \n \n \n 执行引擎：和操作系统打交道，相当于一个翻译官，将字节码翻译为物理机器能够识别的机器指令。 \n",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"September 20, 2021 00:01",createTimeStamp:1632067312e3,contributors:[{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1},{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"数据结构与算法-01-概述",frontmatter:{title:"数据结构与算法-01-概述",categories:["base"],tags:["algorithms"],author:"causes",summary:"数据结构概述 好的代码 = 数据结构 + 算法。 数据结构，也就是数据的组织方式，或者说数据的存放方式；算法，操作数据的一种方法。对于同一个问题，使用不同的算法在执行到结果这个过程中，消耗的资源和时间在数据量庞大的情况下有可能是天差地别。 衡量算法的优劣性，我们可以采用事前进行判断的方式，假设电脑在执行每一行的代码所需事件都相同，并且假设电脑的硬件以及其他条",meta:[{property:"og:url",content:"/base/Algorithms/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"数据结构与算法-01-概述"},{property:"og:description",content:"数据结构概述 好的代码 = 数据结构 + 算法。 数据结构，也就是数据的组织方式，或者说数据的存放方式；算法，操作数据的一种方法。对于同一个问题，使用不同的算法在执行到结果这个过程中，消耗的资源和时间在数据量庞大的情况下有可能是天差地别。 衡量算法的优劣性，我们可以采用事前进行判断的方式，假设电脑在执行每一行的代码所需事件都相同，并且假设电脑的硬件以及其他条"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"algorithms"}]},regularPath:"/base/Algorithms/part1.html",relativePath:"base/Algorithms/part1.md",key:"v-15ed21e8",path:"/base/Algorithms/part1/",headers:[{level:2,title:"数据结构概述",slug:"数据结构概述"},{level:2,title:"时间复杂度",slug:"时间复杂度"},{level:2,title:"线性结构和非线性结构",slug:"线性结构和非线性结构"}],readingTime:{minutes:3.85,words:1155},content:' 数据结构概述 \n 好的代码 = 数据结构 + 算法。 \n 数据结构，也就是数据的组织方式，或者说数据的存放方式；算法，操作数据的一种方法。对于同一个问题，使用不同的算法在执行到结果这个过程中，消耗的资源和时间在数据量庞大的情况下有可能是天差地别。 \n 衡量算法的优劣性，我们可以采用事前进行判断的方式，假设电脑在执行每一行的代码所需事件都相同，并且假设电脑的硬件以及其他条件在执行代码时相同，那么我们就可以从代码执行的两个维度（时间、空间）去考虑。 \n \n 时间：指的是执行当前算法所消耗的时间，通常使用时间复杂度来描述。 \n 空间：指的是执行当前算法所占据的内存大小，通常使用空间复杂度来描述。 \n \n 但是大多数情况下，时间复杂度和空间复杂度二者不可兼得，我们总是要从两者中寻找一个平衡点。 \n 时间复杂度 \n 假设我们执行一行代码的时间为 1 个时间单位，比如下面一行代码： \n System . out . println ( "HELLO" ) ; \n \n 1 那么接下来这段代码的时间单位就是 10： \n for   ( int  i  =   0 ;  i  <   10 ;  i ++ )   { \n     System . out . println ( i ) ; \n } \n \n 1 2 3 代码执行了十次，所以时间单位为 10，看起来比较好理解，那么接下来的时间单位就是 n： \n for   ( int  i  =   0 ;  i  <  n ;  i ++ )   { \n     System . out . println ( i ) ; \n } \n \n 1 2 3 输出了 n 次，所以时间单位是 n，非常好理解，我们将上面的 n 次时间单位使用大 O 表示法来表示：T(n) = O(f(n)) \n 简单来理解一下： \n \n \n f(n) 代表的是每行代码执行次数的和，执行一次为 f(1)，执行十次为 f(10)，执行 n 次为 f(n)。 \n \n \n O 这个字符代表的是正比例的关系，也就是执行次数和最终的时间的系数。 \n 比如 y = x 中，系数为 1，y = 2x 中，系数为 2，那么在上面的代码中，O 的系数就是 1。 \n \n \n T(n) 就是最终的执行时间。 \n \n \n 我们假设一种极端情况，当执行次数 n 为无限大时，无论 O 这个系数的值为多少，那么其实它是多少都是没有意义的。 \n 所以  T(n) = 1 + 2n  和  T(n) = n  在极端情况下是毫无意义的，我们将他们的时间复杂度都看作  O(n) 。 \n 同理， T(n) = 4n^2 + 2n + 8  和  T(n) = n^2  都看作  O(n^2) ，也就是说，我们关心的时间复杂度只关注高数量级，和系数毫无关系。 \n 常见的几种时间复杂度 \n \n \n 常数阶， O(1) ，无论代码执行了多少行，只要没有循环等复杂结构，我们统统看成  O(1) ： \n int  n  =   10 ; \n int  m  =   1 ; \n int  k  =  n  +  m ; \n \n 1 2 3 \n \n 线性阶， O(n) ，循环中的代码会执行 n 次： \n for   ( int  i  =   0 ;  i  <  n ;  i ++ )   { \n     System . out . println ( i ) ; \n } \n \n 1 2 3 \n \n 对数阶， O(logN) ： \n int  i  =   1 ; \n while   ( i  <  n )   { \n    i  =  i  *   2 ; \n } \n \n 1 2 3 4 首先让我们来复习一下数学内容：在数学中， a^n = b (a > 0 且 a != 1) ，那么 n 叫做以 a 为底，b 的对数，可以写为： loga^b = n ; \n 在坐标系上，对数函数是这样画的： \n \n 在上面的例子中，我们假设 i 经过 x 次循环到达了（或大于） n，也就是说 2 的 x 方 = n，即  2^x = n ==> log2^n = x ，所以  O(log2^n) ，常数项在时间复杂度是忽略的，所以是  O(logN) 。 \n \n \n 线性对数阶， O(nlogN) ，简单理解就是将  O(logN)  的代码循环了 n 次： \n for ( m = 1 ;  m < n ;  m ++ ) \n { \n    i  =   1 ; \n     while ( i < n ) \n     { \n        i  =  i  *   2 ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 \n \n 平方阶，就是将  O(n)  代码再次嵌套一遍 \n for ( x = 1 ;  x <= m ;  x ++ ) \n { \n     for ( i = 1 ;  i <= n ;  i ++ ) \n     { \n        j  =  i ; \n        j ++ ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 \n \n k 次方阶，就是将  O(n)  代码嵌套 k 次。 \n 线性结构和非线性结构 \n 线性结构 \n 最常见的数据结构，其特点是数据元素之间存在一一对应的关系，例如数组、队列、栈、链表等。 \n 线性结构又分为两种存储结构： \n \n 顺序结构：内存中，地址值是连续的，例如数组。 \n 链式存储：内存中，地址值不一定是连续的，例如链表。 \n \n 非线性结构 \n 数据元素之间不一定一一对应，比如多维数组、树、图。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"December 16, 2021 16:18",createTimeStamp:1639642717e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"JVM-03-运行时数据区",frontmatter:{title:"JVM-03-运行时数据区",categories:["backend"],tags:["jvm"],author:"causes",summary:"运行时数据区概述 运行时数据区的结构和作用 类加载子系统之后，进入了运行时数据区（Runtime Data Area），其实运行时数据区就类似一个存储容器，但是不做任何的计算操作，真正的计算操作是执行引擎在做的内容。 所以运行时数据区和执行引擎的关系有点类似与内存和 CPU 之间的关系，内存也是一个存储容器，CPU 才是计算的人。 其实运行时数据区使用的就是",meta:[{property:"og:url",content:"/backend/JVM/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"JVM-03-运行时数据区"},{property:"og:description",content:"运行时数据区概述 运行时数据区的结构和作用 类加载子系统之后，进入了运行时数据区（Runtime Data Area），其实运行时数据区就类似一个存储容器，但是不做任何的计算操作，真正的计算操作是执行引擎在做的内容。 所以运行时数据区和执行引擎的关系有点类似与内存和 CPU 之间的关系，内存也是一个存储容器，CPU 才是计算的人。 其实运行时数据区使用的就是"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"jvm"}]},regularPath:"/backend/JVM/part3.html",relativePath:"backend/JVM/part3.md",key:"v-d83236b0",path:"/backend/JVM/part3/",headers:[{level:2,title:"运行时数据区概述",slug:"运行时数据区概述"},{level:3,title:"运行时数据区的结构和作用",slug:"运行时数据区的结构和作用"},{level:3,title:"JVM 中的线程",slug:"jvm-中的线程"},{level:2,title:"PC 寄存器（程序计数器）",slug:"pc-寄存器-程序计数器"},{level:2,title:"虚拟机栈",slug:"虚拟机栈"},{level:3,title:"虚拟机栈概述",slug:"虚拟机栈概述"},{level:3,title:"栈帧概述",slug:"栈帧概述"},{level:3,title:"局部变量表（Local Variables）",slug:"局部变量表-local-variables"},{level:3,title:"操作数栈（Operand Stack）",slug:"操作数栈-operand-stack"},{level:3,title:"动态链接（Dynamic Linking）",slug:"动态链接-dynamic-linking"},{level:3,title:"方法返回地址（Return Address）",slug:"方法返回地址-return-address"},{level:3,title:"一些附加信息",slug:"一些附加信息"},{level:2,title:"本地方法栈",slug:"本地方法栈"},{level:2,title:"堆",slug:"堆"},{level:3,title:"堆的概述",slug:"堆的概述"},{level:3,title:"新生代和老年代",slug:"新生代和老年代"},{level:3,title:"GC 介绍",slug:"gc-介绍"},{level:3,title:"TLAB",slug:"tlab"},{level:3,title:"堆常用参数",slug:"堆常用参数"},{level:3,title:"对象分配存储",slug:"对象分配存储"},{level:2,title:"方法区",slug:"方法区"},{level:3,title:"方法区概述",slug:"方法区概述"},{level:3,title:"设置方法区大小和 OOM",slug:"设置方法区大小和-oom"},{level:3,title:"方法区的内部结构",slug:"方法区的内部结构"},{level:2,title:"运行时常量池",slug:"运行时常量池"},{level:2,title:"对象和直接内存",slug:"对象和直接内存"},{level:3,title:"对象实例化",slug:"对象实例化"},{level:3,title:"对象的内存布局",slug:"对象的内存布局"},{level:3,title:"对象的访问定位",slug:"对象的访问定位"},{level:3,title:"直接内存",slug:"直接内存"}],readingTime:{minutes:44.75,words:13424},content:' 运行时数据区概述 \n 运行时数据区的结构和作用 \n \n 类加载子系统之后，进入了运行时数据区（Runtime Data Area），其实运行时数据区就类似一个存储容器，但是不做任何的计算操作，真正的计算操作是执行引擎在做的内容。 \n 所以运行时数据区和执行引擎的关系有点类似与内存和 CPU 之间的关系，内存也是一个存储容器，CPU 才是计算的人。 \n 其实运行时数据区使用的就是内存，不同的 JVM 对内存的划分方式和管理机制存在差异，这里我们就是用 Hotspot 来作为主要的探索对象。 \n 上图是一个详细版本的，但是不是非常直观，下面放出一个比较直观的图像： \n \n 注意 JIT 缓存，不同人对 JIT 缓存划分的区域有不同的见解，但是有一点是非常明确的：它是非堆空间。 \n \n 在运行时数据区中划分为了很多空间，在这其中，有一些是跟随虚拟机启动而创建，随着虚拟机退出而销毁的，它们的生命周期就是虚拟机的生命周期。还有一些是和线程一一对应的，它们的生命周期就是线程的生命周期。 \n 在下图中，灰色部分是单独线程私有的，红色部分是多个线程之间共享的，也就是红色部分是有可能产生线程安全问题的部分。 \n \n 线程私有： \n \n PC 寄存器（程序计数器）。 \n 栈。 \n 本地方法栈。 \n \n 线程间共享： \n \n 堆。 \n 堆外内存（方法区、JIT 缓存）。 \n \n \n 堆和方法区是线程之间共有的，所以会涉及到线程的安全问题。 \n 堆和方法区都可以进行垃圾回收，但是可以说绝大多数都会在堆中，只有少数在方法区中。 \n 方法区其实只是一个抽象的概念，它的落地实现在不同版本中有所不同（也就是通常说的永久带和元空间）。 \n \n \n 每一个 JVM 都会有独一无二的 Runtime 实例，这个 Runtime 实例其实就可以理解为我们的运行时数据区。 \n JVM 中的线程 \n JVM 允许一个或多个线程并行执行， 在 Hotspot JVM 中，每一个线程都和操作系统的本地线程一对一对应 ，因为线程其实是操作系统的本地线程，Java 并不能直接调用操作系统，所以需要的是一个映射关系来对应操作系统。 \n 当 Java 线程准备好了之后（例如 PC 寄存器、栈存储等），本地线程才开始创建。一旦本地线程执行成功，就会调用 Java 线程中的  run() 。假如  run()  方法出现了一些异常，Java 线程就会终止，但是本地线程的内容还没有结束。 \n 本地线程要在确认 JVM 是否要终止，这个参考条件就是当前终止的 Java 线程是不是最后一个非守护线程，也就是说当程序只剩下守护线程了，那么 JVM 就可以退出了。 \n 在 Hotspot 中，守护线程主要有这样几个： \n \n 虚拟机线程。 \n 周期任务线程。 \n GC 线程。 \n 编译线程。 \n 信号调度线程。 \n PC 寄存器（程序计数器） \n PC 寄存器其实是对物理 PC 寄存器的一个模拟，实际上它和物理机的寄存器不是一个东西。 \n PC 寄存器的主要作用就是存储下一条执行的地址，也就是即将执行的指令代码，执行引擎会读取这个指令去执行。 \n PC 寄存器是线程私有的，也就是说每一个线程都会有一个 PC 寄存器，实际上，每一个线程在任何时间点中，只会有一个方法在运行，也就是所谓的 当前方法 （假如执行的是本地方法栈中的 native 方法，就是 undefined）。 \n \n PC 寄存器是很小的一块空间，几乎可以忽略不计，它也是运行速度最快的一块区域。 \n 在 JVM 规范中，规定了每个线程都要有自己的 PC 寄存器，生命周期与当前线程保持一致。 \n 字节码解释器工作就是依赖 PC 寄存器的值来选取下一条需要执行的字节码指令。 \n 唯一一个在 Java 虚拟机规范中，没有规定任何  OutOfMemoryError  的区域。 \n \n 为什么需要 PC 寄存器 \n 当 CPU 在切换线程之后，需要知道应该从那一条指令继续执行，这个时候应该有一个地方来存储下一条应该执行的指令，那么这就是 PC 寄存器的作用。 \n 并且 PC 寄存器必须为线程私有，否则必定会出现线程之间互相干扰的情况。 \n 虚拟机栈 \n 虚拟机栈概述 \n 虚拟机栈出现的背景 \n 指令集架构有两种： \n \n 基于寄存器的指令集架构。 \n 基于栈的指令集架构。 \n \n 基于寄存器的指令集架构和硬件是绑定在一起的，执行指令时直接使用 CPU 来完成。由于使用高速缓冲区，所以执行速度快，但是无法做到跨平台。 \n 基于栈的指令集架构是基于内存完成的，所以速度上不如基于寄存器的指令集架构，但是优点就是可以做到跨平台，可移植性良好。 \n JVM 一开始在设计的时候就是基于栈的指令集架构。由于跨平台的特性，Java 的很多指令都是基于栈来设计的。 \n 内存中的栈和堆 \n 虽然 JVM 内存结构中不仅仅只有栈和堆，但是这两个比较重要。栈说是运行时的单位，堆是存储时的单位： \n \n 堆需要解决的是存储的问题，数据应该怎么放，放在什么地方，全都是堆需要解决的问题。 \n 栈需要解决的是运行的问题，程序应该如何与运行，如何去处理数据，全都是栈需要解决的问题。 \n \n 整体看下来的关系是这样的，但是这个关系也不是绝对的，从局部来看，基本数据类型和对象引用也是要放在栈中的。 \n 栈的优点 \n 栈是一种比较快速有效的分配方式，它的访问速度仅仅次于 PC 寄存器。JVM 直接对栈进行的操作只有两个： \n \n 每个方法的执行都伴随着压栈（也就是入栈）。 \n 方法执行结束出栈。 \n \n 对于栈来讲，方法执行完成之后就出栈，方法没有执行完成就不会出栈，所以对于栈来讲，它的操作一目了然，根本就不需要进行调优的操作。 \n 栈的异常 \n 栈不存在垃圾回收问题，但是会出现其他的问题。 \n 对于 Java 虚拟机来讲，它允许栈是动态的，也允许栈是固定大小的，但是这两种策略会导致两个问题： \n \n 假如栈是固定不变的，那么当一个栈只有入栈没有出栈，就可能导致  StackOverflowError 。 \n 假如栈是动态地，那么假如当一个栈只有入栈没有出栈，就可能导致电脑的总内存撑爆，也就是  OutOfMemoryError 。 \n \n 当然了，发生 OOM 的另一个可能就是栈太多了，也有可能出现这种问题。 \n 调节栈的大小 \n 我们可以使用参数  -Xss  选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。 \n 栈帧概述 \n 每一个线程都有自己单独的栈，而栈的存储单位就是栈帧（Stack Frame）。每一个线程中，每个执行的方法都对应着一个栈帧。 \n 栈的结构并不简单，事实上，它是一个内存块，是一个数据集。 \n 栈运行原理 \n \n 栈的操作只有两种：压栈和出栈，遵循先进后出（First In，Last Out）的原则。 \n 在一条活动线程中，在某一刻只会有一个栈帧在执行，也就栈的顶部的栈帧，这个栈帧被称为当前栈帧（Current Frame），与当前栈帧相对应的方法就是当前方法，定义这个方法的类就是当前类。 \n 执行引擎运行的所有字节码指令只对当前栈帧进行操作。 \n 如果在该方法中调用了其他的方法，对应的新的栈帧会被创建出来并入栈，称为新的栈顶。 \n \n 上面说到，栈帧其实对应方法，一个方法就是一个栈帧。栈帧中存在如下结构： \n \n Local Variables：局部变量表 \n Operand Stack：操作数栈，或者叫做表达式栈 \n Dynamic Linking：动态链接 \n Return Address：方法返回地址，方法正常或者异常退出的定义 \n 一些附加信息 \n \n 栈能存多少完全取决于栈帧的内部结构的大小，而栈帧内部结构的大小很大程度上来自局部变量表和操作数栈。 \n 局部变量表（Local Variables） \n 局部变量表概述 \n 局部变量表也叫做局部变量数组或者本地变量表，它其实是一个数字数组，主要存放的是方法参数和定义在方法体内部的局部变量（变量类型包括对象引用类型、返回值类型）。 \n \n 它其实是一个数字数组 \n \n 这个局部变量表其实是一个一维数组，从形参直到返回值都是局部变量表中的内容。但是这个数组是数字数组，也就是说所有基本类型的数字都算，而且所有能够被转为数字类型的都算。 \n byte、short、chart 会提前被 JVM 转为 int，char 是有对应 ASCII 或者 Unicode 的，所以当然也可以转为数字。boolean 中，false 为 0，true 为非零数。 \n 对象引用地址、返回值类型，那么其实都可以使用 int 来表示了。 \n 由于局部变量表建立在栈帧上，而栈帧是栈中内容，所以局部变量表不存在线程问题。而且局部变量的生命周期和栈帧一致，局部变量表中的变量只能在当前方法中使用。 \n 局部变量表的所需容量大小是在编译期就确定下来的，并且会保存在方法的 Code 属性的  maximum local variables （局部变量表最大槽数） 中，方法运行期间不会改变局部变量表大小。 \n \n 这个容量大小说的不是占用多大内存，而是指的几个变量，类似上图其实就是一个变量。 \n 在栈中，局部变量表算是和性能调优、栈内存关系比较密切的一个结构，因为局部变量表中可能会存放一些对象的引用，不管是直接引用还是间接引用，这个对象都不能被 GC。 \n 字节码中方法内部结构剖析 \n public   class   Demo   { \n\n   public   static   void   main ( String [ ]  args )   { \n     int  a  =   1 ; \n     int  b  =   2 ; \n   } \n } \n \n 1 2 3 4 5 6 7 \n 最大深度：3，也就是说局部变量表中存有三个变量。 \n \n \n Start PC  指的是字节码中的起始位置。 \n Line Number ：和代码中变量的位置有关。 \n \n \n \n LocalVariablesTable ：局部变量表，可以看到有三个变量： args 、 a 、 b 。 \n Start PC ：字节码中的位置。 \n Length ：字节码的作用长度。 \n Start PC + Length ：当前变量在字节码中的作用范围。 \n \n 变量槽 \n 之前说局部变量表是一个数值类型的数组，这个数组的基本单元我们称之为槽（slot），也就是变量槽。 \n 在局部变量表中，不同的数值类型的存储是有区别的，32 位只占用一个 slot，64 位占用两个 slot。 \n 例如 byte、short、chart、boolean、int，在 slot 存储时全都使用 int 存储，自然占用 1 个 slot，float 也占用一个 slot。对于 double、long 来讲，自然占用两个 slot。 \n 对于占用两个 slot 的变量来讲，它对应的局部变量表的数组对应的是两个下标，我们取起始下标。 \n \n 上图中，b 为 long 类型，索引为 2，但是后面的 c 直接从 4 开始，这也证明 64 位占用两个 slot。 \n \n 假如当前方法是通过构造方法或者非静态方法创建的，那么该对象的引用（this）会存放到当前栈帧局部变量表的 0 号索引处。 \n \n 首先是 Demo 类，当前的  main()  方法并非实例方法，所以第一个参数就是 args。 \n \n 然后是 Person 类，当前的  test()  方法是实例方法，所以第一个参数是当前引用 this。 \n 成员变量和局部变量的对比 \n \n \n 成员变量（在类中定义的变量）： \n \n \n 类变量：使用  static  修饰，属于类的变量。 \n 在类的加载过程中，有一个链接阶段，在链接阶段中的准备阶段有一次默认的赋值操作。之后在加载过程中的初始化阶段会显示赋值。 \n \n \n 实例变量：在类中直接声明的变量，属于对象的变量。 \n 对象创建时会在堆中分配实例变量空间，之后进行默认的赋值操作。 \n \n \n \n \n 局部变量（在方法中定义的变量）： \n 使用之前必须显示进行赋值操作，没有默认赋值操作。 \n 操作数栈（Operand Stack） \n 操作数栈概述 \n \n 每一个栈帧中，除了局部变量表，还有一个操作数栈，也叫做操作栈。操作数栈是使用数组来进行实现的。 \n 虽然操作数栈是基于数组来进行实现的，但是它仍然是栈，也就是说不使用下标来访问，而是使用入栈出栈的方式访问元素。 \n 操作数栈的具体作用就是用来保存计算的中间结果，具体流程如下： \n \n 操作数栈从局部变量表中拿到数据。 \n 执行引擎从操作数栈中拿到数据。 \n 执行引擎进行计算，得到结果。 \n 执行引擎算出的结果放到操作数栈中。 \n 重复操作：操作数栈 -> 执行引擎 -> 操作数栈，直到所有计算全部完成。 \n 将结果同步到局部变量表中。 \n \n 以上局部变量表 -> 操作数栈 -> 执行引擎，这个数据流转的方向类似于电脑中 硬盘 -> 内存 -> CPU 的关系，JVM 本来就是仿照这样的结构来设计的。所以有一句话叫做 JVM 是基于栈的执行引擎。 \n 刚才说操作数栈是使用数组来实现的，所以它的大小其实早在编译期间就已经确定了。 \n \n 操作数栈的空间分配规则类似局部变量表： \n \n 32 位占用一个栈单位的深度。 \n 64 位占用两个栈单位的深度。 \n \n byte、short、char、boolean 会转为 int 存储。 \n 局部变量表、操作数栈、执行引擎的使用 \n public   class   Demo   { \n     public   static   void   main ( String [ ]  args )   { \n         test ( ) ; \n     } \n\n     public   static   void   test ( )   { \n         byte  i  =   15 ; \n\n         int  j  =   8 ; \n\n         int  k  =  i  +  j ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 \n 以上代码的操作数栈深度：2，局部变量表长度：3，字节码长度：11。 \n \n 字节码如上图，进行了如下操作： \n将 15 push 进操作数栈 Operand Stack 中\n0: bipush        15\n将 15 从 Operand Stack 中 pop 出来，并且存放到 Local Variables 中索引为 0 的位置中\n2: istore_0\n将 8 push 到 Operand Stack 中\n3: bipush        8\n将 8 从 Operand Stack 中 pop 出来，并存放到 Local Variables 中索引为 1 的位置中\n5: istore_1\n将 Local Variables 中索引为 0 的位置中的数据取出，push 进 Operand Stack 中\n6: iload_0\n将 Local Variables 中索引为 1 的位置中的数据取出，push 进 Operand Stack 中\n7: iload_1\n将 Operand Stack 栈顶和栈顶前一位的数据相加，并重新 push 到 Operand Stack 中\n8: iadd\n将 Operand Stack 中的数据 pop 出来，并存放到 Local Variables 中索引为 2 的位置中\n9: istore_2\n退出\n10: return\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 因为操作数栈其实是存储在内存中的，所以频繁读写肯定会影响执行速度。Hotspot JVM 提出了栈顶缓存的概念，也就是说将栈顶元素全部都缓存到物理 CPU 的寄存器中，以此来降低对内存的读写次数，提高执行引擎的执行效率。 \n 动态链接（Dynamic Linking） \n 动态链接 \n \n 之前已经讲过局部变量表，操作数栈，下面是动态链接。 \n 这里的动态链接不是真正的动态链接，它其实就是一个引用，里面放着的是运行时常量池中，这个方法的引用，保存这个引用地址的目的其实是为了实现真正的动态链接。 \n 在 Java 文件编译为字节码文件时，所有的方法引用和变量都作为符号引用保存在常量池中，动态链接的真正作用就是将符号引用转换为调用方法的直接调用。 \n 举个例子： \n public   class   DynamicLinkDemo   { \n\n     int  num  =   1 ; \n\n     public   void   A ( )   { \n     } \n\n     public   void   B ( )   { \n         A ( ) ; \n        num ++ ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 当前定义了两个方法 A、B，然后在 B 中使用 A，将如上 Java 文件编译为字节码，之后使用  javap -verbose DynamicLinkDemo.class  转为字节码文件查看，或者可以使用 jclasslib 查看，这里使用这种方式比较好举例。 \n 有条件可以使用 JClassLib 插件查看，比单纯看字节码要方便一些，看的时候注意首先要看方法，然后从方法中找到符号引用。 \n Classfile /C:/Users/causes/Desktop/DynamicLinkDemo.class\n  Last modified 2021-12-14; size 501 bytes\n  MD5 checksum f078fcd1ceaa7a068fa01b25dc11c860\n  Compiled from "DynamicLinkDemo.java"\npublic class causes.classloaders.DynamicLinkDemo\n  minor version: 0\n  major version: 52\n  flags: ACC_PUBLIC, ACC_SUPER\n-- 运行时常量池\nConstant pool:\n   #1 = Methodref          #5.#19         // java/lang/Object."&lt;init>":()V\n   #2 = Fieldref           #4.#20         // causes/classloaders/DynamicLinkDemo.num:I\n   -- 使用了符号引用，符号引用指向的地址是 #4 和 #21\n   #3 = Methodref          #4.#21         // causes/classloaders/DynamicLinkDemo.A:()V\n   -- #4 仍然是符号引用，指向了 #22\n   #4 = Class              #22            // causes/classloaders/DynamicLinkDemo\n   #5 = Class              #23            // java/lang/Object\n   -- 变量 num\n   #6 = Utf8               num\n   -- I 为 int\n   #7 = Utf8               I\n   #8 = Utf8               &lt;init>\n   -- 返回值类型 V，就是 void\n   #9 = Utf8               ()V\n  #10 = Utf8               Code\n  #11 = Utf8               LineNumberTable\n  #12 = Utf8               LocalVariableTable\n  #13 = Utf8               this\n  #14 = Utf8               Lcauses/classloaders/DynamicLinkDemo;\n  -- 字符 A\n  #15 = Utf8               A\n  #16 = Utf8               B\n  #17 = Utf8               SourceFile\n  #18 = Utf8               DynamicLinkDemo.java\n  #19 = NameAndType        #8:#9          // "&lt;init>":()V\n  -- 引用了 #6 和 #7\n  #20 = NameAndType        #6:#7          // num:I\n  -- 引用了 #15 和 #9\n  #21 = NameAndType        #15:#9         // A:()V\n  -- 保存的是类方法的名称\n  #22 = Utf8               causes/classloaders/DynamicLinkDemo\n  #23 = Utf8               java/lang/Object\n{\n  int num;\n    descriptor: I\n    flags:\n\n  public causes.classloaders.DynamicLinkDemo();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object."&lt;init>":()V\n         4: aload_0\n         5: iconst_1\n         6: putfield      #2                  // Field num:I\n         9: return\n      LineNumberTable:\n        line 3: 0\n        line 5: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      10     0  this   Lcauses/classloaders/DynamicLinkDemo;\n\n  public void A();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=0, locals=1, args_size=1\n         0: return\n      LineNumberTable:\n        line 8: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       1     0  this   Lcauses/classloaders/DynamicLinkDemo;\n\n  public void B();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=3, locals=1, args_size=1\n         0: aload_0\n         -- 使用了引用，对应的符号引用为 #3\n         1: invokevirtual #3                  // Method A:()V\n         4: aload_0\n         5: dup\n         -- 符号引用为 #2\n         6: getfield      #2                  // Field num:I\n         9: iconst_1\n        10: iadd\n        -- 符号引用为 #2\n        11: putfield      #2                  // Field num:I\n        14: return\n      LineNumberTable:\n        line 11: 0\n        line 12: 4\n        line 13: 14\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      15     0  this   Lcauses/classloaders/DynamicLinkDemo;\n}\nSourceFile: "DynamicLinkDemo.java"\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 public   class   DynamicLinkDemo   { \n     static   void   eat ( Animal  animal )   { \n        animal . eat ( ) ; \n     } \n\n     public   static   void   main ( String [ ]  args )   { \n         eat ( new   Cat ( ) ) ; \n     } \n } \n\n class   Animal   { \n     void   eat ( )   { \n         System . out . println ( "吃" ) ; \n     } \n } \n\n class   Cat   extends   Animal   { \n\n     void   eat ( )   { \n         System . out . println ( "猫吃鱼" ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 毫无疑问，这个最终输出的是猫吃鱼，这个过程就叫做动态链接。 \n 解析与分派 \n 上面的动态链接说到了符号引用，通过符号引用找到了最终的方法地址，然后调用。 \n 在 JVM 中，将符号引用转换为调用方法的直接引用，这个和方法的绑定机制有关，方法的绑定机制分为两种：动态链接、静态链接。 \n 静态链接：在字节码被加载到 JVM 时，假如被调用的对象在编译期间已经确定了，并且在运行期间保持不变，那么这种符号引用到直接引用的过程叫做静态链接。 \n 动态链接：这个动态链接不是栈帧中的内部结构，而是真正的动态链接，也就是方法的绑定机制。假如方法不能在编译期间确定，也就是说只能在方法的运行过程中将符号引用转换为直接引用，这个过程叫做动态链接。 \n 静态链接和动态链接都需要将符号引用转换为直接引用，区别就是是否能在编译期间就确定转换为何种直接引用。 \n 早期绑定和晚期绑定 \n 早期绑定和静态链接对应，晚期绑定和动态链接对应。绑定和链接的区别就是，链接可以看成是绑定的一个子集。绑定的范围包括类、方法、变量，而链接只是针对方法。 \n 早期绑定就是在编译期可知，并且在运行期间保持不变。晚期绑定就是在编译期无法确定，只有在运行期间才可以确认的。 \n 虚方法、非虚方法 \n 我们刚才在说动态链接的时候，说道最后符号引用转换为直接引用的过程叫做动态链接。但是我们在实际上调用的时候，还是使用的父类的形参去调用的方法，这个就表现为多态。 \n 非虚方法有以下几种： \n \n 静态方法。 \n 私有方法。 \n final 方法。 \n 实例构造器方法。 \n 父类方法。 \n \n 父类方法指的不是在子类中重写之后的方法，指的是在子类中使用  super.方法()  的意思。 \n 这些方法其实都有一个共同的特点，也就是不能被重写的方法，都不能够实现多态的方法。除了这些方法，其他都是虚方法。 \n 为了提高性能，JVM 在类的方法区中建立了虚方法表，方便使用索引查找。假如我们调用子类重写的方法，它会首先寻找子类中的虚方法表，找不到则向上查找，直到调用。 \n 虚方法表形成在类的加载中，链接阶段的解析阶段。 \n 方法返回地址（Return Address） \n \n 方法返回地址有些人将其划分到了帧数据区。 \n 方法的返回地址其实就是栈帧中的一块区域，它存放的是调用该方法的 PC 寄存器的值。简单来讲就是此方法执行完成之后，执行引擎会根据它来确定下一条的指令应该执行什么。 \n 在此时，方法的返回地址存放的指令和 PC 寄存器中存放的指令相同，但是它们两个用于不同的情况：PC 寄存器是线程中的使用，方法返回地址仅在方法中。 \n 假如线程切换回来之后，执行引擎仍然需要依赖 PC 寄存器中的指令，反之线程没有切换时则不需要。 \n 此情况只适合与方法正常退出的时候，假如方法出现了异常则不会采用。 \n 一些附加信息 \n 没什么东西。 \n 本地方法栈 \n 本地方法栈用来管理本地方法的调用，它类似虚拟机栈： \n \n 线程私有。 \n 允许动态扩展或者固定。 \n 当某线程调用一个本地方法（native）时，此线程则不再受虚拟机限制，和虚拟机拥有相同权限。 \n 不是所有 JVM 都支持本地方法，要看具体实现。Java 虚拟机规范中并没有明确要求本地方法栈所使用的语言。 \n 堆 \n 堆的概述 \n \n 在运行时数据区中，堆是最大的一个空间。调优过程主要是对堆进行调优。 \n 一个 Java 程序是一个进程，而堆和方法区是对应一个进程的，进程中有多个线程，所以说多个线程其实是共享一个堆和方法区。 \n \n 一个 JVM 实例只存在一个堆，堆是 Java 内存管理的核心区域。 \n Java 堆区在 JVM 被启动时被创建，其空间大小也被确定了，是 JVM 管理的最大的一块区域（在 JVM 启动之前即可设置，堆内存大小可调）。 \n Java 虚拟机规范中规定，堆可以处于物理上不连续的内存空间中，但是在逻辑上应该被认为是连续的。 \n 所有的线程共享 Java 堆，在这里还可以单独给线程划分私有的缓冲区（Thread Local Allocation Buffer，TLAB）。 \n 几乎所有的对象实例和数组都应该分配到堆上。 \n 在方法结束之后，堆中的对象不会被立刻移除，而是要等到垃圾回收的时候来移除。 \n 尽量减少 GC 的次数，因为 GC 需要消耗资源，并且有些垃圾回收器会出现时停的效果，会影响正常的用户线程。 \n \n System . out . println ( "start……" ) ; \n new   Thread ( ( )   ->   { \n   try   { \n     Thread . sleep ( 1000000 ) ; \n   }   catch   ( InterruptedException  e )   { \n    e . printStackTrace ( ) ; \n   } \n } ) . start ( ) ; \n \n 1 2 3 4 5 6 7 8 之后打开  JDK 的安装目录 --\x3e bin --\x3e jvisualvm.exe ，打开，可以看到： \n \n 这其实就是检测 JVM 的一个工具，点击  工具 --\x3e 插件 --\x3e 可用插件 ，在搜索框中  Visual GC ，安装，或者直接使用 IDEA 的插件  Visual GC 。 \n 给 Java 程序配置如下代码： -Xms10m -Xmx10m ，此代码设置了堆空间的大小，最大值和最小值均为 10M。 \n \n 准备代码： \n System . out . println ( "start..." ) ; \n new   Thread ( ( )   ->   { \n   try   { \n     Thread . sleep ( 1000000 ) ; \n   }   catch   ( InterruptedException  e )   { \n    e . printStackTrace ( ) ; \n   } \n } ) . start ( ) ; \n \n 1 2 3 4 5 6 7 8 \n 上图中有几个区域，之后再讲。 \n 设置堆空间大小 \n \n -Xms ：表示设置堆空间的起始内存，等价于  -XX:InitialHeapSize \n -Xmx ：表示设置堆空间的最大内存，等价于  -XX:MaxHeapSize \n -XX:+PrintGCDetails ：查看内存详细信息。 \n \n 在这其中， -X  是 JVM 的运行参数， mx  代表的是 memory start，也就是起始内存。单位不写默认为字节，可以为 k、m、g。 \n 一旦内存使用大小超出了  -Xmx  的指定，则会抛出 OOM 异常。通常情况下，我们将最大内存和最小内存设置相同的值，为了能够在 GC 完成之后不需要重新计算堆大小，用来提高性能。 \n 默认情况下，堆的初始内存大小为  电脑内存 / 64 ，最大内存： 电脑内存 / 4 。 \n 新生代和老年代 \n 内存结构 \n 堆内存的划分，分为： \n \n 新生代 YoungGen \n 老年代 OldGen \n 元空间 \n \n 对于元空间来说，逻辑上属于堆，但其实是方法区的实现，我们在方法区时探索。这里讲一下新生代和老年代。 \n 堆内存如果更细致地划分，可以划分为新生代（包括 Eden、Survivor0、Survivor1），老年代。 \n 新生代的 Survivor0 和 Survivor1 为幸存者零区（from 区）、幸存者一区（to 区）。 \n \n 在默认情况下，新生代和老年代的内存占比为 1:2，新生代中 Eden:Survivor0:Survivor1 为 8:1:1 \n 新生代和老年代的占比可以使用参数  -XX:NewRatio=2  来表示  老年代/新生代  = 2，也就是新生代占用 1，老年代占用 2。假如设为  -XX:NewRatio=4 ，则表示新生代占用 1，老年代占用 4，新生代占用整个堆的  1/5 。 \n 新生代中  -XX:SurvivorRatio=8  表示 Eden:Survivor0:Survivor1 为 8:1:1。假如设置为  -XX:SurvivorRatio=3 ，这就代表 Eden:Survivor0:Survivor1 为 3:1:1。 \n 虽然官方文档上明确新生代中的比例是 8:1:1，但其实并不是，这是因为默认情况下会开自适应的内存调节，所以会出现这种情况。 \n 下面有几条注意事项： \n \n 几乎绝大部分的 Java 对象都是在伊甸园区被 new 出来的，但是伊甸园区放不下了，也有可能转到老年代。 \n 绝大部分的新生对象都会很快死亡。 \n 可以使用  -Xmn  设置新生代大小。 \n \n 对象分配过程 \n 我们会首先讲解普通情况，之后才会说一些特殊情况，对于一般情况情况来说： \n \n \n 对象在新生代的 Eden 区出生。 \n \n \n 当 Eden 区满后，进行一次 Minor GC（也叫做 YGC），这次 GC 会将 Eden、S0、S1 区的所有垃圾对象回收。 \n 说明一下，因为这是首次 YGC，所以没有 S0 和 S1 的垃圾，只回收了 Eden 的垃圾。 \n 此次回收之后，没有被回收的对象年龄 +1（每一个对象都有一个年龄计数器），然后放到了 S0 区域。 \n \n \n 时间继续发展，Eden 区域又满了，再次进行 YGC。 \n 此时会回收 Eden、S0、S1 的垃圾，但是 S1 没有垃圾，所以只回收了 S0 的垃圾。 \n 没有被回收的对象年龄 +1，并且 S0 和 Eden 的对象会全部放到 S1 区。（也就是说，S0 和 S1 区总有一个空的区域）。 \n \n \n 时间再次进行，再次进行了一次 YGC。 \n 此时回收了 Eden、S0、S1 的垃圾，但是 S0 没有垃圾。 \n 没有被回收的对象年龄 +1，并且 Eden、S1 的对象被放到了 S0 区。 \n \n \n 当某些对象的年龄达到了 16 的时候，这些对象会放到 Old Gen 老年代。老年代的 GC 之后有讲。 \n \n \n 对象分配时的注意点： \n \n YGC 只有在 Eden 区满的时候才会触发，S0 和 S1 不会触发。 \n YGC 会同时回收 Eden、S0、S1。 \n 默认情况下，对象年龄高于 15 则直接放到 Old Gen，但是我们可以使用  -XX:MaxTenuringThreshold=xx  来设置年龄。 \n S0、S1 也叫做 from、to 区，但是 from 和 to 是动态的，向哪个区转移哪个区就叫做 to。 \n 垃圾回收频繁在新生代收集，很少在老年代收集，几乎不在永久代/元空间收集。 \n \n 对象分配特殊情况： \n \n \n 新生代内存问题：一个对象太大，Eden 会判断是否可以直接放到 Old Gen 中，假如可以放则放下，不可以放： \n \n 进行一次 Full GC，判断是否可以放下，可以放则放。 \n 不可以放，则判断是否可以进行 JVM 动态扩容，可以扩容则扩容之后放。 \n 不可以扩容直接 OOM。 \n \n \n \n 非新生代内存问题：Eden 区域可以放下，但是在进行 YGC 后，发现 S0/S1 区放不下了： \n \n 判断可以放到 Old Gen 中，可以则放下。 \n 不可以放下则触发一次 Full GC，再次尝试放下。 \n 放不下尝试 JVM 动态扩容。 \n 不可以扩容则直接 OOM。 \n \n \n \n 调优工具 \n IDEA 中安装插件  JProfile \n GC 介绍 \n 在 HotSpot JVM 中，GC 按照回收区域分为两类： \n \n \n 部分收集（Partial GC）： \n \n YGC/Yong GC/Minor GC：回收新生代。 \n Old GC/Major GC：只收集老年代，某些垃圾回收器支持。 \n Mixed GC：整个新生代和部分老年代，某些垃圾回收器支持。 \n \n \n \n 整堆收集（Full GC）： \n \n 回收整个 Java 堆和方法区。注意，Full GC 和 Major GC 是两个 GC，不要混淆。 \n \n \n \n GC 的触发机制： \n \n \n Minor GC 触发： \n 新生代中的 Eden 区空间不足时，而不是两个 Survivor 区不足时。 \n \n \n Major GC 触发： \n 当对象向老年代转移时，发现老年代空间不足时会首先触发一次 Minor GC，再次尝试仍发现不足时会触发 Major GC。 \n 一般的垃圾回收器会 Minor GC 再进行 Major GC，但是也不是绝对的，比如 Parallel Scavenge 收集器会直接进行 Major GC。 \n \n \n Full GC： \n 调用  System.gc  时，系统会建议 Full GC，但不一定会执行。 \n 当老年代和方法区不足时会执行。 \n Minor GC 之后，或者是 S0 放不下的对象进入到老年代时（其实就是老年代不足时），进行一次 Full GC。 \n \n \n Tips \n 这里注意，Full GC 和 Major GC 是一种混合使用的情况，所以有时会触发 Major GC，有时会触发 Full GC。 \n 尽量不要触发 GC：GC 的过程会有一个时停（STW，Stop The World）的效果，这个效果下除了垃圾回收之外，所有的任务都不会进行，对于用户来说，感觉就会很卡。 \n 如果要触发 GC，YGC 的速度原高于 Full GC 的速度。 \n TLAB \n Thread Local Allocation Buffer，TLAB，是在堆空间（Eden 区）中为每一个线程单独分配的一块空间。 \n 我们知道，每个线程可以访问堆的数据，这样的话加锁是十分频繁的，而且加锁会影响内存的分配速度。因此 TLAB 应运而生。 \n TLAB 为每个线程划分了私有空间，解决了加锁效率低的问题，同时避免了安全问题。所以 Open JDK 的所有 JVM 几乎都会有 TLAB 存在。 \n 其实不是所有的对象实例都可以在 TLAB 中分配内存，因为确实不大（默认是 Eden 的 1%），但是 JVM 确实将 TLAB 作为首选。 \n 我们可以使用选项  -XX:UseTLAB  来设置是否开启 TLAB 空间，他的默认情况下是开启的 \n 我们可以使用选项  -XX:TLABWasteTargetPercent  来设置 TLAB 所占用的空间大小，默认是1% \n Tips \n 注意，ThreadLocal 和 TLAB 没有任何关系，ThreadLocal 是和线程相关的普通类。不过思想差不多。 \n 堆常用参数 \n \n -XX:+PrintFlagsInitial ：查看所有的参数的默认初始值 \n -XX:+PrintFlagsFinal ：查看所有参数的最终值 \n jinfo -flag 参数 进程ID ：通过 jps 查看当前运行的进程的参数的值，比如： jinfo -flag SurvivorRatio 9875 \n -Xms ：初始堆内存空间，默认为物理内存的 1/64 \n -Xmx ：最大堆内存空间，默认为物理内存的 1/4 \n -Xmn ：设置新生代的大小，初始值和最大值 \n -XX:NewRatio ：配置新生代和老年代在堆结构的占比，默认为 1:2 \n -XX:SurvivorRatio ：设置新生代中  Eden:S0:S1  的比例，默认为 8:1:1，可能会被自动分配修改 \n -XX:MaxTenuringThreshold ：设置新生代垃圾的最大年龄，默认大于 15 会被转移到老年代 \n -XX:+PrintGCDetails ：输出详细的 GC 日志 \n -XX:+PrintGC ：打印 GC 简要信息 \n -verbose:gc ：同样是打印 GC 简要信息 \n -XX:HandlePromotionFailure ：是否设置空间分配担保，JDK7 之后不会影响了，也就是可以理解为 true \n 对象分配存储 \n 堆是对象分配的唯一选择吗 \n 其实不是，虽然堆空间是调优的大块，但是随着 JIT 编译器和逃逸分析技术的发展，栈上分配、标量替换等技术将会导致一些变化，对象也不一定绝对会分配到堆上了。 \n 逃逸分析 \n 逃逸分析，其实就是分析对象的作用域。 \n \n \n 当一个对象在方法内部创建之后，假如仅在方法内部使用了，这种情况下自然可以进行栈上分配了。那么我们认为没有发生逃逸。 \n \n \n 当一个对象在方法内部创建之后，假如被外部的方法所调用，这种情况自然不可以在栈上分配。那么我们就认为这个对象逃逸了。 \n 常见的逃逸行为： \n \n 在方法中给成员变量赋值。 \n 方法中返回对象。 \n 实例引用传递。 \n \n \n \n 栈上分配好处绝对是很大的，首先是线程独有的，不用去考虑并发的问题。然后栈帧弹出之后，对象就没有了，这样也没有了 GC。 \n TaoBaoVM 有一个创新行为：GCIH，它可以将生命周期比较长的 Java 对象从堆中转移到堆外，并且 GC 不能管理 GCIH 的 Java 对象，这样就会减少 GC 的频率，提升效率。 \n \n 同步省略 \n 假如一个对象只能在一个线程中被访问，那么对于这个对象的操作就不需要去考虑同步问题。因为同步的代价是相当高的。 \n 在使用动态编译同步块的时候，JIT 可以使用逃逸分析来确定同步块所使用的锁对象是否只能被一个线程访问。 \n 假如同步块只能被单线程访问，那么 JIT 在编译这个同步块的时候会取消这段代码的同步，这样会大大提高并发性和性能。这个取消同步的过程叫做同步省略，也叫做锁消除。 \n 虽然我们从字节码的角度仍然可以看到  monitorenter 、 monitorexit  这两段同步代码，但是在运行时才会去考虑锁消除。因为这个过程是在 JIT 编译期的，而此时字节码早已经编译完成了。 \n \n 标量替换 \n 标量，其实指的就是无法被分解为更小数据的数据。Java 的基本类型就是标量。那些可以被分开的数据我们叫做聚合量。Java 对象就是聚合量。 \n 假如一个对象没有逃逸出方法，那么这个对象就会被 JIT 分解为几个标量。标量替换是很有好处的，因为不需要 new 对象了，也不需要在堆中分配空间了，只需要栈上的空间就足够了，大大减少了 GC。 \n 我们可以使用  -XX:+EliminateAllocations  来开启标量替换，默认情况下是开启的。 \n \n 逃逸分析其实本身也是一个比较消耗性能的操作，本身并不是非常成熟，但是是即时编译器优化中一个比较重要的手段（比如已经被应用的 GCIH）。 \n HotSpot 并没有栈上分配的技术，主要的手段还是标量替换。 \n 方法区 \n 从运行时数据区的角度来说，方法区是我们要讲解的最后一个结构。 \n 方法区概述 \n Person person = new Person(); ，这段代码中： \n \n Person  类这个  .class  文件被放到了方法区中。 \n new Person()  是一个新创建的对象，放到了堆中。 \n person  变量放到了栈中的局部变量表中。 \n \n \n 方法区的演进 \n 在 JDK7 及以前，习惯上将方法区称为永久代，JDK8 开始我们将方法区称为元空间。 \n 本质上来讲，方法区和永久代并不是等价的，我们只能说针对于 HotSpot 来讲是等价的，对于其他的虚拟机来讲，可能还没有永久代的实现。《Java虚拟机规范》并没有对如何实现方法区做统一要求，例如 BEA JRockit/ IBM J9中不存在永久代的概念。 \n 到了 JDK8，HotSpot 终于永久废弃了永久代的概念，改用 JRockit、J9 一样的，在本地内存中实现的元空间 Metaspace 来代替。 \n 元空间的本质和永久代类似，只不过它们两个的最大区别是：元空间不在虚拟机设置的内存中，而是使用本地内存。 \n 也就是说在永久代的时候，它实现在 JVM 虚拟机中设置的内存中。但是在元空间时，直接使用本地内存，也就是说不再占用 JVM 中的内存了。 \n 永久代和元空间不仅仅是名字变了，结构也有了一些调整，我们在后面讲解。 \n 设置方法区大小和 OOM \n 我们在前面讲，方法区是可以设置为固定大小或者是动态扩容的，那么我们在这里讲一下如何进固定大小的设置。在 JDK7 和 JDK8 有了一些变化，所以他们的指令也有所不同。 \n \n -XX:PermSize=xx  设置永久代初始分配空间，默认值是 20.75M。 \n -XX:MaxPermSize=xx  设置永久代的最大可用分配空间，32 位电脑默认 64M，64 位电脑默认是 82M。 \n \n 当JVM加载的类信息超过了这个值，会报错  java.lang.OutOfMemory:PermGen space \n \n \n -XX:MetaspaceSize=xx  元数据区初始大小设置，默认是 21M。 \n 假如触及了这个位置，Full GC 将会被触发，并且卸载没用的类，随后这个 21M 将会被自动重置，重置到多少取决于 GC 释放了多少空间。 \n 假如释放的空间不足，那么会不超过 MaxMetaspaceSize 的情况下适当提高值，反之会降低该值。 \n 假如初始化的 MetaspaceSize 设置太低，那么这个值也会调整多次，为了避免频繁 Full GC，应该设置一个合理的的值。 \n \n \n -XX:MaxMetaspaceSize=xx  设置最大大小，默认是 -1 也就是无限制。 \n 方法区的内部结构 \n \n \n 类的信息： \n 这里的类信息是一个泛指，不仅有 class，还有接口、注解、enum、…… \n \n \n 运行时常量池： \n 这里的运行时常量池中有一个常量池叫做字符串常量池，其中字符串常量池在 JDK 的不同版本中有一些变化 \n \n \n 类型信息 \n JVM 必须在方法区存储以下信息 \n \n 类型的完整有效名称：包名.类名 \n 直接父类的完整有效名：对于 interface 或者是 java.lang.Object 都没有父类 \n 这个类型的修饰符 \n 这个类型实现的接口的一个有序列表 \n \n 域信息（成员变量 Field） \n JVM 必须在方法区存储以下信息 \n \n 保存类型的所有域的相关信息和域的声明顺序 \n 域的相关信息包括：名称、类型、修饰符 \n \n Tips \n 用 final 修饰的变量，其实在编译阶段就已经将值写入到了 class 文件中 \n 使用 static 修饰的变量则没有在编译写入到 class 文件中，而是在类加载中的链接中的准备阶段将 static 的值进行了一次初始化 \n \n 方法信息 \n JVM 必须在方法区存储以下信息： \n \n 方法名称。 \n 返回类型（或者void）。 \n 参数的数量和类型，按顺序。 \n 修饰符。 \n 字节码、操作数栈和他的大小、局部变量表和他的的大小。 \n 异常表。 \n 运行时常量池 \n 字节码文件中的常量池 \n 方法区中包含了运行时常量池，字节码中包含常量池。要明白方法区就要明白字节码文件，要明白运行时常量池就要明白字节码中的常量池。 \n 一个有效的字节码文件中除了包含类的版本信息、字段、方法和接口等描述信息之外，还包含一项信息就是常量池表（Constant Pool Table），包含各种字面量和对类型、域和方法的符号引用。 \n \n 图中就是我们字节码中的的常量池，简而言之，常量池其实是存储基本原材料。常量池也可以看作一张表，虚拟机指令根据这张常量表找到要执行的类名分、方法名、参数类型、字面量等信息。 \n 运行时常量池 \n 运行时常量池是方法区的一部分，是常量池在运行时的表现形式。运行时常量池相对于 Class 文件中的常量池的一个重要特征是：具备动态性。 \n 比如说有一些常量池中没有的，但是能够在代码中表现出来，比如  String.intern() ，这就说明运行时常量池要比常量池具有更多内容信息。 \n 方法区的演进细节 \n 只有 HotSpot 才有永久代。HotSpot 方法区中的变化： \n \n \n \n JDK 版本 \n 方法区 \n \n \n \n \n JDK6 及以前 \n 静态变量存储在在永久代 \n \n \n JDK7 \n 有永久代，但是逐渐"去永久代" 字符串常量池、静态变量移除，保存在堆中 \n \n \n JDK8及以后 \n 无永久代 类型信息、字段、方法、常量保存在本地内存的元空间 字符串常量池、静态变量仍然保存在堆中 \n \n \n \n \n \n \n \n 为什么永久代要被元空间替换 \n \n 被 Oracle 收购了，所以 JRockit 和 J9 融合。 \n 永久代的大小是很难确定的，对永久代的调优比较困难。 \n \n 方法区的垃圾回收 \n 一般来说，方法区是难以垃圾回收的，因为不太好实现，但是这个区域的垃圾回收又是必须要实现的。 \n 方法区的垃圾回收主要回收两种内容： \n \n 常量池中废弃的常量。 \n 不再使用的类型。 \n \n 判断一个常量是否被废弃还是比较简单，但是判断一个类型是否属于不再被使用就比较麻烦了，需要满足： \n \n \n 该类的所有实例都被回收，也就是堆中不包含任何此类和其子类的实例。 \n \n \n 加载该类的类加载器已经被回收。 \n 在字节码被类的加载器加载之后，其实类加载器会记录下加载了谁。当字节码放到方法区之后，方法区中也会存一份是哪个加载器加载了这个字节码文件。 \n 所以这个是一个相互记录的过程。 \n \n \n 该类对应的  java.lang.Class  对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 \n 对象和直接内存 \n 对象实例化 \n 创建对象的几种方式 \n \n \n new \n 最常见的方式 \n 变形1：调用单例模式的 静态方法 \n 变形2：调用 xxxBuilder/xxxFactory 的静态方法 \n \n \n 反射 \n Class  的  newInstance ：在之后其实已经被废弃了，原因是只能使用空参数的构造器，而且必须是 public。 \n Constructor  的  newInstance() ：也是反射的方式，可以调用空参、带参的构造器，没有要求是 public。 \n \n \n 使用  clone() \n \n \n 使用反序列化。 \n \n \n 使用第三方库。 \n \n \n 创建对象的步骤 \n \n \n 判断对象对应的类是否被加载、链接、初始化 \n 虚拟机遇到一条 new 指令 \n 首先会去检查这个指令的参数是否在元空间的常量池中定位到一个类的符号引用，并去检查这个符号引用代表的类是否已经被加载、解析、初始化（也就是判断类元信息是否存在） \n 假如没有，那么就在双亲委派模式下，使用当前类加载器  ClassLoader + 包名 + 类名  为 key 去查找对应的  .class  文件 \n 假如没有找到该文件，那么抛出 ClassNotFoundException，假如找到则进行初始化并生成对应的 Class 对象 \n \n \n 为对象分配内存 \n 首先计算对象占用的空间大小，然后在堆中为对象分配一块内存 \n \n \n 假如堆空间的内存是规整的，就比如在书桌上的书摆放地整整齐齐，那么就是使用指针碰撞来为对象分配一块内存 \n 就是说现在的空间分为两部分，一部分是用过的，一部分是没有用过的，指针碰撞就是说指针指向用过和没用过的交叉点，分配内存的时候根据指针放到没用过的空间，然后指针对应的也移动 \n 垃圾收集器 Serial 和 ParNew 这种基于压缩算法的，虚拟机就采用这种分配方式，一般带有 compact（整理）过程的收集器使用指针碰撞 \n \n \n 假如堆空间的内存是不规整的，就比如在书桌上的书零零散散地放着。那么空间中就有大量的碎片，也就是说有大量的闲置的空间，但是非常零碎，需要使用空闲列表来为对象分配内存 \n 就是说这种情况下虚拟机就需要维护一个列表，记录那些内存块是可以使用的，再分配的时候需要从列表中找到一块足够大的，能够放下的空间放上 \n \n \n \n \n 处理并发安全问题： \n 处理并发安全问题我们一般使用两种方式： \n \n CAS 失败重试、区域加锁保证更新的原子性 \n 为每一个线程预留一块 TLAB，但是这个区域不大，先到先得 \n \n \n \n 初始化分配到的空间 \n 为对象的属性进行一次默认的初始化，这里可以对应类字节码加载的链接阶段的准备阶段 \n \n \n 设置对象的对象头 \n 记录一下对象的元数据信息、hash等等 \n \n \n 执行  init  方法进行初始化 \n 调用类的构造器，就是类的字节码加载的初始化阶段，调用  <init> \n 这一步是对属性的显示初始化、代码快中初始化、构造器中初始化 \n 对象的内存布局 \n 对象的内存布局其实总体上分为三部分： \n \n 对象头 \n 实例数据 \n 对齐填充 \n \n 对象头 Header \n 对象头中包含两部分： \n \n \n 运行时元数据 Mark Word \n \n 哈希值（地址值） \n GC 分代年龄 \n 锁状态标志 \n 线程持有的锁 \n 偏向线程 ID \n 偏向时间锁 \n \n \n \n 类型指针（注意不是所有的对象都有类型指针） \n \n 指向类元数据 InstanceKlass，确定该对象所属的类型 \n \n 假如创建的是数组，那么还需要记录数组的长度 \n \n \n 实例数据 Instance Data \n 对象真正存储的有效信息，包括程序代码中定义的各种类型的字段（包括从父类继承下来的和本身拥有的字段） \n 规则： \n \n 相同宽度的字段总是被分配到一起。 \n 父类中定义的变量会出现在子类之前。 \n 假如 CompactFields 参数为 true（默认为 true），子类的窄变量可能插入到父类变量的空隙。 \n \n 对齐填充 \n 类似占位符 \n 对象的访问定位 \n 对象访问方式主要有两种方式： \n \n 句柄访问。 \n 直接指针（HotSpot 采用）。 \n \n 句柄访问 \n 之前我们在说栈的时候已经说了，本地变量表中存放引用。 \n 在 Java 堆中专门开一块空间放了一个叫做句柄池的东西，句柄池中的指针有两块： \n \n 一块是指向到对象实例数据的指针。 \n 一块是指向到对象类型数据的指针。 \n \n 这种方式的好处是当对象移动位置的时候，Java 栈中的引用不用修改了，只需要修改句柄池中的对象实例数据指针信息即可，但是坏处是效率不高。 \n \n 直接指针 \n HotSpot 采用这种方式，栈的本地变量表中存放引用，直接指向到对象实例数据，对象的实例数据中有一个到对象类型数据的指针，指向方法区中对象类型数据。 \n 这样的坏处是对象移动位置的时候，Java 栈中的引用需要做修改，但是好处是效率变高了，不需要专门开一个句柄池，整体上来说这种方式更好一些，所以 HotSpot 采用这种方式。 \n 直接内存 \n 我们的 JDK8 使用的元空间，元空间就是使用的直接内存。 \n 要注意直接内存并不属于 Java 的运行时数据区，而是本地内存，是 Java 堆外的，直接向系统申请的内存。它的来源是 NIO，通过存储在堆外的 DirectByteBuffer 操作 Native 内存。 \n 通常情况下，我们访问直接内存的速度都要高于访问 Java 堆的速度。平常我们访问，需要首先经过 JVM，然后 JVM 去跟操作系统打交道。访问直接内存就直接和操作系统打交道。 \n 虽然直接内存是 Java 堆外的，使用命令  -Xmx  不会影响它，但是由于系统资源有限，还是会有  OOM（OutOfMemoryError:Direct buffer memory） 。 \n 所以我们也是需要指定直接内存大小的： MaxDirectMemorySize ，假如不指定，默认和堆的最大值  -Xmx  一致。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"September 20, 2021 00:01",createTimeStamp:1632067312e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1}]},{title:"Kubernetes-01-环境搭建",frontmatter:{title:"Kubernetes-01-环境搭建",categories:["backend"],tags:["k8s"],author:"causes",summary:"K8s 介绍 前置知识 Linux; Docker; K8s 介绍 Kunernetes，简称 K8s，因为 K 和 s 之间有 8 个字符，所以简称 8。这是一个开源的，用于管理云平台中多个主机上的容器化的应用。 K8s 是 Google 开发的，在经过生产环境十几年的考验之后，不断完善，最终在 2014 年开源出来。 传统的应用部署方式方式通过插件或者脚",meta:[{property:"og:url",content:"/backend/Kubernetes/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Kubernetes-01-环境搭建"},{property:"og:description",content:"K8s 介绍 前置知识 Linux; Docker; K8s 介绍 Kunernetes，简称 K8s，因为 K 和 s 之间有 8 个字符，所以简称 8。这是一个开源的，用于管理云平台中多个主机上的容器化的应用。 K8s 是 Google 开发的，在经过生产环境十几年的考验之后，不断完善，最终在 2014 年开源出来。 传统的应用部署方式方式通过插件或者脚"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"k8s"}]},regularPath:"/backend/Kubernetes/part1.html",relativePath:"backend/Kubernetes/part1.md",key:"v-8af45558",path:"/backend/Kubernetes/part1/",headers:[{level:2,title:"K8s 介绍",slug:"k8s-介绍"},{level:2,title:"搭建 K8s 集群",slug:"搭建-k8s-集群"},{level:3,title:"先行介绍",slug:"先行介绍"},{level:3,title:"主机环境初始化",slug:"主机环境初始化"},{level:2,title:"搭建 minikube",slug:"搭建-minikube"}],readingTime:{minutes:9.56,words:2869},content:" K8s 介绍 \n 前置知识 \n \n Linux \n Docker \n \n K8s 介绍 \n Kunernetes ，简称 K8s，因为 K 和 s 之间有 8 个字符，所以简称 8。这是一个开源的，用于管理云平台中多个主机上的容器化的应用。 \n K8s 是 Google 开发的，在经过生产环境十几年的考验之后，不断完善，最终在 2014 年开源出来。 \n 传统的应用部署方式方式通过插件或者脚本来安装应用，这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新/回滚等操作，虽然可以通过虚拟机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。 \n 新的方式是通过部署容器方式实现，简单来讲就是带环境安装，让生产环境和测试环境保持一致，避免很多不必要的麻烦。 \n 容器化部署，Docker 虽然也可以做，但是上限也就在大几百，一旦数量增多，Docker 也就有心无力了。K8s 支持自动化部署、大规模的升级/回滚操作，让部署的过程更加简洁方便。 \n K8s 功能 0 \n \n 自动装箱：自动完成，无需手动。 \n 自我修复：当主节点挂掉之后，副节点会自动启动，启动并且自检之后对外提供服务。 \n 水平扩展：高峰期可以自动扩展副本，高峰期过后会自动缩减副本。 \n 服务发现：负载均衡。 \n 滚动更新：应用加某几个服务之后，首先进行自检，检查之后没有问题对外提供服务。 \n 版本回退：新的版本有 BUG，可以回退到上个版本。 \n 密钥和配置管理：热部署，不需要重新构建镜像就可以更新配置。 \n 存储编排：存储系统可以来自本地或者外部、云存储等。 \n 批处理：支持一次任务、定时任务。 \n \n K8s 集群架构组件 \n Kubernetes 的本质其实是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理，目的是为了实现资源管理的自动化。 \n 一个 Kubernetes 集群中的节点主要分为两大类：控制节点（master），工作节点（node），每一个节点上都会安装不同的组件。 \n \n \n \n Master Node：主控节点（管理节点）。 \n \n API Server：集群控制的统一入口，各个组件的协调者。提供认证、授权、API 注册、发现等机制。 \n Scheduler：节点调度，选择工作节点应用部署。 \n Controller Manager：负责维护集群的状态，比如程序部署安排，自动扩展，滚动更新等。 \n ETCD：存储系统，用于保存集群中的相关数据。 \n \n 使用这样的方式干巴巴的，所以来举个例子作为说明。比如我想要在 Kubernetes 集群上运行一个服务 Nginx，那么： \n \n 首先跑到 API Server 这个入口中进入 Kubernetes 集群。 \n Scheduler 去计算，去判断这个活应该交给哪个工作节点来做，比如最后算出来应该交给 Node1，然后交给 API Server 这个信息。 \n Controller Manager 从 API Server 中得知，工作应该交给  Node1 来做，那么 Controller Manager 就去派活。 \n 派活之后管理者应该有一个单子，里面列着谁干了什么活，那么这个就交给 ETCD 存储。 \n \n \n \n Worker Node：工作节点（做事情的节点）。 \n \n Kubelet：Master Node 派到 Worker Node 的一个代表，管理当前节点的容器部分。 \n Kube-proxy：提供网络代理，利用它也可以实现负载均衡等操作。 \n Docker：节点上容器的各种操作。 \n \n node 节点当然就是最后用来干活的节点，但是里面的组件也比较复杂，我们还是以刚才的例子来讲： \n \n 刚才说到，Controller Manager 将活派给了 Node1 节点，那么这个 Node1 节点应该有一个耳朵可以听，有能力可以进行任务分配，那么组件 Kubelet 就是干这个用的，Controller Manager 和 Kubelet 对接。 \n Kubelet 也不干活，Kubelet 会将工作分配给 Docker 来干活，Docker 内部会启动一个有一个的 Pod，交给这些 Pod 去执行任务，Nginx 就运行在这些 Pod 上。 \n Nginx 运行中，我们想要访问，就要通过 kube-proxy 来进行访问 Nginx。 \n \n \n \n Tips \n \n 以后如果单单提到 Master 指的就是 Master Node，如果单单提到 Node 指的就是 Worker Node。 \n master 中，Scheduler 只负责计算任务应该交给谁，分配任务是 Controller Manager 来负责的。 \n ETCD 只是 Kubernetes 集群自带的一个存储工具，完全可以自己配置为别的东西，比如 MySQL。 \n \n \n Tips \n \n \n Kubelet 就相当于工地的工头，它本身不干活，是一个小任务的管理者。 \n \n \n 访问某一个具体的程序是通过 kube-proxy 来访问的，但是注意不要把它和 API Server 混淆了。 \n API Server 是整个集群的控制节点，我们访问集群中的内容才通过 API Server 去访问。 \n 而 Kubelet 只是工作节点上运行的一个程序而已，本身我们没有访问集群中的组件，也没有进行集群控制，所以不需要使用 API Server。 \n \n \n \n 我们再以 Nginx 部署来说明 Kubernetes 各个组件的关系： \n \n 首先明确，一旦 Kubernetes 集群启动之后，master 和 node 的信息都会存储到 etcd 数据库中。 \n 一个 Nginx 服务的安装请求首先会发送到 ApiServer上。 \n Scheduler 会来决定是将服务安装到什么 node 节点上，然后将结果告知给 API Server。 \n API Server 调用 Controller Manager，来安排工作给 node。 \n Kubelet 在 node 节点上等着接活，这个时候 Controller Manager 将工作内容交给了 Kubelet。 \n Kubelet 接受到了指令，会通知给 Docker，然后 Docker 会启动一个 Nginx 的 Pod。 \n Nginx 服务运行在了 Pod 上，假如想要访问这个服务，那么必须要通过 kube-proxy 来对 Pod 产生访问的代理。 \n \n Tips \n Pod 是 Kubernetes 的最小操作单元，容器必须跑在 Pod 中。 \n \n K8s 核心概念 \n \n \n Master：集群控制节点，每一个集群至少需要一个 master 节点负责管理集群。 \n \n \n Node：工作负载节点，干活的节点。 \n \n \n Pod：Kubernetes 中的最小控制单元。 \n \n \n Controller：简单来讲就是用 Controller 对 Pod 管理，比如启动 Pod，关闭 Pod，伸缩 Pod 数量等。 \n Pod 是最小的控制单元，但是我们一般不会直接操控 Pod，而是通过 Pod 控制器（Controller）来实现对 Pod 的控制。\n控制器在 Kubernetes 中不是一个概念，而是一类概念，控制器有很多种，每一种控制器都有它适合的场景。 \n \n \n Service：Pod 对外服务的统一入口，下面可以维护同一类的多个 Pod。 \n \n \n Label：用于对 Pod 分类，同一类的 Pod 拥有多个相同的 Label。 \n \n \n NameSpace：隔离 Pod 的运行环境。 \n 在默认情况下，一个 Kubernetes 中的所有 pod 是可以相互访问的，但是我们可以通过配置 namespace 来隔绝 pod 之间的相互访问，或者做到某几个 pod 可以相互访问，其他的不行，等等。 \n \n \n \n 在上图中，四个紫色的 tomcat 是在 pod 上启动的，service 作为 pod 提供服务的统一入口，用这个来实现负载均衡的效果。 \n 在上图中可以看到，有两类标签： app: tom 、 app: tomcat ，service 通过标签来将 pod 分类，维护了标签相同的 pod。 \n 搭建 K8s 集群 \n 先行介绍 \n 平台规划 \n 之前的内容中提到过，K8s 的两个节点：Master 和 Node，Node 肯定是多个的，那么就要看 Master。 \n 所以我们有两个规划： 单 Master 集群 和 多 Master 集群 。 \n \n \n 为了测试简单，我们使用一主两从的集群来作为测试环境的搭建。 \n 安装方式 \n kubernetes 有多种部署方式，目前的主流方式有 minikube、kubeadm、二进制包： \n \n minikube：搭建单节点的 kubernetes 工具，这个我们不做考虑（我们要搭建的是集群）。 \n kubeadm：快速搭建 kubernetes 的工具。 \n 二进制包：从官网上下载每一个组件的二进制包，依次安装，这个对于理解 kubernetes 的组件更加有效。 \n \n 我们现在使用的是 kubeadm 的方式来进行安装。 \n 主机规划 \n \n \n \n 作用 \n IP 地址 \n 配置 \n \n \n \n \n Master \n 192.168.109.100 \n 2 CPU，2 G 内存，50 G 硬盘 \n \n \n Node1 \n 192.168.109.101 \n 2 CPU，2 G 内存，50 G 硬盘 \n \n \n Node2 \n 192.168.109.102 \n 2 CPU，2 G 内存，50 G 硬盘 \n \n \n \n Tips \n 主机规划时注意，选择软件安装时，选择基础设施服务器。 \n 主机环境初始化 \n 主机安装 \n \n \n 检查操作系统版本，CentOS 必须要在 7.5 上。 \n cat  /etc/redhat-release\n \n 1 \n \n 设置主机名的解析，编辑  /etc/hosts  文件，这是测试服务器，企业环境中一般使用 DNS 服务器做解析： \n 192.168 .109.100 master\n 192.168 .109.101 node1\n 192.168 .109.102 node2\n \n 1 2 3 \n \n 时间同步，Kubernetes 要求集群中的节点时间必须精确一致，这里直接使用 chronyd 服务从网络同步时间： \n systemctl start chronyd\nsystemctl  enable  chronyd\n等待几秒，使用 date 来验证时间 \n date \n \n 1 2 3 4 \n \n Kubernetes 和 Docker 在启动的时候会产生大量的 iptables 规则，为了不让系统规则和他们混淆，我们关闭系统规则，生产环境防火墙关闭一定要慎重： \n systemctl stop firewalld\nsystemctl disable firewalld\nsystemctl stop iptables\nsystemctl disable iptables\n \n 1 2 3 4 \n \n 禁用 selinux，selinux 是一个 Linux 下的安全服务，假如不关闭，可能会产生一些奇葩问题，编辑  /etc/selinux/config ： \n SELINUX = disabled\n \n 1 \n \n 禁用 swap 分区： \n swap 分区在 Linux 指的是虚拟内存分区，在物理内存满了之后，用磁盘空间当内存用。 \n 但是 swap 分区会对系统设备产生极其负面的影响，所以 Kubernetes 要求每一个节点都要禁用 swap 设备，假如实在关不掉，在启动集群的时候就要明确指定参数配置。 \n 编辑  /etc/fstab ，编辑完成之后重启 Linux： \n/dev/mapper/centos-swap swap                    swap    defaults        0 0 \n \n 1 \n \n 修改 Linux 内核参数： \n 为 Linux 添加网桥过滤和地址转发功能，修改  /etc/sysctl.d/kubernetes.conf ： \n net.bridge.bridge-nf-call-ip6tables  =   1 \nnet.bridge.bridge-nf-call-iptables  =   1 \nnet.ipv4.ip_forward  =   1 \n \n 1 2 3 重新加载配置： sysctl -p \n网桥过滤 \nmodprobe br_netfilter\n查看是否加载成功 \nlsmod  |   grep  br_netfilter\n \n 1 2 3 4 \n \n 配置 ipvs 功能 \n kubernetes 中和 service 中有两种代理模式：iptables 和 ipvs，ipvs 的性能高，需要手动载入。 \n yum -y  install  ipset ipvsadmin\n \n 1 cat   << EOF   >  /etc/sysconfig/modules/ipvs.modules \n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack_ipv4\nEOF \n \n 1 2 3 4 5 6 7 8 # 增加可执行权限，之后执行 \n chmod  +x /etc/sysconfig/modules/ipvs.modules\n查看是否加载成功 \nlsmod  |   grep  -e ip_vs -e nf_conntrack_ipv4\n \n 1 2 3 4 \n \n 重启 Linux \n 搭建 minikube \n minikube ，是单节点的 k8s 集群，主要用于本机测试、学习使用。适合配置不高的电脑。 \n",updateTime:"July 11, 2022 16:17",updateTimeStamp:1657527473e3,createTime:"July 17, 2021 10:26",createTimeStamp:162648881e4,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:5},{name:"causes",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Linux-01-基础篇",frontmatter:{title:"Linux-01-基础篇",categories:["base"],tags:["linux"],author:"causes",summary:"Linux 入门 Linux 是什么 Linux是一个操作系统，它免费、开源、稳定、安全、可以处理高并发。 常见的操作系统： windows、IOS、Android、MacOS、Linux、Unix 目前很多企业级项目都会部署到Linux上 --- Linux 吉祥物 Tux，是一只企鹅。 --- Linux 之父 Linus Torvalds，也是 Git",meta:[{property:"og:url",content:"/base/Linux/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Linux-01-基础篇"},{property:"og:description",content:"Linux 入门 Linux 是什么 Linux是一个操作系统，它免费、开源、稳定、安全、可以处理高并发。 常见的操作系统： windows、IOS、Android、MacOS、Linux、Unix 目前很多企业级项目都会部署到Linux上 --- Linux 吉祥物 Tux，是一只企鹅。 --- Linux 之父 Linus Torvalds，也是 Git"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"linux"}]},regularPath:"/base/Linux/part1.html",relativePath:"base/Linux/part1.md",key:"v-2436b22c",path:"/base/Linux/part1/",headers:[{level:2,title:"Linux 入门",slug:"linux-入门"},{level:2,title:"VM和Linux的安装",slug:"vm和linux的安装"},{level:2,title:"Linux基本概念介绍",slug:"linux基本概念介绍"},{level:3,title:"Linux网络链接的三种方式的区别",slug:"linux网络链接的三种方式的区别"},{level:3,title:"虚拟机克隆",slug:"虚拟机克隆"},{level:3,title:"虚拟机快照、迁移和删除",slug:"虚拟机快照、迁移和删除"},{level:3,title:"VMTools",slug:"vmtools"},{level:2,title:"Linux目录结构",slug:"linux目录结构"}],readingTime:{minutes:12.87,words:3862},content:" Linux 入门 \n Linux 是什么 \n Linux是一个操作系统，它免费、开源、稳定、安全、可以处理高并发。 \n 常见的操作系统：\nwindows、IOS、Android、MacOS、Linux、Unix \n 目前很多企业级项目都会部署到Linux上 \n \n Linux 吉祥物 \n \n Tux，是一只企鹅。 \n \n Linux 之父 \n \n Linus Torvalds，也是 Git 创始者。世界著名黑客。 \n \n Linux在什么情况下会使用 \n \n Linux 下面开发项目会使用到：\n \n JavaEE \n 大数据 \n Python \n PHP \n C/C++ \n Go \n \n \n Linux 运维工程师。 \n Linux 嵌入式工程师。 \n \n Linux应用的领域 \n \n 个人桌面领域。 \n 服务器：在服务器端是最强的。 \n 嵌入式领域。\n因为Linux的内核可以进行裁剪，最小可以达到几百KB，所以很轻松就可以移植到嵌入式领域去。\n机顶盒、数字电视、网络电话、手机、PDA、智能家居等等都是它应用的领域。以后在物联网中，应用会更加广泛。 \n \n \n 最新版的Linux内核 \n 可以看到最新版本的稳定版： 网址 。 \n \n \n 包管理工具和 Linux 主要的发行版 \n RPM 包管理工具，全称 Redhat Package Manager，最早是由 Red Hat 公司指定实施，随后被 GUN 开源操作系统接受并成为许多 Linux 的既定软件标准，yum 就基于 rpm。 \n 与 RPM 竞争的是基于 Debian 操作系统的 DEB 软件包管理工具 DPKG，全称是 Debian Package，与 RPM 功能类似。 \n Linux 发行版是 Linux 内核和各种应用软件的集成版本。 \n \n \n \n 基于的包管理工具 \n 商业发行版 \n 社区发行版 \n \n \n \n \n RPM \n Red Hat \n Fedora/CentOS \n \n \n DPKG \n Ubuntu \n Debian \n \n \n \n Linux的发行版和Linux的关系： \n Linux主要指的是一个内核，而在这个内核的基础上有很多人对它进行包装，然后形成不同的发行版。这些发行版的内核可能是一样的，只不过是包装不同而已。 \n \n Linux 和 Unix 的关系 \n Unix 也是一个操作系统。在上世界70年代，贝尔实验室、麻省理工、通用电气要做一款多用户、分时的操作系统，并且命名为 Multics，但是没有成功。后来 ken tompsom 根据这个开发出了 Unix，开始是 B 语言写的（B 语言也是他写的，GO 也是他写的）。 \n 后来 ken tompsom 和 Dennis richres 联手用 C 语言改写了 Unix（C语言是他们两个共同创造的）。 \n 到了上世纪80年代，IBM、SUN、HP（惠普）进行了二次开发，但是他们发现 Unix 只能运行在大型项目中，一般的电脑装不起来，所以Richard Stallman（号称世界第一黑客）提出了一个观点： \n \n 在自由时代，用户应该享有对软件源代码阅读、修改的权力。 \n 软件公司可以靠提供服务、训练来盈利。 \n \n 根据这个观点，他发起了一个 GNU 计划，对 IT 领域产生了巨大的影响。这个计划简单来讲，是可以阅读并修改别人的源码并提交，对某个项目做贡献。\nLinus Torvalds 参加了 GNU 计划，贡献出了 Linux Kernel 这个内核，有很多人就根据这个内核进行升级维护。所以 Linux的全名应该叫做：GNU/Linux。 \n 至于 Linux 和 Unix 的关系，Unix 被别人二次开发之后有很多二次发行版，那么 Linus 就选择了一个比较小巧的、功能也不弱的发行版：Minix，根据 Minix 的基础上进行重新改写，形成了 GNU/Linux 内核。它的一个重大突破是适用于 X86 的个人计算机。于是有公司就根据这个 GNU/Linux 内核开发出了不少发行版，比如 Ubuntu，Redhat，SUSE，Fedora 等。而Redhat又衍生出CentOS（社区版）和redhat（企业版）。 \n VM和Linux的安装 \n 学习Linux需要一个环境，我们需要创建一个虚拟机，然后在虚拟机上安装一个CentOS来学习（或者可以直接在真机上安装一台Linux） \n 步骤： \n \n \n Virtual Machine 15.5 。 \n \n \n LInux（CentOS 7.5） ，下载版本为  7.6.7810  和  8.1.1911  版本，或者有一台云服务器也可。 \n \n \n 新建虚拟机： \n 打开VM，选择新建虚拟机--\x3e典型--\x3e稍后安装操作系统--\x3eLinux（选择版本选择红帽7）--\x3e切换目录--\x3e先给20G，拆分为多个文件--\x3e内存按照它的推荐（这个先记住，等会用），处理器按照真机的CPU数量给，CPU的内核给真机内核的一半--\x3e网络适配器选NAT--\x3e关闭。 \n \n CentOS本来就是红帽家族的产品，所以选择红帽即可。 \n \n \n 右键新添加的  CentOS--\x3eCD/DVD--\x3e使用ISO镜像文件 。 \n \n \n 打开虚拟机，选择 Install。 \n \n \n \n 语言选择中文，下一步，然后开始等待，一定要等待，否则乱点可能会卡死。 \n \n \n 软件选择： \n \n 最小安装是不带界面的，这不利于我们学习，但是在实际工作中可以选择。 \n \n \n 软件选择界面选择如下： \n \n 选择开发工具后，我们默认的GCC，JDK，MYSQL等都默认装上了，以后不想用它的也可以自己更改，然后点击完成。点击完成之后，等待，鼠标乱点可能会导致卡死\n安装位置： \n \n \n \n 安装位置选择： \n \n \n \n 分区设置：\nLinux我们一般分为三个部分： \n \n boot分区，也叫引导分区。 \n swap分区，也叫交换分区。 \n 根分区。 \n \n 三者大小设置一般来说，boot分区一般给1G即可，交换分区和分配的内存大小一致，也就是我们在一开始定义硬件部分的内存大小设置，这里定义了2G，剩下的都是根分区的。\nboot分区：引导分区。 \n \n swap分区：就是可以临时充当内存，比如现在内存里塞了三个程序，塞不下了，那么第四个程序可以临时到swap分区，等到前面三个程序执行完成之后才会放到真实内存中。但是它毕竟是虚拟内存，速度不如真实内存 \n \n 根分区。 \n \n \n \n \n KDUMP：\nKDUMP是一个内核崩溃的转存机制，就是保护你的系统用的，但是这个会占用一部分内存，真正的生产环境要选择，但是在学习过程中就不需要了 \n \n \n \n \n 网络和主机名： \n \n \n \n \n 安全策略 \n \n 这个安全策略可以不应用，比如在设置用户名密码的时候有些要求 \n \n \n \n 安装，设置密码： \n \n \n 在实际工作中，密码一定要复杂一些，这里设置了  root  为密码。 \n \n \n 创建用户：\n一般来说，Linux建议我们再用一个权限比较低的用户作为登陆，而Root用户也可以，但是建议再弄一个。 \n \n 密码仍是root。 \n \n \n 安装成功，点击重启，同意许可证，我们可以使用非root用户登陆，也可以使用root用户登陆。 \n Linux基本概念介绍 \n Linux网络链接的三种方式的区别 \n 在刚才我们安装CentOS的时候曾经选择过网络，那里有几种方式： \n \n 桥接模式。 \n NAT 模式。 \n 仅主机模式。 \n 自定义。 \n LAN区段。 \n \n 下面我们说一下几种模式的区别。 \n \n 桥接模式 \n 它可以令Linux能够和外部进行通讯，只需要Linux和外部的主机在同一个网段下即可。 \n 比如现在张三有主机A，虚拟机B，王五有主机C，虚拟机D，网关为  255.255.255.0 。\n这个时候张三的主机是  192.168.0.20 ，虚拟机是  192.168.0.80 ，所以张三的主机和虚拟机都是在一个网段下。\n那么王五的主机是  192.168.0.30 ，它们三者共同在一个网段下，张三的虚拟机就可以直接和王五的主机通信。 \n 但是这种方式有可能回造成冲突，比如一个教室里面 300 个人，但是网段只有 255，那么肯定就会产生冲突。\n但是在这种模式下，A 可以找 C，C 也可以找 A。 \n NAT模式 \n 假如现在张三的主机A、B，王五有主机C\nA 的 ip 为  192.168.0.20 ，B 的 ip 为  192.168.100.88 ，C 的 ip 为   192.168.0.30 。 \n 那么这个时候，看似张三的 Linux 和另外两个不在同一个网段，但是在 NAT 模式下一切皆有可能：张三的主机 A 会生成一个对应的网卡，和 Linux 在同一个网段下，比如  192.168.100.99 。那么 B 就可以和 A 进行互通，并且 B 可以根据 A 作为一个跳板去通信  192.168.0.xx  频段的内容。 \n 所以 NAT 模式就是我们说的网络地址转换模式，不造成 IP 冲突，但是这个时候虚拟的 B 可以和外部进行通信。但是这个时候注意，外部不能去访问内部的，也就是 C 不能找 B。 \n 主机模式 \n 不和外部进行通讯 \n 虚拟机克隆 \n 方式一 \n 直接拷贝一份安装好的虚拟机文件。 \n 方式二 \n 使用 VMWare 的克隆操作：\n注意，在克隆之前要先关闭 Linux。 \n 虚拟机快照、迁移和删除 \n 快照 \n 假如我们拍摄了快照B，然后拍摄了快照A，那么假如想从虚拟机的状态A回滚到状态B，那么直接可以使用快照回滚 \n 如果想再次回到快照A，也可以使用回滚 \n 但是注意，快照会占用虚拟机的空间 \n 虚拟机的迁移和删除 \n 我们可以将虚拟机的整体文件拷贝到别的地方，这就是迁移。假如我们要删除文件夹，那么就直接删除即可 \n VMTools \n VMTools可以让我们在Windows下面更好地管理VM虚拟机，可以设置windows和centos的共享文件夹。\n安装VMTools有如下步骤： \n \n \n 进入 centos，注意首先需要 GCC，只需在终端输入  gcc -v  ，假如安装了会输出相关信息，没安装会找不到。 \n \n \n 点击 vm 菜单中的 install vmware tools。 \n \n \n centos 会出现一个  xxx.tar.gz 。 \n \n \n 拷贝到  /opt 。 \n \n \n 使用解压命令  tar -zxvf xxx ，得到一个安装文件夹。 \n \n \n \n 进入解压的目录。 \n \n \n 安装  ./vmware-install.pl 。 \n \n \n 全部使用默认设置。 \n \n \n 点击当前 centos 的  设置--\x3e共享文件夹--\x3e选择 。 \n Linux目录结构 \n 基本概述 \n \n Linux 中的文件系统是采用层级结构的树状目录结构，最上层是  /  根目录，然后在此目录下再创建其他的目录。\n注意，这些目录的作用都是规定好的，不能更改。 \n 在Linux中，一切皆文件。\n之所以号称一切皆文件的原因是它会将所有的硬件都转换成文件来进行显示，CPU、硬盘，甚 U 盘。 \n \n \n 一定要背这种主体的结构，起码常用的要知道啥意思 ，我们讲的都是根目录之下的目录结构： \n \n /bin ：常用，是 Binary 的缩写\n这个目录下存放着最常用的命令，除了这个目录还有  /usr/local/bin  和  /usr/bin ，也存放一些命令。 \n /sbin ：常用，管理员指令，权限比较高的指令。 \n /home ：常用，是普通用户的存放主目录，在 Linux 中，每一个用户都有一个自己的目录，这个目录名称一般是以用户的账号命名，比如我们刚才的 tom。 \n /root ：常用，为系统管理员的主目录。 \n /etc ：常用，所有的系统管理所需要的配置文件和子目录，比如 MySQL 数据库的 my.conf 和系统配置。 \n /usr ：常用，非常重要，用户的很多应用程序和文件都会放到这个目录下，类似 windows 的 program。 \n /boot ：常用，存放 Linux 启动时的一些核心文件，包括一些连接文件和镜像文件。 \n /media ：常用，Linux 会识别一些设备，比如 U 盘，光驱等，识别之后会把别的设备挂在到这个目录下。 \n /mnt ：常用，为了让用户临时挂载别的文件系统，我们可以将外部的存储挂在到这里，比如我们上面的 VMTools 共享文件夹。 \n /local ：常用，另一个给主机额外安装软件所安装的目录，一般是通过编译源码方式安装的程序。\n注意，这里是安装到这个目录，而且是源码编译安装，比如我要编译安装 Redis，那就可以这么用。 \n /var ：常用，存放一些不断扩充的东西，习惯将被经常修改的目录放在这个目录下，比如各种日志文件。 \n \n \n \n /dev ：类似设备管理器，所有的硬件文件都会以文件的形式存储在这里。 \n /opt ：给主机额外安装软件摆放的目录。\n注意是安装文件而不是安装到这里，比如要安装 IDEA，就把安装包先拷贝到这里。 \n /tmp ：临时文件目录。 \n /lost+found ：一般是空的，但是当系统非法关机后，就会存放一些文件，但是这个目录找不到，因为它隐藏了，要在控制台看。 \n \n \n \n /lib ：系统开机所需要的最基本的动态链接共享库，类似 Windows 里面的 DLL 文件，几乎所有的应用程序都需要这些共享库。 \n /proc ：一个虚拟目录，是系统内存的映射，访问这个目录来获取系统信息。 \n /srv ：service 的缩写，存放一些服务启动之后需要提取的数据。 \n /sys ：Linux2.6 内核的一个很大变化，在 2.6 内核中出现的一个文件系统 sysfs。 \n \n 以上四个别动，否则很可能造成系统崩溃。 \n \n \n /selinux [security-enhanced linux] ：是一种安全子系统，它能控制程序只能访问特定文件，有三种工作模式，可自行设置。 \n \n",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 16, 2021 20:13",createTimeStamp:1629115991e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"causes",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Git-01-常用指令",frontmatter:{title:"Git-01-常用指令",categories:["base"],tags:["git"],author:"causes",sidebarDepth:4,summary:"说明 本文档目前的部分来自 Oh Shit，Git？，部分来自之前的笔记，日后有比较好用的操作也会放进来。 Git 分区 在 Git 中，有几种分区：工作区、暂存区、本地仓库、远程仓库。我们用一个文件来说明这三种分区情况： 1. 一个文件被创建了，这个时候文件在工作区中，也就是你能够在屏幕前看到的代码。它还不被 Git 管理，所以在 Git 上，它是一个未追",meta:[{property:"og:url",content:"/base/Git/part0.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Git-01-常用指令"},{property:"og:description",content:"说明 本文档目前的部分来自 Oh Shit，Git？，部分来自之前的笔记，日后有比较好用的操作也会放进来。 Git 分区 在 Git 中，有几种分区：工作区、暂存区、本地仓库、远程仓库。我们用一个文件来说明这三种分区情况： 1. 一个文件被创建了，这个时候文件在工作区中，也就是你能够在屏幕前看到的代码。它还不被 Git 管理，所以在 Git 上，它是一个未追"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"git"}]},regularPath:"/base/Git/part0.html",relativePath:"base/Git/part0.md",key:"v-2dfdfd20",path:"/base/Git/part0/",headers:[{level:2,title:"说明",slug:"说明"},{level:2,title:"Git 分区",slug:"git-分区"},{level:2,title:"Git 常用操作",slug:"git-常用操作"}],readingTime:{minutes:4.9,words:1469},content:" 说明 \n 本文档目前的部分来自  Oh Shit，Git？ ，部分来自之前的笔记，日后有比较好用的操作也会放进来。 \n Git 分区 \n 在 Git 中，有几种分区：工作区、暂存区、本地仓库、远程仓库。我们用一个文件来说明这三种分区情况： \n \n \n 一个文件被创建了，这个时候文件在工作区中，也就是你能够在屏幕前看到的代码。它还不被 Git 管理，所以在 Git 上，它是一个未追踪的状态。 \n \n \n 使用  git add xx  命令，将这个文件的当前内容添加到 Git 中，这个时候文件就会被 Git 管理，这个时候是放到了 Git 的暂存区中，这个时候文件是已经追踪，但是没有提交的状态。 \n \n \n 使用  git commit  命令，就会将文件的当前内容从暂存区中挪动到本地仓库中，这个时候文件是已经提交的状态。 \n \n \n 可能文件发生了改动，那么这个时候因为发生了改动，Git 会检测到，那么文件当前的状态就变成了文件发生改动的状态。 \n 注意，在此时 Git 已经有了上一次文件的全部内容，但是没有这次文件的内容。 \n \n \n 再次使用  git add ，那么文件当前的状态就会再次被 Git 追踪，添加到了暂存区中。 \n \n \n 再次使用  git commit ，文件当前的状态就会被放到本地仓库中。 \n 注意，此时的本地仓库中一共有两次提交，第一次提交是文件没有发生改动之前的状态，第二次提交是文件发生改动之后的状态。 \n \n \n 使用  git push  命令，文件就会从本地仓库上传到远程仓库，这个时候文件的所有 commit 都会 push 上去。 \n Git 常用操作 \n git 回滚 \n \n 在上图的例子中，Git 进行了两次 commit，它们的编号分别为 A、B。 \n 回滚其实就是对于 Git 几个分区的管理： \n \n git reset ：默认使用  git reset --mixed  方式回滚。 \n git reset --soft ：仅仅将本地仓库回滚，工作区和暂存区保持不变，也就是回到你没有进行 commit 之前的状态。 \n git reset --mixed ：回滚本地仓库和暂存区中的代码，工作区保持不变，也就是回到你没有进行 add 之前的状态。 \n git reset --hard ：回滚本地仓库、暂存区、工作区中的代码，也就是回到你没有更改代码之前的状态。 \n git reset --keep ：回滚本地仓库、工作区中的代码，暂存区保持不变。这个一般用得少。 \n \n 查看当前所有的 commit \n git reflog  操作可以查看当前所有的 commit，包括所有的分支，所有已经被删除的 commit。这个操作可以在某些特定的时间吃一颗后悔药。 \n \n 效果如上图，可以清晰地看到每一个分支的提交情况，然后就可以再调用  git reset HEAD@{index} ，就可以回到对应的位置了。 \n 覆盖本地上次的 commit 操作 \n 当你 commit 了之后，可能就会发现自己还有需要改动的地方，这个时候假如为了一丁点的小改动再次提交一个 commit 就显得太难看了。 \n git commit --amend  可以让你去覆盖上一次 commit 内容，做到推送到远程时，只会有一条 commit 信息。 \n git commit --amend  会重新让你去编辑 commit 的信息，假如你不想重新编辑信息，使用  git commit --amend --no-edit \n Tips \n 注意，这种操作不要对刚刚拉下来的分支做，因为远程分支的内容是上一次提交的内容，你在上一次的提交上进行  amend  操作，相当于覆盖了上次的提交。 \n 上次的提交甚至有可能不是你做的，是别人做的。 \n \n 直接提交到了 master 上的内容再切到新的分支 \n 有这样一种情况：本来应该是放到一个新的分支上的内容，却由于忘记切换分支，直接提交到了 master 上。 \n 第一种解决方式： \n \n git branch new-branch ：首先从当前的 master 分支上切出一个新的分支。 \n git reset HEAD~ --hard ：master 节点直接强制回滚到上次提交的位置，使用 hard 会将所有内容强制回滚到之前。 \n git checkout new-branch ：切到新的分支。 \n \n 第二种解决方式： \n \n git checkout new-branch ：首先切换到新的分支。 \n git cherry-pick master ：抓取 master 节点最后一个 commit 到当前分支下。 \n git checkout master ：切回 master。 \n git reset HEAD^ --hard ：强制回滚到之前的 commit。 \n \n Tips \n 这种方式只能在没有提交到远程分支的时候使用，不过一般来讲 master 分支是受保护的，一般人推不上去，有权限的推上去只能 revert 了。 \n \n 查看保存在暂存区中的改动 \n git diff  命令可以查看当前的代码与之前的 commit 有什么改动，但是使用  git add  工具之后要使用  git diff --staged  来查看。 \n 撤回某一个文件的改动 \n 假如现在提交的某一个文件发现不对，那么回滚整个项目明显是不正常的，可以通过  git checkout [回滚的 hash 值] -- path/to/file 。 \n 使用 checkout 来回滚某一个文件，这操作也太渣了…… \n 干掉某一个分支上的所有未追踪的文件 \n \n git fetch origin ：获取远程的最新状态，使用 master 来举例。 \n git checkout master \n git reset origin/master --hard \n git clean -d --force ：干掉所有未追踪的文件和目录。 \n \n",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 20, 2021 11:43",createTimeStamp:1629431035e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"王宏照",email:"2592716753@qq.com",commits:1}]},{title:"Linux-02-实际操作篇",frontmatter:{title:"Linux-02-实际操作篇",categories:["base"],tags:["linux"],author:"causes",summary:"远程登陆（Xshell XFTP） 1. Linux服务器是开发小组共享。 1. 正式上线的项目是运行在公网上的。 1. 远程登录的客户端有 XShell6、XFTP、....，我们选择 XShell6 和 XFTP，其他的都大同小异。 Vi和Vim编辑器 基本概述 在Linux中，会内置VI编辑器。 VIM具有程序编辑的功能，可以看作是Vi的增强版本，可以",meta:[{property:"og:url",content:"/base/Linux/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Linux-02-实际操作篇"},{property:"og:description",content:"远程登陆（Xshell XFTP） 1. Linux服务器是开发小组共享。 1. 正式上线的项目是运行在公网上的。 1. 远程登录的客户端有 XShell6、XFTP、....，我们选择 XShell6 和 XFTP，其他的都大同小异。 Vi和Vim编辑器 基本概述 在Linux中，会内置VI编辑器。 VIM具有程序编辑的功能，可以看作是Vi的增强版本，可以"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"linux"}]},regularPath:"/base/Linux/part2.html",relativePath:"base/Linux/part2.md",key:"v-1d1a5ab0",path:"/base/Linux/part2/",headers:[{level:2,title:"远程登陆（Xshell XFTP）",slug:"远程登陆-xshell-xftp"},{level:2,title:"Vi和Vim编辑器",slug:"vi和vim编辑器"},{level:3,title:"基本概述",slug:"基本概述"},{level:3,title:"Vi和VIM的三种模式",slug:"vi和vim的三种模式"},{level:2,title:"开机、重启、登陆、用户",slug:"开机、重启、登陆、用户"},{level:3,title:"开关机和重启",slug:"开关机和重启"},{level:3,title:"用户管理",slug:"用户管理"},{level:3,title:"用户组",slug:"用户组"},{level:2,title:"实用指令",slug:"实用指令"},{level:3,title:"指定运行级别",slug:"指定运行级别"},{level:3,title:"找回Root密码",slug:"找回root密码"},{level:3,title:"帮助指令",slug:"帮助指令"},{level:3,title:"文件目录",slug:"文件目录"},{level:3,title:"时间日期类",slug:"时间日期类"},{level:3,title:"搜索查找类",slug:"搜索查找类"},{level:3,title:"压缩和解压",slug:"压缩和解压"},{level:2,title:"组管理和权限管理",slug:"组管理和权限管理"},{level:3,title:"组",slug:"组"},{level:3,title:"权限",slug:"权限"},{level:2,title:"定时任务调度",slug:"定时任务调度"},{level:3,title:"crond 定时任务调度概述",slug:"crond-定时任务调度概述"},{level:3,title:"crond",slug:"crond"},{level:3,title:"at",slug:"at"},{level:2,title:"磁盘分区与挂载",slug:"磁盘分区与挂载"},{level:3,title:"磁盘分区与挂载原理介绍",slug:"磁盘分区与挂载原理介绍"},{level:3,title:"挂载的经典案例",slug:"挂载的经典案例"},{level:3,title:"磁盘情况查询",slug:"磁盘情况查询"},{level:2,title:"Linux网络配置",slug:"linux网络配置"},{level:3,title:"Linux网络概述",slug:"linux网络概述"},{level:3,title:"Linux网络配置指令",slug:"linux网络配置指令"},{level:2,title:"进程管理",slug:"进程管理"},{level:3,title:"进程管理基本介绍",slug:"进程管理基本介绍"},{level:3,title:"ps指令详解",slug:"ps指令详解"},{level:3,title:"父子进程",slug:"父子进程"},{level:3,title:"终止进程",slug:"终止进程"},{level:3,title:"pstree",slug:"pstree"},{level:2,title:"服务管理",slug:"服务管理"},{level:3,title:"服务管理基本介绍",slug:"服务管理基本介绍"},{level:3,title:"服务的运行级别（runlevel）",slug:"服务的运行级别-runlevel"},{level:3,title:"chkconfig",slug:"chkconfig"},{level:3,title:"systemctl",slug:"systemctl"},{level:3,title:"防火墙的端口设置",slug:"防火墙的端口设置"},{level:2,title:"动态监控",slug:"动态监控"}],readingTime:{minutes:48.62,words:14586},content:' 远程登陆（Xshell XFTP） \n \n Linux服务器是开发小组共享。 \n 正式上线的项目是运行在公网上的。 \n 远程登录的客户端有 XShell6、XFTP、....，我们选择 XShell6 和 XFTP，其他的都大同小异。 \n Vi和Vim编辑器 \n 基本概述 \n 在Linux中，会内置VI编辑器。 \n VIM具有程序编辑的功能，可以看作是Vi的增强版本，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 \n 代码补完，编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛应用。 \n Vi和VIM的三种模式 \n 正常模式 \n 以 vim 打开一个文档就是进入了正常模式，这也是默认模式。 \n 在这个模式中，可以使用【上下左右】按键来移动光标。可以使用【删除字符】和【删除整行】来处理档案内容。可以使用【复制，粘贴】来处理文件数据。 \n 插入模式 \n 按下  i、I、o、O、a、A、r、R  等任何一个字母才会进入到编辑模式。 \n 命令行模式 \n 在这个模式中，可以提供相关指令，完成读取，存盘，替换，离开vim，显示行号等操作。 \n 各种模式的切换 \n \n 基本快捷键的使用练习 \n \n 拷贝当前行：  yy ，拷贝当前行向下的5行  5yy ，粘贴  p 。 \n 删除当前行：  dd ，删除当前行向下的5行  5dd 。 \n 在文件中查找某个单词（区分大小写）：命令行下  /关键字 --\x3e 回车查找 --\x3e 输入n查找下一个 --\x3e shift+n  查找上一个。 \n 设置文件的行号：命令行下--\x3e显示  set nu  --\x3e:取消显示  :set nonu 。 \n 快捷键  G  到最末行， gg  到最首行。 \n 撤销上一步的动作： u 。 \n 将光标移动到 20 行：先输入 20 --\x3e  shift + g 。 \n 开机、重启、登陆、用户 \n 开关机和重启 \n \n sync ：将内存的数据同步到磁盘。 \n shutdown -h now ：立刻关机。 \n halt ：关机，作用和上面一样。 \n shutdown -h 1 ：一分钟后关机。 \n shutdown -r now ：立刻重启。 \n shutdown -r 1 ：一分钟后重启。 \n reboot ：立刻重启。 \n \n \n 不管是重启还是关机，首先要运行  sync ，将内存中的数据写入到磁盘中。 \n 目前的  shutdown  和  reboot  和  halt  等命令虽然在关机前进行了  sync ，但是还是要首先运行一遍，因为小心驶得万年船。 \n 假如只输入一个  shutdown ，默认是 shutdown -h 1 。 \n 用户管理 \n Linux 是一种多用户的系统，我们这个系统中可以有多个普通用户，每一个用户都对应自己的目录。 \n \n \n 用户登录和注销： \n 在工作中，我们一般不会使用 root 权限来登陆，因为它是最大的权限，我们要避免操作失误。我们可以先使用普通账号登陆，假如真的需要权限，那么再登录之后可以使用  su - 用户名  来切换为系统管理员权限，或者直接使用  sudo 命令  来执行命令（推荐这一种）。 \n \n 直接使用  sudo 命令  来执行命令 \n \n 在这种情况下，只有在  /etc/sudoers  配置文件中的用户才可以使用该指令。 \n 在提示符下输入 logout （或者  exit ）即可注销用户。 \n 细节：logout注销指令在图形运行级别无效，在运行级别3下有效，运行级别在以后讲。 \n \n 注意，假如我使用tom这个用户首先登陆系统，那么它使用  su root  的命令会得到管理员的权限。 \n 假如这个时候使用  logout ，它首先会退回到 tom 的权限，假如再次使用  logout ，那么会退出系统。 \n 权限高的用户切换到权限低的用户不需要输入密码，反之需要。 \n \n \n 添加用户： \n \n \n useradd 用户名 ： \n 它会自动添加一个用户，默认的用户目录在  /home/用户名 ，切换到这个用户后，会自动到这个用户的文件夹。 \n 可以使用命令  pwd  来查看当前所在目录。 \n 我们也可以通过  useradd -d 指定目录 用户名  来新建一个用户，并且指定这个用户的 home 目录。 \n \n \n 给用户设置密码： \n passwd 用户名  --\x3e 回车 --\x3e 密码。 \n 注意，假如不写用户名，那就是给当前用户设置密码。 \n \n \n 删除用户： \n 删除用户有两种情况： \n \n 删除此用户，但是保留用户的目录： userdel 用户名 。 \n 删除此用户和此用户的目录： userdel -r 用户名 。 \n \n \n \n 查询用户信息： \n \n id 用户名 。 \n who am i ：查看第一次登陆到 Linux 的信息。 \n 用户组 \n 可以将某些用户分组，然后对他们进行统一管理，比如增删权限等。 \n \n \n 组的管理： \n \n 新增组： groupadd 组名 。 \n 删除组： groupdel 组名 。 \n \n \n \n 用户的管理组： \n \n \n 增加用户时直接加上组： useradd -g 用户组 用户名 。 \n 假如我们新建一个用户的时候没有指定组，那么 Linux 会根据这个用户新建一个组，组名是这个用户的名字，然后把用户放到这个组中。 \n \n \n 修改用户的组： usermod -g 用户组 用户名 。 \n \n \n \n \n 用户和组相关的文件： \n \n \n /etc/passwd ：用户 user 的配置文件，记录用户的各种表示信息。 \n 每当我们添加一个用户的时候，用户的信息就会保存到这里。 \n 每行的含义： 用户名:口令(加密的，用x显示):用户标识号(user的id):组标识号(group的id):注释性描述:主目录:登陆Shell 。 \n 这个登陆 Shell 其实就是一个翻译官，在控制台输入什么命令的时候（比如使用  cd ），Linux 内核是听不懂我们在干什么，我们需要将这个发给 Shell，然后由 Shell 翻译为 Linux 内核能够听懂的东西。 \n 一般来讲，我们的 Shell 用的是 bash（最多使用）/zsh，别的国家有的用 tcsh，csh。 \n \n \n /etc/shadow ：口令的配置文件。 \n 在上面的  /etc/passwd  我们说这个登录的口令是加密的，在那里用x表示，但是其实它最终是寻找的  /etc/shadow ，这里才是真正加密口令的存放位置。 \n 每行的含义： 登录名:加密口令:最后一次的修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志  这个加密口令在这里自然就是很长一串的加密密码，如果不设置他会使用  !!  来代替原来加密的密码。 \n 后面的修改时间，时间间隔啥的是用特殊数字来进行处理的。 \n \n \n /etc/group ：组的配置文件，记录Linux包含的组的信息。 \n 每行的含义： 组名:口令:组标识号:组内用户列表 。 \n 实用指令 \n 指定运行级别 \n 基本概述 \n 运行级别说明： \n \n 0：关机。 \n 1：单用户（找回丢失密码）。 \n 2：多用户状态没有网络服务。 \n 3：多用户状态有网络服务（用的最多）。 \n 4：系统未使用保留给用户。 \n 5：图形界面（用的也比较多）。 \n 6：系统重启。 \n \n 常用运行级别是 3 和 5，也可以指定默认的运行级别。 \n 应用实例： init[0 1 2 3 4 5] ：用 init 来切换不同的运行级别，比如 init 3 。 \n 指定默认运行级别 \n \n 指定为3运行级别： systemctl set-default multi-user.target 。 \n 指定为5运行级别： systemctl set-default graphical.target 。 \n \n 为什么要这样指定呢，因为在 CentOS7 之前，我们要修改运行级别必须要去  /etc/inittab  文件中修改。而这个文件中 3 级别就是  multi-user.target ，5 级别就是  graphical.target 。改变了运行级别之后，我们再次启动这个 Linux，它会默认进入新指定的运行级别。 \n 查看当前的运行级别： systemctl get-default ，查看的结果不是显示 3 或者 5，而是显示  graphical.target  或者  multi-user.target 。 \n 找回Root密码 \n 在不同的版本，找回 root 密码的方式有些区别，在 CentOS7 及以后中： \n \n \n 启动系统，进入开机界面，在界面中按  e  进入编辑界面。 \n \n \n \n 找到以  Linux16  开头所在的行数。 \n \n \n \n 在行的最后写上  init=/bin/sh 。 \n \n \n \n 输入快捷键  ctrl+x ，进入单用户模式 \n \n \n 在光标闪烁处的位置输入  mount -o remount,rw / ，然后按回车 \n \n \n \n 在新的一行输入  passwd ，然后按键盘的回车，然后输入密码，然后确认密码。 \n \n \n 输入  touch /.autorelabel ，然后回车。 \n \n \n 输入  exec /sbin/init ，然后回车，等待系统自动修改密码（时间可能会有点长，但不是死机，耐心等待），然后系统会重启，密码生效。 \n 帮助指令 \n \n \n man  获得帮助信息： \n 基本语法：man[命令/配置文件]：获得帮助信息 \n 比如： man ls 。 \n \n \n \n help  指令： \n 基本语法： help 命令 ：获得 shell 内置命令的帮助信息，比如： help cd 。 \n \n \n 百度： \n 英语不好，看不懂提示的可以百度。 \n 文件目录 \n \n \n pwd ：显示当前目录的绝对路径。 \n \n \n ls ：显示当前目录的文件和目录。 \n 常用选项： \n \n -a ：显示当前目录所有的文件和目录，包括隐藏的。 \n -l ：以列表方式显示信息。 \n -h ：以人能够比较直观的方式显示大小。 \n \n 案例： ls -l -a 。 \n \n \n cd ：切换到指定目录。 \n 常用选项： \n \n ~ 或者 : ：回到自己家目录。 \n .. ：回到上一层目录。 \n \n 案例： cd ~ 、 cd : 、 cd .. \n \n \n mkdir ：创建目录。 \n 常用选项： \n \n -p ：创建多级目录。 \n \n 案例： mkdir -p /home/animal/dog 。 \n \n \n rmdir ：删除空目录，如果目录下有内容则不可删除。 \n 常用选项： \n \n \n rm -rf ：递归强制删除则需要使用命令 rm -rf 。 \n recursive ：递归， force ：强制。 \n \n \n 案例： rmdir /home/animal/dog ， rm -rf /home/animal 。 \n 注意，不要使用 rm -rf / ，这虽然是个梗，但是问题很严重，这种动作要非常谨慎。 \n \n \n touch ：创建一个文件。 \n 案例： touch hello.txt 。 \n \n \n \n \n \n cp ：拷贝文件到指定目录。 \n 常用选项： \n \n -r ：递归复制整个文件夹。 \n \n 案例： cp /home/test/hello.txt /home/animal/ ， cp -r /home/test/ /home/animal/ 。 \n 强制覆盖不提示的方式： \\cp ，比如 \\cp /home/test/ /home/animal 。 \n \n \n rm ：删除文件或者删除目录。 \n 常用选项： \n \n -r ：递归删除。 \n -f ：强制删除。 \n \n recursive：递归，force：强制。 \n 案例： rm -r /home/animal/ \n 强制删除不提示，带上  -f  即可，但是注意这个操作非常危险，你要知道自己在做什么。 \n \n \n mv ：移动文件和目录（或者重命名）。 \n 基本语法： \n \n mv oldNameFile.txt newNameFile.txt ：重命名。 \n mv /home/animal/hello.txt /home/test/ ：移动，移动可以移动文件夹或者文件。 \n mv /home/animal/hello.txt /home/test/hello2.txt ：移动并且重命名。 \n \n \n \n cat ：查看文件但是不能修改。 \n 常用选项： \n \n -n ：显示行号。 \n \n 案例： cat -n hello.txt 。 \n cat 只能浏览文件，而不能修改，为了方便，我们一般要带上管道命令  | more 。也就是  cat -n hello.txt | more 。 more 可以分批查看文件，一次不会全部进行显示。 \n 管道命令就是将前面的结果再次交个下一个命令进行处理，管道命令就是  | ，下一个命令比如说  more 。 \n \n \n more ：more 是一个基于 vi 编辑器的文本过滤器，它以全屏的方式按页进行显示文本文件的内容，more 指令中内置了若干快捷键。 \n 常用选项： \n \n 空格：向下翻一页。 \n 回车：向下翻一行。 \n q ：立刻离开 more，不再显示其他内容。 \n Ctrl+F ：向下滚动一屏。 \n Ctrl+B ：向上滚动一屏。 \n = ：输出当前行的行号。 \n :f ：输出文件名和当前行的行号。 \n \n 案例： more 文件 。 \n \n \n less ：分屏查看文件内容，功能类似 more，但是比 more 更加强大，支持各种显示终端。 \n less 在查看文件内容时，并不是一次加载到内存中，而是随用随加载，所以对大文件有较高的效率。 \n 常用选项： \n \n 空格：向下翻一页。 \n [pagedown]：向下翻一页。 \n [pageup]：向上翻一页。 \n /字符串 ：向下搜索字符串，使用  n  向下查找，使用  N  向上查找。 \n ?字符串 ：向上搜索字符串，使用  n  向上查找，使用  N  向下查找。 \n q ：退出 less。 \n \n 案例： less 文件 。 \n \n \n \n \n \n echo ：输出内容到控制台。 \n 案例： echo "hello,world" ， echo $PATH ：输出环境变量。 \n \n \n 重定向： \n 重定向的意思是指使用文件来代替标准输入、标准输出、标准错误输出。 \n 比如说，平常使用  echo  将会打印到终端上，但是使用了重定向之后，完全可以打印到某个文件中。 \n \n \n \n \n 代码 \n 运算符 \n \n \n \n \n 标准输入 \n 0 \n < 或 << \n \n \n 标准输出 \n 1 \n > 或 >> \n \n \n 标准错误输出 \n 2 \n 2> 或 2>> \n \n \n \n 在这其中，有一个箭头的表示使用覆盖的方式进行重定向，两个箭头的方向表示使用追加的方式来重定向。 \n 例如  echo "HELLO WORLD" >> /dev/null ，这代表着我们将标准输出输出到了  /dev/null  中，这个路径相当于是一个垃圾桶，输出的内容就丢弃了，但是我们也完全可以输出到某个文件中。 \n 假如我们需要将标准输出和错误输出重定向到一个文件，那就必须将某个输出转换为另一种输出，例如将错误输出转换为标准输出，然后随着其他的标准输出一起重定向到另一个文件中。 \n 2>&1  代表着将标准错误输出转换为标准输出，如果需要同时输出到一个文件中，比如  ll > log 2>&1 ，表示错误输出转换为标准输出，同时输出到 log 文件中。 \n \n \n head ：显示文件开头部分的内容，默认情况下显示文件的前十行内容。 \n 常用选项： \n \n -n 行 ：查看文件头指定行内容，n 可以为任意数字。 \n \n 案例： head 文件 ， head -n 5 文件 。 \n \n \n tail ：输出文件末尾的内容，默认显示文件的后十行内容。 \n 常用选项： \n \n -n 行 ：查看文件头指定行内容，n 可以为任意数字。 \n -f ：实时追踪文档的所有更新。 \n \n 案例： tail  文件， tail -n 5  文件， tail -f  文件。 \n 注意，这个  tail -f  看日志必备，使用了这个命令之后，它就会在控制台中实时输出这个文件的输出。 \n 退出使用  Ctrl+C 。 \n \n \n \n \n \n ln ：软链接，也叫做符号链接，类似 windows 里面的快捷方式，主要存放了链接其他文件的路径。 \n 基本语法： ln -s [原文件/目录] [软链接名] \n 案例： \n \n ln -snf /root/ /home/myroot 。 \n rm /home/myroot ：注意， rm /home/myroot/ ，也就是最后带上  /  的时候，Linux 会认为是一个目录，会将数据全部删除，而不是删除软连接保留数据。 \n \n \n \n history ：查看已经执行过的历史命令，也可以执行历史命令。 \n 基本语法： history 。 \n 常用选项： \n \n n ：用于查看最近的 n 条命令。 \n !n ：重新执行历史编号为 n 的命令。 \n \n 案例： history 10 ， !5 。 \n 时间日期类 \n \n \n 显示时间 \n \n date ：显示当前时间。 \n date +%Y ：显示当前年份。 \n date +%m ：显示当前月份。 \n date +%d ：显示当前是哪一天。 \n date +"%Y-%m-%d %H:%M:%S" ：年-月-日 时：分：秒。 \n \n 案例： date +"%Y-%m-%d %H:%M:%S" ，显示时间的  年-月-日 时：分：秒 。 \n 为什么说到了年月日时分秒的时候要用一个字符串包起来呢，这是因为加号管不到空格之后的东西。 \n \n \n 设置时间： \n 基本语法： date -s 字符串时间 。 \n 案例： date -s 2020-11-03 20:02:10 。 \n \n \n cal ：查看日历，不加选项则显示本月日历。 \n 常用选项： \n \n 日期：直接显示对应的日期的时间。 \n \n 案例： cal ， cal 2020 。 \n 搜索查找类 \n \n \n find ：从指定的目录向下递归，查找满足条件的文件或者目录，并显示在终端。 \n 常用选项： \n \n -name ：查找文件名字，也可以使用通配符。 \n -user ：查找属于指定用户的文件。 \n -size ：查找指定大小的文件，其中使用 + 代表大于， - 代表小于，不写为等于，单位有 K，M，G。 \n \n 案例： find /home -name hello.txt ， find /home -user tom ， find /home -size +200M 。 \n \n \n localte ：快速定位文件的位置。 \n 在使用 locate 命令之前必须先使用 updatedb 来创建数据库，然后才能使用 locate 命令。 \n 因为它的快速定位是基于数据库来进行查询的，所以才如此快。 \n 案例： updatedb ， locate hello.txt 。 \n \n \n which ：可以查看某个指令在哪个目录下。 \n 案例： which ls 。 \n \n \n grep、| ：过滤查找  grep  和管道符  |  天生一对，表示将前一个命令的处理结果输出传递给管道符后面的命令处理。 \n 基本语法： grep 查找内容 源文件 。 \n 常用选项： \n \n -n ：显示匹配行和行号 \n -i ：忽略字母大小写 \n \n 案例： \n 在hello.txt中查询yes的所在行并且显示行号。 \n \n cat /home/hello.txt | grep -n "yes" 。 \n grep -n "yes" /home/hello.txt 。 \n \n 以上的两个都是可以的，两种写法都正确。 \n 压缩和解压 \n \n \n gzip/gunzip ：gzip 用于压缩文件，gunzip 用于解压文件。 \n gzip 只能将文件压缩为  .gz  文件。 \n 案例： gzip hello.txt ， gunzip hello.txt.gz 。 \n \n \n zip/unzip：zip 用于压缩文件，unzip 用于解压文件，这两个命令在项目打包发布的时候十分有用。 \n 基本语法： \n \n zip： zip xxx.zip 要压缩的目标 \n unzip： unzip xxx.zip \n \n zip 常用选项： \n \n -r ：递归压缩，也就是用于压缩目录。 \n \n unzip 常用选项： \n \n -d<目录> ：指定解压后文件的存放目录。 \n \n 案例： zip -r tom.zip tom/ ， unzip tom.zip -d /home/test/ \n \n \n tar ：tar 指令可以做打包（文件或者文件夹），或者解压。 \n 打包后的文件是 .tar.gz 的文件。 \n 基本语法： \n \n tar xxx.tar.gz 打包的内容 。 \n \n 常用选项： \n \n -c ：产生 .tar 打包文件。 \n -v ：显示详细信息。 \n -f ：指定压缩后的文件名。 \n -z ：打包同时压缩。 \n -x ：解包 .tar 文件。 \n \n 案例： \n \n 压缩多个文件： tar -zcvf AB.tar.gz A.txt B.txt 。 \n 解压文件： tar -zxvf AB.tar.gz 。 \n 解压文件到指定的temp文件夹下面： tar -zxvf /home/tom/AB.tar.gz -C /home/temp/ 。 \n 组管理和权限管理 \n 组 \n Linux组的基本介绍 \n Linux中的用户必须属于一个组，不能独立在组之外。假如不给用户一个组，那么 Linux 会根据它的用户名创建一个和它用户名相同的组，然后将用户放进去。我们也可以使用指令更改用户所在的组。 \n 在 Linux 中，对于文件来说，每个文件有所有者、所在组、其他组的概念： \n \n 所有者。 \n 所在组。 \n 其他组。 \n 改变用户所在的组。 \n 所有者 \n \n 当我们使用  ls  指令来查看内容的时候，我们会看到最右边是文件夹/文件的名称，最左边的用户其实是所有者的意思。也就是红框的内容中，第一个内容是所有者，第二个内容是文件。 \n 在所有者的问题上，有如下指令： \n \n \n 修改文件的所有者： chown 用户名 文件名 \n 组的创建和更改 \n \n \n gruopadd 组名 ：组的创建。 \n 接下来我们要创建一个用户组 monster，然后创建一个用户并指定这个用户的用户组为 monster。 \n \n 我们使用一个用户创建文件，这个文件的默认所有者是该用户，我们这个文件默认的所在组是改用户所在的组。 \n 但是这个时候要注意了，假如我们修改了这个文件的所有者，这并不意味这个文件的所在用户组也进行了更改。 \n \n 我们来看， A.txt  的所在用户从 tom 改为了  root ，但是第二个（用户组）没有发生改变，还是 tom。 \n \n \n chgrp 组名 文件名 ：组的更改。 \n \n 成功地将文件 A 的默认用户组改为了 monster。 \n 改变用户所在的组 \n 在添加用户时，可以指定将该用户添加到那个组中，同样的用 root 的管理权限可以改变某个用户所在的组。 \n 改变用户所在组： \n \n usermod -g 新组名 用户名 。 \n usermod -g 目录名 用户名 改变该用户登录的初始目录 。 \n \n 说明：用户需要有进入到新目录的权限，假如权限不够就会很麻烦。比如用户 tom 竟然想要进入 root 目录，那这肯定是不可以的。 \n 案例： usermod -g monster tom 。 \n 权限 \n 权限的基本介绍 \n \n \n 文件介绍： \n 在我们使用  ls -l  显示文件内容的时候，会出现如下内容： \n -rw-r--r-- 1 root root 52894708 Dec 11 10:45 System.war\n \n 1 第 0-9 位确定文件，在这里就是 -rw-r--r-- \n \n \n 第 0 位确定文件的类型，这里就是  - ： \n \n l ：链接，相当于 windows 的快捷方式。 \n d ：目录，相当于 windows 的文件夹。 \n c ：字符设备文件，比如鼠标和键盘。 \n b ：块设备，比如硬盘。 \n - ：普通文件。 \n \n \n \n 第 1-3 位确定文件/文件夹所有者拥有该文件的权限，这里就是 rw- ： \n 文件的所有者就是  root ，1后面的那个第一个  root  代表文件的所有者。 \n \n \n 第 4-6 位确定所属用户组的用户拥有该文件的权限，这里就是  r-- ： \n 第二个  root  代表这个文件的所属组，这里的  r--  就是所属组中，组员对此文件的权限。 \n \n \n 第 7-9 位确定其他用户拥有该文件的权限，这里就是  r-- 。 \n \n \n \n \n 权限的  r、w、x ： \n \n \n 对于文件来讲： \n \n r ：read：可以读，查看。 \n w ：write：可以修改，但是不代表可以删除文件，只有对目录有写权限才能删除此文件。 \n x ：execute：可以被执行。 \n \n 对目录有 w 权限，那么才可以删除文件。 \n \n \n 对于目录来讲： \n \n r ：read：可以读，ls查看目录内容。 \n w ：write：可以修改，对目录内创建+删除+重命名。 \n x ：execute：可以进入该目录。 \n \n 在 Linux 中，我们也可以使用数字来表示权限： \n \n r = 4 。 \n w = 2 。 \n x = 1 。 \n \n 按照这个来推断， rwx  是 7， rw-  是 6，...... \n \n \n \n \n 其他说明： \n -rw-r--r--  1  root root  52894708  Dec  11   10 :45 System.war\n \n 1 \n 1 ：文件的硬连接数  或者  目录的子目录数+文件数。 \n root ：用户（第一个 root）。 \n root ：所在组（第二个 root）。 \n 52894708 ：文件大小（字节）。 \n Dec 11 10:45 ：最后文件修改日期。 \n System.war ：文件名。 \n 修改权限 \n 我们可以使用  chmod  指令，来将文件或者目录的权限进行修改。 \n 在修改权限之前，先说一下角色： \n \n u ：user，代表文件/目录的所有者。 \n g ：group，代表文件/目录的所在组。 \n o ：other，代表相对于文件/目录来说的其他人。 \n a ：all，代表对于文件/目录来说的所有人。 \n \n 修改权限： \n \n \n 第一种方式修改权限： \n 对于这几种角色来说，有下面几种方式来赋于权限： \n \n = ：直接重置某个角色的权限。 \n + ：向某个角色追加新的权限。 \n - ：删除某个角色已有的权限。 \n \n 案例： \n \n chmod u=rwx,g=rx,o=x 目录/文件 ：更改 user 权限为 rwx，所在组为 rx，其他为 x。 \n chmod o+w 目录/文件 ：向其他人追加  w  权限。 \n chmod a-x 目录/文件 ：所有人删除  x  权限。 \n \n \n \n 第二种方式修改权限： \n 我们之前在基本介绍的时候，曾经说过我们的 Linux 可以使用数字来表示权限： r=4、w=2、x=1 。 \n 所以我们也可以直接使用数字来修改权限。 \n 案例： chmod 761 文件/目录 ，这个等同于  chmod u=rwx,g=rw,o=x abc 。 \n 修改文件所有者、修改文件所在的组 \n \n chown newowner 文件/目录 ：改变此文件的所有者。 \n chown newowner:newgroup 文件/目录 ：改变所有者和所在组。 \n chgrp newgruop 文件/目录 ：改变文件/目录所在的组。 \n -R ：假如是目录，那么则使其下所有子文件或者目录递归生效。 \n 定时任务调度 \n crond 定时任务调度概述 \n 简单来说，Linux 中可以有一个定时任务调度的说法，也就是说我们可以指定在某一个时间就执行一次我们指定的任务 \n 这种任务往往是一种周期性任务，比如说 MySQL 的备份，病毒的扫描，.... \n 我们说的这个任务不仅仅是 Linux 中的命令，还有程序。 \n crond \n \n \n crontab ：我们使用 crontab 来进行定时任务的设置。 \n 基本语法： corntab [选项] 。 \n 常用选项有这么几种： \n \n -e ：编辑 crontab 定时任务。 \n -l ：查询 crontab 任务。 \n -r ：删除当前用户所有的 crontab 任务。 \n service crond restart ：重启任务调度。 \n \n 我们使用  crontab -e  之后就可以点击回车了，会进入一个类似 vim 编辑器的东西，在那里我们输入指定的时间和命令。 \n \n \n \n 时间介绍： \n 时间是这样定义的： * * * * * ，这样你可能看不懂，但是马上就会懂了 \n \n \n \n 项目 \n 含义 \n 范围 \n \n \n \n \n 第一个星 \n 一个小时的第几分钟 \n 0-59 \n \n \n 第二个星 \n 一天中的第几个小时 \n 0-23 \n \n \n 第三个星 \n 一个月中的第几天 \n 1-31 \n \n \n 第四个星 \n 一年中的第几月 \n 1-12 \n \n \n 第五个星 \n 一周中的星期几 \n 0-7（0和7都代表星期天） \n \n \n \n 看到这个有没有感觉有点熟悉，其实就是类似我们在学习 SpringBoot 中的 CRON 表达式。 \n \n \n 时间的特殊说明： \n 上面的特殊符号显然不能让我们满意，下面我们来搞一下特殊符号的说明。 \n \n \n \n 特殊符号 \n 说明 \n \n \n \n \n * \n 代表任何时间，比如第一个 * 就代表所有分钟就执行一次 \n \n \n , \n 代表不连续的时间，比如 "0 8,12,16 * * *" 就代表每天的8点0分、12点0分、16点0分就执行一次命令 \n \n \n - \n 代表连续的事件范围。比如 0 5 * * 1-6 ，就代表在周一到周六的凌晨5点0分执行命令 \n \n \n */n \n 代表隔多久执行一次，比如 */1 * * * * 代表每分钟执行一次 \n \n \n \n 我们看周和天，都是代表的天，只不过一个是代表周的天，一个是代表月的天，所以最好不要同时出现。假如我们定义一个，另一个只需要定义  *  就得了。 \n \n \n 案例： \n \n \n 案例一： \n 每隔一分钟将当前时间追加到  time.txt  文件中。 \n 方式一：写一个 crond 表达式，表达式的内容为： */1 * * * * date time.txt \n 方式二：写一个脚本，脚本将时间追加到 time.txt 中，然后crond表达式调用这个脚本 \n 命令如下  my.sh ： \n vim  my.sh\n date   >>  time.txt\n:wq\n crontab  -e\n*/1 * * * * ./my.sh\n:wq\n tail  -f time.txt\n \n 1 2 3 4 5 6 7 \n at \n \n \n at  介绍： \n crond  定时任务是反复执行的，但是  at  定时任务是一次执行的定时任务。 \n \n at 的原理是通过守护进程的方式在后台运行，检查作业队列来执行。 \n 默认情况下，atd 守护进程每 60 秒检查作业队列，有作业时，会检查作业运行时间，假如时间与当前时间匹配，则运行此作业。 \n at 命令是一次性的定时计划任务，执行完一个任务之后不再执行此任务。 \n 在使用 at 命令的时候，一定要保证 atd 进程的启动，可以使用指令来查看。 \n \n 使用  ps -ef ：这个  ps -ef  是用于检测当前执行的进程。我们再次使用管道符进行过滤，只需要过滤，查看是否有  atd  即可。 \n 例如，我现在使用： ps -ef | grep atd ： \n \n \n \n at 命令格式： \n at 【选项】 【时间】 ， ctrl + d  结束命令的输入。 \n \n \n \n 选项 \n 含义 \n \n \n \n \n -m \n 当指定的任务被完成之后，给用户发送邮件 \n \n \n 即使没有标准输出 \n \n \n \n -I \n atq的别名 \n \n \n -d \n atrm的别名 \n \n \n -v \n 显示任务将被执行的时间 \n \n \n -c \n 打印任务的内容到标准输出 \n \n \n -V \n 显示版本信息 \n \n \n -q<队列> \n 使用指定的队列 \n \n \n -f<文件> \n 从指定文件读入任务而不是从标准输入读入 \n \n \n -t<时间参数> \n 以时间参数的形式提交要运行的任务 \n \n \n \n 通过  atq  命令来查看系统中没有执行的任务。通过  atrm  来删除系统中的任务，根据 at 任务的编号删除。 \n \n \n \n 时间： \n at 的时间指定相对于crond比较复杂一些，但是仍然非常好理解，它有如下几种方式： \n \n 接受在当天的  hh:mm 形式指定，比如  04:00 代表当天的凌晨4点执行，假如今天过去了，那么明天执行。 \n 使用比较模糊的概念： midnight(深夜) 、 noon(中午) 、 teatime（饮茶时间，一般在下午四点） 。 \n 采用 12 小时 + AM/PM 的方式，比如： 8pm （下午8点）。 \n 采用具体日期，格式为： month day ，或者  mm/dd/yy ，或者  dd.mm.yy ，日期在时间后面，比如： 04:00 2021-03-1 。 \n 采用相对计时法，格式为： now + count time-units ，count 是时间数量，time-units 是时间单位，时间单位可以使用： minutes 、 hours 、 days 、 weeks ，比如： now + 5 minutes 表示 5 分钟之后执行。 \n 直接使用 today ， tomorrow 来指定完成命令的时间。 \n \n \n \n 案例： \n \n \n 两天后的下午五点执行指令  /bin/ls /home 。 \n第一步，输入完成之后回车 \nat 5pm +  2  days\n第二步，在回车之后的at输入框中输入指令，输入两次 ctrl+d ，注意是两次 \n/bin/ls /home\n \n 1 2 3 4 \n \n 使用 atq 来查看系统没有执行的任务。 \n \n \n 明天 17 点，输出时间到  /root/data100.log  文件中。 \n第一步，输入完成之后回车 \nat 5pm tomorrow\n第二步，在回车之后的at输入框中输入指令，输入两次 ctrl+d ，注意是两次 \n date   >  /root/date100.log\n \n 1 2 3 4 \n 磁盘分区与挂载 \n 磁盘分区与挂载原理介绍 \n \n \n Linux，无论是几个分区，分给几个目录使用，归根结底就是一块根目录  / ，只不过这个根目录中有很多分区，共同组成了文件系统。 \n \n \n Linux中采用了一个叫做  载入 ，或者叫  挂载  的处理方法，它的整个文件系统包含了一整套的文件和目录，并且将一个分区和一个目录联系起来。 \n 这么说可能有些难以理解，举一个例子，就是拿我们一开始创建 Linux 时的分区举例子： \n \n 我们看上面这张图，是我们一开始在创建 Linux 虚拟机的时候执行的，我们给了根目录 17G，给了 boot 目录1G，给了 swap2G。 \n 其实这些加起来是一块硬盘，只不过硬盘里面有几个分区，看下图： \n \n 假如我们还有另外一块硬盘，仍然可以这样挂载。 \n \n \n \n Linux硬盘 \n Linux硬盘分为两种类型： IDE  硬盘、 SCSI  硬盘，目前主流是  SCSI  硬盘。 \n \n \n 对于  IDE  硬盘，驱动盘标识符为  hdx~ ： \n 其中 hd 代表IDE硬盘，x为盘号(a为基本盘、b为基本从属盘、c为辅助主盘、d为辅助从属盘)，也可以记作第一块硬盘，第二块硬盘，第三块硬盘，第四块硬盘。 \n ~  代表硬盘中的分区，前四个分区用数字 1-4 表示，它们是主分区或者扩展分区，从 5 开始就是逻辑分区。 \n 比如  hda3  代表  第一个IDE硬盘第三主分区  或  第二个IDE硬盘第三扩展分区 。 \n 比如  hdb2  代表  第二个IDE硬盘第二主分区  或  第二个IDE硬盘第二扩展分区 。 \n \n \n 对于  SCSI  标识符为  sdx~ ： \n sd  代表  SCSI  硬盘， x  代表第几块硬盘， ~  代表硬盘中的分区。 \n 比如 sda1 代表SCSI硬盘中的第一块硬盘中的第一块分区。 \n \n \n 我们可以使用命令  lsblk  来查看硬盘的情况，使用  lsblk -f  可以查看更加详细的信息： \n 挂载的经典案例 \n 挂载 \n \n \n 准备硬盘： \n \n \n \n \n \n \n \n 分区 \n 首先重启系统，然后使用查看分区指令  lsblk 。 \n \n 我们可以看到  sdb  但是没有看到分区，这是因为我们只是添加了，但是没有进行分区，下面我们进行分区： \n 为了意思意思，分出一个区就可以了，分区命令  fdisk /dev/sdb ： \n \n m ：显示命令列表。 \n p ：显示磁盘分区，同  fdisk -l 。 \n n ：新增分区。 \n d ：删除分区。 \n w ：写入并退出。 \n \n 说明：开始分区后输入  n  新增分区，然后选择  p ，分区类型为主分区。两次回车默认剩余全部空间。最后输入  w  写入分区并推出，假如不保存退出输入  q 。 \n \n \n 这里的分区号注意了，数字是几就是几个磁盘分区，默认是 1 就是一个分区，2 就是两个分区....直到 4 就是四个分区。 \n \n 一路默认回车，但是注意到最后的时候输入  w  表示写入并退出。 \n \n \n \n 格式化： \n 分区之后还不能直接挂载，我们要对这个分区进行格式化，指定它的文件类型。 \n 格式化之后会给一个分区分配给一个 UUID，我们使用命令  lsblk -f  可以查看： \n \n 格式化： mkfs -t ext4 /dev/sdb1 \n 解释一下上面的格式化命令， ext4  是分区类型， sdb1  就是第二块硬盘的第一个分区。 \n \n \n \n 挂载： \n 我们现在在  /  下面创建一个目录  newdisk ，作为我们测试挂载的路径，但是注意，这个分区可以挂载到任何目录下面，只不过在根目录下比较好测试罢了。 \n mount /dev/sdb1 /newdisk/ \n \n \n \n 卸载： \n 假如因为种种原因，我想要卸载这个分区，那么只需要命令： umount /dev/sdb1 。 \n 卸载有两个注意点： \n \n 卸载硬盘之前要首先退出这个目录。 \n 卸载完成之后，硬盘中的文件不会消失。 \n \n \n \n 永久挂载： \n 用命令行挂载，重启之后会失效，所以我们需要永久挂载，永久挂载，需要修改  /etc/fstab  文件。 \n 添加完成之后，只需要执行  mount -a  那么就会立刻生效。 \n \n vim /etc/fstab 。 \n 新加上我们刚才挂载成功的 UUID，假如记不住，直接写上  /dev/sdb1  也行。 \n 磁盘情况查询 \n \n \n 查询系统整体磁盘使用情况： df -h 。 \n \n 我们说，假如文件的占用率已经达到 80% 及以上，那么就需要考虑空间清理或者扩容了。 \n \n \n 查询指定目录的磁盘占用情况： du -h 。 \n 默认为  du-h ，查询当前目录，有以下参数： \n \n -s ：指定目录占用大小汇总。 \n -h ：带计量单位。 \n -a ：含文件。 \n --max-depth=1 ：子目录深度。 \n -c ：列出明细的同时，增加汇总值。 \n \n 比如查询 /opt 的磁盘占用情况，深度为1： du -hac --max-depth=1 /opt 。 \n \n \n \n 下面有几个场景： \n \n \n 统计文件夹下文件的个数： \n ls -l /opt | grep "^-" | wc -l \n 首先查询出  /opt  下的所有文件，然后选择出以  -  开头的，也就是普通文件，然后使用  wc  统计个数，最后列出。 \n \n \n \n \n 统计文件夹下目录的个数： \n ls -l /opt | grep "^d" | wc -l \n \n \n 统计文件夹下文件的个数，包括子文件夹下： \n ls -lR /opt | grep "^-" | wc -l \n \n \n 统计文件夹下目录的个数，包括子文件夹： \n ls -lR /opt | grep "^d" | wc -l \n \n \n 以树状显示目录结构： \n tree /opt \n 注意，默认情况下没有安装 tree 指令，首先要安装tree： yum -y install tree \n Linux网络配置 \n Linux网络概述 \n 在我们一开始讲解Linux的时候，曾经讲过Linux的网络关系，现在再次进行一次讲解 \n VMWare 中，网络有这么几种： \n \n 桥接模式。 \n NAT 模式。 \n 仅主机模式。 \n 自定义。 \n LAN 区段。 \n \n 下面我们说一下几种模式的区别： \n \n \n 桥接模式： \n 它可以令 Linux 能够和外部进行通讯，只需要 Linux 和外部的主机在同一个网段下即可。 \n 比如现在张三有主机 A，虚拟机 B，王五有主机 C，虚拟机 D，子网掩码 255.255.255.0。 \n 这个时候张三的主机是 192.168.0.20，虚拟机是 192.168.0.80，所以张三的主机和虚拟机都是在一个网段下 \n 那么王五的主机是 192.168.0.30，它们三者共同在一个网段下，张三的虚拟机就可以直接和王五的主机通信。 \n 是这种方式有可能造成冲突，比如一个教室里面 300 个人，但是网段只有 255，那么肯定就会产生冲突。 \n 但是在这种模式下，A 可以找 C，C 也可以找 A。 \n \n \n NAT模式： \n 假如现在张三的主机 A、虚拟机 B，王五有主机 C。 \n A的 ip 为  192.168.0.20 ，B 的 ip 为  192.168.100.88 ，C的 ip 为  192.168.0.30 。 \n 那么这个时候，看似张三的虚拟机和另外两个不在同一个网段，但是在 NAT 模式下一切皆有可能。 \n 张三的主机 A 会生成一个对应的网卡，和 Linux 虚拟机在同一个网段下，比如  192.168.100.99 。 \n 那么 B 就可以和 A 进行互通，并且 B 可以根据 A 作为一个跳板去通信  192.168.0.xx  频段的内容。 \n 所以 NAT 模式就是我们说的网络地址转换模式，不造成 IP 冲突，这个时候虚拟机 B 可以和外部进行通信，但是这个时候注意，外部不能去访问内部的，也就是 C 不能找 B。 \n 假如一切都正常，检查一下电脑的防火墙是否关闭，关闭后再次测试。 \n \n \n 主机模式：不和外部进行通讯。 \n \n \n \n NAT详解 \n 那么我们根据 NAT 模式进行讲解，虚拟机是如何和外界进行网络通信的。 \n 首先我们来看下面这张图片，下面这张图片上面是来自电脑的网络配置，其中 VMWare Network Adapter VMnet8 指的就是 VMWare，可以很清楚的看到他们其实都在一个网段中: \n \n 在一个网段中的意思就是：两者可以相互 ping 通，假如 ping 通不了那么一定是 windows 防火墙的问题。 \n 那么在 windows 中还有一个 IP 地址，这个 IP 地址就是无线网络适配器，如下图： \n \n 这个无线局域网适配器也是放在电脑上面的，它承担了和互联网进行数据通信的工作，上面的这个其实是比较特殊的 IP 地址，正常的 IP 地址不会是 0。 \n 我们的 Linux 虚拟机和互联网进行通信其实是依靠了一个中间的代理网卡才能达到这种效果。 \n Linux网络配置指令 \n 查看网络和IP地址 \n \n \n 在 VMWare 下面查看网络： \n 上面我们在讲解 Linux 使用 NAT 模式是如何进行与互联网通信的过程中，曾经讲过有一个 Linux 的网络地址和 VMWare 网络地址，而 Linux 虚拟机想要和外部进行通信必须依靠 VMWare 这个外部地址： \n 那么有一个问题就来了：这两个网络的 IP 地址的网段为什么必须是   192.168.145.x  呢？ \n \n 其实这是因为我们是在 VMWare 中主动进行设置的，这个设置我们走的是默认情况，下面我们来查看： \n 打开 VMWare，编辑 --\x3e 虚拟网络编辑器，看到下面的图，这里定义了网段，所以我们的网段就是这么来的 \n \n 从这里，我们还可以看到 IP 的分配范围，点击 DHCP 设置，就可以看到他的分配范围： \n \n 我们还可以查看 NAT 设置，也可以看到它的网关： \n \n \n \n 查看 IP 配置： \n \n windows下面： ipconfig \n Linux下面： ifconfig \n 网络配置 \n 网络配置有两种情况： \n \n \n 自动获取 IP 地址（采用 DHCP 分配）。 \n \n \n 固定 IP 地址。 \n \n \n 这两者有分别的好处，自动获取IP地址可以尽量的避免网络冲突，在家用电脑上一般使用的就是这种配置。 \n 固定IP地址有可能会出现网络冲突，但是服务器一定要固定 IP 地址，才不会出现重启之后连接原来 IP 连不上的情况，或者你想搞一个主机作为代理设置，这个 IP 一定是固定的。 \n 我们这里主要讲的就是固定 IP 地址： \n 我们直接修改配置文件来制定 IP，并且可以连接到外网。 \n 只需要编辑  /etc/sysconfig/network-scripts/ifcfg-ens33  即可改变我们的配制。 \n 下面是实操部分，比如我们这里就要固定 IP 地址为  192.168.145.130 \n 这里说明一下  ifcfg-ens33  这个文件的内容 \n网络类型，通常就是Ethernet \n TYPE = "Ethernet" \n PROXY_METHOD = "none" \n BROWSER_ONLY = "no" \n分配方式，这里是DHCP，也就是自动分配的意思，我们可以改为static，为静态分配 \n BOOTPROTO = "dhcp" \n下面这个IP地址在原本的配置文件中是没有的，这段代码就是说假如是static，那么给网络分配什么具体的IP，我们分配时要加上 \nIPADDR=192.168.145.130 \n子网掩码，子网掩码在默认的这里也没有加，所以加上即可，三个255代表IP的前三位都是网段，后一位是IP地址分配 \nNETMASK=255.255.255.0 \n网关，这里的网关在配置文件中也是没有的，所以我们要加上网关的代码，这个网关注意用自己的网关，别照抄 \nGATEWAY=192.168.145.2 \n域名解析器，域名解析器在原本的配置文件中也是没有的，所以我们也需要手动添加，这个DNS也用自己的，别照抄 \nDNS1=192.168.145.2 \n如果觉得一个DNS解析器不保险，那么就多加几个 \nDNS2=8.8.8.8 \nDNS3=114.114.114.114 \n DEFROUTE = "yes" \n IPV4_FAILURE_FATAL = "no" \n IPV6INIT = "yes" \n IPV6_AUTOCONF = "yes" \n IPV6_DEFROUTE = "yes" \n IPV6_FAILURE_FATAL = "no" \n IPV6_ADDR_GEN_MODE = "stable-privacy" \n NAME = "ens33" \n唯一的随机标识符 \n UUID = "f85bd30f-ffea-47de-a768-a856fb61ada6" \n设备名字 \n DEVICE = "ens33" \n系统启动后网络接口是否有效，这里默认YES即可 \n ONBOOT = "yes" \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 下面我们直接给修改好的配置文件截张图即可 \n \n 假如我们还想让我们的 Linux 上网，那么还有一个步骤就是设置 VMWare 的 IP，因为我们刚才讲过 Linux 其实是利用 VMWare 这个代理网卡进行的网络通信。 \n 那么我们的Linux虚拟机的网段设置的是  192.168.145.xxx ，那么我们的 VM 应该也设置这个地址。 \n \n 注意，上面是 VMWare 的网卡配置而不是 Linux 的网卡配置，毕竟 Linux 的网卡我们刚才已经配置完成了，所以我们仍然需要 DHCP 去给 VMWare 分配 IP 地址。 \n 然后是 NAT 设置中配置网关，网关注意要和 Linux 配置的网关一样。 \n \n 完成之后，重启网络服务或者重启系统： \n \n service network restart \n reboot \n Linux 主机名和 hosts 映射 \n 为了方便记忆，我们可以给Linux设置主机名字，这样方便记忆 \n \n hostname ：查看主机名字。 \n /etc/hostname ：主机名字，可以直接使用 vi 编辑器修改，修改后重启机器。 \n \n 下面我们可以使用主机名字和 hosts 进行映射，这样就可以直接使用主机名字进行操作，比如 ping 操作。我们 ping 目标主机名字的时候直接 ping 是 ping 不通的，但是我们只需要进行主机的指定即可。 \n 在 windows 平台和 linux 平台有着不同的映射操作： \n \n windows： C\\Windows\\System32\\drivers\\etc\\hosts  中指定。 \n linux： /etc/hosts  文件中指定。 \n \n 直接使用 windows 的映射来举个例子，linux 也是一样的： \n \n \n 下面我们进行 linux 的配置，注意这个 IP 其实是 VMWare 的代理网卡的 IP，不要真搞成电脑的 IP。 \n \n \n \n Linux主机名和hosts映射的原理 \n Domain Name System：简称 DNS，翻译就是域名系统，他是互联网上作为域名和 IP 地址相互映射的一个分布式数据库。\nHosts：是一个文本文件，用来记录 IP 和 Hostname（主机名）的映射关系。 \n 进程管理 \n 进程管理基本介绍 \n 在Linux中，每一个执行的程序都叫做一个进程，每一个进程都有一个ID号（pid进程号）。每一个进程都可能以两种方式存在：前台和后台。 \n 前台的意思就是可以在用户目前的屏幕上可以进行操作的，后台的意思就是在屏幕上看不见，但是在默默运行。 \n 一般系统的服务都是以后台进程来存在的，而且都是常驻系统中，等到关机才结束。 \n ps指令详解 \n 我们可以通过 ps 来查看目前系统中，有哪些正在执行，以及他们执行的情况。可以不加任何参数，但是带出来的信息很少。 \n \n PS显示的信息选项 \n \n \n \n \n 字段 \n 说明 \n \n \n \n \n PID \n 进程识别号 \n \n \n TTY \n 终端机号 \n \n \n TIME \n 此进程所消CPU时间 \n \n \n CMD \n 正在执行的命令或者进程名 \n \n \n \n \n PS命令 \n \n \n ps -a ：显示当前终端的所有进程信息。 \n ps -u ：以用户的格式显示进程信息。 \n ps -x ：显示后台进程运行的参数。 \n \n 一般来讲，我们将这三个字段组合使用，并且还会组合管道符进行组合使用。 \n \n VSZ 和 RSS 的占用大小单位都是 KB。 \n STAT 的状态分为这么几个：S-睡眠、s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 \n COMMAND  是启动此进程的执行指令，假如太长会被截断，就是后面的那些进程。 \n 有时候，我们只关心某一个进程，所以可以加上一个管道符和 grep 来查看进程情况，比如我们查看 sshd 这个进程情况（SSHD 的作用就是远程登录）。 \n \n 其实只有最上面那一个代表的是我们这个 sshd 这个进程正在执行，下面的二三个是 root 用户登录进去的情况，最下面是我们刚才输入  ps -aux | grep sshd  查看的代码。 \n 父子进程 \n 在 Linux 中，有父子进程的概念，一个进程可以创建出子进程。 \n 比如现在我们有一个进程 A，进程 A 创建出了两个进程 A1 和 A2，那么 A1 和 A2 就是 A 的子进程。 \n 假如我们干掉了 A 这个父进程，它的子进程也都会一并被干掉，这样利于我们对系统的管理。 \n ps -ef  是以全格式显示所有进程， -e  代表所有进程， -f  代表全格式。 \n 我们再次以 sshd 这个进程来做演示，查看它的全格式： \n \n 然后我们再去看全格式的全部的内容： \n \n 从上图我们可以看出来，PID 为 1 的是刚才的 sshd 的父进程，PID 为 1 的这个进程的父进程是 0，但是这里又没有 0，所以我们可以得出这个结论：PID 为 1 的进程是最开始的一个根进程，它有很多子进程，其中就有一个 sshd 进程。 \n 终止进程 \n 假如一个进程执行了一半需要停止或者已经消耗了大量的系统资源，此时可以考虑停止此进程，使用 kill 命令来完成。 \n 基本语法 \n \n kill [选项] 进程号 ：通过进程号干掉进程。 \n killall 进程名称 ：通过进程名称干掉进程，支持通配符。 \n \n 注意，使用  killall  的方式干掉一个进程，那么他的子进程也会被干掉。 \n 常用选项： \n \n \n -9 ：强迫进程立刻停止。 \n 有时候系统认为这个进程十分重要，那么可能会忽略单纯的kill命令，这个时候  -9  就可以强制干掉进程。\n这个命令在干掉非法用户，终止远程登录服务，强制干掉某个终端等情况很有用。\n干掉进程之后，可以通过  /bin/systemctl start 服务名字  来启动这个服务进程，重新启动之后进程号会变化。\n举个例子，强制关闭终端（这个终端和远程登录没关系，远程登录是 sshd 服务起作用，终端指的是 linux 本机上运行的终端 bash），那么查看终端就是  ps -aux | grep bash ，强制关闭终端就是  kill -9 bash进程号 。 \n pstree \n 查看 linux 进程可以更加直观的查看进程信息。 \n \n pstree [选项] \n \n 常用选项 \n \n -p ：显示进程PID \n -u ：显示进程的所属用户 \n 服务管理 \n 服务管理基本介绍 \n 服务本身就是跑在后台的进程，通常都会监听某一个端口，等待其他程序的请求，比如MySQL、SSHD、防火墙等，因此我们又称为守护进程，是Linux种非常重要的知识点 \n \n service  管理指令： \n \n \n \n service 服务名 [start | stop | restart | reload | status] \n 选项就是这么几个：start 启动，stop 停止，restart 重启，reload 重载，status 查看状态。 \n \n \n 在 CentOS7.0 之后，很多服务不再使用  service ，而是使用  systemctl （后面专讲）。 \n \n \n 那么在 CentOS7.0 之后，可以继续使用 service 指令管理的服务在  /etc/init.d  中查看，绿色的仍然可以。 \n \n 到了 CentOS8 之后，network 也没了，service 命令基本凉透了。 \n \n \n \n 查看服务名字： \n \n 有两种方式： \n \n \n ls -l /etc/init.d ：这种方式可以查看有限的服务。 \n \n \n setup ：会出现一个弹框页面，选择系统服务回车就可以了，退出就按  tab  进入下面的退出选项。 \n \n \n 注意，在前面有星号的就是随着 Linux 启动自动启动的，没有的就是手动启动。使用空格可以切换是否自动启动。 \n 服务的运行级别（runlevel） \n Linux 有 7 种运行级别：常用级别是 3 和 5。 \n \n 运行级别 0：系统停机。 \n 运行级别 1：单用户工作状态，root 权限，用于系统维护，禁止远程登录。 \n 运行级别 2：多用户状态（没有 NFS），不支持网络。 \n 运行级别 3：完全多用户状态（有 NFS），登录后进入控制台命令行模式。 \n 运行级别 4：系统未使用，保留。 \n 运行级别 5：X11 控制台，登录后进入图形 GUI 模式。 \n 运行级别 6：系统正常关闭重启，默认级别不能运行 6，否则不能正常启动。 \n \n 开机流程： \n 开机->BIOS引导->/boot->systemd进程1->运行级别->运行级对应的服务 \n 运行级别介绍： \n 在  /etc/initab  可以进行设置，并且进行了简化： \n \n multi-user.target ：等同  analogous to runlevel 3 。 \n graphical.target ：等同  analogous to runlevel 5 。 \n \n 查看运行级别： \n 那么我们进行查看的指令： systemctl get-default ： \n \n 修改运行级别： \n \n systemctl set-default graphical.target 。 \n systemctl set-default multi-user.target 。 \n chkconfig \n 通过  chkconfig  命令可以给服务的各个运行级别设置自 启动/关闭。 \n 比如有一个服务，可以通过 chkconfig 设置在 0 级别中是自启动还是关闭，在 1 级别中是自启动还是关闭，在 2 级别中...，也就是说对于某一个服务，在不同的启动级别中它的启动时不同的 \n chkconfig指令管理的服务在  /etc/init.d  中查看，注意，在 CentOS7.0 后，很多服务使用  systemctl  管理自启动。 \n 基本语法： \n \n \n chkconfig --list [| grep xxx] ：查看服务。 \n \n \n \n chkconfig --level 级别 服务名 on/off ：设置这个服务在某一个级别下是自启动还是关闭状态 \n 比如设置network在5级别下自启动： chkconfig --level 5 network on \n systemctl \n \n \n 管理指令： \n \n 基本语法： systemctl [start | stop | restart | status] 服务名 \n systemctl 指令管理的服务在  /usr/lib/systemd/system  中查看。 \n \n \n \n 服务的关闭和启动和查看： \n \n systemctl stop 服务 ：启动。 \n systemctl start 服务 ：关闭。 \n systemctl status 服务 ：查看状态。 \n \n 比如防火墙： systemctl stop firewalld 、 systemctl status firewalld \n 细节讨论： \n 刚才我们关闭或者开启防火墙后，指令立刻生效。这种方式只是临时生效，当重启系统之后，还是回归之前对服务的设置 \n 如果设置某个服务永久自启动/关闭，要使用 systemctl [enable | disable] 服务名 。 \n \n \n systemctl 可以设置服务的自启动状态： \n \n systemctl list-unit-files [| grep 服务名] ：查看服务开机启动状态，grep 可以进行过滤。 \n systemctl enable 服务名 ：设置服务开机启动。 \n systemctl disable 服务名 ：关闭服务开机启动。 \n systemctl is-enabled 服务名 ：查询某个服务是否是自启动的。 \n 防火墙的端口设置 \n 我们在真正生产环境，肯定是打开防火墙的，但是我们又需要打开某一个端口，那么我们进行如下设置： \n \n firewall-cmd --permanent --add-port=端口号/协议 ：打开端口。 \n firewall-cmd --permanent --remove-port=端口号/协议 ：关闭端口。 \n firewall-cmd --reload ：重新载入才可以生效新的设置。 \n firewall-cmd --query-port=端口号/协议 ：查看某端口是否开放。 \n 动态监控 \n 动态监控，也就是说动态的监控进程，有一个指令叫做  top 。top 指令和 ps 指令其实差不多，但是最大的不同之处在于  top  一般用于某个时间范围内的查看情况。 \n 基本使用： \n \n top [选项] \n \n 选项说明： \n \n -d 秒数 ：指定top命令每隔几秒更新，默认是3秒。 \n -i ：使top不显示任何闲置或者僵死进程。 \n -p ：通过指定监控进程ID来仅仅监控某一个进程的状态。 \n \n \n 上面这张图涉及到的内容还是比较多的，从第一行开始看： \n 21 :43:57：代表的是当前时间\n3min：代表系统运行了多长时间\n 1  user：一个用户\nload average：负载均衡，这三个数全都加起来然后除3，只要没有超过70%就算可以\n\nTasks：263 total ： 代表了一共263个任务数\n 1  running：一个正在运行的任务\n 262  sleeping：262个休眠的任务\n 0  stopped：没有停止的任务\n 0  zombie：没有僵死的任务\n\n 0 .0us：us指的是user，代表了用户占用CPU资源为0%\n 0 .1sy：sy是system，代表了系统占用0.1%的CPU资源\nid：Idle，空闲，系统空闲了99.9%的CPU\n\n 2028116  total：总共的内存资源为这些\n 1171352  free：内存资源有这些剩余\n 431064  used：内存用了这些\n 425700  buff/cache：这些作为缓存\n\n 2097148  total：总共这些Swap，Swap我们一开始分配资源的时候说过是分区\n剩下的和内存差不多\n 1382232  avalil Mem：这些可以申请的空间\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n 注意一下僵死进程：程序死了但是内存没有释放，这就叫做僵死进程，出现僵死进程就会占用正常进程的资源。 \n \n \n top动态监控中的交互 \n \n \n \n 操作 \n 功能 \n \n \n \n \n P \n 以CPU使用率排序，默认就是此项 \n \n \n M \n 以内存的使用率排序 \n \n \n N \n 以PID排序 \n \n \n q \n 退出top \n \n \n \n 监控指定用户： top  -> 回车 -> 输入  u  -> 回车 -> 输入用户名 -> 回车。 \n 终止指定的进程： top  -> 回车查看执行的进程 -> 输入  k  -> 回车 -> 输入要结束的进程 ID。 \n \n 监控网络状态 \n 基本语法： \n \n netstat [选项] \n \n 选项说明： \n \n -an ：按照一定的顺序排列输出。 \n -p ：显示按照哪个进程在调用。 \n \n \n 上面图片的信息其实还是比较多的： \n \n Proto：协议，我们可以看到下面有这种协议 tcp 的，tcp6 的、 \n Local Address：本机的地址，可以理解为 Linux 的地址，后面有 IP:端口，其中 0.0.0.0 和 127.0.0.1 都代表本地。 \n Foreign Address：外部地址。 \n 可以看到有两个端口的外部地址和本机的一个地址相互联通了，State 是 Establish，学计算机网络的时候三次握手有这个状态。 \n 可以看到 tcp6 的 LocalAddress 是三个冒号拼一个端口号，这是 IPv6 的写法，兼容 IPv4 和 IPv6。 \n \n 应用案例： \n \n 查看服务名称为 sshd 的服务信息： netstat -anp | grep sshd 。 \n 检测主机连接命令：ping。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 16, 2021 20:13",createTimeStamp:1629115991e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"causes",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Linux-03-安装配置",frontmatter:{title:"Linux-03-安装配置",categories:["base"],tags:["linux"],author:"causes",summary:"RPM 包的管理 RPM 介绍 rpm 用于互联网下载包的打包和安装工具，它包含在某些 Linux 发行版中。 它生成具有 .RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 Windows 的 setup.exe。 RPM 包的管理 rpm 包的简单查询指令：; 查看已经安装的 rp",meta:[{property:"og:url",content:"/base/Linux/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Linux-03-安装配置"},{property:"og:description",content:"RPM 包的管理 RPM 介绍 rpm 用于互联网下载包的打包和安装工具，它包含在某些 Linux 发行版中。 它生成具有 .RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 Windows 的 setup.exe。 RPM 包的管理 rpm 包的简单查询指令：; 查看已经安装的 rp"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"linux"}]},regularPath:"/base/Linux/part3.html",relativePath:"base/Linux/part3.md",key:"v-15fe0334",path:"/base/Linux/part3/",headers:[{level:2,title:"RPM 包的管理",slug:"rpm-包的管理"},{level:3,title:"RPM 介绍",slug:"rpm-介绍"},{level:3,title:"RPM 包的管理",slug:"rpm-包的管理-2"},{level:2,title:"YUM",slug:"yum"},{level:3,title:"YUM 介绍",slug:"yum-介绍"},{level:3,title:"YUM 指令",slug:"yum-指令"},{level:2,title:"搭建 JavaEE 环境",slug:"搭建-javaee-环境"},{level:3,title:"环境介绍",slug:"环境介绍"},{level:3,title:"安装 JDK",slug:"安装-jdk"},{level:3,title:"安装 tomcat",slug:"安装-tomcat"},{level:3,title:"配置 MySQL5.7",slug:"配置-mysql5-7"}],readingTime:{minutes:3.36,words:1008},content:" RPM 包的管理 \n RPM 介绍 \n rpm 用于互联网下载包的打包和安装工具，它包含在某些 Linux 发行版中。 \n 它生成具有 .RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 Windows 的 setup.exe。 \n RPM 包的管理 \n \n \n rpm  包的简单查询指令： \n 查看已经安装的 rpm 列表： rpm -qa | grep xx \n 举例：查看当前系统是否安装了 firefox： rpm -qa | grep firefox \n 一个 rpm 包名包含：\n- 一个包名： firefox-60.2.2-1.el7.centos.x86_64 \n- 名称： firefox \n- 版本号： 60.2.2-1 \n- 适用操作系统： centos.x86_64 \n 如果是  i686 、 i386  表示 32 位系统， noarch  表示通用。 \n \n \n rpm 包的其他指令： \n \n rpm -qa ：查询所安装的所有 rpm 软件包。 \n rpm -qi 软件包名 ：查询软件包信息。 \n rpm -ql 软件包名 ：查询软件包里的文件。 \n rpm -qf 文件全路径名 ：查询文件所属的软件包。 \n \n \n \n 卸载 RPM 包 \n \n 基本语法： rpm -e 软件包名称 ，比如： rpm -e firefox  。 \n \n 假如其他软件包依赖于这次要卸载的软件包，它可能会出现错误信息。\n假如要强制删除此软件包，使用： rpm -e --nodeps 软件包名 。 \n \n \n 安装 rpm 包： \n \n 基本语法： rpm -ivh rpm包全路径名称 ，比如： rpm -ivh /xxx/firefox \n 参数说明：\n \n i = install：安装。 \n v = verbose：提示。 \n h = hash 进度条。 \n YUM \n YUM 介绍 \n yum，一个 Shell 前端软件包管理器，基于 RPM 包管理，能够自动从指定的服务器中下载 RPM 包并进行安装，可以自动处理依赖关系，并且一次性安装所有依赖软件包。 \n YUM 指令 \n \n yum 的基本指令：\n \n yum list | grep xxx ：查询 yum 服务器是否有需要安装的软件。 \n yum install xxx ：下载安装软件，比如： yum -y install firefox 。 \n 搭建 JavaEE 环境 \n 环境介绍 \n 如果需要在 Linux 环境下进行 JavaEE 的开发，则需要如下软件： \n \n IDEA \n Apache-Tomcat \n MySQL \n JDK \n 安装 JDK \n \n \n mkdir /opt/jdk \n \n \n 通过 xftp6 上传到  /opt/jdk  下。 \n \n \n cd /opt/jdk \n \n \n 解压  tar -zxvf jdk-8u-xxx \n \n \n mkdir /usr/local/java \n \n \n mv /opt/jdk/jdk1.8.0xxx /usr/local/java \n \n \n vim /etc/profile \n \n \n 编辑对应的内容： \n export   JAVA_HOME = /usr/local/java/jdk1.8.0xxx\n export   PATH = $JAVA_HOME /bin: $PATH \n \n 1 2 $JAVA_HOME/bin:$PATH  后面一定要将  $PATH  带进去，假如不加这个，那么 PATH 将只剩下这一个路径了，原先的环境变量就给破坏了。 \n \n \n source /etc/profile ：让文件生效。 \n \n \n 测试是否安装成功，编写一个简单的 Hello.java 输出 Hello World。 \n 安装 tomcat \n \n 上传安装文件，并且解压至  /opt/tomcat \n 进入解压目录  /bin ，启动tomcat： ./startup.sh \n 开放端口  8080 \n 测试是否安装成功：在 windows/linux 下面访问  http://linuxip:8080 \n 配置 MySQL5.7 \n \n \n 新建文件夹 /opt/mysql ，然后进入。 \n \n \n 通过网络获取 MySQL 安装包。 \n wget  http://dev.mysql.com/get/mysql-5.7.26-1.el7.x86_64.rpm-bundle.tar\n \n 1 \n \n 解压  tar -xvf xxx.tar \n \n \n 运行  rpm -qa | grep mari ，查询 mariadb 相关安装包。 \n \n \n 运行  rpm -e --nodeps mariadb-libs ，卸载。 \n \n \n 然后开始真正安装 MySQL，依次运行如下几条命令： \n \n \n \n 运行 systemctl start mysqld.service ，启动 MySQL \n \n \n 开始设置 root 用户密码。 \n MySQL 会自动给 root 用户设置用户密码，运行 grep \"password\" /var/log/mysqld.log 可以查看当前密码 \n \n \n 运行  mysql -uroot -p ，用 root 用户登录，输入上述密码，可以成功进入 MySQL 命令行。 \n \n \n 可以重设 root 密码，对于个人开发环境要设置简单密码即可。 \n 可以运行  set global validate_password_policy=0  提示密码设置策略。 \n validate_password_policy 默认为 1。 \n MySQL 密码复杂度有三种： \n \n 低：0 or low：只要求长度（默认为8位）。 \n 中：1 or MEDIUM：要求长度、数字、大小写和特殊字符。 \n 高：2 or STRONG：要求长度、数字、大小写、特殊字符和字典文件。 \n \n \n \n set password for 'root'@'localhost'=password('密码') 。 \n \n \n 运行  flush privileges  使密码生效。 \n \n \n",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"August 16, 2021 22:13",createTimeStamp:162912318e4,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1}]},{title:"Linux-04-Shell",frontmatter:{title:"Linux-04-Shell",categories:["base"],tags:["linux"],author:"causes",summary:"Shell 概述 Shell 俗称壳，是用来和操作系统打交道的一层马甲。同时 Shell 也是一种程序设计的语言，是一个用 C 编写的程序，是使用 Linux 的桥梁。 我们的 Shell 脚本就是使用 Shell 语言，为 Shell 编写的脚本程序。我们之后的 Shell 都作为 Shell 脚本编程，而不是开发 Shell 本身。 Shell 环境 L",meta:[{property:"og:url",content:"/base/Linux/part4.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Linux-04-Shell"},{property:"og:description",content:"Shell 概述 Shell 俗称壳，是用来和操作系统打交道的一层马甲。同时 Shell 也是一种程序设计的语言，是一个用 C 编写的程序，是使用 Linux 的桥梁。 我们的 Shell 脚本就是使用 Shell 语言，为 Shell 编写的脚本程序。我们之后的 Shell 都作为 Shell 脚本编程，而不是开发 Shell 本身。 Shell 环境 L"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"linux"}]},regularPath:"/base/Linux/part4.html",relativePath:"base/Linux/part4.md",key:"v-0ee1abb8",path:"/base/Linux/part4/",headers:[{level:2,title:"Shell 概述",slug:"shell-概述"},{level:2,title:"变量和注释",slug:"变量和注释"},{level:2,title:"字符串",slug:"字符串"},{level:2,title:"传递参数",slug:"传递参数"},{level:2,title:"数组",slug:"数组"},{level:2,title:"表达式（运算符）",slug:"表达式-运算符"},{level:2,title:"echo 与 printf",slug:"echo-与-printf"},{level:2,title:"流程控制",slug:"流程控制"},{level:2,title:"函数",slug:"函数"},{level:2,title:"重定向",slug:"重定向"},{level:2,title:"引用外部文件",slug:"引用外部文件"}],readingTime:{minutes:7.97,words:2391},content:' Shell 概述 \n Shell 俗称壳，是用来和操作系统打交道的一层马甲。同时 Shell 也是一种程序设计的语言，是一个用 C 编写的程序，是使用 Linux 的桥梁。 \n 我们的 Shell 脚本就是使用 Shell 语言，为 Shell 编写的脚本程序。我们之后的 Shell 都作为 Shell 脚本编程，而不是开发 Shell 本身。 \n Shell 环境 \n Linux 的 Shell 种类众多，常见有： \n \n Bourne Shell： /usr/bin/sh  或  /bin/sh \n Bourne Again Shell： /bin/bash \n Shell for Root： sbin/sh \n …… \n \n 因为免费、易用，在中国广泛用到的都是 Bash（Bourne Again Shell），同时 Bash 也是大多数 Linux 的默认 Shell。一般情况下我们不区分。Bourne Shell 和 Bourne Again Shell。 \n 所以  #!/bin/sh ，它同样也可以改为  #!/bin/bash 。 \n 快速起步 \n 新建文件  hello.sh ，输入以下内容： \n #!/bin/bash \n echo   "HELLO WORLD" \n \n 1 2 之后在命令行中，使用  sh hello.sh  来执行脚本，控制台上将会打印出  HELLO WORLD 。还可以使用  chmod  给与脚本可执行权限，即可不加  sh  命令执行。 \n 在上面这个脚本中： \n \n #!/bin/bash  是一个约定标记，告诉系统应该使用  /bin/bash  这个 shell 来执行脚本，我们自然也可以换为其他的。 \n echo  是一个命令，用于向窗口输出文本。 \n 变量和注释 \n 变量基本使用 \n 在 Shell 中，定义变量不需要加任何修饰符，但是引用变量需要加入  $  符号引用，定义变量有如下注意点： \n \n 只能用英文、数字、下划线，首个字符不可使用数字。 \n 变量和等号中间不可使用空格。 \n 不可使用 bash 中的关键字。 \n \n #!/bin/bash \n定义变量 \n shell = "SHELL" \n使用变量，也可以使用 ${shell} 的方式来使用 \n echo   $shell \n更改变量的值 \n shell = "shell" \n删除变量，从这一行往下，shell 这个变量就被删除了 \n unset  shell\n定义只读变量，只读变量不可更改，不可删除 \n readonly   name = "tom" \n \n 1 2 3 4 5 6 7 8 9 10 11 变量作用范围 \n 在 shell 中，变量有三种作用范围： \n \n 局部变量：作用于单个的 shell 脚本，或者单个脚本的某块语句。 \n 环境变量：作用于所有程序，包括 shell 启动的程序。环境变量可以保证某些程序的正常运行，必要时可以使用 shell 脚本来定义。 \n shell 变量：shell 中的特殊变量，shell 变量中有一部分是环境变量，有一部分是局部变量。 \n \n 注释 \n 在 shell 中单行注释使用  #  开头。多行注释使用以下格式： \n : << EOF\n多行注释方式 1\nEOF \n\n: << ! \n多行注释方式  2 \n ! \n\n: << \'\n多行注释方式 3\n\' \n \n 1 2 3 4 5 6 7 8 9 10 11 #  字符串 \n #!/bin/bash \n shell = "SHELL" \n双引号字符串，可以使用 ${shell} 的方式使用 shell 变量，这行如果输出将会是 SHELL。双引号中也可以出现转义字符。 \nstr  =   " ${shell} " \n单引号字符串，不可以使用 shell 变量，这行如果输出将会是 ${SHELL}。单引号中不可出现转义字符。 \n str = \'${shell}\' \n取得字符串长度 \n echo   ${ # str} \n截取字符串，从 0 号位开始，截取两个字符，注意，假如使用了 sh 执行脚本，在 ubuntu 报错不要慌张，ubuntu /bin/bash 连接的是 /bin/dash 而不是传统的 /bin/bash \n解决方法是在终端执行 sudo dpkg-reconfigure dash，之后选择 no，或者直接使用 bash 或者 ./ 执行 \n echo   ${str : 0 : 2} \n找到变量 shell 中，H 的第一个索引，注意，这里使用的是反引号 \n echo   ` expr  index  " $shell "  H ` \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 #  传递参数 \n 在 shell 脚本执行时，我们可以传递参数，格式为  $n ，其中  $0  代表  文件名 ，从  $1  开始代表传递的第几个参数，比如： \n #!/bin/bash \n文件名 \n echo   $0 \n第一个参数 \n echo   $1 \n第二个参数 \n echo   $2 \n传递到脚本的参数个数 \n echo   $# \n单字符串的形式输出所有参数，还有 $@ 功能相同，不同点是 * 代表传递了一个参数字符串结果，而 @ 是多个参数拼成了结果 \n echo   $* \n脚本运行的进程 ID \n echo   $$ \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 执行  bash hello.sh 1 2 ，得到 \n hello.sh\n1\n2\n2\n1 2\n34949\n \n 1 2 3 4 5 6 #  数组 \n bash shell 仅支持一维数组，不需要定义数组大小，不需要定义数组元素类型，数组使用括号表示，元素间使用空格分开。 \n #!/bin/bash \n直接定义 \n arr = ( 1   2   "3"   4 ) \n下标定义 \narr [ 4 ] = 5 \n获取某元素 \n echo   " ${arr [ 0 ] } " \n获取所有元素，arr[*] 也可以 \n echo   " ${arr [ @ ] } " \n获取长度 \n echo   " ${ # arr [ @ ] } " \n \n 1 2 3 4 5 6 7 8 9 10 11 #  表达式（运算符） \n 原生 bash 不支持数学运算，但是可以使用  awk  和  expr  来实现，其中  expr  更常用，可以完成表达式操作。 \n 普通运算符 \n #!/bin/bash \n: << EOF\n1. expr 表达式计算工具，注意使用的是反引号\n1. 支持 + - * / % == !=，但是乘法需要使用转义字符。\n1. mac 中的 shell expr 的语法是 $(())，并且乘法不需要转义符号\nEOF \n a = 10 \n b = 20 \n echo   ` expr  $a + $b ` \n关系型运算符仅支持数字，或者字符串类型的数字。使用 if 语句来做判断，之后的流程控制有章节 \n关系运算符 \n if   [   $a  -eq  $b   ] \n then \n   echo   " $a  ==  $b " \n else \n   echo   " $a  !=  $b " \n fi \n\n if   [   $a  -ne  $b   ] \n then \n   echo   " $a  !=  $b " \n else \n   echo   " $a  ==  $b " \n fi \n\n if   [   $a  -gt  $b   ] \n then \n   echo   " $a  >  $b " \n else \n   echo   " $a  <=  $b " \n fi \n\n if   [   $a  -ge  $b   ] \n then \n   echo   " $a  >=  $b " \n else \n   echo   " $a  <=  $b " \n fi \n\n if   [   $a  -lt  $b   ] \n then \n   echo   " $a  <  $b " \n else \n   echo   " $a  >=  $b " \n fi \n\n if   [   $a  -le  $b   ] \n then \n   echo   " $a  <=  $b " \n else \n   echo   " $a  >  $b " \n fi \n!：非，-o（or）：或，也可以使用 || 代替；-a（all）：与，也可以使用 && 代替 \n if   [   $a   !=   $b  -o  $a   ==   $b   ] \n then \n   echo   "true" \n else \n   echo   "false" \n fi \n\n if   [   $a   !=   $b  -a  $a   ==   $b   ] \n then \n   echo   "true" \n else \n   echo   "false" \n fi \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 字符串运算符 \n #!/bin/bash \n字符串运算符： \n1. `=` 检测两者是否相等，`!=` 检测两者是否不等。 \n2. `-z` 检测字符串长度是否为 0，`-n` 检测字符串长度是否不为 0. \n3. `$` 检测字符串是否为空。 \n shell = "SHELL" \n if   [  -z  $shell   ] \n then \n   echo    "str length is zero" \n else \n   echo   "str lenth is not zero" \n fi \n\n if   [   $shell   ] \n then \n   echo   "str is null" \n else \n   echo   "str not null" \n fi \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 文件运算符 \n #!/bin/bash \n文件运算符 \n1. `-d`：是否为目录 \n2. `-f`：是否为普通文件 \n3. `-r`：文件是否可读 \n4. `-w`：文件是否可写 \n5. `-x`：文件是否可执行 \n6. `-s`：文件是否为空 \n7. `-e`：文件/目录是否存在 \n file = "/home/user/log" \n if   [  -e  $file   ] \n then \n   echo   "file is exists" \n else \n   echo   "file is not exists" \n fi \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #  echo 与 printf \n echo 没啥好说的，说一下 printf。printf 模仿 c 中的  print() ，可以格式化字符串。 \n printf 格式化： \n \n \n %s  输出字符串。 \n %-10s  表示任何字符不够 10 个使用空格补充，超出的部分会显示出来： printf %-10s helloworldhelloshell \n \n \n %d  输出整型。 \n \n \n %c  输出字符。 \n \n \n %f  以小数形式输出实数。 \n %-4.2f :格式化为小数，并且保留两位小数。 \n 流程控制 \n shell 中的条件判断可以使用  test  语句，也可以使用  []  做判断。不过  test  仅可以判断数值、字符、文件三个测试，比如 \n a = 10 \n b = 20 \n if   test   $a  -eq  $b \n then \n   echo   "a > b" \n else \n   echo   "a <= b" \n fi \n \n 1 2 3 4 5 6 7 8 if - else \n多行 \n if  condition\n then \n    commands\n fi \n \n 1 2 3 4 5 # 一行 \n if  condition ;   then  commands ;   fi ; \n \n 1 2 if  condition ;   then \n    commands\n else \n    commands\n fi \n \n 1 2 3 4 5 if  condition ;   then \n    commands\n elif  condition ;   then \n    commands\n else \n    commands\n fi \n \n 1 2 3 4 5 6 7 for \n for   var   in  item1 item2 item3  .. ..  itemN\n do \n    commands\n done \n \n 1 2 3 4 for   var   in  item1 item2 item3  .. . itemn ;   do  commands ;   done \n \n 1 循环中存在 break 和 continue。 \n while \n while   ((  condition  )) \n do \n    commands\n done \n \n 1 2 3 4 循环中存在 break 和 continue。 \n until \n until  condition\n do \n    commands\n done \n \n 1 2 3 4 循环中存在 break 和 continue。 \n case - esac \n case  value  in \n    value1 ) \n        commands\n     ; ; \n    value2 ) \n        commands\n     ; ; \n     .. .\n    * ) \n        commands\n     ; ; \n esac \n \n 1 2 3 4 5 6 7 8 9 10 11 12 #  函数 \n shell 中可以定义用户函数，之后在 shell 中可以随意调用。自定义函数： \n [   function   ]  funname   [ ( ) ] \n\n { \n    action ; \n\n     [ return int ; ] \n } \n \n 1 2 3 4 5 6 7 \n 可以带  function fun()  定义，也可以直接  fun() 。 \n 参数返回时可以显示加 return 返回，如果不加则将最后一条命令结果返回，return 后跟数值 0-255。 \n \n #!/bin/bash \n fun ( )   { \n   echo   "demo function" \n   return   0 \n } \n直接调用，注意，在 shell 中 0 代表 true，其余为 false \nfun\n funWithParam ( )   { \n   echo   $1 \n   echo   $2 \n   return   $(( $ 1 + $ 2 )) \n } \n带参数调用 \nfunWithParam  1   2 \n函数返回值在调用之后使用 $? 获取，$? 指令仅对其上一条指令负责，一旦函数返回值没有立刻获取就再也获取不到了。 \n echo   $? \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #  重定向 \n 重定向的意思是指使用文件来代替标准输入、标准输出、标准错误输出。 \n 比如说，平常使用  echo  将会打印到终端上，但是使用了重定向之后，完全可以打印到某个文件中。 \n \n \n \n \n 代码 \n 运算符 \n \n \n \n \n 标准输入 \n 0 \n < 或 << \n \n \n 标准输出 \n 1 \n > 或 >> \n \n \n 标准错误输出 \n 2 \n 2> 或 2>> \n \n \n \n 在这其中，有一个箭头的表示使用覆盖的方式进行重定向，两个箭头的方向表示使用追加的方式来重定向。 \n \n \n \n 命令 \n 说明 \n \n \n \n \n command > file \n 文件输出覆盖写到 file \n \n \n command >> file \n 文件输出追加到 file \n \n \n n >& m \n 输出文件 n 和 m 合并 \n \n \n \n n>&m  有很多实现，比如  command >> file 2>$1  代表将错误输出和标准输出合并输出到 file 中 \n 垃圾桶 \n如果希望执行某个命令，但是不希望日志保存下来，那么就可以丢到垃圾桶  /dev/null ，这是一个特殊文件，任何写入到它的内容都会被丢弃。 \n 引用外部文件 \n shell 可以包含外部脚本，这样可以有效封装一些公用代码作为独立文件。文件包含的语法如下： \n注意点号 \n .  filename\n或者直接使用 \n source  filename\n \n 1 2 3 4 ',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 4, 2022 13:02",createTimeStamp:1641272567e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Proxy",frontmatter:{title:"Proxy",categories:["base"],tags:["proxy"],author:"causes",summary:"Linux 和 Windows、Mac 是不一样的，虽然支持科学上网的软件有一些，但是大部分都不支持订阅链接的形式，而是要求有一台自己的服务器。 electron-ssr，这个工具是 ShadowsocksR 桌面应用，最重要的是支持订阅链接的方式，并且开源。 Linux 下的安装下载 AppImage 即可，AppImage 是各种发行版通用的。下载下来之",meta:[{property:"og:url",content:"/base/LinuxProxy/linux-proxy.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Proxy"},{property:"og:description",content:"Linux 和 Windows、Mac 是不一样的，虽然支持科学上网的软件有一些，但是大部分都不支持订阅链接的形式，而是要求有一台自己的服务器。 electron-ssr，这个工具是 ShadowsocksR 桌面应用，最重要的是支持订阅链接的方式，并且开源。 Linux 下的安装下载 AppImage 即可，AppImage 是各种发行版通用的。下载下来之"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"proxy"}]},regularPath:"/base/LinuxProxy/linux-proxy.html",relativePath:"base/LinuxProxy/linux-proxy.md",key:"v-08950870",path:"/base/LinuxProxy/linux-proxy/",readingTime:{minutes:1.66,words:499},content:' Linux 和 Windows、Mac 是不一样的，虽然支持科学上网的软件有一些，但是大部分都不支持订阅链接的形式，而是要求有一台自己的服务器。 \n electron-ssr ，这个工具是 ShadowsocksR 桌面应用，最重要的是支持订阅链接的方式，并且开源。 \n Linux 下的安装下载 AppImage 即可，AppImage 是各种发行版通用的。下载下来之后给一个执行的权限  chmod +x electron  然后即可执行，将订阅链接放进去之后即可。 \n 工具有了，但是在 Linux 系统下配置还没有完成 \n 系统代理设置：在 设置 --\x3e 网络中即可设置代理，端口号 electron 的默认设置为  http://127.0.0.1:12333 ，如果想要改变那就去设置中手动更改。 \n 浏览器想要科学上网有几种方式： \n \n 修改 Google Chrome 或者其他浏览器的配置文件，手动设置  http_proxy  的代理。 \n 在 Google Chrome 的设置中设置代理模式。 \n 使用插件 SwitchyOmega 手动设置代理，在 proxy 选项中设置 HTTP 的端口号 12333 和主机 127.0.0.1。 \n \n 除此之外，假如想要设置 Git 之类的工具代理，那么只能手动进行设置，比如  export http_proxy xxx 。 \n \n 除此之外，还可以使用  Qv2ray ，本身支持  vmess  协议，而且他可以增加插件来适配  ss/ssr  订阅链接，可以作为 v2ray、ss、ssr 客户端使用。 \n 插件地址： \n \n Qv2ray  总插件地址。 \n SS 。 \n SSR 。 \n \n 使用插件时，只需要将对应的文件放到  qv2ray  目录下的  plugins  文件夹下，然后重启，就可以在插件目录上看到对应的插件。 \n 浏览器代理（如  Google Chrome ），在 Ubuntu  上可以在  google-chrome.desktop  中添加  --proxy-server="socks5://127.0.0.1:12333"  代理选项。 \n \n ssrmu \n',updateTime:"July 4, 2022 11:31",updateTimeStamp:1656905496e3,createTime:"August 14, 2021 23:48",createTimeStamp:1628956128e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:5},{name:"causes",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Flink-01-基础",frontmatter:{title:"Flink-01-基础",categories:["bigdata"],tags:["flink"],author:"causes",summary:"概述 流处理和批处理 当前大多数企业都将数据处理分为两类： 事务处理：OLTP; 分析处理：OLAP; 对于大数据技术来说，主要面向的是分析处理，大数据技术可以为公司的业务运营提供参考意见，比如分析延迟发货原因、预测未来销量等。 大量的、多种类型的数据 ETL 进入到数据仓库后，就可以对数据进行查询。 在之前的技术中，无论是 MapReduce 还是 Spa",meta:[{property:"og:url",content:"/bigdata/Flink/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Flink-01-基础"},{property:"og:description",content:"概述 流处理和批处理 当前大多数企业都将数据处理分为两类： 事务处理：OLTP; 分析处理：OLAP; 对于大数据技术来说，主要面向的是分析处理，大数据技术可以为公司的业务运营提供参考意见，比如分析延迟发货原因、预测未来销量等。 大量的、多种类型的数据 ETL 进入到数据仓库后，就可以对数据进行查询。 在之前的技术中，无论是 MapReduce 还是 Spa"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"flink"}]},regularPath:"/bigdata/Flink/part1.html",relativePath:"bigdata/Flink/part1.md",key:"v-6c4d9170",path:"/bigdata/Flink/part1/",headers:[{level:2,title:"概述",slug:"概述"},{level:2,title:"Flink 运行架构基础",slug:"flink-运行架构基础"},{level:2,title:"起步",slug:"起步"},{level:2,title:"Flink DataStream API",slug:"flink-datastream-api"},{level:3,title:"读取数据源",slug:"读取数据源"},{level:3,title:"基本算子",slug:"基本算子"},{level:3,title:"键控流转换算子",slug:"键控流转换算子"},{level:3,title:"分布式转换算子",slug:"分布式转换算子"},{level:3,title:"Flink 类型系统",slug:"flink-类型系统"},{level:3,title:"富函数",slug:"富函数"},{level:3,title:"写入下游设备",slug:"写入下游设备"}],readingTime:{minutes:13.66,words:4097},content:' 概述 \n 流处理和批处理 \n 当前大多数企业都将数据处理分为两类： \n \n 事务处理：OLTP \n 分析处理：OLAP \n \n 对于大数据技术来说，主要面向的是分析处理，大数据技术可以为公司的业务运营提供参考意见，比如分析延迟发货原因、预测未来销量等。 \n 大量的、多种类型的数据 ETL 进入到数据仓库后，就可以对数据进行查询。 \n 在之前的技术中，无论是 MapReduce 还是 Spark，其实都是对数据的批处理计算，简单来说就是将大量的数据集合到一起，然后算一段时间，这个时间几小时、几天甚至都是有可能的。 \n 批处理有好处，但是也有它的局限性，在日常生活中，数据其实是源源不断地产生的，所以在实际的生活中，往往产生的是无限的事件流（无界流）。那样的话，批处理难免就会出现滞后性。 \n 这样，传统的架构难免就力不从心，即使是 Spark Streaming，其实也是攒批处理，只不过批次很小，所以叫做微批次。这是架构设计上的硬伤，毕竟 Spark 本质上是为批计算产生的。 \n 假如我们想要处理无限的数据流，并且不愿每次收到一个事件就记录一次，那么我们的应用程序应该是有状态的，也就是说可以存储和访问中间的数据，我们叫做有状态的流式处理。 \n \n 我们可以看到上图的架构，黄色的圆圈代表原始的事件，经过  Application Logic  进行处理，其中产生的红色方块数据（状态）存到本地的变量中，可以是本地内存、磁盘、数据库等。 \n 经过处理之后的绿色三角形数据继续向下游发送，可能还会有其他的处理要进行。 \n 其实这就是 Flink 的流式处理架构，我们可以看到比较有意思的事情，就是事件完全是按照先后顺序排列处理的，所以不管是发生故障还是其他原因，我们都可以在检查点恢复状态，这样就可以恢复整个应用。 \n Flink 概述 \n Apache Flink ，一个框架、分布式处理引擎，用于对无界流和有界流进行状态运算。 \n 对于 Flink 来讲，Flink 的延迟极低，吞吐量大，结果准确、容错性高（精准一次），支持多种存储系统，高可用。 \n 对于 Flink 来说，它是事件驱动的，也就是来一个事件计算一次。并且是基于流的世界观，离线数据是有界限的流，实时数据是无界限的流。 \n 对于 Flink 来说，API 是分层的，越是顶层的 API 越抽象，表达越简单，使用越方便。越底层表达能力越强，使用越灵活。 \n Flink 和 Spark 是不同的： \n \n Spark 采用 RDD 的架构，Spark Streaming 其实本质上也是攒批操作。Flink 是数据流和事件 Event 序列。 \n Spark 是批处理，将 DAG 划分为一个个 Stage，每个 Stage 完成之后才可以算下一个 Stage。Flink 是标准的流执行模式，一个事件在一个节点处理完成之后就可以直接发送到下一个节点。 \n Flink 运行架构基础 \n 组件、任务提交流程 \n Flink 包含四个不同组件： \n \n \n 作业管理器 JobManager：控制一个应用程序执行的主进程，每个应用程序都会被一个不同的作业管理器控制。 \n 作业管理器会接受到作业图 JobGraph、逻辑数据流图 LogicalDataFlowGraph、jar 包。 \n JobManager 会将 JobGraph 转为物理的数据流图：执行图 ExecutionGraph，包含了所有可以并发执行的任务。 \n JobManager 会向 ResourceManager 申请资源（TaskManager 上的 slot），获取资源之后会发送到负责运行的 TaskManager 上运行。 \n JobManager 还会负责协调，例如检查点 checkpoint 的协调。 \n \n \n 资源管理器 ResourceManager：管理 TaskManager 的 slot。 \n JobManager 申请资源时，ResourceManager 会将有空闲 slot 的 TaskManager 分给 JobManager。 \n 假如没有足够资源，它会向资源提供平台（例如 Yarn）发起会话，以启动新的 TaskManager 的容器。 \n ResourceManager 还负责资源的回收。 \n \n \n 任务管理器 TaskManager：工作进程。 \n 一般来说，Flink 中有多个 TaskManager，每个 TaskManager 都是一个 JVM 进程。 \n 每个 TaskManager 上都含有一定数量（至少一个）的插槽 slot，每个 slot 都会启动一个线程，slot 的数量决定了它能够执行的任务数量。 \n 启动之后，TaskManager 会向 ResourceManager 注册插槽，收到 ResourceManager 的指令后，就会提供给 JobManager 调用。 \n JobManager 会向 slot 分配任务 task 执行。 \n 在默认情况下，Flink 允许子任务共享 slot，这样的结果是，一个 slot 可以保存作业的整个管道。 \n \n \n 分发器 Dispatcher：跨作业运行，提交了 REST 接口，可以作为集群的 HTTP 入口。 \n 分发器也会提供一个 Web UI 来展示和监控作业运行情况。Dispatcher 在架构中可能不是必须的，取决于作业提交的方式。 \n \n \n \n 数据流 \n 所有的 Flink 程序都是由三部分组成的：Source、Transformation 和 Sink。Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出。 \n 并行度 \n 一个特定算子的子任务 subtask 的个数叫做并行度 parallelism。一个程序中，不同的算子可能有不同的并行度。一般情况下，一个流的并行度就是这个流的算子中的最大并行度。 \n \n 看上图中，每个任务节点中右下角的数字，代表并行度。例如 A 的并行度是 4，所以在右边的图中每一个 slot 中都有一个 A，同样的，B 也是每个 slot 中都有一个。 \n 但是 C 不同，C 的并行度只有 2，所以它在右图中只有两个。D 又是 4，所以 D 在右图中每个 slot 都有。 \n 重点来了：对于 A -> B，B -> D 来说，每个 slot 都有，这就代表数据的交换不需要跨 slot；但是对于 C -> D 来说，C 不是每个 slot 都有，所以在交换数据时需要跨 slot。 \n 那么这就是 Flink 的任务链，在满足两个或者多个算子并行度相同、并且通过本地转发（local forward）的方式链接时，就会减少本地通信产生的开销。 \n 起步 \n WordCount \n \n \n 搭建环境 \n < properties > \n     < flink.version > 1.13.0 </ flink.version > \n     < scala.binary.version > 2.12 </ scala.binary.version > \n     < slfj.version > 1.7.30 </ slfj.version > \n </ properties > \n\n < dependencies > \n     < dependency > \n         < groupId > org.apache.flink </ groupId > \n         < artifactId > flink-java </ artifactId > \n         < version > ${flink.version} </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.apache.flink </ groupId > \n         < artifactId > flink-streaming-java_${scala.binary.version} </ artifactId > \n         < version > ${flink.version} </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.apache.flink </ groupId > \n         < artifactId > flink-clients_${scala.binary.version} </ artifactId > \n         < version > ${flink.version} </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n \n WordCount 程序： \n public   class   WordCount   { \n     public   static   void   main ( String [ ]  args )   throws   Exception   { \n         StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n         // 给程序整体设置并行度，这里的设置的优先级要高于配置 \n        env . setParallelism ( 1 ) ; \n         DataStreamSource < String >  stream  =  env . fromElements ( "HELLO WORLD" ,   "HELLO WORLD" ) ; \n        stream\n             . flatMap ( new   FlatMapFunction < String ,   Tuple2 < String ,   Integer > > ( )   { \n             @Override \n             public   void   flatMap ( String  value ,   Collector < Tuple2 < String ,   Integer > >  out )   throws   Exception   { \n                 String [ ]  arr  =  value . split ( "\\\\s" ) ; \n                 Arrays . stream ( arr ) . forEach ( s  ->  out . collect ( Tuple2 . of ( s ,   1 ) ) ) ; \n             } \n             } ) \n             // 类似 groupBy，按照 f0 分组 \n             . keyBy ( r  ->  r . f0 ) \n             . sum ( 1 ) \n             . print ( ) ; \n         // 程序执行 \n        env . execute ( ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n Flink DataStream API \n 接下来的内容是大量的 API 操作，需要大量的练习使用 \n 读取数据源 \n 准备基础类 \n @Data \n @NoArgsConstructor \n @AllArgsConstructor \n public   class   UserBehavior   { \n\n   private   String  userId ; \n   private   String  itemId ; \n   private   String  categoryId ; \n   private   String  behaviorType ; \n   private   Long  timeStamp ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 从集合中读取 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n // 1. 接收一个可变长数组，直接取得数据 \nenv . fromElements ( \n     new   UserBehavior ( "543462" ,   "1715" ,   "1464116" ,   "pv" ,   1511658000   *   1000L ) , \n     new   UserBehavior ( "662867" ,   "2244074" ,   "1575622" ,   "pv" ,   1511658000   *   1000L ) \n ) ; \n\n // 2. 通过集合取得数据 \n List < UserBehavior >  userBehaviors  =   new   ArrayList < > ( ) ; \nuserBehaviors . add ( new   UserBehavior ( "543462" ,   "1715" ,   "1464116" ,   "pv" ,   1511658000   *   1000L ) ) ; \nuserBehaviors . add ( new   UserBehavior ( "662867" ,   "2244074" ,   "1575622" ,   "pv" ,   1511658000   *   1000L ) ) ; \nenv . fromCollection ( userBehaviors ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 从文件中读取 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv . readTextFile ( "/tmp/userBehavior.csv" ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 从 Socket 中读取 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv . socketTextStream ( host ,  port ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 从 Kafaka 中读取 \n Tips \n 待补充 \n \n 自定义数据源读取 \n Tips \n 待补充 \n 基本算子 \n 基本算子：对每个单独的事件做处理，每个输入都会产生一个输出。包括转换、数据分割、过滤等。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n List < UserBehavior >  userBehaviors  =   new   ArrayList < > ( ) ; \nuserBehaviors . add ( new   UserBehavior ( "543462" ,   "1715" ,   "1464116" ,   "pv" ,   1511658000   *   1000L ) ) ; \nuserBehaviors . add ( new   UserBehavior ( "662867" ,   "2244074" ,   "1575622" ,   "click" ,   1511658000   *   1000L ) ) ; \n\n DataStreamSource < UserBehavior >  stream  =  env . fromCollection ( userBehaviors ) ; \n\n // 1. map \nstream . map ( UserBehavior :: getItemId ) ; \n\n // 2. filter \nstream . filter ( userBehavior  ->   "pv" . equalsIgnoreCase ( userBehavior . getBehaviorType ( ) ) ) ; \n\n // 3. flatMap 就不用解释作用了，这里注意，我们是可以在 flatMap 中向下游发送多次的内容的。并且在转换之后，还需要指定一下流的种类 \nstream\n     . map ( UserBehavior :: getBehaviorType ) \n     . flatMap ( ( FlatMapFunction < String ,   String > )   ( s ,  out )   ->   { \n       if   ( "pv" . equals ( s ) )   { \n        out . collect ( s ) ; \n       }   else   { \n        out . collect ( s ) ; \n        out . collect ( s ) ; \n       } \n     } ) \n     . returns ( Types . STRING ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #  键控流转换算子 \n 简单来说，就是对数据进行分组。DataStream API 提供了一个叫做 KeyedStream 的抽象，这个抽象会从逻辑上对数据流进行分区，分区后的数据具有相同的 key。不同分区的流互不相关。 \n 接下来也有基于 key 的操作：滚动聚合、reduce。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n // 准备一组 Tuple3，进行分流和做计算 \n DataStreamSource < Tuple3 < Integer ,   Integer ,   Integer > >  stream  =  env . fromElements ( \n     Tuple3 . of ( 1 ,   2 ,   2 ) , \n     Tuple3 . of ( 2 ,   3 ,   1 ) , \n     Tuple3 . of ( 2 ,   2 ,   4 ) , \n     Tuple3 . of ( 1 ,   5 ,   3 ) \n ) ; \n\n /*\n  对第一个字段进行分流。很多 API 都是 groupBy，不过在 Flink 中使用 keyBey 是分流。\n\n  滚动聚合方法：\n\n  - sum()：在输入流上滚动相加，可以输入值的索引来针对某个位置做计算\n  - min()：求输入流上的最小值\n  - max()：求输入流上的最大值\n  - minBy()：再输入流上针对某字段求最小值，并返回包含最小值的事件\n  - maxBy()：类似 minBy()，不过是求最大值\n\n  虽然流是针对第一个字段进行分流的，但是计算是根据第二个字段做计算：\n\n  1. 分流，形成两个流 [(1, 2, 2)、(1, 5, 3)]、[(2, 3, 1)、(2, 2, 4)]\n  2. 每组中分别做计算 [(1, 2, 2)、(1, 7, 2)]、[(2, 3, 1)、(2, 5, 1)]\n\n  从结果中可以看出以下事情：\n\n  1. 流处理的意思就是每个事件都会处理，所以在进行 print() 时，每组中的第一个元素都会打印。\n  2. 对于每组来说，都会基于第一个作为基础，然后按照指定字段进行累加。\n*/ \nstream . keyBy ( 0 ) . sum ( 1 ) . print ( ) ; \n\n /*\n  第二种方式来分流，其实作用都是一样的，写法不同而已，真实中这样的方式更常用\n\n  reduce 是滚动聚合的泛化实现，它不会改变流的事件类型，需要你自己去实现内容，我们会求每组中，第二个值的最大值\n*/ \nstream\n     . keyBy ( r  ->  r . f0 ) \n     . reduce ( ( ReduceFunction < Tuple3 < Integer ,   Integer ,   Integer > > )   ( in ,  out )   ->  in . f1  >  out . f1  ?  in  :  out ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #  分布式转换算子 \n 有时候，我们需要在应用程序的层面控制分区策略，或者做自定义分区策略（例如负载均衡、解决数据倾斜等），又或者需要数据拆分并行计算等，我们可以使用 DataStream 的一些方法自定义分区策略。 \n 注意，这个分区和  keyBy  有本质的不同， keyBy  产生的是  KeyedStream ，而自定义的分区策略产生的是  DataStream 。 \n Random \n 随机数据交换，由  DataStream.shuffle()  方法实现，shuffle 方法将数据随机地分配到下游算子中的并行任务中去。 \n Round-Robin \n rebalance()  方法使用的是轮询的方式负载均衡，它会将数据流平均分配到之后的所有并行任务中。 \n rescale()  也是 Round-Robin 方式，不过它会将数据平均分配到一部分的任务中 \n 两者的区别：是在于任务之间连接机制不同，rebalance 会针对所有的任务发送者和接受者建立通道，但是 rescale 只会在这个任务的下游中建立通道。 \n \n Broadcast \n broadcast() ，类似 Spark 的广播变量，会将数据复制并发送到下游所有算子的并行任务中。 \n Global \n global()  将所有的输入流数据都发送到下游算子的第一个并行任务中去，这个操作会将所有数据发送到同一个 task，所以需要谨慎。 \n Custom \n 可以使用  partitionCustom()  自定义分区策略，此方法接受一个  Partitioner  对象，这个对象需要实现分区逻辑以及定义针对流的哪一个字段或者 key 来分区。 \n 设置并行度 \n 一个算子并行任务的个数叫做并行度。在 Flink 中可以设置并行度，每个算子的并行任务都会处理这个算子的输入流的一份子集。 \n 假如我们在本地运行，并行度将被设置为 CPU 的核数，假如将应用程序提交到 Flink 集群中，并行度将被设置为集群的默认并行度（除非在提交时，在客户端显示设置并行度）。 \n 设置某个算子的并行度优先级 > 代码中总体设置的并行度优先级 > 环境中的并行度。 \n 并行度是一个动态的概念，插槽数量是一个静态的概念，并行度 <= 插槽数量。一个任务槽最多运行一个并行度。这也就意味着，当任务槽数量 < 并行度时，任务将无法运行。 \n Flink 类型系统 \n Flink 支持 Java 所有普通数据类型，并且还包含专门为 Java 实现的元组 Tuple，支持 Pojo 类。 \n Tuple \n Tuple 是强类型，根据元素数量的不同被实现了不同的类，从 Tuple1 一直到 Tuple25。 \n Tuple 可以通过下标访问，下标从 0 开始，访问时使用  tuple.f0  或者  tuple.getField(0)  获取元素。 \n Tuple 是可变数据结构，所以 Tuple 中的元素可以重新赋值，重复利用 Tuple 可以减轻 GC 压力。 \n Tuple2 < String ,   Integer >  tuple  =   Tuple2 . of ( "causes" ,   23 ) ; \n System . out . println ( tuple . f0 ) ; \n System . out . println ( ( String )  tuple . getField ( 0 ) ) ; \n // 设置索引为 0 的位置的数值 \ntuple . setField ( 23 ,   0 ) ; \n \n 1 2 3 4 5 Pojo \n 在 Java 中，类型信息是  org.apache.flink.api.common.typeinfo.Types ，例如  Types.INT 、 Types.POJO(UserBehavior.class); 。 \n Lambda 表达式 \n Java 支持 Lambda 表达式，但是需要注意一个点：Java 编译器在 lambda 表达式的推断类型信息时，在编译一些信息时可能会出现错误，例如  flatMap 、 map  等需要泛型的算子。 \n 在使用一个  flatMapFunction  时，本来是  void flatMap(IN value, Collector<OUT> out) ，但是 Java 会编译为  void flatMap(IN value, Collector out) \n 如此一来，Flink 就无法自动推断输出的类型信息，在这种情况下，我们需要手动指定类型信息，否则会被视为 Object，这会导致低效的序列化，甚至可能会报错。 \n 一般来说，这种类型被擦除的问题可以有两种方式解决： \n \n 手动指定类型信息。 \n 使用类来代替。 \n \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     . fromElements ( 1 ,   2 ,   3 ) \n     . flatMap ( ( FlatMapFunction < Integer ,   Integer > )   ( num ,  out )   ->   { \n      out . collect ( num ) ; \n     } ) \n     // 1. 手动指定类型信息 \n     . returns ( Types . INT ) \n     . print ( ) ; \n\nenv\n     . fromElements ( 1 ,   2 ,   3 ) \n     // 2. 使用类 / 匿名类直接代替 \n     . flatMap ( new   FlatMapFunction < Integer ,   Integer > ( )   { \n       @Override \n       public   void   flatMap ( Integer  num ,   Collector < Integer >  out )   throws   Exception   { \n        out . collect ( num ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #  富函数 \n 富函数就是普通函数的升级版本，它可以提供  open  和  close  方法，用于在执行真正的函数之前和之后做一些其他操作。 \n 提供了  getRuntimeContext()  提供了函数的  RuntimeContext  的一些信息，例如并行度，当前子任务的索引，子任务的名字，同时包含了访问分区状态的方法。 \n 基本上每个常规函数都有富函数版本，只要在函数前面加上  Rich  就是富函数，例如  RichMapFunction 、 RichFlatMapFunction  等。 \n new   RichFlatMapFunction < Integer ,   Integer > ( )   { \n     @Override \n     public   void   open ( Configuration  parameters )   throws   Exception   { \n     super . open ( parameters ) ; \n     } \n\n     @Override \n     public   RuntimeContext   getRuntimeContext ( )   { \n     return   super . getRuntimeContext ( ) ; \n     } \n\n     @Override \n     public   void   flatMap ( Integer  integer ,   Collector < Integer >  collector )   throws   Exception   { \n\n     } \n\n     @Override \n     public   void   close ( )   throws   Exception   { \n     super . close ( ) ; \n     } \n } ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     . fromElements ( 1 ,   2 ,   3 ) \n     . map ( new   RichMapFunction < Integer ,   Integer > ( )   { \n       @Override \n       public   Integer   map ( Integer  value )   throws   Exception   { \n         return  value  *   2 ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #  写入下游设备 \n Tips \n TODO \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"March 30, 2022 14:56",createTimeStamp:1648623383e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Flink-02-进阶",frontmatter:{title:"Flink-02-进阶",categories:["bigdata"],tags:["flink"],author:"causes",summary:"窗口 一般来说，真实数据都是无界流，那么我们如何去处理？其实就是将无界流切为有界流进行处理。窗口其实就是切分的一种方式，它会将流数据分发到不同的桶中进行分析。 窗口类型有两种： 时间窗口 Time Window：; 滚动时间窗口; 滑动时间窗口; 会话窗口（只有 Flink 支持）; 计数窗口 Count Window：; 滚动计数窗口; 滑动计数窗口; 其",meta:[{property:"og:url",content:"/bigdata/Flink/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Flink-02-进阶"},{property:"og:description",content:"窗口 一般来说，真实数据都是无界流，那么我们如何去处理？其实就是将无界流切为有界流进行处理。窗口其实就是切分的一种方式，它会将流数据分发到不同的桶中进行分析。 窗口类型有两种： 时间窗口 Time Window：; 滚动时间窗口; 滑动时间窗口; 会话窗口（只有 Flink 支持）; 计数窗口 Count Window：; 滚动计数窗口; 滑动计数窗口; 其"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"flink"}]},regularPath:"/bigdata/Flink/part2.html",relativePath:"bigdata/Flink/part2.md",key:"v-16441730",path:"/bigdata/Flink/part2/",headers:[{level:2,title:"窗口",slug:"窗口"},{level:2,title:"进阶",slug:"进阶"},{level:3,title:"KeyedProcessFunction",slug:"keyedprocessfunction"},{level:3,title:"状态变量",slug:"状态变量"},{level:3,title:"ProcessWindowFunction",slug:"processwindowfunction"},{level:3,title:"AggregateFunction",slug:"aggregatefunction"},{level:3,title:"ProcessWindowFunction + AggregateFunction",slug:"processwindowfunction-aggregatefunction"},{level:2,title:"时间和水位线",slug:"时间和水位线"},{level:3,title:"水位线",slug:"水位线"},{level:3,title:"迟到数据处理",slug:"迟到数据处理"},{level:3,title:"自定义水位线逻辑",slug:"自定义水位线逻辑"},{level:3,title:"多流转换",slug:"多流转换"},{level:3,title:"联结流",slug:"联结流"},{level:3,title:"CoProcessFunction",slug:"coprocessfunction"},{level:3,title:"基于间隔和窗口的 JOIN",slug:"基于间隔和窗口的-join"}],readingTime:{minutes:30.21,words:9062},content:' 窗口 \n 一般来说，真实数据都是无界流，那么我们如何去处理？其实就是将无界流切为有界流进行处理。窗口其实就是切分的一种方式，它会将流数据分发到不同的桶中进行分析。 \n 窗口类型有两种： \n \n 时间窗口 Time Window：\n \n 滚动时间窗口 \n 滑动时间窗口 \n 会话窗口（只有 Flink 支持） \n \n \n 计数窗口 Count Window：\n \n 滚动计数窗口 \n 滑动计数窗口 \n \n \n \n 其中时间窗口是比较重要的，我们以时间窗口为主。 \n 滚动窗口、滑动窗口、会话窗口 \n \n 滚动窗口就是普通的窗口，数据按照窗口长度进行切分，窗口之间没有重叠。 \n \n 是窗口大小 + 一段滑动距离组成，滑动间隔可以为 0，那样就成为了滚动窗口。 \n 一个元素可能同时存在多个窗口中，但是这种存在多个窗口的实现方式其实是复制。元素将会复制多份，每个窗口都存放此元素。所以假如窗口交集比较多，那么最终会存在很多冗余的元素。 \n \n 注意，这个会话窗口并不是真正的 HTTP sesion，它的意思是说，指定一个超时时间，假如过了这个时间还没有收到新的数据那就会生成新的窗口。 \n 特点就是时间不定长。 \n \n 以处理时间为例： \n // 滚动窗口，给定窗口大小 \n . window ( TumblingProcessingTimeWindows . of ( Time . seconds ( 5 ) ) ) \n // 滑动窗口，给定窗口大小、滑动距离 \n . window ( SlidingProcessingTimeWindows . of ( Time . seconds ( 10 ) ,   Time . seconds ( 5 ) ) ) \n // 会话窗口，给定超时时间 \n . window ( ProcessingTimeSessionWindows . withGap ( Time . seconds ( 10 ) ) ) \n \n 1 2 3 4 5 6 事件时间其实就是将 process 改为 event，例如  TumblingEventTimeWindows \n 进阶 \n 处理函数，Process Function，是底层 API。 \n 我们之前使用到的所有函数其实都是基于处理函数来进行实现的，而我们使用处理函数可以实现更加复杂的需求。例如，Flink SQL 就是利用 Process Function 来实现的。 \n Flink 提供了 8 个 Process Function： \n \n ProcessFunction \n KeyedProcessFunction \n CoProcessFunction \n ProcessJoinFunction \n BroadcastProcessFunction \n KeyedBroadcastProcessFunction \n ProcessWindowFunction \n ProcessAllWindowFunction \n \n 所有的 Process Function 都继承了 RichFunction 接口，所以都有富函数的优点。 \n KeyedProcessFunction \n 用来操作 keyBy 之后的流，输出 0 个、1 个 或多个。可以看成是 flatMap 和 reduce 的终极加强版。 \n 除了富函数的函数，还额外提供了两个方法： \n \n \n processElement(I value, Context ctx, Collector<O> out) ：流中的每一个元素都会调用此方法。 \n 流中的每一个元素都会调用此方法，结果会放到 collector 数据类型中输出。 \n Context 可访问元素的时间戳、key、TimeService 时间服务，还可以输出元素到别的流。 \n \n \n onTimer(long timestamp, OnTimerContext ctx, Collector<O> out) ：回调函数，定时器： \n 定时器的回调函数，可以在定时器倒计时结束之后调用。 \n timestamp 是定时器触发的时间戳。 \n Collector 是输出集合。 \n OnTimerContext 类似 processElement 的 Context。 \n \n \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     . socketTextStream ( "localhost" ,   9999 ) \n     // keyedProcessFunction 需要的是 keyBy 之后的 流，所以先分流 \n     . keyBy ( r  ->   1 ) \n     /*\n      1. 调用一个 process function 的方式，就是 .process()\n      2. 三个泛型分别为： key、输入、输出\n    */ \n     . process ( new   KeyedProcessFunction < Integer ,   String ,   String > ( )   { \n       /**\n       * 每个元素都会调用此方法处理\n       */ \n       @Override \n       public   void   processElement ( String  value ,   KeyedProcessFunction < Integer ,   String ,   String > . Context ctx ,   Collector < String >  out )   throws   Exception   { \n         // 获取机器时间 \n         long  ts  =  ctx . timerService ( ) . currentProcessingTime ( ) ; \n        out . collect ( String . format ( "元素 %s 在 %s 到达" ,  value ,   new   Timestamp ( ts ) ) ) ; \n         // 注册一个十秒钟之后的定时器，十秒钟后将会调用方法 onTimer \n        ctx . timerService ( ) . registerProcessingTimeTimer ( ts  +   10   *   1000L ) ; \n       } \n\n       /**\n       * 定时器，在 processElement 注册之后，时间到达将会调用此回调函数\n       */ \n       @Override \n       public   void   onTimer ( long  timestamp ,   KeyedProcessFunction < Integer ,   String ,   String > . OnTimerContext ctx ,   Collector < String >  out )   throws   Exception   { \n         super . onTimer ( timestamp ,  ctx ,  out ) ; \n        out . collect ( String . format ( "定时器触发，时间为：%s" ,   new   Timestamp ( timestamp ) ) ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 Tips \n 每个 key 都可以注册自己的定时器，对于每个 key，在某个时间戳，只能注册一个定时器。 \n 每个 key 独享定时器，定时器之间在逻辑上相互隔离。 \n \n 时间服务和定时器 \n 除了之前的例子，Context 和 OnTimerContext 持有的 TimeService 对象拥有如下方法： \n \n currentProcessingTime() ：返回当前处理时间。 \n currentWatermark() ：返回当前水位线的时间戳 \n registerProcessingTimeTimer(long time) ：会注册当前 key 的 processing time 的 timer。当 processing time 到达定时时间时，触发 timer。 \n registerEventTimeTimer(long time) ：会注册当前 key 的 event time timer。当水位线大于等于定时器注册的时间时，触发定时器执行回调函数。 \n deleteProcessingTimeTimer(long time) ：删除之前注册处理时间定时器。如果没有这个时间戳的定时器，则不执行。 \n deleteEventTimeTimer(long time) ：删除之前注册的事件时间定时器，如果没有此时间戳的定时器，则不执行。 \n 状态变量 \n 状态变量，顾名思义，保存状态。我们以一个平均数的需求来开始状态变量。状态变量有很多种，例如  ValueState 、 MapState 、 ListState 。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     . addSource ( new   SourceFunction < Integer > ( )   { \n       private   boolean  shouldRunning  =   true ; \n       private   Random  random  =   new   Random ( ) ; \n\n       @Override \n       public   void   run ( SourceContext < Integer >  ctx )   throws   Exception   { \n         while   ( shouldRunning )   { \n          ctx . collect ( random . nextInt ( 10 ) ) ; \n           Thread . sleep ( 100L ) ; \n         } \n       } \n\n       @Override \n       public   void   cancel ( )   { \n        shouldRunning  =   false ; \n       } \n     } ) \n     . keyBy ( r  ->   true ) \n     . process ( new   KeyedProcessFunction < Boolean ,   Integer ,   Double > ( )   { \n\n       /*\n        1. 声明状态变量，做累加器，这里声明一个值状态变量\n        2. 状态变量的可见范围是当前 key\n        3. 不同 key 的状态变量是相互隔离的\n        4. 状态变量是单例，只能被实例化一次，这是用于宕机之后检查点恢复的\n        5. 我们需要给状态变量起名字，也是用于检查点恢复的\n      */ \n       private   ValueState < Tuple2 < Integer ,   Integer > >  valueState ; \n       // 保存定时器时间戳 \n       private   ValueState < Long >  timerTs ; \n\n       @Override \n       public   void   open ( Configuration  parameters )   throws   Exception   { \n         super . open ( parameters ) ; \n         // 固定写法，调用 runtimeContext 来获取一个状态变量（给定状态变量的名称和类型） \n        valueState  =   getRuntimeContext ( ) . getState ( new   ValueStateDescriptor < Tuple2 < Integer ,   Integer > > ( "sumCount" ,   Types . TUPLE ( Types . INT ,   Types . INT ) ) ) ; \n        timerTs  =   getRuntimeContext ( ) . getState ( new   ValueStateDescriptor < Long > ( "timer" ,   Types . LONG ) ) ; \n       } \n\n       @Override \n       public   void   processElement ( Integer  value ,   KeyedProcessFunction < Boolean ,   Integer ,   Double > . Context context ,   Collector < Double >  out )   throws   Exception   { \n         // 做累加器的操作 \n         if   ( Objects . isNull ( valueState . value ( ) ) )   { \n          valueState . update ( Tuple2 . of ( value ,   1 ) ) ; \n         }   else   { \n           Tuple2 < Integer ,   Integer >  tmp  =  valueState . value ( ) ; \n          valueState . update ( Tuple2 . of ( tmp . f0  +  value ,  tmp . f1  +   1 ) ) ; \n         } \n\n         if   ( Objects . isNull ( timerTs . value ( ) ) )   { \n           // 注册十秒钟之后的定时器 \n           long  timer  =  context . timerService ( ) . currentProcessingTime ( )   +   10   *   1000L ; \n          context . timerService ( ) . registerProcessingTimeTimer ( timer ) ; \n          timerTs . update ( timer ) ; \n         } \n       } \n\n       @Override \n       public   void   onTimer ( long  timestamp ,   KeyedProcessFunction < Boolean ,   Integer ,   Double > . OnTimerContext ctx ,   Collector < Double >  out )   throws   Exception   { \n         super . onTimer ( timestamp ,  ctx ,  out ) ; \n         if   ( Objects . isNull ( valueState . value ( ) ) )   { \n           return ; \n         } \n         // 发送数据 \n        out . collect ( ( double )  valueState . value ( ) . f0  /  valueState . value ( ) . f1 ) ; \n         // 清空定时器的状态变量 \n        timerTs . clear ( ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 #  ProcessWindowFunction \n 按照 key 分区完毕，然后按照 window 分区之后，我们就可以使用  ProcessWindowFunction  了，它也是一个底层 API。 \n 比如，我们要计算每个用户每 5 秒钟的 pv（其实应该是 0- 4999ms，因为窗口是左闭右开）。 \n @Data \n @NoArgsConstructor \n @AllArgsConstructor \n public   class   Event   { \n\n   private   String  user ; \n   private   String  url ; \n   private   Long  timestamp ; \n } \n \n 1 2 3 4 5 6 7 8 9 public   class   ClickSource   implements   SourceFunction < Event >   { \n\n   private   boolean  shouldRunning  =   true ; \n   private   String [ ]  userArr  =   { "Mary" ,   "Bob" ,   "Alice" ,   "Liz" } ; \n   private   String [ ]  urlArr  =   { "./home" ,   "./cart" ,   "./fav" ,   "./prod?id=1" ,   "./prod?id=2" } ; \n   private   Random  random  =   new   Random ( ) ; \n\n   @Override \n   public   void   run ( SourceContext < Event >  ctx )   throws   Exception   { \n     while   ( shouldRunning )   { \n      ctx . collect ( \n           new   Event ( \n              userArr [ random . nextInt ( userArr . length ) ] , \n              urlArr [ random . nextInt ( urlArr . length ) ] , \n               Calendar . getInstance ( ) . getTimeInMillis ( ) \n           ) \n       ) ; \n       Thread . sleep ( 1000L ) ; \n     } \n   } \n\n   @Override \n   public   void   cancel ( )   { \n    shouldRunning  =   false ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // 每个用户每 5 秒钟的 pv \n public   class   Demo   { \n   public   static   void   main ( String [ ]  args )   throws   Exception   { \n     StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n    env . setParallelism ( 1 ) ; \n\n    env\n         . addSource ( new   ClickSource ( ) ) \n         . keyBy ( Event :: getUser ) \n         // 先分流，再开窗。这里开了一个 5s 的滚动窗口 \n         . window ( TumblingProcessingTimeWindows . of ( Time . seconds ( 5 ) ) ) \n         // 开窗之后进行 processWindowFunction \n         . process ( new   WindowResult ( ) ) \n         . print ( ) ; \n\n    env . execute ( ) ; \n   } \n\n   /**\n   * 注意，processWindowFunction 的泛型有四个：\n   * <p>\n   * 1. 输入泛型\n   * 2. 输出泛型\n   * 3. key 的泛型\n   * 4. Window 的泛型，这里自然就是 TimeWindow\n   */ \n   public   static   class   WindowResult   extends   ProcessWindowFunction < Event ,   String ,   String ,   TimeWindow >   { \n\n     /**\n     * processWindowFunction 的 process 方法会在窗口结束时调用\n     */ \n     @Override \n     public   void   process ( String  key ,   ProcessWindowFunction < Event ,   String ,   String ,   TimeWindow > . Context ctx ,   Iterable < Event >  elements ,   Collector < String >  out )   throws   Exception   { \n       // 获取窗口开启时间 \n       long  windowStart  =  ctx . window ( ) . getStart ( ) ; \n       // 获取窗口关闭时间 \n       long  windowEnd  =  ctx . window ( ) . getEnd ( ) ; \n       // 迭代器中的元素个数 \n       long  count  =  elements . spliterator ( ) . getExactSizeIfKnown ( ) ; \n      out . collect ( String . format ( "用户 %s 在窗口 %s - %s 的 pv 次数是 %s" ,  key ,   new   Timestamp ( windowStart ) ,   new   Timestamp ( windowEnd ) ,  count ) ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 我们可以看到，上面有一个迭代器，迭代器中保存的是所有的数据，所以像这种函数我们也可以叫做全窗口聚合函数。 \n 其实全窗口聚合函数对于这种累加计算的情况不太好，因为我们需要的是 pv 次数，不需要保留原始数据，所以我们仍然可以参考累加器的思路来进行计算，一条数据加完之后就扔掉， \n AggregateFunction \n 我们说 processWindowFunction 是一个全窗口聚合函数，但是不太适合累加计算的情况，因为累加不需要保存原始数据。 \n 所以出现了增量聚合聚合方面的函数，一个是 ReduceFunction，一个是 AggregateFunction，其中 AggregateFunction 可以实现更多功能，所以以它为例。 \n 准备工作就是 ProcessWindowFunction 中的 Event 和 ClickSource，主要思路仍然是先分流再开窗，只不过这里的  process()  换位了  aggregate() \n // 每个用户每 5 秒钟的 pv \n public   class   Demo   { \n   public   static   void   main ( String [ ]  args )   throws   Exception   { \n     StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n    env . setParallelism ( 1 ) ; \n\n    env\n         . addSource ( new   ClickSource ( ) ) \n         . keyBy ( Event :: getUser ) \n         . window ( TumblingProcessingTimeWindows . of ( Time . seconds ( 5 ) ) ) \n         // 这里注意，聚合操作直接使用 aggregate 即可，需要使用到的就是 AggregateFunction \n         . aggregate ( new   CountAgg ( ) ) \n         . print ( ) ; \n\n    env . execute ( ) ; \n   } \n\n   /**\n   * AggregateFunction的三个泛型：\n   * <p>\n   * 1. key 的类型\n   * 2. 累加器的泛型\n   * 3. 输出泛型\n   */ \n   public   static   class   CountAgg   implements   AggregateFunction < Event ,   Integer ,   Integer >   { \n\n     /**\n     * 针对每一个窗口，都会创建一个累加器\n     *\n     * @return 默认数值\n     */ \n     @Override \n     public   Integer   createAccumulator ( )   { \n       return   0 ; \n     } \n\n     /**\n     * 定义累加规则\n     */ \n     @Override \n     public   Integer   add ( Event  event ,   Integer  accumulator )   { \n       return  accumulator  +   1 ; \n     } \n\n     /**\n     * 在窗口关闭时返回结果\n     */ \n     @Override \n     public   Integer   getResult ( Integer  accumulator )   { \n       return  accumulator ; \n     } \n\n     /**\n     * 当窗口合并的时候，需要实现这个 merge，当前需求我们不需要将窗口合并，不用实现这个\n     */ \n     @Override \n     public   Integer   merge ( Integer  integer ,   Integer  acc1 )   { \n       return   null ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 相对于全窗口聚合函数，优点是不需要知道所有的数据是什么，但是缺点就是无法访问窗口的信息，所以不知道得到的结果属于哪个窗口。 \n 那我们不能接受了，所以我们需要将增量聚合函数和全窗口聚合函数结合使用的例子 \n ProcessWindowFunction + AggregateFunction \n 这里注意，我们之前调用全窗口聚合函数使用的是  process() ，增量聚合函数是  aggregate() ，那么如果将两者集合使用，那么其实是用的是  aggregate() ，只不过这个方法还有第二个参数，就是全窗口聚合函数。 \n 其实增量聚合函数 + 全窗口聚合函数，在这个过程中，全窗口聚合函数的作用其实就是在增量聚合函数的外层包裹一层窗口信息而已。 \n 当窗口闭合的时候，增量聚合函数会将它的结果发送到全窗口聚合函数。 \n \n \n \n \n // 每个用户每 5 秒钟的 pv \n public   class   Demo   { \n   public   static   void   main ( String [ ]  args )   throws   Exception   { \n     StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n    env . setParallelism ( 1 ) ; \n\n    env\n         . addSource ( new   ClickSource ( ) ) \n         . keyBy ( Event :: getUser ) \n         . window ( TumblingProcessingTimeWindows . of ( Time . seconds ( 5 ) ) ) \n         // 增量聚合 + 全窗口，全窗口聚合函数的作用是就是将增量聚合的结果包裹一层窗口信息 \n         . aggregate ( new   CountAgg ( ) ,   new   WindowResult ( ) ) \n         . print ( ) ; \n\n    env . execute ( ) ; \n   } \n\n   /**\n   * AggregateFunction的三个泛型：\n   * <p>\n   * 1. key 的类型\n   * 2. 累加器的泛型\n   * 3. 输出泛型\n   */ \n   public   static   class   CountAgg   implements   AggregateFunction < Event ,   Integer ,   Integer >   { \n\n     /**\n     * 针对每一个窗口，都会创建一个累加器\n     *\n     * @return 默认数值\n     */ \n     @Override \n     public   Integer   createAccumulator ( )   { \n       return   0 ; \n     } \n\n     /**\n     * 定义累加规则\n     */ \n     @Override \n     public   Integer   add ( Event  event ,   Integer  accumulator )   { \n       return  accumulator  +   1 ; \n     } \n\n     /**\n     * 在窗口关闭时返回结果\n     */ \n     @Override \n     public   Integer   getResult ( Integer  accumulator )   { \n       return  accumulator ; \n     } \n\n     /**\n     * 当窗口合并的时候，需要实现这个 merge，当前需求我们不需要将窗口合并，不用实现这个\n     */ \n     @Override \n     public   Integer   merge ( Integer  integer ,   Integer  acc1 )   { \n       return   null ; \n     } \n   } \n\n   /**\n   * 注意，processWindowFunction 的泛型有四个：\n   * <p>\n   * 1. 输入泛型\n   * 2. 输出泛型\n   * 3. key 的泛型\n   * 4. Window 的泛型，这里自然就是 TimeWindow\n   * <p>\n   * 注意：\n   * <p>\n   * 1. 当增量聚合函数的数据发送给全窗口聚合函数时，全窗口聚合函数的输入类型就是增量聚合函数的输出类型了，这里自然就是 Integer\n   * 2. 增量聚合函数的输出结果是一个元素，所以这时候迭代器的参数就只包含一个元素了，这个元素的值就是增量聚合函数的结果\n   */ \n   public   static   class   WindowResult   extends   ProcessWindowFunction < Integer ,   String ,   String ,   TimeWindow >   { \n\n     @Override \n     public   void   process ( String  key ,   ProcessWindowFunction < Integer ,   String ,   String ,   TimeWindow > . Context ctx ,   Iterable < Integer >  elements ,   Collector < String >  out )   throws   Exception   { \n       long  windowStart  =  ctx . window ( ) . getStart ( ) ; \n       long  windowEnd  =  ctx . window ( ) . getEnd ( ) ; \n       long  count  =  elements . iterator ( ) . next ( ) ; \n      out . collect ( String . format ( "用户 %s 在窗口 %s - %s 的 pv 次数是 %s" ,  key ,   new   Timestamp ( windowStart ) ,   new   Timestamp ( windowEnd ) ,  count ) ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 #  时间和水位线 \n 水位线 \n 在之前事件的处理过程中，我们一直用到的时间其实是数据到达算子的时间，而不是真正的事件发生的时间。当网络被阻塞时，事件时间和到达算子的时间就完全不同了。 \n 在 Flink 中，时间分为三种类型： \n \n Event Time 事件时间：事件创建的时间（这个时间 Flink 肯定是不知道的，所以只能包含在数据中进行读取，读到多少就是多少）。 \n Ingestion Time 摄入时间：数据进入 Flink 的 source 算子的时间，和机器时间相关。 \n Processing Time 处理时间：执行操作算子的本地系统时间，和机器相关。 \n \n 我们之前用到其实一直是 processing Time。 \n 在这里需要强调的是事件时间 Event Time，这个时间事件发生的时间，Flink 肯定是不知道的，所以只能读取数据中的时间戳，比如数据的  createdTime 。 \n 为了保证计算结果的准确性，只要数据源中包含事件时间，我们就要用事件时间。假如一个数据迟到了 50 年，用处理时间就凉了，但是事件时间还是照常处理。 \n 但是使用事件时间会出现一个问题，就是窗口不知道什么时候应该关闭。万一一个事件因为网络原因迟到了，那么还是需要按照事件发生的时间窗口进行分配。 \n 那么有一个问题来了，一个窗口究竟要等待多长时间？总不可能永远也不关闭，那样内存就炸了，结果也算不出来了。 \n 为了解决这个问题，出现了一个逻辑时钟：水位线 Watermark。 \n 水位线 Watermark \n 水位线是一种衡量事件时间进展的机制，是逻辑时钟，专门用来处理乱序事件。 \n 比如，我们每小时设置一个水位线。事件时间位于两点到三点的水位线中，那么就会归类到两点到三点的这个窗口中，以此类推。 \n 水位线的默认计算公式是： 水位线 = 观察到的最大时间戳 - 最大延迟时间 - 1 毫秒 。 \n 解释一下计算公式： \n \n 观察到的最大时间戳这个就是数据中自带的事件时间。 \n 最大延迟时间是自定义的，我们不可能一直开着窗口，所以我们设置一个最大延迟时间，超过这个最大延迟时间就不等了。 \n \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     /*\n      注意，我们输入的数据应该是类似 `a 1` 的模式：\n      - `a` 指的就是事件。\n      - `1` 指的是事件时间，1s\n     */ \n     . socketTextStream ( "localhost" ,   9999 ) \n     // 我们将 `a 1` 转为 (a, 1000L) 的形式，1000L 就是 1000 毫秒 \n     . map ( ( MapFunction < String ,   Tuple2 < String ,   Long > > )  value  ->   { \n       String [ ]  arr  =  value . split ( " " ) ; \n       return   Tuple2 . of ( arr [ 0 ] ,   Long . parseLong ( arr [ 1 ] )   *   1000L ) ; \n     } ) \n     . returns ( Types . TUPLE ( Types . STRING ,   Types . LONG ) ) \n     /*\n      1. 注意，这里就是指定时间戳和水位线的方法\n      2. 水位线其实也是一个特殊的事件，默认情况下会每隔 200 毫秒的机器时间插一次水位线\n     */ \n     . assignTimestampsAndWatermarks ( \n         /*\n          1. 给定超时时间为 5s\n          2. 指定数据流中的泛型，这种写法比较奇怪，但也是没办法的事情，是 Flink 和 Java 之前的妥协\n          3. withTimestampAssigner 用于指定当前数据中，哪一个是事件时间：element.f1\n        */ \n         WatermarkStrategy \n             . < Tuple2 < String ,   Long > > forBoundedOutOfOrderness ( Duration . ofSeconds ( 5 ) ) \n             . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n               @Override \n               public   long   extractTimestamp ( Tuple2 < String ,   Long >  element ,   long  l )   { \n                 return  element . f1 ; \n               } \n             } ) \n     ) \n     . keyBy ( r  ->  r . f0 ) \n     // 开一个 5s 的滚动窗口，注意了，这个窗口是事件时间的滚动窗口 \n     . window ( TumblingEventTimeWindows . of ( Time . seconds ( 5 ) ) ) \n     . process ( new   ProcessWindowFunction < Tuple2 < String ,   Long > ,   String ,   String ,   TimeWindow > ( )   { \n       @Override \n       public   void   process ( String  key ,   ProcessWindowFunction < Tuple2 < String ,   Long > ,   String ,   String ,   TimeWindow > . Context ctx ,   Iterable < Tuple2 < String ,   Long > >  elements ,   Collector < String >  out )   throws   Exception   { \n         long  windowStart  =  ctx . window ( ) . getStart ( ) ; \n         long  windowEnd  =  ctx . window ( ) . getEnd ( ) ; \n         long  count  =  elements . spliterator ( ) . getExactSizeIfKnown ( ) ; \n        out . collect ( String . format ( "用户 %s 在窗口 %s - %s 的 pv 次数是 %s" ,  key ,   new   Timestamp ( windowStart ) ,   new   Timestamp ( windowEnd ) ,  count ) ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 我们在这个程序中，举个例子作为说明： \n \n \n 水位线是一个特殊的事件，默认情况下每隔 200ms 会插入一次水位线。在程序运行的一开始，会首先插入一个负无穷大的水位线。 \n \n \n 当这时候输入一个数据  a 1  时，隔了 200ms 之后，根据水位线的公式  水位线 = 观察到的最大时间戳 - 最大延迟时间 - 1 毫秒 ，这个水位线就为  1000ms - 5000ms - 1ms = -4001ms \n \n \n 再次输入一个  a 2 ，隔了 200ms 之后，根据水位线公式，新的水位线为  2000ms - 5000ms -1 ms = -3001ms 。 \n \n \n 再次输入一个  a 5 ，新的水位线为  -1ms 。 \n \n \n 再次输入一个  a 3 ，因为  3000ms  不是最大的时间戳，所以水位线不变，仍然是  -1ms 。 \n 此时输入的  a 3  在物理的场景中，属于延迟到达的情况，但是在事件的时间中，仍然是  a 5  之前。 \n \n \n 再次输入一个  a 10 ，将会插入一个  4999ms  的水位线。因为最大延迟时间为 5s，又因为窗口是左闭右开的，所以  0 -> 5s  的窗口可以关闭并对收集的数据进行计算了。 \n 注意，再次梳理一下时间，当前的代码中有两套时间，一套时间为水位线，一套时间为窗口开窗的时间。 \n 水位线是事件中的逻辑时钟，当水位线到达 4999ms 的时候，在事件的时间里，已经到了 4999ms 了。 \n 窗口开窗时间为 5s，但其实窗口有左闭右开的特性，所以其实真实窗口应该是  0 - 4999ms ，那就正好是水位线的时间。 \n 那么这时候窗口关闭了，事件统计就是  a 1 、 a 2 、 a 3 。 \n \n \n 此时将会输出  用户 a 在窗口 1970-01-01 08:00:00.0 - 1970-01-01 08:00:05.0 的 pv 次数是 3 。 \n 1970-01-01  为格林威治时间，我们输入的  1s  就是从 1970 年开始之后的  1s ，因为在事件的时间中，起始点是  1970-01-01 00:00:00 \n 至于  08:00:00 ，是因为我们在东八区，和格林威治差距 8 个时区。 \n \n \n 之前说水位线是一个事件，这个意思是说，每个算子其实不知道当前水位线是多少，只能等待上一个算子将水位线传下来，然后立刻更新。 \n 迟到数据处理 \n 迟到元素：时间戳小于当前水位线的数据。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv\n     . socketTextStream ( "localhost" ,   9999 ) \n     . map ( ( MapFunction < String ,   Tuple2 < String ,   Long > > )  value  ->   { \n       String [ ]  arr  =  value . split ( " " ) ; \n       return   Tuple2 . of ( arr [ 0 ] ,   Long . parseLong ( arr [ 1 ] )   *   1000L ) ; \n     } ) \n     . returns ( Types . TUPLE ( Types . STRING ,   Types . LONG ) ) \n     . assignTimestampsAndWatermarks ( \n         WatermarkStrategy \n             // 其实就相当于 <Tuple2<String, Long>>forBoundedOutOfOrderness(Duration.ofSeconds(0))，将最大延迟时间设置为 0 \n             . < Tuple2 < String ,   Long > > forMonotonousTimestamps ( ) \n             . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n               @Override \n               public   long   extractTimestamp ( Tuple2 < String ,   Long >  element ,   long  l )   { \n                 return  element . f1 ; \n               } \n             } ) \n     ) \n     // 注意一件事情，我们在这里没有进行过 keyBy，所以我们不能使用关于 key 的方法（例如 onTimer），只能用个 processElement，虽然编译期不会报错，但是运行时会报错 \n     . process ( new   ProcessFunction < Tuple2 < String ,   Long > ,   String > ( )   { \n       @Override \n       public   void   processElement ( Tuple2 < String ,   Long >  value ,   ProcessFunction < Tuple2 < String ,   Long > ,   String > . Context ctx ,   Collector < String >  out )   throws   Exception   { \n         if   ( value . f1  <  ctx . timerService ( ) . currentWatermark ( ) )   { \n          out . collect ( "迟到元素到达" ) ; \n         }   else   { \n          out . collect ( "元素未迟到" ) ; \n         } \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 当前我们给定的水位线迟到时间是 0，而且没有开窗口，这说明我们每一个输入元素都是最新的水位线。 \n \n 输入  a 1 ，水位线更新 \n 输入  a 2 ，水位线更新 \n 输入  a 1 ，水位线没有更新，当前元素在水位线之前，属于迟到元素。 \n \n 迟到元素我们知道了，但是问题是，我们如何去处理事件时间下的迟到元素。DataSream API 有三种策略： \n \n \n 直接抛弃迟到元素。 \n 在开窗口的前提下，假如窗口没有关闭，迟到元素自然也可以进入结果，假如窗口关闭了，那默认策略就是直接抛弃元素。 \n \n \n 将迟到元素发送到另一条流中去。 \n 之前我们都只有一条主流作为数据的处理，但其实我们可以专门开辟另外的 n 条流处理迟到数据。区别于主流的流叫做侧输出流。 \n \n \n 可以更新窗口已经计算完的结果，并且发出计算结果。 \n \n \n 迟到元素到侧输出流 \n // 我们给即将创建的这条侧输出流一个标签，注意，在 new 对象的时候必须也要写上泛型，否则运行时会报错，而且必须写上花括号，侧输出标签也是一个单例 \n private   static   OutputTag < String >  lateOutputTag  =   new   OutputTag < String > ( "late-element" )   { \n } ; \n\n public   static   void   main ( String [ ]  args )   throws   Exception   { \n   StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n  env . setParallelism ( 1 ) ; \n\n   SingleOutputStreamOperator < String >  result  =  env\n       . addSource ( new   SourceFunction < Tuple2 < String ,   Long > > ( )   { \n         @Override \n         public   void   run ( SourceContext < Tuple2 < String ,   Long > >  ctx )   throws   Exception   { \n           /*\n            指定时间，发送数据：\n\n            1. 第一个参数是向下游发送的数据\n            2. 第二个参数是时间戳\n           */ \n          ctx . collectWithTimestamp ( Tuple2 . of ( "HELLO WORLD" ,   1000L ) ,   1000L ) ; \n           // 发送水位线事件，更新水位线 \n          ctx . emitWatermark ( new   Watermark ( 999L ) ) ; \n          ctx . collectWithTimestamp ( Tuple2 . of ( "HELLO FLINK" ,   2000L ) ,   2000L ) ; \n          ctx . emitWatermark ( new   Watermark ( 1999L ) ) ; \n           // 定义迟到数据，发送 \n          ctx . collectWithTimestamp ( Tuple2 . of ( "LATE" ,   1000L ) ,   1000L ) ; \n         } \n\n         @Override \n         public   void   cancel ( )   { \n\n         } \n       } ) \n       . process ( new   ProcessFunction < Tuple2 < String ,   Long > ,   String > ( )   { \n         @Override \n         public   void   processElement ( Tuple2 < String ,   Long >  value ,   ProcessFunction < Tuple2 < String ,   Long > ,   String > . Context ctx ,   Collector < String >  out )   throws   Exception   { \n           if   ( value . f1  <  ctx . timerService ( ) . currentWatermark ( ) )   { \n             /*\n              迟到元素发送到侧输出流：\n\n              1. 第一个参数为侧输出流标签\n              2. 第二个是侧输出流的泛型，这里为 String\n             */ \n            ctx . output ( lateOutputTag ,   String . format ( "迟到元素 %s" ,  value ) ) ; \n           }   else   { \n            out . collect ( String . format ( "正常到达的元素 %s" ,  value ) ) ; \n           } \n         } \n       } ) ; \n\n  result . print ( "主流数据：" ) ; \n  result . getSideOutput ( lateOutputTag ) . print ( "侧输出流数据：" ) ; \n\n  env . execute ( ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 开窗口状态下将迟到数据发送到侧输出流： \n private   static   OutputTag < String >  lateOutputTag  =   new   OutputTag < String > ( "late-element" )   { \n } ; \n\n public   static   void   main ( String [ ]  args )   throws   Exception   { \n   StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n  env . setParallelism ( 1 ) ; \n\n   SingleOutputStreamOperator < String >  result  =  env\n       . addSource ( new   SourceFunction < String > ( )   { \n         @Override \n         public   void   run ( SourceContext < String >  ctx )   throws   Exception   { \n          ctx . collectWithTimestamp ( "a" ,   1000L ) ; \n          ctx . emitWatermark ( new   Watermark ( 999L ) ) ; \n          ctx . collectWithTimestamp ( "a" ,   2000L ) ; \n          ctx . emitWatermark ( new   Watermark ( 1999L ) ) ; \n          ctx . collectWithTimestamp ( "a" ,   4000L ) ; \n           //这里定义了水位线为 4999L，之后将会定义 5s 的滑动窗口，所以到这里，0 - 5s 的窗口就会关闭 \n          ctx . emitWatermark ( new   Watermark ( 4999L ) ) ; \n           // 迟到数据 \n          ctx . collectWithTimestamp ( "a" ,   3000L ) ; \n         } \n\n         @Override \n         public   void   cancel ( )   { \n\n         } \n       } ) \n       . keyBy ( r  ->   1 ) \n       // 开一个 5s 的事件时间的滑动窗口 \n       . window ( TumblingEventTimeWindows . of ( Time . seconds ( 5 ) ) ) \n       // 注意，在这里设置了一下，迟到数就会发送到侧输出流 \n       . sideOutputLateData ( lateOutputTag ) \n       . process ( new   ProcessWindowFunction < String ,   String ,   Integer ,   TimeWindow > ( )   { \n         @Override \n         public   void   process ( Integer  integer ,   ProcessWindowFunction < String ,   String ,   Integer ,   TimeWindow > . Context context ,   Iterable < String >  elements ,   Collector < String >  out )   throws   Exception   { \n          out . collect ( String . format ( "窗口中共有：%s 条数据" ,  elements . spliterator ( ) . getExactSizeIfKnown ( ) ) ) ; \n         } \n       } ) ; \n  result . print ( "主流数据：" ) ; \n  result . getSideOutput ( lateOutputTag ) . print ( "侧输出流数据：" ) ; \n\n  env . execute ( ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 侧输出流标签其实是个匿名类，所以需要花括号。 \n 窗口重新计算 \n 之前的默认策略是：水位线超过窗口距离之后，窗口自动触发计算并且自动销毁，如此一来数据要么被丢弃，要么发送到侧输出流。 \n 但是除此之外，我们还有一种方式，就是水位线超过窗口距离之后，窗口触发计算但是不销毁，等待指定的时间，假如这段时间内数据到达，则重新触发计算，这个时候过了之后才会销毁窗口。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n SingleOutputStreamOperator < String >  result  =  env\n     . socketTextStream ( "localhost" ,   9999 ) \n     . map ( ( MapFunction < String ,   Tuple2 < String ,   Long > > )  value  ->   { \n       String [ ]  arr  =  value . split ( " " ) ; \n       return   Tuple2 . of ( arr [ 0 ] ,   Long . parseLong ( arr [ 1 ] )   *   1000L ) ; \n     } ) \n     . returns ( Types . TUPLE ( Types . STRING ,   Types . LONG ) ) \n     . assignTimestampsAndWatermarks ( \n         WatermarkStrategy \n             . < Tuple2 < String ,   Long > > forBoundedOutOfOrderness ( Duration . ofSeconds ( 5 ) ) \n             . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n               @Override \n               public   long   extractTimestamp ( Tuple2 < String ,   Long >  element ,   long  l )   { \n                 return  element . f1 ; \n               } \n             } ) \n     ) \n     . keyBy ( r  ->  r . f0 ) \n     . window ( TumblingEventTimeWindows . of ( Time . seconds ( 5 ) ) ) \n     // 等待 5s 的迟到事件 \n     . allowedLateness ( Time . seconds ( 5 ) ) \n     . sideOutputLateData ( new   OutputTag < Tuple2 < String ,   Long > > ( "late" )   { \n     } ) \n     . process ( new   ProcessWindowFunction < Tuple2 < String ,   Long > ,   String ,   String ,   TimeWindow > ( )   { \n       @Override \n       public   void   process ( String  s ,   ProcessWindowFunction < Tuple2 < String ,   Long > ,   String ,   String ,   TimeWindow > . Context context ,   Iterable < Tuple2 < String ,   Long > >  elements ,   Collector < String >  out )   throws   Exception   { \n         /*\n          初始化一个窗口状态变量，注意：窗口状态变量的范围是当前窗口\n\n          当窗口第一次触发时，也就是窗口闭合的时候，firstCaculate 为 null。\n         */ \n         ValueState < Boolean >  firstCaculate  =  context . windowState ( ) . getState ( new   ValueStateDescriptor < Boolean > ( "first" ,   Types . BOOLEAN ) ) ; \n         if   ( Objects . isNull ( firstCaculate . value ( ) ) )   { \n          out . collect ( String . format ( "窗口第一次触发计算，水位线为：%s，窗口中有 %s 个元素" ,  context . currentWatermark ( ) ,  elements . spliterator ( ) . getExactSizeIfKnown ( ) ) ) ; \n           // 第一次触发计算之后，更新为 true \n          firstCaculate . update ( true ) ; \n         }   else   { \n          out . collect ( String . format ( "迟到数据到了，更新后的计算结果为 %s" ,  elements . spliterator ( ) . getExactSizeIfKnown ( ) ) ) ; \n         } \n       } \n     } ) ; \n\nresult . print ( "主流：" ) ; \nresult\n     . getSideOutput ( new   OutputTag < Tuple2 < String ,   Long > > ( "late" )   { \n     } ) \n     . print ( "侧输出流：" ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 上面的代码中：水位线最大延迟时间为 5s，滚动窗口的大小为 5s，允许 5s 的迟到元素，还有一个侧输出流： \n \n 输入  a 1 \n 输入  a 10 ，根据水位线公式，当前水位线为  10000L - 5000L -1L = 4999L ，窗口触发计算，并且更新窗口状态变量。 \n 输入  a 1 ，此时窗口没有关闭，所以继续向此窗口发送元素，窗口更新计算结果。 \n 输入  a 15 ，因为超出允许迟到时间，所以窗口关闭。 \n 输入  a 1 ，因为窗口关闭，所以发送到侧输出流。 \n \n 那问题来了：为啥还要搞一个迟到元素的时间呢？为啥不直接设置水位线的最大延迟时间为 10s 呢？这因为可以提前 5s 看到结果，虽然结果不一定准确，但是万一没有迟到元素，那就赚了。 \n 自定义水位线逻辑 \n 底层的水位线接口实际上是  WatermarkStrategy ，它提供了两个必须实现的方法： \n \n onEvent ：每个事件必须调用一次。 \n onPeriodicEmit ：周期性调用（默认 200ms 一次），可能会产生新的水位线，也可能不会。调用周期使用  ExecutionConfig.getAutoWatermarkInterval  配置。 \n \n public   class   CustomWatermarkGenerator   implements   WatermarkStrategy < Tuple2 < String ,   Long > >   { \n\n   // 水位线最大延迟时间 \n   private   Long  bound  =   5000L ; \n   /*\n    最大时间戳，给定初始值为负无穷大，这里就是 -Long.MAX_VALUE + bound + 1L\n    之所以加 bound 在加 1L 的原因是水位线的计算公式，水位线的计算公式是 `最大时间戳 - 最大延迟时间 - 1ms`，这里假如不加，之后就溢出了\n   */ \n   private   Long  maxTs  =   - Long . MAX_VALUE  +  bound  +   1L ; \n\n   /**\n   * @param context\n   * @return 最新的水位线\n   */ \n   @Override \n   public   WatermarkGenerator < Tuple2 < String ,   Long > >   createWatermarkGenerator ( WatermarkGeneratorSupplier . Context  context )   { \n\n     /**\n     * 每个事件都会调用一次\n     */ \n     return   new   WatermarkGenerator < Tuple2 < String ,   Long > > ( )   { \n       @Override \n       public   void   onEvent ( Tuple2 < String ,   Long >  event ,   long  l ,   WatermarkOutput  output )   { \n        maxTs  =   Math . max ( maxTs ,  event . f1 ) ; \n       } \n\n       /**\n       * 默认 200ms 调用一次，用于产生水位线\n       */ \n       @Override \n       public   void   onPeriodicEmit ( WatermarkOutput  output )   { \n        output . emitWatermark ( new   Watermark ( maxTs  -  bound  -   1L ) ) ; \n       } \n     } ; \n   } \n\n   /**\n   * @param context\n   * @return 返回时间戳是哪个字段\n   */ \n   @Override \n   public   TimestampAssigner < Tuple2 < String ,   Long > >   createTimestampAssigner ( TimestampAssignerSupplier . Context  context )   { \n     return   new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n       @Override \n       public   long   extractTimestamp ( Tuple2 < String ,   Long >  value ,   long  l )   { \n         return  value . f1 ; \n       } \n     } ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 注意，虽然生成水位线的公式可以自定义了，但是不要随便改这个公式，因为它是一个最佳实践。 \n 多流转换 \n DataStreamSource < Integer >  stream1  =  env . fromElements ( 1 ,   2 ) ; \n DataStreamSource < Integer >  stream2  =  env . fromElements ( 3 ,   4 ) ; \n DataStreamSource < Integer >  stream3  =  env . fromElements ( 5 ,   6 ) ; \n\n /*\n  union 可以：\n\n  1. 用于多条流的合并。\n  2. 多条流中事件类型必须相同。\n\n  有队列的特点，合并时先来的先合并。\n  */ \n DataStream < Integer >  result  =  stream1 . union ( stream2 ,  stream3 ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 \n 上图的序号代表顺序，可以看出，当事件到来时（多条流合流时），union 算子可以开辟多个空间，每个空间都会存放一个流上的数据内容。 \n 在向后广播变量的时候，算子有优先考虑所有流上已经到达的事件，寻找一个最小的时间戳的数据向下广播发送。所以可以不用担心水位线一下会推得很高，这是比较合理的解决方案。 \n \n 我们假设这样一种情况：设置水位线最大延迟时间为 0，开窗口的事件时间为 5000ms，输入类似  a 1  的数据，其中第一个数据为事件，第二个事件为事件（单位为秒） \n 我们计划输入  a 1 、 b 5  两条数据来测试： \n \n \n 在一开始的时候，水位线为负无穷大。 \n \n \n \n 输入  a 1 ，根据水位线计算公式，此时水位线应该为  1000L - 1L = 999L 。 \n 因为数据按照 key 来进行分区了，所以  a 1  这条数据只能进入到一个 key 通道中，但是  999ms  的水位线被分发到了所有的下游。 \n \n \n \n 输入  b 5 ，水位线到达了  4999ms \n 同样的，因为  b 5  因为 key 不同，所以进入了其他通道中，但是水位线被广播到了所有下游环境中。 \n \n \n \n \n 上面的案例是分流的情况，下面是合流的情况：我们监听两个端口  9999 、 9998 ，水位线最大延迟时间为 0，不开窗直接进行 process（直接处理事件）。 \n SingleOutputStreamOperator < Tuple2 < String ,   Long > >  stream1  =  env\n     . socketTextStream ( "localhost" ,   9999 ) \n     . map ( ( MapFunction < String ,   Tuple2 < String ,   Long > > )  s  ->   { \n       String [ ]  arr  =  s . split ( " " ) ; \n       return   Tuple2 . of ( arr [ 0 ] ,   Long . parseLong ( arr [ 1 ] )   *   1000L ) ; \n     } ) \n     . returns ( Types . TUPLE ( Types . STRING ,   Types . LONG ) ) \n     . assignTimestampsAndWatermarks ( \n         WatermarkStrategy \n             . < Tuple2 < String ,   Long > > forMonotonousTimestamps ( ) \n             . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n               @Override \n               public   long   extractTimestamp ( Tuple2 < String ,   Long >  element ,   long  l )   { \n                 return  element . f1 ; \n               } \n             } ) \n     ) ; \n\n SingleOutputStreamOperator < Tuple2 < String ,   Long > >  stream2  =  env\n     . socketTextStream ( "localhost" ,   9998 ) \n     . map ( ( MapFunction < String ,   Tuple2 < String ,   Long > > )  s  ->   { \n       String [ ]  arr  =  s . split ( " " ) ; \n       return   Tuple2 . of ( arr [ 0 ] ,   Long . parseLong ( arr [ 1 ] )   *   1000L ) ; \n     } ) \n     . returns ( Types . TUPLE ( Types . STRING ,   Types . LONG ) ) \n     . assignTimestampsAndWatermarks ( \n         WatermarkStrategy \n             . < Tuple2 < String ,   Long > > forMonotonousTimestamps ( ) \n             . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Long > > ( )   { \n               @Override \n               public   long   extractTimestamp ( Tuple2 < String ,   Long >  element ,   long  l )   { \n                 return  element . f1 ; \n               } \n             } ) \n     ) ; \n\nstream1\n     . union ( stream2 ) \n     . process ( new   ProcessFunction < Tuple2 < String ,   Long > ,   String > ( )   { \n       @Override \n       public   void   processElement ( Tuple2 < String ,   Long >  stringLongTuple2 ,   ProcessFunction < Tuple2 < String ,   Long > ,   String > . Context context ,   Collector < String >  out )   throws   Exception   { \n        out . collect ( String . format ( "当前水位线是 %s" ,  context . timerService ( ) . currentWatermark ( ) ) ) ; \n       } \n     } ) . print ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 当前有两条 stream，这两条 stream 在 union 的时候，union 算子会开启两个位置存放当前的事件，水位线则是取两者的最小值。 \n \n \n 在一开始的时候，两者的水位线都是负无穷。 \n \n \n \n 在  9999  端口输入  a 1 ，对应的位置的水位线改为了  999ms ，但是水位线取得两者的最小值，所以还是负无穷。 \n \n \n \n 在  9998  端口输入  a 2 ，对应位置的水位线改为了  1999ms ，水位线取得两者最小值，所以为  999ms 。 \n 联结流 \n 联结流， connect 。和  union  有区别： \n \n connect  只能联结两条流。 \n 两条流的元素类型可以不同。 \n \n 既然两条流的类型可以不同，那么我们在联结时就需要注意自己去处理这两条流的类型，因为合流之后只能输出一种类型。 \n stream1\n     . keyBy ( r  ->  r . f0 ) \n     // 使用 connect 进行链接，这里注意，stream2 进行了一次广播，为的是下游中的所有任务中的 stream1 都可以和 stream2 进行连接 \n     . connect ( stream2 . broadcast ( ) ) \n     // 这里注意，既然是输入的两个流，那么第一个和第二个参数就是输入，第三个参数是输出，因为只能输出一种类型 \n     . flatMap ( new   CoFlatMapFunction < Tuple2 < String ,   Long > ,   Tuple2 < String ,   Long > ,   String > ( )   { \n       // 第一个 flatMap 是第一个流的处理 \n       @Override \n       public   void   flatMap1 ( Tuple2 < String ,   Long >  value ,   Collector < String >  out )   throws   Exception   { \n        out . collect ( value . f0 ) ; \n       } \n\n       // 第二个 flatMap 是第二个流的处理 \n       @Override \n       public   void   flatMap2 ( Tuple2 < String ,   Long >  value ,   Collector < String >  out )   throws   Exception   { \n        out . collect ( value . f0 ) ; \n       } \n     } ) \n     . print ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #  CoProcessFunction \n 我们在联结流的时候，用到 flatMap 时，使用的是  CoFlatMapFunction ，它就属于  CoProcessFunction 。 \n 这种  CoProcessFunction  也是处理函数中的一种，我们曾经讲过，Flink 提供了八种 Process Function，CoProcessFunction 就是其中一种。它是双流合并的 API。 \n 我们来看这样一条 SQL： SELECT * FROM A INNER JOIN B WHERE A.id = B.id; \n 对于 Spark 这种批处理的框架来说，它会将 A、B 所有相同 id 的数据 shuffle 到一个分区中再做笛卡尔积，然后进行处理。 \n 但是对于 Flink 来讲，A 和 B 都是数据流，它要求两条流的等值内连接。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n DataStreamSource < Tuple2 < String ,   Integer > >  stream1  =  env . fromElements ( \n     Tuple2 . of ( "a" ,   1 ) , \n     Tuple2 . of ( "a" ,   2 ) , \n     Tuple2 . of ( "b" ,   2 ) \n ) ; \n\n DataStreamSource < Tuple2 < String ,   String > >  stream2  =  env . fromElements ( \n     Tuple2 . of ( "a" ,   "a" ) , \n     Tuple2 . of ( "b" ,   "b" ) \n ) ; \n\nstream1\n     // stream1 根据 key 分区 \n     . keyBy ( r  ->  r . f0 ) \n     // stream2 也根据 key 分区，这样可以保证 stream1 和 stream2 的相同 key 的数据可以进入到一个分区中 \n     . connect ( stream2 . keyBy ( r  ->  r . f0 ) ) \n     . process ( new   CoProcessFunction < Tuple2 < String ,   Integer > ,   Tuple2 < String ,   String > ,   String > ( )   { \n\n       // 既然要做等值连接，那么肯定要将数据保存下来，这里就可以利用状态变量了 \n       ListState < Tuple2 < String ,   Integer > >  list1 ; \n       ListState < Tuple2 < String ,   String > >  list2 ; \n\n       @Override \n       public   void   open ( Configuration  parameters )   throws   Exception   { \n         super . open ( parameters ) ; \n        list1  =   getRuntimeContext ( ) . getListState ( \n             new   ListStateDescriptor < Tuple2 < String ,   Integer > > ( "list1" ,   Types . TUPLE ( Types . STRING ,   Types . INT ) ) \n         ) ; \n        list2  =   getRuntimeContext ( ) . getListState ( \n             new   ListStateDescriptor < Tuple2 < String ,   String > > ( "list2" ,   Types . TUPLE ( Types . STRING ,   Types . STRING ) ) \n         ) ; \n\n       } \n\n       @Override \n       public   void   processElement1 ( Tuple2 < String ,   Integer >  value ,   CoProcessFunction < Tuple2 < String ,   Integer > ,   Tuple2 < String ,   String > ,   String > . Context context ,   Collector < String >  out )   throws   Exception   { \n        list1 . add ( value ) ; \n        list2 . get ( ) . forEach ( e  ->   { \n          out . collect ( String . format ( "%s => %s" ,  value ,  e ) ) ; \n         } ) ; \n       } \n\n       @Override \n       public   void   processElement2 ( Tuple2 < String ,   String >  value ,   CoProcessFunction < Tuple2 < String ,   Integer > ,   Tuple2 < String ,   String > ,   String > . Context context ,   Collector < String >  out )   throws   Exception   { \n        list2 . add ( value ) ; \n        list1 . get ( ) . forEach ( e  ->   { \n          out . collect ( String . format ( "%s => %s" ,  e ,  value ) ) ; \n         } ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #  基于间隔和窗口的 JOIN \n CoProcessFunction 确实是对于两条流合并的功能十分强大，但是需要用到大量的状态变量、定时器等，而且写法比较麻烦。为了简化，Flink 提供了两个语法糖：基于间隔的 JOIN、基于窗口的 JOIN。 \n 使用时可以优先使用这俩语法糖，不行再用 CoProcessFunction。 \n 基于间隔的 JOIN \n 这个意思是说，第一个流的一个元素和第二个流中某一段元素进行 JOIN。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n SingleOutputStreamOperator < Event >  orderStream  =  env\n     . fromElements ( \n         // 给一个下订单时间，发生时间是在 20min 的时候 \n         Event . of ( "user-1" ,   "order" ,   20   *   60   *   1000L ) \n     ) \n     . assignTimestampsAndWatermarks ( WatermarkStrategy \n         . < Event > forMonotonousTimestamps ( ) \n         . withTimestampAssigner ( new   SerializableTimestampAssigner < Event > ( )   { \n           @Override \n           public   long   extractTimestamp ( Event  event ,   long  l )   { \n             return  event . getTimestamp ( ) ; \n           } \n         } ) \n     ) ; \n\n SingleOutputStreamOperator < Event >  pvStream  =  env\n     . fromElements ( \n         // 给三个浏览事件，时间分别在 5min、10min、12min 时 \n         Event . of ( "user-1" ,   "pv" ,   5   *   60   *   1000L ) , \n         Event . of ( "user-1" ,   "pv" ,   10   *   60   *   1000L ) , \n         Event . of ( "user-1" ,   "pv" ,   12   *   60   *   1000L ) \n     ) \n     . assignTimestampsAndWatermarks ( WatermarkStrategy \n         . < Event > forMonotonousTimestamps ( ) \n         . withTimestampAssigner ( new   SerializableTimestampAssigner < Event > ( )   { \n           @Override \n           public   long   extractTimestamp ( Event  event ,   long  l )   { \n             return  event . getTimestamp ( ) ; \n           } \n         } ) \n     ) ; \n\norderStream\n     . keyBy ( r  ->  r . getUserId ( ) ) \n     // 使用 intervalJoin，就是间隔 JOIN \n     . intervalJoin ( pvStream . keyBy ( r  ->  r . getUserId ( ) ) ) \n     // 采用之前 10min 的 pv 事件进行 JOIN，这也就代表 pv 为 5min 的不会被 JOIN，不仅可以 JOIN 过去，还可以 JOIN 未来。 \n     . between ( Time . minutes ( - 10 ) ,   Time . minutes ( 0 ) ) \n     // 使用间隔 JOIN，那么使用 ProcessJoinFunction 即可 \n     . process ( new   ProcessJoinFunction < Event ,   Event ,   String > ( )   { \n       @Override \n       public   void   processElement ( Event  event ,   Event  event2 ,   ProcessJoinFunction < Event ,   Event ,   String > . Context context ,   Collector < String >  out )   throws   Exception   { \n        out . collect ( String . format ( "%s => %s" ,  event ,  event2 ) ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 其实两条流相互 JOIN 都是相对的，假如是 pvStream JOIN orderStream，那么 JOIN 的时间就需要变化了。 \n 基于窗口的 JOIN \n 两条流的元素进入到相同的窗口，然后进行 JOIN。 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n SingleOutputStreamOperator < Tuple2 < String ,   Integer > >  stream1  =  env\n     . fromElements ( Tuple2 . of ( "a" ,   1 ) ,   Tuple2 . of ( "b" ,   1 ) ) \n     . assignTimestampsAndWatermarks ( WatermarkStrategy \n         . < Tuple2 < String ,   Integer > > forMonotonousTimestamps ( ) \n         . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Integer > > ( )   { \n           @Override \n           public   long   extractTimestamp ( Tuple2 < String ,   Integer >  element ,   long  l )   { \n             return  element . f1 ; \n           } \n         } ) \n     ) ; \n\n SingleOutputStreamOperator < Tuple2 < String ,   Integer > >  stream2  =  env\n     . fromElements ( Tuple2 . of ( "a" ,   2 ) ,   Tuple2 . of ( "b" ,   2 ) ,   Tuple2 . of ( "b" ,   3 ) ) \n     . assignTimestampsAndWatermarks ( WatermarkStrategy \n         . < Tuple2 < String ,   Integer > > forMonotonousTimestamps ( ) \n         . withTimestampAssigner ( new   SerializableTimestampAssigner < Tuple2 < String ,   Integer > > ( )   { \n           @Override \n           public   long   extractTimestamp ( Tuple2 < String ,   Integer >  element ,   long  l )   { \n             return  element . f1 ; \n           } \n         } ) \n     ) ; \n\n // 我们发现之前的写法都是先 keyBy 之后再 JOIN，这里就成了 JOIN 然后指定 key，这就是个历史遗留问题，其实也是因为不怎么有用导致不更新的 \nstream1\n     . join ( stream2 ) \n     // stream1 的 key \n     . where ( r  ->  r . f0 ) \n     // equalTo stream2 的 key \n     . equalTo ( r  ->  r . f0 ) \n     . window ( TumblingEventTimeWindows . of ( Time . seconds ( 5 ) ) ) \n     // 这里也不是 process，而是 apply \n     . apply ( new   JoinFunction < Tuple2 < String ,   Integer > ,   Tuple2 < String ,   Integer > ,   String > ( )   { \n       @Override \n       public   String   join ( Tuple2 < String ,   Integer >  first ,   Tuple2 < String ,   Integer >  second )   throws   Exception   { \n         return   String . format ( "%s => %s" ,  first ,  second ) ; \n       } \n     } ) \n     . print ( ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"March 30, 2022 14:56",createTimeStamp:1648623383e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Flink-03-机制",frontmatter:{title:"Flink-03-机制",categories:["bigdata"],tags:["flink"],author:"causes",summary:"Flink 中的状态管理 Flink 是有状态的流式计算。状态可以理解为是一个本地变量，隔一段时间保存到文件系统上，用于宕机后恢复程序，状态变量可以被任务的业务逻辑访问。 总体来说，Flink 中的状态有两种： 算子状态（Operator State）：算子状态的作用范围限定为算子任务。; 键控状态（Keyed State）：根据输入数据流中定义的 key ",meta:[{property:"og:url",content:"/bigdata/Flink/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Flink-03-机制"},{property:"og:description",content:"Flink 中的状态管理 Flink 是有状态的流式计算。状态可以理解为是一个本地变量，隔一段时间保存到文件系统上，用于宕机后恢复程序，状态变量可以被任务的业务逻辑访问。 总体来说，Flink 中的状态有两种： 算子状态（Operator State）：算子状态的作用范围限定为算子任务。; 键控状态（Keyed State）：根据输入数据流中定义的 key "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"flink"}]},regularPath:"/bigdata/Flink/part3.html",relativePath:"bigdata/Flink/part3.md",key:"v-1fe2b188",path:"/bigdata/Flink/part3/",headers:[{level:2,title:"Flink 中的状态管理",slug:"flink-中的状态管理"},{level:2,title:"Flink 中的容错机制",slug:"flink-中的容错机制"},{level:2,title:"Flink 端到端一致性",slug:"flink-端到端一致性"},{level:2,title:"Flink 连接器",slug:"flink-连接器"},{level:3,title:"Kafka",slug:"kafka"},{level:3,title:"Redis",slug:"redis"},{level:3,title:"自定义 sink",slug:"自定义-sink"}],readingTime:{minutes:12.23,words:3668},content:' Flink 中的状态管理 \n Flink 是有状态的流式计算。状态可以理解为是一个本地变量，隔一段时间保存到文件系统上，用于宕机后恢复程序，状态变量可以被任务的业务逻辑访问。 \n 总体来说，Flink 中的状态有两种： \n \n 算子状态（Operator State）：算子状态的作用范围限定为算子任务。 \n 键控状态（Keyed State）：根据输入数据流中定义的 key 来维护和访问。 \n \n 之前我们大部分时间用的都是键控状态（ValueState、MapState、ListState 等），没用过算子状态。 \n 那么算子状态和键控状态和监控状态的区别就是：键控状态可见范围是当前 key，算子状态的可见状态是当前任务槽。 \n 状态后端 \n 状态后端是一个可插入的组件，用于本地的状态管理（内存），将状态写入到远程存储（磁盘、文件系统）。 \n 状态后端有几种： \n \n \n MemoryStateBackend \n 内存级状态后端，默认的状态后端。会将键控状态作为内存中的对象管理，存在 TaskManager 的 JVM 上，检查点则存在 JobManager 的内存中。 \n 特点：快速、低延迟、不稳定。 \n \n \n FsStateBackend \n 文件系统状态后端，可以选择本地文件系统和远程文件系统。本地状态处理和  MemoryStateBackend  相同，checkpoint 则放到文件系统。 \n \n \n RocksDBStateBackend \n 所有状态均序列化，放到本地的 RocksDB。RocksDB 是一个硬盘的 KV 数据库。 \n \n \n 修改状态后端： \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\nenv . setStateBackend ( new   FsStateBackend ( "file:///home/user/Desktop" ) ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 Flink 默认只保存最近一次的检查点。 \n Flink 中的容错机制 \n Flink 中的容错机制主要有以下几点： \n \n 一致性检查点 checkpoint，从检查点恢复状态。 \n Flink 检查点算法，chandy-lamport 的变种。 \n 保存点 save point。 \n \n 一致性检查点 checkpoint \n 一致性检查点其实可以看成一个快照，用于保存某个时间点的状态。 \n 这个时间点应该是所有和上游打交道的、需要数据的任务都恰好处理完一个相同的输入数据的时候。 \n \n 从上游（比如 kafka）中拿到的数据从 source 拿到，并且分发给两个算子，其中算子  sum_event  计算偶数求和，算子  sum_odd  计算奇数求和。上游数据向 flink 发送  1、2、3、4、5、6、7、……  数据。 \n 在上图中， source(5)  代表的是偏移量，索引从 0 开始。 \n 那么这表示算子已经处理完了  1、2、3、4、5 ，也就是  sum_event  已经处理了  2 + 4 ， sum_odd  已经处理了  1 + 3 + 5 ，并且对于 kafka 来讲，数据源  source  刚刚消费完偏移量为 5 的数据。 \n 此时进行检查点保存，存储保存了  5、6、9 ，也就是将计算的结果和将要计算的数据的偏移量都保存了。 \n 这个检查点之前已经说了，恰好处理完一个相同输入数据的时候。对于 flink 来讲，此时只有一个  source  来处理上游的输入数据，那么只要当 source 刚好消费完成之后但是还没来得及向下游的算子发送数据时，这个时候就是检查点。 \n \n 此时一个算子发生了故障，看到上图中，算子  sum_odd  挂了，那么就需要从检查点恢复数据了。 \n \n 恢复数据时，首先就是重启应用 \n \n 重启应用之后，根据状态变量的名字来读取状态变量 \n \n 读取完成状态变量之后，我们重新消费数据。这个重新消费数据需要注意，我们的上游必须要支持能够支持根据偏移量重新读取数据的操作（比如使用 kafka，可以支持），否则数据肯定会丢失（比如 socket）。 \n 这种检查点的恢复和保存机制可以为程序提供精准一次（exactly-once）的特点，因为所有的算子都会保存检查点并恢复所有状态，所以针对所有的输入数据都会进行计算，并且只计算一次。 \n 检查点算法 \n Flink 实现的检查点算法是异步的思想，是基于 Chandy-Lamport 算法的一种改变，它的思想是将保存和数据处理分离，不暂停整个应用。 \n Flink 的检查点算法用到了一种叫做检查点分界线（checkpoint barrier）的特殊数据形式，用于将一条流上数据按照不同检查点分开，也可以理解为是一种特殊的事件。 \n 假如现在的任务中，有两个输入流，两个算子，两个 sink： \n \n 那么检查点的操作应该是这样的： \n \n \n JobManager 会向每一个 Source 算子发送一个检查点的事件，检查点事件 ID 应该都是相同的（比如说检查点事件 ID 为 2），也就是下图中三角形的事件。 \n \n \n \n 检查点事件发送到了两个 Source 算子，两个 Source 算子将自己的状态交给状态后端用于保存 Source 算子当前的状态，保存状态之后，状态后端告诉 Source 算子，Source 算子再告诉 JobManager。 \n \n \n 确认两个 Source 的状态保存完成之后，分界线继续向下游发送，发送给两个 sum 算子。 \n \n source 算子是两个，那么保存完成检查点之后，每一个 sum 算子都会复制一份自己的得到的分界线事件并广播到下游中，所以每一个下游的算子都会得到上游的每个 source 算子的检查点事件。 \n 我们以 sum event 算子为例子： \n 当第一个 source 算子的检查点事件到达之后，此算子就会停止计算，继续等待其他的检查点事件算子到达（也就是上图中，属于 source2 的黄色的检查点和属于 source1 蓝色的检查点都到达）。 \n 第一个检查点算子算子到达之后，第二个检查点算子还没有到达这期间，即使有需要计算的数据到来，算子也只是将数据缓存下来不会进行计算。 \n 只有两个检查点算子都到达了，这个算子会进行状态保存，然后将检查点算子发送到下游，然后才会计算数据。 \n 那么 sum odd 算子也是相同的操作。 \n \n \n 两个计算算子完成了，那么继续向下游转发检查点分界线。到了 sink 算子，那么 sink 也会保存自己当前的状态。 \n \n sink 算子处理完成之后，在这里也就是所有的任务都确认已经完成了状态保存。 \n 那么此次状态保存的操作就真正的完成了，Flink 会将这次的状态保存标志为完成态，在默认策略下，会替换掉上次的检查点，只留一个。 \n \n \n 检查点是随着数据流动的，这也就说明，假如检查点之前的数据没有被算子处理完成，那么检查点就会卡在这个算子上，所以假如检查点迟迟完不成，那么就需要看一下到底是在哪一步被阻塞了。 \n 保存点 save point \n 检查点是自动保存自动恢复，保存点是手动保存手动恢复，它底层算法和检查点是一样的。保存点可以用来做 AB 测试，看看两个程序哪个好使就用哪个。 \n Flink 端到端一致性 \n 一致性保证，有如下分类： \n \n 最多一次：AT_MOST_ONCE：任务故障时，什么也不做，也不重播丢失的数据，也不恢复状态，也就是最多处理一次事件。例如 UDP，不提供任何保障。 \n 至少一次：AT_LEAST_ONCE：大多数场景中，我们不希望丢失任何事件。所有的事件都会得到处理，但是有可能会被处理多次。 \n 精准一次：EXACTLY_ONCE：数据没有丢失，并且都进行了处理，并且恰好每个数据只处理了一次，是最理想的结果，也是最难实现的。 \n \n Flink 的容错机制保证的是 Flink 内部的一致性，那么端到端的一致性如何保证？因为在真实的场景中，除了 Flink 内部的一致性，还有上面的数据源（比如 Kafka、其他消息队列、文件等），以及下游的输出（Kafka、Redis、文件系统等）。 \n 整个端到端的一致性保证最薄弱的点取决于所有组件一致性最弱的组件。那么要保证端到端的一致性，就必须要保证每一个组件都保证它自己的一致性。 \n 在 Flink 中，和其他端对接时，内部保证的是检查点算法，Source 端需要的是可重设读取位置的数据（Kafka、文件系统等），sink 端提供的是不会重复写入外部系统的操作（幂等性写入、事务写入）。 \n 上游设备我们只能尽可能选用可以重设读取位置的数据（比如 Kafka、文件系统），一旦选了不能重复的组件（比如 Socket），那么绝对不能重现数据了。 \n 我们主要考虑是下游的对接：幂等性、事务写入。 \n 幂等写入 \n 幂等操作的意思是，一个操作可以重复很多次，但是只会更改一次数据。比如 map，无论输入几次数据，只会有一次更改数据；再比如 hash，也是输入相同输出相同。或者可以理解为，幂等性就是无状态的服务。 \n 当数据写到一半程序宕机了，那么 Flink 会回退到上一个版本的检查点，也会重新给下游的 sink 之前的数据，这样会导致结果的回退。 \n 所以幂等性写入可以保证 exactly once。 \n 事务写入 \n Flink 的事务写入的实现思想是和检查点对应，当检查点完成的时候再将结果写入到 sink 中。 \n Flink 中的事务写入分两种： \n \n \n 预写日志 Write Ahead Log，WAL：只能保证 at least once。 \n 将结果数据先保存到状态后端（这个不是检查点，是需要输出的数据），检查点完成之后会一下将结果放到 sink。 \n 其实本身它不是个事务，因为万一在输出到 sink 之后挂掉，结果就没了。 \n \n \n 两阶段提交 Two Phase Commit，2PC：可以保证 exactly once。 \n 对每一个检查点，下游设备都会开启一个事务（下游设备必须支持事务），Flink 将结果数据放到事务中，检查点完成之后给下游通知，此时下游的事务提交。 \n \n \n 那么事务的两阶段提交可能会导致在事务提交之前看不到数据，只有事务写入之后才能看到数据。 \n 2PC 对下游 sink 系统的要求： \n \n 必须提供事务支持，或者可以模拟事务。 \n 在每个 checkpoint 间隔期间，必须能够开启一个事务并接受事务写入。 \n 在收到 checkpoing 完成的通知前，不能提交事务。假如 Flink 写入 sink 失败了（或者写入超时了），那么事务必须回滚，必须丢弃未提交的数据。 \n 在进程失败之后必须能够恢复事务。 \n 提交事务必须是幂等操作。 \n Flink 连接器 \n Kafka \n \n \n 添加 flink-kafka 依赖 \n < dependency > \n     < groupId > org.apache.flink </ groupId > \n     < artifactId > flink-connector-kafka_2.12 </ artifactId > \n     < version > 1.13.0 </ version > \n </ dependency > \n \n 1 2 3 4 5 maven 中添加依赖需要有些注意事项，类似这种连接器一般放到后面（但是在日志之前），这个顺序有可能会影响程序执行。 \n \n \n kafka 写入 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n Properties  props  =   new   Properties ( ) ; \nprops . put ( "bootstrap.servers" ,   "localhost:9092" ) ; \n\n // 读取 csv 文件写入到 kafka \nenv\n     . readTextFile ( "UserBehavior.csv" ) \n     // 三个参数分别为：kafka 的 topic、数据类型（这里是 String）、配置文件 \n     . addSink ( new   FlinkKafkaProducer < String > ( \n         "user-behavior" , \n         new   SimpleStringSchema ( ) , \n        props\n     ) ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n \n kafka 读取 \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n Properties  props  =   new   Properties ( ) ; \nprops . setProperty ( "bootstrap.servers" ,   "localhost:9092" ) ; \n // 消费者组 \nprops . setProperty ( "group.id" ,   "consumer-group" ) ; \n // 从 kafka 读取的时候需要反序列化，这里用的类型就是字符串的反序列化 \nprops . setProperty ( "key.deserializer" ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \nprops . setProperty ( "value.deserializer" ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \n // 重置 offset 到最后 \nprops . setProperty ( "auto.offset.reset" ,   "latest" ) ; \n\nenv . addSource ( new   FlinkKafkaConsumer < String > ( "user-behavior" ,   new   SimpleStringSchema ( ) ,  props ) ) . map ( new   MapFunction < String ,   UserBehavior > ( )   { \n   @Override \n   public   UserBehavior   map ( String  s )   throws   Exception   { \n     String [ ]  arr  =  s . split ( "," ) ; \n     return   new   UserBehavior ( arr [ 0 ] ,  arr [ 1 ] ,  arr [ 2 ] ,  arr [ 3 ] ,   Long . parseLong ( arr [ 4 ] )   *   1000L ) ; \n   } \n } ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n Redis \n \n \n 导入依赖 \n < dependency > \n     < groupId > org.apache.bahir </ groupId > \n     < artifactId > flink-connector-redis_2.11 </ artifactId > \n     < version > 1.0 </ version > \n </ dependency > \n \n 1 2 3 4 5 这个驱动比较诡异，他底层依赖的是 flink 1.2，并且到现在都没有更新。所以一定要将它放到依赖的最后面。 \n Redis 虽然有持久化机制，但毕竟不是个正经的持久化技术。所以一般不向 Redis 写数据。 \n MySQL 虽然是持久化技术，但是并发性能差（一般只有几十，不超过百），并且一般前面有个缓存，我们一般也不写到 MySQL 中。 \n \n \n 写入到 Redis \n public   static   void   main ( String [ ]  args )   throws   Exception   { \n     StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \n    env . setParallelism ( 1 ) ; \n\n     FlinkJedisPoolConfig  conf  =   new   FlinkJedisPoolConfig . Builder ( ) . setHost ( "localhost" ) . setPort ( 6379 ) . build ( ) ; \n\n    env\n         . fromElements ( Tuple2 . of ( "key" ,   1 ) ,   Tuple2 . of ( "key" ,   2 ) ) \n         . addSink ( new   RedisSink < Tuple2 < String ,   Integer > > ( conf ,   new   CustRedisMapper ( ) ) ) ; \n\n    env . execute ( ) ; \n } \n\n public   static   class   CustRedisMapper   implements   RedisMapper < Tuple2 < String ,   Integer > >   { \n\n     @Override \n     public   RedisCommandDescription   getCommandDescription ( )   { \n     // 这就相当于 redis 命令中的 `hset tuple ${key} ${value}` \n     return   new   RedisCommandDescription ( RedisCommand . HSET ,   "tuple" ) ; \n     } \n\n     // 指定 key \n     @Override \n     public   String   getKeyFromData ( Tuple2 < String ,   Integer >  in )   { \n     return  in . f0 ; \n     } \n\n     // 指定 value \n     @Override \n     public   String   getValueFromData ( Tuple2 < String ,   Integer >  in )   { \n     return  in . f1 . toString ( ) ; \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \n 自定义 sink \n 我们以 MySQL 为例，写一个进入到 MySQL 的 sink \n \n \n JDBC 驱动 \n < dependency > \n     < groupId > mysql </ groupId > \n     < artifactId > mysql-connector-java </ artifactId > \n     < version > 8.0.21 </ version > \n </ dependency > \n \n 1 2 3 4 5 \n \n 自定义 sink \n StreamExecutionEnvironment  env  =   StreamExecutionEnvironment . getExecutionEnvironment ( ) ; \nenv . setParallelism ( 1 ) ; \n\n FlinkJedisPoolConfig  conf  =   new   FlinkJedisPoolConfig . Builder ( ) . setHost ( "localhost" ) . setPort ( 6379 ) . build ( ) ; \n\nenv\n     . fromElements ( Tuple2 . of ( "key" ,   1 ) ,   Tuple2 . of ( "key" ,   2 ) ) \n     . addSink ( new   RichSinkFunction < Tuple2 < String ,   Integer > > ( )   { \n     private   Connection  conn ; \n     private   PreparedStatement  stmt ; \n\n     @Override \n     public   void   open ( Configuration  parameters )   throws   Exception   { \n         super . open ( parameters ) ; \n         // MySQL 连接 \n        conn  =   DriverManager . getConnection ( "jdbc:mysql://localhost:3306/userbehavior" ,   "root" ,   "root" ) ; \n        stmt  =  conn . prepareStatement ( "INSERT INTO userbehavior (k, v) VALUES (?, ?)" ) ; \n     } \n\n     @Override \n     public   void   invoke ( Tuple2 < String ,   Integer >  value ,   Context  context )   throws   Exception   { \n         super . invoke ( value ,  context ) ; \n        stmt . setString ( 1 ,  value . f0 ) ; \n        stmt . setString ( 2 ,  value . f1 . toString ( ) ) ; \n     } \n\n     @Override \n     public   void   close ( )   throws   Exception   { \n         super . close ( ) ; \n        stmt . close ( ) ; \n     } \n     } ) ; \n\nenv . execute ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \n \n',updateTime:"April 14, 2022 15:11",updateTimeStamp:1649920262e3,createTime:"April 14, 2022 15:11",createTimeStamp:1649920262e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"HBase-01-起步",frontmatter:{title:"HBase-01-起步",categories:["bigdata"],tags:["hbase"],author:"causes",summary:"HBase 简介 HBase 是分布式的、可扩展的、支持海量数据存储的 NoSQL 数据库（基于 Hadoop 的数据库），支持对数据进行大量、实时、随机读写的操作。 HBase 的逻辑结构 HBase 在表现上类似关系型数据库，但是在底层存储是 kv，更像是一个多维度 map，但是我们一般将其归类为列存储 NoSQL。 列族：; HBase 和我们之前的关",meta:[{property:"og:url",content:"/bigdata/HBase/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"HBase-01-起步"},{property:"og:description",content:"HBase 简介 HBase 是分布式的、可扩展的、支持海量数据存储的 NoSQL 数据库（基于 Hadoop 的数据库），支持对数据进行大量、实时、随机读写的操作。 HBase 的逻辑结构 HBase 在表现上类似关系型数据库，但是在底层存储是 kv，更像是一个多维度 map，但是我们一般将其归类为列存储 NoSQL。 列族：; HBase 和我们之前的关"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hbase"}]},regularPath:"/bigdata/HBase/part1.html",relativePath:"bigdata/HBase/part1.md",key:"v-13d1b368",path:"/bigdata/HBase/part1/",headers:[{level:2,title:"HBase 简介",slug:"hbase-简介"},{level:2,title:"HBase 基本架构",slug:"hbase-基本架构"},{level:2,title:"环境搭建",slug:"环境搭建"},{level:2,title:"Shell 操作",slug:"shell-操作"}],readingTime:{minutes:5.57,words:1670},content:" HBase 简介 \n HBase 是分布式的、可扩展的、支持海量数据存储的 NoSQL 数据库（基于 Hadoop 的数据库），支持对数据进行大量、实时、随机读写的操作。 \n HBase 的逻辑结构 \n \n HBase 在表现上类似关系型数据库，但是在底层存储是 kv，更像是一个多维度 map，但是我们一般将其归类为列存储 NoSQL。 \n \n \n 列族： \n HBase 和我们之前的关系型数据库不同的第一点就是列族，每一个列族下面可以任意指定列的数量。 \n 在 HBase 中，列不能单独存在，必须属于某一个列族。 \n \n \n Row Key： \n row key，也叫做行键。 \n 在 HBase 中，每一行数据都有自己的 row key，这个 row key 是唯一的。 \n row key 是会自动排序的，也就是说数据进入到 HBase 中会根据 row key 自动排序。 \n 排序规则是根据字典顺序来的，比如  1 -> 11 -> 2 ，而不是  1 -> 2 -> …… -> 11 。 \n \n \n region： \n 在 HBase 中，横向将表进行切分，比如上图中， row_key3、row_key4、row_key5  对应行的数据为一个 region（分区）。 \n 切分的原因就是因为表太大了，不好维护，所以必须要进行切分，每一个 region 去单独维护。 \n 每一个 region 中的数据绝对会存储到一台机器上。 \n \n \n store： \n 我们横向切完之后会纵向切分 region，形成 store，比如上图中， row_key1、row_key11、row_key2  对应的 region 根据列族切分，形成了两个 store。 \n store，存储，顾名思义，物理存储是以一个 store 为单位进行存储的。 \n 所以，每一个 region 的数据都会存到一个机器上，但是又会按照每一个列族都切分，每一个列族都会存到不同的文件中。 \n \n \n 物理存储结构 \n \n 我们以一个 store 为例子，说明物理存储方式。 \n 对于  row_key1  对应的行来说，它有三个列： name 、 city 、 phone 。那么这行中的每一列都会在物理上成为 kv 键值对。 \n k 包括  row key 、 列族 、 列名称 、 时间戳 、 类型（PUT/DELETEColumn） ，value 就是当前对应的值，比如 name 为  张三 。 \n 在上图中，手机号存储了两次，时间戳和值都是不同的，这就代表着手机号有多个版本，也就是数据进行了修改操作（在 HBase 中，添加/修改都是 PUT 操作，删除是操作有多种标识，之后会涉及）。 \n HBase 号称是支持随机实时读写操作，但是也不能违背 HDFS 的规则。所以 HBase 会将我们的每一个操作都追加到文件末尾，给我们一种随机实时的假象。 \n 也就是说 HBase 在一开始并没有真正的修改这条数据，而是又记录了一个新的内容，然后通过时间戳去判断应该使用哪一个。 \n 但是 HBase 会在一段时间后删除之前版本的记录，留下最后的内容，防止垃圾数据太多，也就是先假后真。 \n 术语 \n \n \n Name Space： \n 命名空间，类似关系型数据库的 database，每个 namespace 下有多个表，自带 default 和 hbase 内置表。 \n \n \n Table： \n 表，HBase 定义表只需要声明列族，不需要指定列。这意味着字段在写入时，可以动态指定。 \n \n \n Row： \n 每行数据都由一个 Row Key + 多个 Column（列） 组成，数据按照 Row Key 排序检索（一般我们会按照 Row Key 查询，假如按照别的字段查询，它没有索引，会扫描整张表，效率太低）。 \n \n \n Column： \n 列由列族（Column Family） + 列限定符（Column Qualifier、列名字）组成。 \n \n \n Timestamp：时间戳 \n \n \n Cell： \n Row Key、Column Family、Column Qualifier、Timestamp 唯一确定一个单元叫做 cell，cell 中的数据全部都是字节码形式存储。 \n HBase 基本架构 \n \n \n \n Region Server： \n Region 的管理者，可以对数据实现增删改查的操作，可以对 Region 实现切分、合并（StoreFile 合并）的操作。 \n 每个 Region Server 中可以有多个 Region，这些 Region 不一定是来自同一张表，可能会来自不同的表。 \n Region 划分的 Store 将会存储到机器的不同文件中，这些文件叫做 StoreFile（或者叫做 HFile） \n \n \n Master： \n Region Server 的管理者，可以对表进行增删改的操作，可以对 Region Server 进行监控、分配 region、负载均衡、故障转移操作。 \n \n \n Zookeeper： \n HBase 通过 Zookeeper 实现 Master 高可用、Region Server 监控、元数据入口、集群配置等工作。 \n \n \n HDFS： \n 底层存储服务，提供高可用支持。 \n 环境搭建 \n TODO \n Shell 操作 \n 基本操作 \n \n 链接 hbase shell： hbase shell \n \n \n \n \n 列出 namespace： list_namespace \n default：默认空间 \n hbase：系统使用的 \n \n \n 创建 namespace： create_namespace \"test\" \n 可以在创建 namespace 时给定属性值： create_namespace \"test01\", {\"author\"=>\"wyh\", \"create_time\"=>\"2020-03-10 08:08:08\"} \n \n \n 查看 namespace 详细情况： describe_namespace \"test01\" \n \n \n 修改 namespace： alter_namespace \"test01\", {METHOD => 'set', 'author' => 'weiyunhui'} \n 通过 set 设置属性值，使用 unset 删除属性值。 \n \n \n 删除 namespace： drop_namespace \"test01\" \n 要删除的 namespace 必须是空的，下面必须没有表，有表存在是 drop 不掉的。 \n \n \n \n \n \n 查看有哪些表： list \n 此命令会将所有 namespace 下的，非系统创建的所有表列出。 \n \n \n 创建表： create 'student' \n 不指定 namespace 的话，默认使用 default，假如想要在某个 namespace 下建立，需要使用  {namespace}:{table} \n 例如： create 'ns1:t1'  代表在 n1 这个 namespace 下创建了 t1 表。 \n 可以使用 NAME 语法指定属性： create ns1:t1,{NAME=>'f1'} ，指定了 f1 这个列族。除了指定列族之外，还可以指定其他属性，例如  VERSION  版本。 \n 假如只想要指定列族属性，可以简化为： create 'n1:t1','f1' \n \n \n 查看表的详细信息： describe 'student' \n \n \n 变更表： alter 'student',{NAME=>'f1',VERSIONS=>3},{NAME=>'f2',VERSIONS=>6} \n 如果需要对列族更改的话，如果需要加列族，直接写就可以了，删除使用  alter 'student','delete'=>'f1' \n 在实际过程中，不回去搞很多列族，既然列族下面可以有 n 个列，在大部分情况下，按照业务分列族就够用了。 \n \n \n 表的启动和下线： \n 下线表： disable 'student' 。启动表： enable 'student' 。 \n \n \n 删除表： drop 'student' \n HBase 中，如果需要删除一张表，需要先令表下线 \n \n \n \n \n \n 插入数据： \n \n put 'namespace:表'， 'rowKey'，'列族:列', '值' ： put 'stu' '1001', 'info:name', 'zhangsan' \n \n 插入数据时注意，我们平常说的 HBase 是一张大表，其实指的是逻辑结构，底层存储是 kv，所以 rowKey 可以对应任意的列数量，不需要和其他 rowKey 对应的列数量一致。 \n \n \n 查询数据： \n \n get 'namespace:表', 'rowKey' : get 'stu', '1001' \n \n \n \n",updateTime:"July 11, 2022 14:00",updateTimeStamp:1657519215e3,createTime:"May 30, 2022 13:06",createTimeStamp:1653887199e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2}]},{title:"Flume",frontmatter:{title:"Flume",categories:["bigdata"],tags:["flume"],author:"causes",summary:"Flume 概述 Flume，是一个日志采集系统，Cloudera 提供，是高可用的、高可靠的、分布式的，海量日志采集、聚合、传输的系统。Flume 流式架构，灵活简单。 Flume 可以从多个渠道获取内容，写入到多种渠道。 Flume 基础架构 Agent 一个 JVM 进程，主要由 Source、Channel、Sink 组成。它会将数据以事件的方式从源",meta:[{property:"og:url",content:"/bigdata/Flume/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Flume"},{property:"og:description",content:"Flume 概述 Flume，是一个日志采集系统，Cloudera 提供，是高可用的、高可靠的、分布式的，海量日志采集、聚合、传输的系统。Flume 流式架构，灵活简单。 Flume 可以从多个渠道获取内容，写入到多种渠道。 Flume 基础架构 Agent 一个 JVM 进程，主要由 Source、Channel、Sink 组成。它会将数据以事件的方式从源"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"flume"}]},regularPath:"/bigdata/Flume/part1.html",relativePath:"bigdata/Flume/part1.md",key:"v-521bf728",path:"/bigdata/Flume/part1/",headers:[{level:2,title:"Flume 概述",slug:"flume-概述"},{level:2,title:"Flume 基础架构",slug:"flume-基础架构"},{level:2,title:"Flume 开始",slug:"flume-开始"},{level:3,title:"安装部署",slug:"安装部署"},{level:3,title:"入门案例",slug:"入门案例"},{level:2,title:"事务",slug:"事务"},{level:2,title:"Agent 内部原理",slug:"agent-内部原理"},{level:2,title:"拓扑结构",slug:"拓扑结构"},{level:2,title:"自定义组件",slug:"自定义组件"}],readingTime:{minutes:13.06,words:3917},content:' Flume 概述 \n Flume，是一个日志采集系统，Cloudera 提供，是高可用的、高可靠的、分布式的，海量日志采集、聚合、传输的系统。Flume 流式架构，灵活简单。 \n Flume 可以从多个渠道获取内容，写入到多种渠道。 \n Flume 基础架构 \n \n Agent \n 一个 JVM 进程，主要由 Source、Channel、Sink 组成。它会将数据以事件的方式从源头送到目的地。 \n Source \n 主要负责从源头将数据接受，Source 组件可以处理多种格式的数据，比如 avro、thrift、exec、jms、spooling directory、netcat、taildir、sequence generator、http、legacy 等。 \n Channel \n 主要用于传输，将数据源中的数据传送到目的地。可以看成是一个缓冲区，因此 Channel 允许 Source 和 Sink 运送在不用的速率上。 \n Channel 线程安全，可以同时处理几个 Source 的写入和几个 Sink 的读取。 \n Sink \n Sink 位于 Agent 的消费端。它不断轮询 Channel 中的事件并且批量移除它们，并且将这些事件写入到存储中，或者发送到下一个 Flume Agent。 \n Sink 的目的地有：HDFS、Logger、avro、thrift、ipc、file、HBase、solr、自定义等。 \n Event \n Flume 中，数据传输的最小单元。包含 Header 和 Body 两部分，Header 为 kv 结构，存放一些属性。Body 存放一些数据，形式是字节数组。 \n Flume 开始 \n 安装部署 \n \n 官网 ，下载  apache-flume-1.9.0.tar-gz  即可。 \n 上传到服务器  /opt/software ，解压到  /opt/module 。 \n 配置环境变量。 \n 如果安装了 Hadoop，需要删除 lib 包下的  guava-11.0.2 ，兼容  Hadoop3.1.3 。 \n 入门案例 \n 监听端口 \n \n \n 思路：监听端口 44444，收集此端口的数据，并且打印到控制台中。 \n \n \n 安装  netcat ，此工具可以用于向端口发送数据： yum -y install nc \n \n \n 判断 44444 是否被占用： sudo netstat -lnp | grep 44444 \n \n \n 在 Flume Agent HOME 目录下创建 job 文件夹，并且进入。 \n \n \n 创建配置文件  flume-netcat-logger.conf ，以下配置来自官方 手册 \n 监控端口 \nName the components on this agent \nr1：a1 的 source 名称 \n a1.sources   =   r1 \nk1：a1 的 sink 名称 \n a1.sinks   =   k1 \nc1：a1 的 channel 名称 \n a1.channels   =   c1 \nDescribe/configure the source \na1 的输入源为 netcat \n a1.sources.r1.type   =   netcat \na1 监听主机 \n a1.sources.r1.bind   =   localhost \na1 监听端口号 \n a1.sources.r1.port   =   44444 \nDescribe the sink \na1 输出类型为控制台 logger \n a1.sinks.k1.type   =   logger \nUse a channel which buffers events in memory \na1 的 channel 类型为内存 \n a1.channels.c1.type   =   memory \na1 的 channel 总容量为 1000 个 event \n a1.channels.c1.capacity   =   1000 \na1 的 channel 传输时收集到了 100 条 event 之后再去提交事务 \n a1.channels.c1.transactionCapacity   =   100 \nBind the source and sink to the channel \nsource r1 和 channel c1 连接 \n a1.sources.r1.channels   =   c1 \nchannel c1 和 sink k1 连接 \n a1.sinks.k1.channel   =   c1 \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \n \n \n 开启 flume，监听端口： \n方法一： \nbin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger = INFO,console\n方法二： \nbin/flume-ng agent -c conf -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger = INFO,console\n \n 1 2 3 4 \n --conf/-c ：配置文件存储在  conf/  下。 \n --name/-n ：给 agent 起名。 \n --conf-file/-f ：本次 flume 启动时执行的读取的配置文件时使用的文件。 \n -Dflume.root.logger=INFO,console ： -D  表示 flume 运行时动态修改  flume.root.logger  参数属性值，并且将级别改为  INFO （日志级别： LOG、INFO、WARN、ERROR ）。 \n \n \n \n netcat 向本机 44444 发送内容： nc localhost 44444 ，之后便可以发送内容。 \n \n \n 结果： \n \n \n \n \n 监听单个文件 \n 监控 Hive 日志，并且上传到 HDFS 中。 \n \n \n Flume 需要 Hadoop 相关的 jar 包才可以进行此操作。检查 Hadoop 和 Java 环境变量配置。 \n \n \n 在 job 文件夹下创建  flume-file-hdfs.conf  文件 \n 由于 Hive 日志在 Linux 中，所以读取文件需要按照 Linux 的规则来，下方  exec  指的是  execute  执行，表示执行 Linux 命令。 \n 对于所有和时间相关的转义序列，Event Header 必须含有时间戳，也就是以 timestamp 的 key（除非  hdfs.useLocalTimeStamp  设置为 true，也就是使用本地时间）。 \n 监控文件 \n定义 source、sink、channel\na2.sources = r2\na2.sinks = k2\na2.channels = c2\n定义 source 类型为执行命令，命令为 tail -F /opt/module/apache-hive-3.1.2-bin/logs/hive.log\na2.sources.r2.type = exec\na2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log\n\na2.sinks.k2.type = hdfs\na2.sinks.k2.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H\n上传文件的前缀\na2.sinks.k2.hdfs.filePrefix = logs-\n是否按照时间滚动文件夹\na2.sinks.k2.hdfs.round = true\n多少时间单位创建一个新的文件夹\na2.sinks.k2.hdfs.roundValue = 1\n重新定义时间单位\na2.sinks.k2.hdfs.roundUnit = hour\n是否使用本地时间戳\na2.sinks.k2.hdfs.useLocalTimeStamp = true\n积攒多少个 Event 才 flush 到 HDFS 一次\na2.sinks.k2.hdfs.batchSize = 100\n设置文件类型，可支持压缩\na2.sinks.k2.hdfs.fileType = DataStream\n多久生成一个新的文件\na2.sinks.k2.hdfs.rollInterval = 60\n设置每个文件的滚动大小\na2.sinks.k2.hdfs.rollSize = 134217700\n文件的滚动与 Event 数量无关\na2.sinks.k2.hdfs.rollCount = 0\n缓冲区类型、大小\na2.channels.c2.type = memory\na2.channels.c2.capacity = 1000\na2.channels.c2.transactionCapacity = 100\n绑定 source、channel、sink\na2.sources.r2.channels = c2\na2.sinks.k2.channel = c2\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \n \n \n 运行 flume： bin/flume-ng agent -c conf -n a2 -f job/flume-file-hdfs.conf -Dflume.root.logger=INFO,console \n 如果报错  Exception in thread “SinkRunner-PollingRunner-DefaultSinkProcessor“ java.lang.NoSuchMethodError ，可以将  $HADOOP_HOME/share/hadoop/common/lib  下的  guava-27.0-jre.jar  覆盖  $FLUME_HOME/lib  的低版本 guava \n \n \n 开启 Hadoop 和 Hive \n \n \n 在 HDFS 上查看文件 \n \n \n 监控目录下多个文件 \n \n \n 创建  job/flume-dir-hdfs.conf \n 监控目录下多个文件 \n定义 source、channel、sink\na3.sources = r3\na3.sinks = k3\na3.channels = c3\nspooldir：定义 source 类型为目录，spoolDir：给定目录位置，fileSuffix：给定文件上传完成的后缀，fileHeader：是否有文件头\na3.sources.r3.type = spooldir\na3.sources.r3.spoolDir = /opt/module/apache-flume-1.9.0/upload\na3.sources.r3.fileSuffix = .COMPLETED\na3.sources.r3.fileHeader = true\n#忽略所有以.tmp结尾的文件，不上传\na3.sources.r3.ignorePattern = ([^ ]*\\.tmp)\nDescribe the sink\na3.sinks.k3.type = hdfs\na3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload/%Y%m%d/%H\n#上传文件的前缀\na3.sinks.k3.hdfs.filePrefix = upload-\n#是否按照时间滚动文件夹\na3.sinks.k3.hdfs.round = true\n#多少时间单位创建一个新的文件夹\na3.sinks.k3.hdfs.roundValue = 1\n#重新定义时间单位\na3.sinks.k3.hdfs.roundUnit = hour\n#是否使用本地时间戳\na3.sinks.k3.hdfs.useLocalTimeStamp = true\n#积攒多少个Event才flush到HDFS一次\na3.sinks.k3.hdfs.batchSize = 100\n#设置文件类型，可支持压缩\na3.sinks.k3.hdfs.fileType = DataStream\n#多久生成一个新的文件\na3.sinks.k3.hdfs.rollInterval = 60\n#设置每个文件的滚动大小大概是128M\na3.sinks.k3.hdfs.rollSize = 134217700\n#文件的滚动与Event数量无关\na3.sinks.k3.hdfs.rollCount = 0\nUse a channel which buffers events in memory\na3.channels.c3.type = memory\na3.channels.c3.capacity = 1000\na3.channels.c3.transactionCapacity = 100\nbanding source、channel、sink\na3.sources.r3.channels = c3\na3.sinks.k3.channel = c3\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \n 使用 Spooling Directory Source 时，不要在监控目录下持续创建并修改文件。 \n 上传的文件会以  .COMPLETED  结尾，比如  atguigu.log.COMPLETED 。 \n 被监控的文件夹每 500ms 扫描一次文件变动。 \n \n \n 在此文件夹下添加文件即可。 \n \n \n 实时监控目录下的多个追加文件 \n 使用  Taildir Source ，可以实现监控多个文件，并且可以实现断点续传。 \n \n 创建  job/flume-taildir-hdfs.conf \n \n 实时监控多个追加文件 \n a4.sources = r4\na4.sinks = k4\na4.channels = c4\n使用 Taildir Source，可以实现监控多个文件，并且可以实现断点续传\na4.sources.r4.type = TAILDIR\n配置文件组\na4.sources.r4.filegroups = f1 f2\n定义监控目录文件，组 f1 监控哪些文件\na4.sources.r4.filegroups.f1 = /opt/module/apache-flume-1.9.0/job/.*file.*\n定义监控目录文件，组 f2 监控哪些文件\na4.sources.r4.filegroups.f2 = /opt/module/apache-flume-1.9.0/job/.*log.*\n记录每一个文件读取到了哪个位置，是一个 json 文件\na4.sources.r4.positionFile = /opt/module/apache-flume-1.9.0/job/position.json\nDescribe the sink\na4.sinks.k4.type = hdfs\na4.sinks.k4.hdfs.path = hdfs://hadoop102:8020/flume/upload2/%Y%m%d/%H\n#上传文件的前缀\na4.sinks.k4.hdfs.filePrefix = upload-\n#是否按照时间滚动文件夹\na4.sinks.k4.hdfs.round = true\n#多少时间单位创建一个新的文件夹\na4.sinks.k4.hdfs.roundValue = 1\n#重新定义时间单位\na4.sinks.k4.hdfs.roundUnit = hour\n#是否使用本地时间戳\na4.sinks.k4.hdfs.useLocalTimeStamp = true\n#积攒多少个Event才flush到HDFS一次\na4.sinks.k4.hdfs.batchSize = 100\n#设置文件类型，可支持压缩\na4.sinks.k4.hdfs.fileType = DataStream\n#多久生成一个新的文件\na4.sinks.k4.hdfs.rollInterval = 60\n#设置每个文件的滚动大小大概是128M\na4.sinks.k4.hdfs.rollSize = 134217700\n#文件的滚动与Event数量无关\na4.sinks.k4.hdfs.rollCount = 0\nUse a channel which buffers events in memory\na4.channels.c4.type = memory\na4.channels.c4.capacity = 1000\na4.channels.c4.transactionCapacity = 100\nBind the source and sink to the channel\na4.sources.r4.channels = c4\na4.sinks.k4.channel = c4\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \n 事务 \n 事务为了保证的是事务中的内容要么同时成功，要么同时失败。主要是为了保持数据的完整性、安全性、一致性。 \n 在 Flume 中，数据是要进行多次传输的，所以为了保证数据中的完整性和一致性，必须要引入事务。 \n 那么从 Source -> Channel 的过程中，需要进行传输，就要使用到事务。Channel -> Sink 的时候，也必须要用到事务。 \n Put 事务 \n 从 source -> channel 的过程需要用到事务，我们叫做 put 事务。 \n put 事务的流程： \n \n \n source 进行一个攒批操作，也就是 batch data。 \n \n \n source 微批次满了之后，进行一个 doPut 的操作，将 batch data 向一个缓冲区 putList 中放数据。 \n \n \n 缓冲区满了之后，执行一次 doCommit 操作，向 channel 中放数据。 \n 假如 doCommit 操作失败了，那么回滚数据。 \n 但是注意，Flume 中的回滚数据和我们之前别的技术中的回滚操作不一样，它会将 putList 中的数据全扔了，同时给 source 抛一个异常，告诉 source 这一批的数据失败了。 \n 之后 source 重新采集这一批的数据。 \n \n \n \n 我们说，putList 为缓冲区，缓冲区就肯定有大小，我们之前有配置： \nchannel 的容量\na4.channels.c4.capacity = 1000\n事务的容量，也就是 putList 能放多少个 Event\na4.channels.c4.transactionCapacity = 100\n \n 1 2 3 4 Task 事务 \n 和 put 事务差不多，task 事务是 sink 从 channel 中拿取数据的事务。 \n \n \n batch data：channel 中拿到的数据攒一个微批次。 \n \n \n doTask 操作，将 batch data 放到 taskList 中。 \n \n \n doCommit：提交事务。 \n 处理数据失败了之后，会将 taskList 中的数据全部放回到 channel 中，注意，不是丢弃，是放回 channel 中。 \n 但是这样会导致一个问题，就是数据重复。 \n 原因是：假如 taskList 中的数据交给 sink 处理到一半失败了，那么数据全都放回到 channel 中，这样肯定是不会丢失数据。但是 sink 已经处理完的数据也没办法再要回来了。 \n Agent 内部原理 \n 在 Agent 中，除了之前提到的 source、channel、sink 之外，还有其他组件： \n \n \n channel processor \n 在 source 给到 channel 之前，会先给 channel processor，它相当于在 channel 之前的一个拦截器。 \n \n \n interceptor \n 拦截器，可以有多个拦截器组成拦截器链。 \n channel process 拦截到事件之后会交给拦截器链去处理事件，假如合法的事件则回到 channel processor，不合法就被拦截。 \n \n \n channel selector \n 经过了 channel processor 和 interceptor 之外，就要进入 channel selector 了。 \n 一个 source 可能会对应多个 channel，进入一个或者多个 channel，进入哪一个 channel 都是由 channel selector 决定的。 \n channel selector 有两种类型： replicating channel selector 、 multiplexing channel selector 。 \n replicating，副本，顾名思义，可以将 source 发过来的 events 给所有 channel。 \n multiplexing，多路，可以配置发送哪个 channel。 \n \n \n channel：event 进入了 channel \n \n \n sink processor \n channel 的 event 也可以进入到多个 sink，那么配置进入哪个 sink 就是由 sink processor 决定的。 \n sink processor 有三种： default sink processor 、 load balancing sink processor 、 failover sink processor \n \n default sink processor：它只允许有一个 sink 接收数据，我们默认用的就是这个。 \n load balancing sink processor：负载均衡的 sink processor，负载均衡策略是可以配置的，比如轮询、随机等。 \n failover sink processor：故障转移 sink processor，一开始只用一个 sink，假如这个 sink 故障了，那么就换另一个一直用。可以认为是高可用版本。 \n 拓扑结构 \n 拓扑结构，也就是多个 agent 怎么去接，多个 agent 怎么去接，B 里面的 source 怎么去接 A 里面的 sink。 \n 简单串联 \n \n 下游的是服务端，上游的是客户端。服务端的 source 接客户端的 sink。 \n 简单串联是最简单的拓扑结构，从实际意义上来看其实没啥用，组件越多风险就越大，但是重要的是可以让人快速理解啥是拓扑结构。 \n 复制和多路复用 \n \n 一份数据做多次处理，或者将数据进行分离放到不同的位置中，这个是比较有用的。 \n 负载均衡和故障转移 \n \n Flume 支持将多个 sink 在逻辑上分到一个 sink 组，sink 组配合不同的 sink processor 可以实现负载均衡和错误恢复的功能。 \n 聚合 \n \n 最常见的拓扑结构。 \n 案例 \nagent 的写法建议直接翻阅 官方文档 ，里面标注的比较清楚。注意一点，因为 agent 之后需要放到同一个机器下，所以 agent 的名字不能相同。 \n 拓扑结构——复制 \n 使用 Flume-1 监控文件变动，将变动内容传递给 Flume-2 和 Flume-3。Flume-2 存到 HDFS，Flume-3 存到本地文件系统。 \n \n 拓扑结构——负载均衡 \n \n 拓扑结构——故障转移 \n \n 拓扑结构——聚合 \n 自定义组件 \n 自定义 Interceptor \n 自定义 Interceptor \n \n \n 加 flume 的依赖： \n  ```xml\n <dependency>\n     <groupId>org.apache.flume</groupId>\n     <artifactId>flume-ng-core</artifactId>\n     <version>1.9.0</version>\n </dependency>\n ```\n \n \n \n 继承  org.apache.flume.interceptor.Interceptor  接口，编写 builder 类。 \n /**\n* 自定义拦截器\n*/ \n public   class   EventHeaderInterceptor   implements   Interceptor   { \n\n     @Override \n     public   void   initialize ( )   { } \n\n     /**\n    * 拦截方法，处理每一个 Event\n    */ \n     @Override \n     public   Event   intercept ( Event  event )   { \n\n         // 1. 获取 event 的 headers \n         Map < String ,   String >  headers  =  event . getHeaders ( ) ; \n         // 2. 获取 event 的 body，转为 utf-8（默认就是） \n         String  body  =   new   String ( event . getBody ( ) ,   StandardCharsets . UTF_8 ) ; \n         // 3. 处理内容 \n        headers . put ( "key" , "value" ) ; \n         return  event ; \n     } \n\n     /**\n    * 所有的 event\n    */ \n     @Override \n     public   List < Event >   intercept ( List < Event >  list )   { \n        list . forEach ( this :: intercept ) ; \n         return  list ; \n     } \n\n     @Override \n     public   void   close ( )   { } \n\n     // flume 在之后会通过反射来创建对象，会通过 builder 来创建对象，所以我们需要提供 Builder 内部类 \n     public   static   class   EventBuilder   implements   Builder   { \n\n         @Override \n         public   Interceptor   build ( )   { \n         return   new   EventHeaderInterceptor ( ) ; \n         } \n\n         @Override \n         public   void   configure ( Context  context )   { \n\n         } \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \n \n 打为 jar 包，放到 flume 中的 libs 目录下。 \n \n \n 指定 interceptor： com.causes.flume.interceptor.EventHeaderInterceptor$EventBuilder ： \n a1.source.r1.interceptors = i1\na1.source.r1.interceptors.i1.type = com.causes.flume.interceptor.EventHeaderInterceptor$EventBuilder\n \n 1 2 \n \n 自定义 Source \n 不重要，按照 官方文档 直接写。 \n 自定义 Sink \n 按照 官方文档 直接写。 \n \n 一半来说，Source 和 Sink 官方都考虑到了大量的场景，除非是一些冷门的需求，其余官方都考虑到了。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"March 16, 2022 15:26",createTimeStamp:1647415589e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"HBase-02-进阶",frontmatter:{title:"HBase-02-进阶",categories:["bigdata"],tags:["hbase"],author:"causes",summary:"Region Server 架构和读写流程 HBase 的基本架构就是 Zookeeper -> Master -> Region Server -> Region -> HDFS。这里重点要说的是 Region Server 的架构。 再来回顾一下 region： 为了解决文件太大的困扰，HBase 会横向切分表，每一块就是一个 Region，而每一个 R",meta:[{property:"og:url",content:"/bigdata/HBase/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"HBase-02-进阶"},{property:"og:description",content:"Region Server 架构和读写流程 HBase 的基本架构就是 Zookeeper -> Master -> Region Server -> Region -> HDFS。这里重点要说的是 Region Server 的架构。 再来回顾一下 region： 为了解决文件太大的困扰，HBase 会横向切分表，每一块就是一个 Region，而每一个 R"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hbase"}]},regularPath:"/bigdata/HBase/part2.html",relativePath:"bigdata/HBase/part2.md",key:"v-3ed67088",path:"/bigdata/HBase/part2/",headers:[{level:2,title:"Region Server 架构和读写流程",slug:"region-server-架构和读写流程"},{level:2,title:"API 操作",slug:"api-操作"},{level:2,title:"HBase 优化",slug:"hbase-优化"}],readingTime:{minutes:12.14,words:3643},content:" Region Server 架构和读写流程 \n HBase 的基本架构就是 Zookeeper -> Master -> Region Server -> Region -> HDFS。这里重点要说的是 Region Server 的架构。 \n \n 再来回顾一下 region： \n \n 为了解决文件太大的困扰，HBase 会横向切分表，每一块就是一个 Region，而每一个 Region 根据列族进行纵向切分，形成的就是 Store。 \n 为了方便读写，每一个 Region 的内容一定会存储到一台服务器上，而具体存储的物理文件以 Store 为主，也就是说每一个 Store 都是一个 StoreFile（或者叫做 HFile）。 \n 既然每一个 Region 都会存到一台服务器上，那么我们就有 Region Server 的概念： \n \n 在每个 Region Server 中，可以有多个 Region，一个 WAL（预写日志），一个 Block Cache（读缓存）。每一个 Store 的结构都有一个 MemStore（读写缓存），一个 StoreFile（物理文件）。 \n 写流程 \n \n \n Client 请求 Zookeeper，获取 HBase 的 meta 表位于哪个 Region Server。 \n \n \n 访问对应 Region Server，获取 meta，根据请求的 namespace:table/rowKey 获取位于哪个 Region Server 的哪个 Region。 \n \n \n 将上面的信息缓存到 Client 的 meta cache，方便下次访问。 \n \n \n 与目标 Region Server 进行通信。 \n \n \n 将数据顺序追加到 WAL 中（避免意外情况导致数据丢失）。 \n \n \n 将数据写入 MemStore，数据会在 MemStore 中进行重新排序（所以 HFile 中的数据是顺序的）。 \n \n \n 向客户端发送 ack。 \n \n \n 等到 MemStore 满足条件之后，将数据写入到 HFile（每次刷写都会生成一个 HFile），减少 WAL 文件。 \n 单个满足条件的时机： \n \n 单个 MemStore 大小达到了配置的值  hbase.hregion.memstore.flush.size ，默认  128M \n 单个 MemStore 时间达到了配置的值  hbase.regionserver.optionalcacheflushinterval ，默认 1h \n \n 总体满足条件的时机： \n \n Region Server 中总的 MemStore 大小达到了  java_heapsize * hbase.regionserver.global.memstore.size（默认值0.4）* hbase.regionserver.global.memstore.size.lower.limit（默认值0.95） ，会按照 MemStore 大小由大到小依次刷写，直到 RegionServer 中，MemStore 的总大小减少到上述值以下。 \n WAL 文件超过 32，按照时间顺序自动刷写，直到文件数量减少到 32 以下（现在已经无需手动设置）。 \n \n 停止刷写到 MemStore 的时机： \n \n 单个 MemStore 大小达到了  hbase.hregion.memstore.flush.size（默认值128M）* hbase.hregion.memstore.block.multiplier（默认值4）  将停止向此 MemStore 刷写数据。 \n RegionServer 总大小达到了  java_heapsize * hbase.regionserver.global.memstore.size（默认值0.4）  会停止向所有 MemStore 写入数据。 \n \n \n \n 读流程 \n \n \n Client 访问 Zookeeper，获取 HBase 的 meta 表位于哪个 Region Server。 \n \n \n 访问到 meta 表，根据读请求的 namespace:table/rowKey 得到目标所在的 Region Server。 \n \n \n 将该信息缓存在 Client 的 meta cache 中。 \n \n \n 与目标 Region Server 进行通讯。 \n \n \n 查询数据 \n 因为缓存的存在，所以 Block Cache 和 HFile 的数据是相同的，所以假如 Block Cache 中有数据，就不需要从 HFile 中读取。 \n 版本问题也不用考虑，Block Cache 缓存的只是某个版本的数据，假如 Block Cache 存在我们需要某个版本的数据那么直接就返回了，假如需要其他版本的数据，仍然需要读取 HFile。 \n 除了 Block Cache 和 HFile，读数据还有可能在 MemStore 中读取（已经写入 Memory Cache 但是尚未 flush 到 HFile 中的数据）。 \n 注意一点，某条数据可能有多个版本，所以可能会在多个 HFile 中存在，所以可能会读取多个 HFile。 \n \n \n 合并数据 \n 因为数据存在多个版本，所以要从 MemStore + Block Cache / HFile，从而得到我们最终想要的版本。 \n 注意一点，MemStore 中的数据虽然是最新的，但是不一定是我们需要的。 \n 比如说，假如 MemStore 想要删除某个版本的数据，这肯定就不是我们想要的结果，所以还需要进行数据合并。 \n \n \n 将查询到的数据块（某个版本的数据）缓存到 Block Cache。 \n \n \n 结果返回给客户端。 \n \n \n Tips \n 注意，在进行读取 HFile 的过程中，HBase 提供了三种手段进行读取加速。 \n \n 时间范围过滤。在进行读取的时候，首先会根据时间范围过滤 HFile，避免读取不必要的文件。 \n RowKey 过滤。根据 RowKey 过滤 HFile，缩小读取范围。 \n 布隆过滤器。每个 HFile 都有自己的布隆过滤器，它可以告诉某个文件中没有某条数据。 \n \n \n StoreFile Compaction \n 之前我们提到过有一种叫做 Region 合并的情况。其实这种说法不太准确，Region 是不能合并的，我们合并的是 Region 中的 HFile。 \n 因为 MemStore 每次 flush 都会产生一个 HFile，所以对于同一条数据，不同版本、不同类型，都可能会存在不同的 HFile 中。 \n 长此以往，读取数据就会在多个文件中读取，速度会下降。为了减少 HFile 的个数，删除的多余数据，HBase 会进行 HFile 的合并，也就是 StoreFile Compaction。 \n Compaction 分为两种，一种是 Minor Compaction（小合并），一种是 Major Compaction（大合并）： \n \n \n Minor Compaction 会将临近的几个若干个小的 HFile 合并为一个较大的 HFile，并且清理掉部分过期和删除的数据。 \n 在 Minor Compaction 中，清理过期和需要删除的数据只能是一小部分，有些数据它不能确定有用还是没用，只能留着。 \n 每次 flush 数据都有可能产生小合并，但是不一定会，还需要满足一些条件。 \n \n \n Major Compaction 会合并一个 Store 下的所有 HFile 为一个大的 HFile，清理所有过期和删除的数据。 \n 大合并定时合并，默认七天一次，可以进行配置。 \n \n \n Region Split \n HBase 在开始只有一个 region，但是当表逐渐增大时，region 会自动切开为多个（当然，在生产环境可能会做预分区优化）。 \n 为了负载考虑，HMaster 可能会将多个 Region 分给多个 Region Server。我们之前提到，每一个 Region 的数据都会存储到一台机器上，这句话没错，但是一张表有可能会分为多个 Region，那多个 Region 就可能分散给不同的 Region Server。 \n 当一个 Region 中的某个 Store 下的 StoreFile 的总大小超过  Min(initialSize * R^3 , hbase.hregion.max.filesize\") ，此 Region 就会切分。 \n 其中  initialSize  默认为  2 * hbase.hregion.memstore.flush.size ，R 为当前 Region Server 中，属于此 Table 的 Region 个数，默认情况下，具体的策略： \n \n 第一次： 1^3 * 256 = 256MB < 10GB ，取值 256MB。 \n 第二次： 2^3 * 256 = 2048MB ，同理取值 2048MB。 \n 第三次： 3^3 * 256 = 6912MB ，通离去之 6912MB。 \n 第四次： 4^3 * 256 = 16384MB > 10GB ，取值较小的 10GB。 \n 之后，每次都是 10GB。 \n \n 因为这种方式比较麻烦，在 HBase2.0 引入了新的策略：假如当前 RegionServer 上，此表只有一个 Region，按照  2 * hbase.hregion.memstore.flush.size  分裂，否则按照  hbase.hregion.max.filesize  分裂。 \n API 操作 \n 环境搭建 \n < dependency > \n     < groupId > org.apache.hbase </ groupId > \n     < artifactId > hbase-server </ artifactId > \n     < version > 2.0.5 </ version > \n </ dependency > \n < dependency > \n     < groupId > org.apache.hbase </ groupId > \n     < artifactId > hbase-client </ artifactId > \n     < version > 2.0.5 </ version > \n </ dependency > \n \n 1 2 3 4 5 6 7 8 9 10 用户 API  参考 \n 案例 \n import   org . apache . hadoop . conf . Configuration ; \n import   org . apache . hadoop . hbase . CellUtil ; \n import   org . apache . hadoop . hbase . HBaseConfiguration ; \n import   org . apache . hadoop . hbase . NamespaceDescriptor ; \n import   org . apache . hadoop . hbase . TableName ; \n import   org . apache . hadoop . hbase . client . * ; \n import   org . apache . hadoop . hbase . util . Bytes ; \n import   org . junit . After ; \n import   org . junit . Before ; \n\n import   java . io . IOException ; \n import   java . util . Arrays ; \n import   java . util . List ; \n import   java . util . stream . Collectors ; \n\n /**\n * 1. 获取 connection 对象，重量级别实现，打开一直用即可\n * 2. 获取 table，DML 操作，随用随打开即可\n * 3. 获取 admin，DDL 操作，随用随打开即可\n */ \n public   class   HBaseDemo   { \n\n   private   static   Connection  connection ; \n\n   @Before \n   public   void   config ( )   throws   IOException   { \n     Configuration  conf  =   HBaseConfiguration . create ( ) ; \n    conf . set ( \"hbase.zookeeper.quorum\" ,   \"hadoop102,hadoop103,hadoop104\" ) ; \n    connection  =   ConnectionFactory . createConnection ( conf ) ; \n   } \n\n   /*------------------------------- DDL -------------------------------*/ \n\n   public   void   createNamespace ( String  namespace )   throws   IOException   { \n     Admin  admin  =  connection . getAdmin ( ) ; \n     // 除了 createNamespace 之外，还可以 list、modify 等，不说了 \n    admin . createNamespace ( NamespaceDescriptor . create ( namespace ) . build ( ) ) ; \n    admin . close ( ) ; \n   } \n\n   /**\n   * 创建表\n   *\n   * @param namespace\n   * @param tableName 表名称\n   * @param cfs       列族\n   */ \n   public   void   createTable ( String  namespace ,   String  tableName ,   String . . .  cfs )   throws   IOException   { \n     if   ( tableExists ( namespace ,  tableName ) )   { \n       return ; \n     } \n     Admin  admin  =  connection . getAdmin ( ) ; \n     TableDescriptorBuilder  tableDescriptorBuilder  =   TableDescriptorBuilder . newBuilder ( TableName . valueOf ( namespace ,  tableName ) ) ; \n\n     List < ColumnFamilyDescriptor >  columnFamilyDescriptors  =   Arrays . stream ( cfs ) \n         . map ( family  ->   ColumnFamilyDescriptorBuilder . newBuilder ( Bytes . toBytes ( family ) ) . build ( ) ) \n         . collect ( Collectors . toList ( ) ) ; \n    tableDescriptorBuilder . setColumnFamilies ( columnFamilyDescriptors ) ; \n\n     TableDescriptor  tableDescriptor  =  tableDescriptorBuilder . build ( ) ; \n    admin . createTable ( tableDescriptor ) ; \n\n    admin . close ( ) ; \n   } \n\n   public   Boolean   tableExists ( String  namespace ,   String  tableName )   throws   IOException   { \n     Admin  admin  =  connection . getAdmin ( ) ; \n     return  admin . tableExists ( TableName . valueOf ( namespace ,  tableName ) ) ; \n   } \n\n   public   void   dropTable ( String  namespace ,   String  tableName )   throws   IOException   { \n     if   ( ! tableExists ( namespace ,  tableName ) )   { \n       return ; \n     } \n     Admin  admin  =  connection . getAdmin ( ) ; \n     TableName  table  =   TableName . valueOf ( namespace ,  tableName ) ; \n     // 删除表之前首先需要禁用表 \n    admin . disableTable ( table ) ; \n    admin . deleteTable ( table ) ; \n    admin . close ( ) ; \n   } \n\n   /*------------------------------- DML -------------------------------*/ \n\n   /**\n   * @param namespace\n   * @param tableName\n   * @param rowKey\n   * @param columnFamily 列族\n   * @param columnName   列的名字\n   * @param value        数据\n   */ \n   public   void   put ( String  namespace ,   String  tableName ,   String  rowKey ,   String  columnFamily ,   String  columnName ,   String  value )   throws   IOException   { \n     Table  table  =  connection . getTable ( TableName . valueOf ( namespace ,  tableName ) ) ; \n\n     Put  put  =   new   Put ( Bytes . toBytes ( rowKey ) ) ; \n    put . addColumn ( Bytes . toBytes ( columnFamily ) ,   Bytes . toBytes ( columnName ) ,   Bytes . toBytes ( value ) ) ; \n     // 可使用重载，放 put 的 list 集合 \n    table . put ( put ) ; \n\n    table . close ( ) ; \n   } \n\n   /**\n   * 删除时，可以指定删除某个 rowKey 的数据，也可以直接删除某个列族的数，也可以直接删除某个列的数据。\n   * <p>\n   * columnFamily、columnName 可选\n   *\n   * @param namespace\n   * @param tableName\n   * @param rowKey\n   * @param columnFamily\n   * @param columnName\n   */ \n   public   void   delete ( String  namespace ,   String  tableName ,   String  rowKey ,   String  columnFamily ,   String  columnName )   throws   IOException   { \n     Table  table  =  connection . getTable ( TableName . valueOf ( namespace ,  tableName ) ) ; \n\n     /*\n        删除某个 rowKey 对应的数据\n        HBase 标记为 DeleteFamily，因为这里删除的是一整行的数据，删除的是所有列、所有列族的数据\n     */ \n     Delete  delete  =   new   Delete ( Bytes . toBytes ( rowKey ) ) ; \n    table . delete ( delete ) ; \n\n     /*\n        删除整个列族的数据\n        HBase 标记为 DeleteFamily，但是由于一行中可能有多个列族，那么没有指定的列族自然不会删除\n     */ \n     Delete  deleteFamily  =   new   Delete ( Bytes . toBytes ( rowKey ) ) ; \n    delete . addFamily ( Bytes . toBytes ( columnFamily ) ) ; \n    table . delete ( deleteFamily ) ; \n\n     /*\n        删除某个列族中的某个列的最后一个版本，HBase 标记为 Delete\n        除了 addColumn，还可以指定 addColumns(family, column)，这个指定的是一个列的所有版本，它的标记为 DeleteColumn\n     */ \n     Delete  deleteColumn  =   new   Delete ( Bytes . toBytes ( columnName ) ) ; \n    delete . addColumn ( Bytes . toBytes ( columnFamily ) ,   Bytes . toBytes ( columnName ) ) ; \n    table . delete ( deleteColumn ) ; \n\n    table . close ( ) ; \n   } \n\n   /**\n   * get 也可以获取某个 rowKey、列族、列的数据\n   *\n   * @param namespace\n   * @param tableName\n   * @param rowKey\n   * @param columnFamily\n   * @param columnName\n   */ \n   public   void   get ( String  namespace ,   String  tableName ,   String  rowKey ,   String  columnFamily ,   String  columnName )   throws   IOException   { \n     Table  table  =  connection . getTable ( TableName . valueOf ( namespace ,  tableName ) ) ; \n\n     // 拿到一整行数据 \n     Get  get  =   new   Get ( Bytes . toBytes ( rowKey ) ) ; \n     Result  result  =  table . get ( get ) ; \n     Arrays . stream ( result . rawCells ( ) ) . forEach ( cell  ->   { \n       // 直接使用 cell.getRowArray() 的方式有问题，需要工具类转换一下 \n       String  rowKeyStr  =   Bytes . toString ( CellUtil . cloneRow ( cell ) ) ; \n       String  columnFamilyStr  =   Bytes . toString ( CellUtil . cloneFamily ( cell ) ) ; \n       String  valueStr  =   Bytes . toString ( CellUtil . cloneValue ( cell ) ) ; \n       System . out . printf ( \"rowKey %s, columnFamily %s, value %s\\n\" ,  rowKeyStr ,  columnFamilyStr ,  valueStr ) ; \n     } ) ; \n\n     // 拿到列族的数据 \n     Get  getFamily  =   new   Get ( Bytes . toBytes ( rowKey ) ) ; \n    getFamily . addFamily ( Bytes . toBytes ( columnFamily ) ) ; \n     Result  resultFamily  =  table . get ( getFamily ) ; \n\n     // 拿到列的数据 \n     Get  getColumn  =   new   Get ( Bytes . toBytes ( rowKey ) ) ; \n    getColumn . addColumn ( Bytes . toBytes ( columnFamily ) ,   Bytes . toBytes ( columnName ) ) ; \n     Result  resultColumn  =  table . get ( getColumn ) ; \n\n    table . close ( ) ; \n   } \n\n   /**\n   * 扫描表中数据\n   *\n   * @param namespace\n   * @param tableName\n   * @param startRow  可选，可以指定从表的哪个位置开始扫描\n   * @param stopRow   可选，可以指定从表的哪个位置结束扫描\n   */ \n   public   void   scan ( String  namespace ,   String  tableName ,   String  startRow ,   String  stopRow )   throws   IOException   { \n     Table  table  =  connection . getTable ( TableName . valueOf ( namespace ,  tableName ) ) ; \n\n     Scan  scan  =   new   Scan ( ) ; \n     // 指定从表的哪个位置开始扫描，可选 \n    scan . withStartRow ( Bytes . toBytes ( startRow ) ) ; \n     // 指定从表的哪个位置结束扫描，可选 \n    scan . withStopRow ( Bytes . toBytes ( stopRow ) ) ; \n     ResultScanner  scanner  =  table . getScanner ( scan ) ; \n     for   ( Result  result  :  scanner )   { \n       Arrays . stream ( result . rawCells ( ) ) . forEach ( cell  ->   { \n         System . out . println ( Bytes . toString ( CellUtil . cloneValue ( cell ) ) ) ; \n       } ) ; \n     } \n\n    scanner . close ( ) ; \n    table . close ( ) ; \n   } \n\n   @After \n   public   void   close ( )   throws   IOException   { \n    connection . close ( ) ; \n   } \n\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 #  HBase 优化 \n 预分区 \n 这个预分区说的是预先分为多个 region，让数据一进来之后就开始负载均衡。假如之后一个 region 数据量很大，HBase 还是会自动拆分的。 \n \n \n 建表时手动分区： create 'staff1','info',SPLITS => ['1000','2000','3000','4000'] \n 划分为了 5 个 region 范围： 负无穷 -> 1000 、 1000 -> 2000 、……、 4000 -> 正无穷 \n \n \n 16 进制序列分区： create 'staff2','info',{NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'} \n NUMREGIONS  指定为要分为 15 个区，SPLITALGO 指定每个分区的范围（使用  HexStringSplit  这个 16 进制） \n 这个 15 分区按照 16 进制，也就是从  00000000  一直到  ffffffff ，那分区就是  负无穷 -> 11111111 、 11111111 -> 22222222 、……、 dddddddd -> eeeeeeee 、 eeeeeeee -> 正无穷 \n rowKey 的设计和预分区是分不开的，假如按照这种内容，为了均匀放到这几个分区中，rowKey 最好也设计为 16 进制。 \n \n \n 按照文件进行分区： create 'staff3','info',SPLITS_FILE => 'splits.txt' \n 这个  splits.txt  是我们自己指定的，这里的  SPLITS_FILE  指定的就是相对路径下的文件。 \n 比如我们指定 \n aaaa\ncccc\nbbbb\ndddd\n \n 1 2 3 4 HBase 会首先将文件进行排序，然后进行预分区。 \n \n \n API 创建分区： \n public   void   createTable ( String  namespace ,   String  tableName ,   String . . .  cfs )   throws   IOException   { \n     if   ( tableExists ( namespace ,  tableName ) )   { \n         return ; \n     } \n     Admin  admin  =  connection . getAdmin ( ) ; \n     TableDescriptorBuilder  tableDescriptorBuilder  =   TableDescriptorBuilder . newBuilder ( TableName . valueOf ( namespace ,  tableName ) ) ; \n     TableDescriptor  tableDescriptor  =  tableDescriptorBuilder . build ( ) ; \n\n     byte [ ] [ ]  spliteKeys  =   new   byte [ 4 ] [ ] ; \n    spliteKeys [ 0 ]   =   Bytes . toBytes ( \"1000\" ) ; \n    spliteKeys [ 1 ]   =   Bytes . toBytes ( \"2000\" ) ; \n    spliteKeys [ 2 ]   =   Bytes . toBytes ( \"3000\" ) ; \n    spliteKeys [ 3 ]   =   Bytes . toBytes ( \"4000\" ) ; \n\n    admin . createTable ( tableDescriptor ,  spliteKeys ) ; \n\n    admin . close ( ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n \n RowKey 设计 \n 预分区和 RowKey 密不可分，设计 RowKey 的目的是让数据均匀地进入 region。 \n 原则： \n \n 唯一性。 \n 散列。 \n 在保证以上两者后，长度尽量设计地短。 \n \n 基础优化 \n HBase 对内存需要大量开销，但是不建议分配大量的堆内存。因为 Full GC 太久会导致 RegionServer 长期处于不可用状态。 \n 假如服务器内存为 128G，给个 16 -> 36 即可。或者给一台服务器为 16 -> 36G，专门跑 HBase 也行。 \n 接下来是  hbase-site.xml  的基础优化。 \n \n \n RegionServer 和 Zookeeper 会话时间： \n zookeeper.session.timeout ，默认 90000ms（90s），可以减少一点，例如 60s。 \n \n \n RegionServer(RPC) 的监听数量： \n hbase.regionserver.handler.count ，默认为 30。 \n 读写操作都是打到 RegionServer 的，假如读写比较高，可以考虑调高此值 \n \n \n Major Compaction： \n HFile 大合并， hbase.hregion.majorcompaction ，默认  604800000s (七天)，可以设置为 0，手动触发大合并。 \n \n \n HFile 大小： \n HFile 的大小， hbase.hregion.max.filesize  默认  10737418240 (10G) \n 假如需要运行 MR，可以减少此值，因为一个 region 会对应一个 MapTask，假如单个 region 太大，会导致 MapTask 过长。 \n \n \n 优化 HBase 客户端缓存： \n hbase.client.write.buffer ，默认 2M，用于客户端缓存。增大可减少 RPC 调用次数，但是会消耗更多内存。反之会增加 RPC 调用次数，但是会减少内存。 \n \n \n scan 获取的行数： \n hbase.client.scanner.caching \n 使用 API 的 scanner 操作时，返回的 result 不是所有的值（如果是所有的值一次性返回就炸了），而是需要迭代，每次迭代都会返回一些数据。 \n 这个参数可以控制每次迭代返回多少行，值越大会消耗越多的内存。 \n \n \n BlockCache 占用 RegionServer 堆内存的比例： \n hfile.block.cache.size  默认 0.4 \n \n \n MemStore 占用 RegionServer 堆内存的比例： \n hbase.regionserver.global.memstore.size  默认 0.4 \n \n \n",updateTime:"July 11, 2022 14:00",updateTimeStamp:1657519215e3,createTime:"July 11, 2022 14:00",createTimeStamp:1657519215e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:1}]},{title:"Hadoop-01-起步",frontmatter:{title:"Hadoop-01-起步",categories:["bigdata"],tags:["hadoop"],author:"causes",summary:"前言 大数据（Bigdata），主要解决海量数据的采集、存储、计算问题。 按照顺序给出数据存储的单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。 其中每一个单位向前都是 1024，例如 1TB = 1024GB 大数据的特点（4V）： Volume：大量。; Velocity：高速，以及到 2025 年，全球数据使用",meta:[{property:"og:url",content:"/bigdata/Hadoop/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hadoop-01-起步"},{property:"og:description",content:"前言 大数据（Bigdata），主要解决海量数据的采集、存储、计算问题。 按照顺序给出数据存储的单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。 其中每一个单位向前都是 1024，例如 1TB = 1024GB 大数据的特点（4V）： Volume：大量。; Velocity：高速，以及到 2025 年，全球数据使用"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hadoop"}]},regularPath:"/bigdata/Hadoop/part1.html",relativePath:"bigdata/Hadoop/part1.md",key:"v-12defbfc",path:"/bigdata/Hadoop/part1/",headers:[{level:2,title:"前言",slug:"前言"},{level:2,title:"Hadoop 概述",slug:"hadoop-概述"},{level:2,title:"环境搭建",slug:"环境搭建"},{level:3,title:"模板虚拟的准备",slug:"模板虚拟的准备"},{level:3,title:"克隆虚拟机",slug:"克隆虚拟机"},{level:3,title:"安装环境",slug:"安装环境"},{level:3,title:"Hadoop 介绍",slug:"hadoop-介绍"},{level:3,title:"本地模式",slug:"本地模式"},{level:3,title:"完全分布式",slug:"完全分布式"}],readingTime:{minutes:16.27,words:4882},content:' 前言 \n 大数据（Bigdata），主要解决海量数据的 采集、存储、计算 问题。 \n 按照顺序给出数据存储的单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。 \n 其中每一个单位向前都是 1024，例如 1TB = 1024GB \n 大数据的特点（4V）： \n \n Volume：大量。 \n Velocity：高速，以及到 2025 年，全球数据使用量将达到 163ZB。 \n Variety：多样：结构化、半结构化、非结构化数据。 \n Value：低价值密度：在大量的数据中，有价值的数据较少。 \n \n 大数据部门组织架构： \n \n 大数据生态体系： \n \n 案例，推荐系统： \n Hadoop 概述 \n Hadoop 由 Apache 基金会开发，是一个 分布式系统基础架构 ，主要解决海量数据的存储和计算问题。但是广义上来讲，Hadoop 是一个生态。 \n \n Hadoop 有三大发行版本： Apache （原始版本，适合学习）、 Cloudera （产品 CDH）、 Hortonworks （产品 HDP，被 Cloudera 收购）。 \n Hadoop 的优势： \n \n 高可靠性：底层维护多个数据副本，即使某个存储出现故障也不会导致数据丢失。 \n 高扩展性：在集群之间分配任务数据，方便扩展数千节点。 \n 高效性：在 MapReduce 思想下，Hadoop 是并行的，加快了任务处理速度。 \n 高容错性：失败任务自动分配。 \n \n Hadoop 1.x、2.x、3.x 区别： \n \n \n Hadoop 1.x 时代，仅有： \n \n Common：辅助工具。 \n HDFS：数据存储。 \n MapReduce：计算 + 资源调度。 \n \n \n \n hadoop 2.x 时代： \n \n Common：辅助工具。 \n HDFS：数据存储。 \n Yarn：资源调度。 \n MapReduce：计算。 \n \n 也就是 Hadoop 2.x 时代，将计算和资源调度分开，降低了耦合。 \n \n \n Hadoop 3.x 时代和 Hadoop 2.x 时代在架构上没有区别，在一些细节问题上有所变化，这是之后的内容。 \n \n \n Hadoop 架构： \n \n \n HDFS（Hadoop Distributed File System）：是一个 分布式文件系统 。 \n \n NN（NameNode）：存储文件的元数据（例如文件名字、文件存储位置、目录结构等）。 \n DN（DataNode）：在本地文件系统存储文件块数据和块数据的校验。 \n 2NN（Secondary NameNode）：每隔一段时间对 NameNode 元数据备份。 \n \n \n \n YARN：是一种资源协调者，是 Hadoop 的资源管理器。 \n \n RM（Resource Manager）：管理整个集群的资源（如 CPU、内存 等）。 \n NM（NodeManager）：管理集群中单个节点的资源。 \n AM（ApplicationMaster）：管理节点中单个任务的资源，一个任务可以分为多个 Task，AM 管理这些 Task。 \n Container：容器，相当于一台独立的服务器，里面封装了任务运行需要的资源（比如 CPU、内存、网络），任务在 Container 中运行。 \n \n 说明：可以有多个客户端连接集群提交 Job（任务、作业），集群上可以运行多个 NodeManager，每个 NodeManager 中可以运行多个 Container，一个 Container 对应一个 ApplicationMaster 或者 Task。 \n \n \n \n MapReduce：任务计算使用。 \n Hadoop MapReduce 的计算分为两个阶段：Map、Reduce，和分治算法有点相似。 \n Map 阶段并行，将数据进行计算处理，Reduce 阶段将 Map 结果进行汇总。 \n 环境搭建 \n 模板虚拟的准备 \n \n 使用 VMWare + CentOS7，网上资料很多，这里不再赘述（注意，电脑在 BIOS 界面开启虚拟化，设置网络为 NAT）。 \n 准备一台虚拟机，IP 地址为 192.168.10.100，主机名称为 hadoop100，内存 4G，硬盘 50G。 \n 安装系统时注意：\n \n 时区选择上海。 \n 软件选择中，选择 GNOME 桌面，不用选择附加选项。 \n 磁盘分区配置分区， /boot  为 1G，ext4 文件系统， /swap  交换分区为 4G， /  分区为 45G，ext4 文件系统。 \n 关闭 kdump。 \n 修改主机名称为 hadoop100（或者之后在命令行中修改），并且连接以太网。 \n 设置一个好记的 root 密码，比如六个 0。 \n \n \n 网络配置：\n \n \n VMWare -> 编辑 -> 虚拟网络编辑器，设置子网 IP 为  192.168.10.0 ，NAT 设置中设置网关为  192.169.10.2 。 \n \n \n \n \n Windows 设置，找到网络 --\x3e 更改适配器选项 --\x3e VMnet8 --\x3e 属性 --\x3e ipv4 --\x3e DNS 和 IP 修改。 \n \n \n \n \n \n \n 进入 VMWare 中，已经安装的 CentOS，编辑文件  /etc/sysconfig/network-scripts/ifcfg-ens33 ，设置 IP 为静态 IP 地址，设置网关、域名解析器： \n #网络类型（通常是Ethemet）\nTYPE="Ethernet"\nPROXY_METHOD="none"\nBROWSER_ONLY="no"\n#IP的配置方法[none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议）\nBOOTPROTO="static"\nDEFROUTE="yes"\nIPV4_FAILURE_FATAL="no"\nIPV6INIT="yes"\nIPV6_AUTOCONF="yes"\nIPV6_DEFROUTE="yes"\nIPV6_FAILURE_FATAL="no"\nIPV6_ADDR_GEN_MODE="stable-privacy"\nNAME="ens33"\n#随机id\nUUID="e83804c1-3257-4584-81bb-660665ac22f6"\n#接口名（设备,网卡）\nDEVICE="ens33"\n#系统启动的时候网络接口是否有效（yes/no）\nONBOOT="yes"\n#IP地址\nIPADDR=192.168.10.100\n#网关\nGATEWAY=192.168.10.2\n#域名解析器\nDNS1=192.168.10.2\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 文件编辑完成之后，执行命令  systemctl restart network  重启网络服务，假如出错则重启系统。 \n 设置之后，可以通过命令  ifconfig  查看当前网络。 \n \n \n 编辑文件  /etc/hostname ，将主机名修改为  hadoop100 。 \n \n \n 编辑文件  /etc/hosts ，在映射文件中添加以下内容： \n 192.168.10.100 hadoop100\n192.168.10.101 hadoop101\n192.168.10.102 hadoop102\n192.168.10.103 hadoop103\n192.168.10.104 hadoop104\n192.168.10.105 hadoop105\n192.168.10.106 hadoop106\n192.168.10.107 hadoop107\n192.168.10.108 hadoop108\n \n 1 2 3 4 5 6 7 8 9 从映射文件中可以看到，我们目前增加了八个映射（但其实三台就差不多了，但是先搞定再说）。 \n \n \n 重启 CentOS系统。 \n \n \n 编辑 Windows hosts 映射文件，修改  C:\\Windows\\System32\\drivers\\etc\\hosts ，添加： \n 192.168.10.100 hadoop100\n192.168.10.101 hadoop101\n192.168.10.102 hadoop102\n192.168.10.103 hadoop103\n192.168.10.104 hadoop104\n192.168.10.105 hadoop105\n192.168.10.106 hadoop106\n192.168.10.107 hadoop107\n192.168.10.108 hadoop108\n \n 1 2 3 4 5 6 7 8 9 \n \n 远程工具可以使用  XShell && XFTP  或者其他。 \n \n \n 远程工具连接 hadoop100，安装 epel-release（一个软件仓库）： yum install -y epel-release 。 \n \n \n 关闭防火墙： \n systemctl stop firewalld\nsystemctl disable firewalld.service\n \n 1 2 企业开发时，一般会关闭单个服务器的防火墙，开启对外的一个防火墙。 \n \n \n 创建用户 atguigu，修改 atguigu 的密码： \n useradd  atguigu\n passwd  atguigu\n \n 1 2 \n \n 为 atguigu 用户添加 root 权限，方便操作： \n \n \n 修改  /etc/sudoers  文件。 \n \n \n 在  %wheel  行下添加一行  atguigu ALL=(ALL) NOPASSWD:ALL ，比如： \n ## Allow root to run any commands anywhere\nroot    ALL=(ALL)     ALL\n\n## Allows people in group wheel to run all commands\n%wheel  ALL=(ALL)       ALL\natguigu   ALL=(ALL)     NOPASSWD:ALL\n \n 1 2 3 4 5 6 atguigu 这一行不要直接放到root行下面，因为所有用户都属于 wheel 组，配置了 atguigu 具有免密功能，但是程序执行到 %wheel 行时，该功能又被覆盖回需要密码。\n所以 atguigu 要放到 %wheel 这行下面。 \n \n \n \n \n 在  /opt  下创建文件夹，并修改权限： \n之后软件的目录，例如 JDK、Hadoop 的存放位置 \n mkdir  /opt/module\n软件安装包存放目录 \n mkdir  /opt/software\n将两者的所有者和所属组更改为 atguigu \n chown  atguigu:atguigu /opt/module\n chown  atguigu:atguigu /opt/software\n \n 1 2 3 4 5 6 7 \n \n 卸载虚拟机自带的 JDK： \n rpm  -qa  |   grep  -i java  |   xargs  -n1  rpm  -e --nodeps\n \n 1 \n \n 重启虚拟机。 \n 克隆虚拟机 \n \n \n 克隆虚拟机，注意选择完全克隆，使用 hadoop102 作为案例。 \n \n \n 修改克隆虚拟机的静态 IP，修改文件  /etc/sysconfig/network-scripts/ifcfg-ens33 ： \n BOOTPROTO=static\nNAME="ens33"\nIPADDR=192.168.10.102\nPREFIX=24\nGATEWAY=192.168.10.2\nDNS1=192.168.10.2\n \n 1 2 3 4 5 6 \n \n 修改主机名称，修改文件  /etc/hostname  为  hadoop102 。 \n \n \n 重启。 \n 安装环境 \n \n \n JDK 安装： \n 因为在模板虚拟及已经全部卸载了虚拟机的自带 JDK，所以重新安装 JDK。 \n \n 利用 XFTP 传输 JDK 到  /opt/software ，JDK 版本为  jdk-8u212 ，其实 JDK8 即可，中间差别不大。 \n 解压 JDK 到  /opt/module ： tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/ \n 配置环境变量：\n \n \n 新建文件  /etc/profile.d/my_env.sh ，编辑，添加： \n #JAVA_HOME\nexport JAVA_HOME=/opt/module/jdk1.8.0_212\nexport PATH=$PATH:$JAVA_HOME/bin\n \n 1 2 3 \n \n source /etc/profile ，使用新的环境变量。 \n 注意，这里直接编辑  my_env.sh  是因为  /etc/profile  有一段为： \n for i in /etc/profile.d/*.sh /etc/profile.d/sh.local ; do\n    if [ -r "$i" ]; then\n        if [ "${-#*i}" != "$-" ]; then\n            . "$i"\n        else\n文件黑洞，写到 `/dev/null` 的内容会被立刻丢弃，无用的日志可以向里面放。\n            . "$i" >/dev/null\n        fi\n    fi\ndone\n \n 1 2 3 4 5 6 7 8 9 10 它会遍历所有  /etc/profile.d/*.sh ，并加入到环境变量。 \n \n \n 使用  java -version  测试是否安装成功。 \n \n \n \n \n \n \n Hadoop 安装： \n \n \n 使用  hadoop-3.1.3 。 \n \n \n 上传至  /opt/software/ \n \n \n 解压： tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/ \n \n \n 编辑  /etc/profile.d/my_env.sh ，将 Hadoop 目录添加到文件末尾： \n #HADOOP_HOME\nexport HADOOP_HOME=/opt/module/hadoop-3.1.3\nexport PATH=$PATH:$HADOOP_HOME/bin\n存在 sbin 时，也需要添加 sbin 到环境变量\nexport PATH=$PATH:$HADOOP_HOME/sbin\n \n 1 2 3 4 5 \n \n 使用  hadoop version  测试是否成功，不成功重启虚拟机。 \n Hadoop 介绍 \n Hadoop 目录结构 \n drwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 bin\ndrwxr-xr-x. 3 atguigu atguigu  4096 5月  22 2017 etc\ndrwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 include\ndrwxr-xr-x. 3 atguigu atguigu  4096 5月  22 2017 lib\ndrwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 libexec\n-rw-r--r--. 1 atguigu atguigu 15429 5月  22 2017 LICENSE.txt\n-rw-r--r--. 1 atguigu atguigu   101 5月  22 2017 NOTICE.txt\n-rw-r--r--. 1 atguigu atguigu  1366 5月  22 2017 README.txt\ndrwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 sbin\ndrwxr-xr-x. 4 atguigu atguigu  4096 5月  22 2017 share\n \n 1 2 3 4 5 6 7 8 9 10 \n bin：存放对 Hadoop 相关服务（HDFS、YARN、MapReduce）进行操作的脚本。 \n etc：Hadoop 的配置文件目录，存放 Hadoop 的配置文件。 \n lib：存放 Hadoop 的本地库（对数据进行压缩和解压）。 \n sbin：存放启动或者停止 Hadoop 相关服务的脚本。 \n share：Hadoop 的依赖 jar 包、文档、官方案例。 \n \n Hadoop 运行模式 \n hadoop 运行模式包括： \n \n 本地模式。 \n 伪分布式。 \n 完全分布式。 \n 本地模式 \n \n \n 在 hadoop 安装目录（ /opt/module/hadoop-3.1.3 ）下创建一个文件夹  wcinput ，在里面创建一个文件  word.txt ： \n hadoop yarn\nhadoop mapreduce\natguigu\natguigu\n \n 1 2 3 4 \n \n 使用官方案例 wordCount 执行： \n \n 回到 Hadoop 安装目录。 \n 执行官方案例 wordcount： hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput \n 进入 wcoutput，查看结果。 \n \n 注意：wcoutput 在执行之前假如存在会报错。 \n 完全分布式 \n 伪分布式没什么好说的，准备完全分布式。 \n scp、rsync \n 工欲善其事，必先利其器，首先来看两个集群之间的分发工具： \n scp：可以实现服务器之间的数据拷贝。 \n \n 语法： scp -r $pdir/$fname $user@$host:$pdir/$fname \n \n -r ：递归。 \n $pdir/$fname ：要拷贝的文件路径/名称。 \n $user@$host:$pdir/$fname ：目的地用户@目的地主机IP:目的地路径/目的地文件名称。 \n \n \n 案例： scp -r /opt/module/jdk1.8.0_212 atguigu@hadoop103:/opt/module \n 其他用法：任意指定服务器的内容，可以复制到任意服务器上，例如： scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module \n \n rsync ：主要用于备份和镜像，速度快，避免复制相同内容，并且支持符号链接。 \n \n 和 scp 的区别：rsync 主要用于同步差异文件，scp 会同步所有文件。 \n 语法： rsync -av $pdir/$fname $user@$host:$pdir/$fname \n \n -a ：归档拷贝。 \n -v ：显示复制过程。 \n 其余类似 scp 的命令。 \n \n \n 案例：\n \n rsync -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/ \n \n \n \n 完全分布式 \n 准备虚拟机 hadoop102、hadoop103、hadoop104，准备阶段参考 hadoop102。 \n \n \n 创建文件夹  /home/atguigu/bin ，在文件夹下面创建  xsync  文件。 \n \n \n 编辑文件  xsync  编写集群分发脚本： \n #!/bin/bash \n\n #1. 判断参数个数 \n if   [   $#  -lt  1   ] \n then \n     echo  Not Enough Arguement ! \n     exit ; \n fi \n\n #2. 遍历集群所有机器 \n for   host   in  hadoop102 hadoop103 hadoop104\n do \n     echo   == == == == == == == == == ==    $host    == == == == == == == == == == \n     #3. 遍历所有目录，挨个发送 \n\n     for   file   in   $@ \n     do \n         #4. 判断文件是否存在 \n         if   [  -e  $file   ] \n             then \n                 #5. 获取父目录 \n                 pdir = $( cd  -P  $( dirname $file ) ;   pwd ) \n\n                 #6. 获取当前文件的名称 \n                 fname = $( basename  $file ) \n                 ssh   $host   "mkdir -p  $pdir " \n                 rsync  -av  $pdir / $fname   $host : $pdir \n             else \n                 echo   $file  does not exists ! \n         fi \n     done \n done \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \n \n 修改脚本执行权限： chmod +x xsync \n \n \n 测试脚本： xsync /home/atguigu/bin ，将脚本复制到  /bin/  下，以便全局调用。 \n \n \n 同步环境变量配置  sudo ./bin/xsync /etc/profile.d/my_env.sh 。使用了 sudo 则必须写全 xsync 路径。 \n \n \n SSH 免密钥登陆 \n 这块内容是计算机基础知识，使用到了公钥和私钥，详细了解可以查看计算机网络。 \n 在三台机器上分别做以下操作： \n \n \n 配置 SSH 密钥： ssh-keygen -t rsa ： \n 此次将会在用户 home 目录下（比如  /home/atguigu ）生成  .ssh  文件夹，文件夹中包含  id_rsa （私钥）， id_rsa.pub （公钥）。 \n \n \n 复制公钥到需要免密登陆的服务器上，注意，本机器也需要配置： \n ssh-copy-id hadoop102\nssh-copy-id hadoop103\nssh-copy-id hadoop104\n \n 1 2 3 此次步骤将会在用户 home 目录下的  .ssh  文件夹中生成  authorized_keys  文件，其中包含三个密钥，分别对应三台服务器的公钥。 \n \n \n 使用 ssh 尝试访问其他两台服务器，会出现文件  known_hosts ，这是记录 ssh 访问过计算机的公钥。 \n \n \n 集群配置 \n \n \n 集群配置： \n \n \n \n \n hadoop102 \n hadoop103 \n hadoop104 \n \n \n \n \n HDFS \n NameNode   DataNode \n DataNode \n SecondaryNameNode   DataNode \n \n \n YARN \n NodeManager \n ResourceManager   NodeManager \n NodeManager \n \n \n \n 注意： \n \n NN 和 2NN 不要配置到一台机器上，因为 2NN 是 NN 的备份，假如配置在一台服务器上，当这台服务器挂了就凉凉。 \n RM 同样消耗资源，不要和 NN 或 2NN 放到一起。 \n \n \n \n 集群默认配置文件： \n \n core-default.xml ：文件存放到了  hadoop-common-3.1.3.jar/core-default.xml \n hdfs-default.xml ：文件存放到了  hadoop-hdfs-3.1.3.jar/hdfs-default.xml \n yarn-default.xml ：文件存放到了  hadoop-yarn-common-3.1.3.jar/yarn-default.xml \n mapred-default.xml ：文件存放到了  hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml \n \n \n \n 以上是集群默认配置文件，不可更改，但是我们可以自定义配置文件： \n \n core-site.xml \n hdfs-site.xml \n yarn-site.xml \n mapred-site.xml \n \n 自定义的配置文件将会覆盖原有的配置文件，它们存放到了  $HADOOP_HOME/etc/hadoop  中。 \n 事实上在之后写代码的时候，放在 java resources 包下的会覆盖这里的自定义配置文件，写在代码中的配置又会覆盖自定义的配置文件。 \n \n \n 配置核心文件： $HADOOP_HOME/etc/hadoop/core-site.xml : \n <?xml version="1.0" encoding="UTF-8"?> \n <?xml-stylesheet type="text/xsl" href="configuration.xsl"?> \n\n < configuration > \n     \x3c!-- 指定NameNode的地址 --\x3e \n     < property > \n         < name > fs.defaultFS </ name > \n         < value > hdfs://hadoop102:8020 </ value > \n     </ property > \n\n     \x3c!-- 指定hadoop数据的存储目录 --\x3e \n     < property > \n         < name > hadoop.tmp.dir </ name > \n         < value > /opt/module/hadoop-3.1.3/data </ value > \n     </ property > \n\n     \x3c!-- 配置HDFS网页登录使用的静态用户为atguigu --\x3e \n     < property > \n         < name > hadoop.http.staticuser.user </ name > \n         < value > atguigu </ value > \n     </ property > \n </ configuration > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n \n 配置 HDFS 文件： $HADOOP_HOME/etc/hadoop/hdfs-site.xml : \n <?xml version="1.0" encoding="UTF-8"?> \n <?xml-stylesheet type="text/xsl" href="configuration.xsl"?> \n\n < configuration > \n     \x3c!-- nn web端访问地址--\x3e \n     < property > \n         < name > dfs.namenode.http-address </ name > \n         < value > hadoop102:9870 </ value > \n     </ property > \n     \x3c!-- 2nn web端访问地址--\x3e \n     < property > \n         < name > dfs.namenode.secondary.http-address </ name > \n         < value > hadoop104:9868 </ value > \n     </ property > \n </ configuration > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n \n 配置 YARN 文件： $HADOOP_HOME/etc/hadoop/yarn-site.xml : \n <?xml version="1.0" encoding="UTF-8"?> \n <?xml-stylesheet type="text/xsl" href="configuration.xsl"?> \n\n < configuration > \n     \x3c!-- 指定MR走shuffle --\x3e \n     < property > \n         < name > yarn.nodemanager.aux-services </ name > \n         < value > mapreduce_shuffle </ value > \n     </ property > \n\n     \x3c!-- 指定ResourceManager的地址--\x3e \n     < property > \n         < name > yarn.resourcemanager.hostname </ name > \n         < value > hadoop103 </ value > \n     </ property > \n\n     \x3c!-- 环境变量的继承 --\x3e \n     < property > \n         < name > yarn.nodemanager.env-whitelist </ name > \n         < value > JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME </ value > \n     </ property > \n </ configuration > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n \n 配置 MapReduce 文件： $HADOOP_HOME/etc/hadoop/mapred-site.xml : \n <?xml version="1.0" encoding="UTF-8"?> \n <?xml-stylesheet type="text/xsl" href="configuration.xsl"?> \n\n < configuration > \n     \x3c!-- 指定MapReduce程序运行在Yarn上 --\x3e \n     < property > \n         < name > mapreduce.framework.name </ name > \n         < value > yarn </ value > \n     </ property > \n </ configuration > \n \n 1 2 3 4 5 6 7 8 9 10 \n \n 分发脚本： xsync /opt/module/hadoop-3.1.3/etc/hadoop/ \n \n \n 群起集群 \n \n \n 配置 workers（2.x 之前叫做 slaves），修改  /opt/module/hadoop-3.1.3/etc/hadoop/workers ，改为如下： \n hadoop102\nhadoop103\nhadoop104\n \n 1 2 3 \n /opt/module/hadoop-3.1.3/etc/hadoop/workers \n \n 注意，此文件添加的内容文件结尾不准有空格，文件中不准有空行。 \n \n \n 分发： xsync /opt/module/hadoop-3.1.3/etc \n \n \n 启动集群： \n \n \n 如果集群初次启动，则需要在 NameNode 节点格式化，这里就是 hadoop102 节点： hdfs namenode -format \n 格式化 NameNode 会产生新的集群 ID，假如集群需要重新格式化 NameNode，一定要首先删除机器的 data 和 logs 目录，然后再进行格式化，否则集群 ID 不一致会导致集群找不到以往数据。 \n \n \n 启动 HDFS： sbin/start-dfs.sh \n \n \n 在 ResourceManager 节点，这里是 hadoop103 节点，启动 YARN： sbin/start-yarn.sh \n \n \n 在浏览器上输入  http://hadoop102:9870  查看是否启动了 HDFS。在  http://hadoop103:8088  查看 YARN 上的 Job 信息。 \n \n \n \n \n 配置历史服务器： \n \n \n 修改  $HADOOP_HOME/etc/hadoop/mapred-site.xml ，增加配置： \n \x3c!-- 历史服务器端地址 --\x3e \n < property > \n     < name > mapreduce.jobhistory.address </ name > \n     < value > hadoop102:10020 </ value > \n </ property > \n\n \x3c!-- 历史服务器web端地址 --\x3e \n < property > \n     < name > mapreduce.jobhistory.webapp.address </ name > \n     < value > hadoop102:19888 </ value > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 10 11 \n \n 分发配置： xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml \n \n \n 启动历史服务器： mapred --daemon start historyserver \n \n \n 使用命令  jps  查看是否启动（jps 不生效是因为 Java 环境没配好）。 \n \n \n 查看 JobHistory： http://hadoop102:19888/jobhistory \n 假如失败，则重启 HDFS 再次查看。 \n \n \n \n \n 配置日志聚集功能： \n 日志聚集，其实就是将程序运行日志信息上传到 HDFS 上，方便查看。 \n \n \n 编辑  $HADOOP_HOME/etc/hadoop/yarn-site.xml ，增加配置： \n \x3c!-- 开启日志聚集功能 --\x3e \n < property > \n     < name > yarn.log-aggregation-enable </ name > \n     < value > true </ value > \n </ property > \n \x3c!-- 设置日志聚集服务器地址 --\x3e \n < property > \n     < name > yarn.log.server.url </ name > \n     < value > http://hadoop102:19888/jobhistory/logs </ value > \n </ property > \n \x3c!-- 设置日志保留时间为7天 --\x3e \n < property > \n     < name > yarn.log-aggregation.retain-seconds </ name > \n     < value > 604800 </ value > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n \n 分发配置： xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml \n \n \n 重启 NameNode、ResourceManager、HistoryServer： \n sbin/stop-yarn.sh\nmapred --daemon stop historyserver\nsbin/start-yarn.sh\nmapred --daemon start historyserver\n \n 1 2 3 4 \n \n 执行 Word Count 程序，查看日志。 \n \n \n \n \n 其他 \n \n \n 整体启动/停止模块： \n \n start-dfs.sh/stop-dfs.sh \n start-yarn.sh/stop-yarn.sh \n \n \n \n 各个服务组件单独启动/停止： \n \n hdfs --daemon start/stop namenode/datanode/secondarynamenode \n yarn --daemon start/stop  resourcemanager/nodemanager \n \n \n \n 群起集群脚本： /home/atguigu/bin/myhadoop.sh ： \n #!/bin/bash \n查看输入参数 \n if   [   $#  -lt  1   ] \n then \n     echo   "No Args Input..." \n     exit   ; \n fi \n当前输入参数为 start 则启动集群，输入为 stop 关闭集群 \n case   $1   in \n "start" ) \n         echo   " =================== 启动 hadoop集群 ===================" \n\n         echo   " --------------- 启动 hdfs ---------------" \n         ssh  hadoop102  "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh" \n         echo   " --------------- 启动 yarn ---------------" \n         ssh  hadoop103  "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh" \n         echo   " --------------- 启动 historyserver ---------------" \n         ssh  hadoop102  "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver" \n ; ; \n "stop" ) \n         echo   " =================== 关闭 hadoop集群 ===================" \n\n         echo   " --------------- 关闭 historyserver ---------------" \n         ssh  hadoop102  "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver" \n         echo   " --------------- 关闭 yarn ---------------" \n         ssh  hadoop103  "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh" \n         echo   " --------------- 关闭 hdfs ---------------" \n         ssh  hadoop102  "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh" \n ; ; \n* ) \n     echo   "Input Args Error..." \n ; ; \n esac \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \n \n 查看三台服务器进程脚本： /home/atguigu/bin/jpsall \n #!/bin/bash \n\n for   host   in  hadoop102 hadoop103 hadoop104\n do \n         echo   == == == == == == == =   $host   == == == == == == == = \n         ssh   $host  jps\n done \n \n 1 2 3 4 5 6 7 \n \n 常用端口号： \n \n \n \n \n \n 端口名称 \n Hadoop2.x \n Hadoop3.x \n \n \n \n \n NameNode 内部通信端口 \n 8020/9000 \n 8020/9000/9820 \n \n \n NameNode HTTP UI \n 50070 \n 9870 \n \n \n MapReduce 查看执行任务端口 \n 8088 \n 8088 \n \n \n 历史服务器通信端口 \n 19888 \n 19888 \n \n \n \n 文件上传和下载 \n \n \n 上传文件到 HDFS： hadoop fs -put ${文件路径} ${HDFS 路径} \n \n \n 上传文件后查看真实的存储位置： \n /opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1436128598-192.168.10.102-1610603650062/current/finalized/subdir0/subdir0 \n 注意，这里的文件夹名称有些不一定相同（比如  BP-1436128598-192.168.10.102-1610603650062 ），但是大体位置是一样的。 \n \n \n 从 HDFS 下载到本地： hadoop fs -get ${HDFS 文件路径} ${本地文件路径} \n \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"November 8, 2021 23:12",createTimeStamp:1636384322e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1},{name:"causes",email:"2592716753@qq.com",commits:1}]},{title:"Hadoop-02-HDFS",frontmatter:{title:"Hadoop-02-HDFS",categories:["bigdata"],tags:["hadoop"],author:"causes",summary:"HDFS 概述 概述和优缺点 随着数据量越来越大，一台服务器肯定存不下所有的数据，那么需要一种分布式文件系统来进行文件的存储。HDFS（Hadoop Distributed File System） 就是这样一种分布式文件系统。 HDFS 适合用于一次写入，多次读取的场景，也就是说一个文件经过创建之后就不再进行改变，这也是大数据的特点：从已经存在的数据进行分",meta:[{property:"og:url",content:"/bigdata/Hadoop/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hadoop-02-HDFS"},{property:"og:description",content:"HDFS 概述 概述和优缺点 随着数据量越来越大，一台服务器肯定存不下所有的数据，那么需要一种分布式文件系统来进行文件的存储。HDFS（Hadoop Distributed File System） 就是这样一种分布式文件系统。 HDFS 适合用于一次写入，多次读取的场景，也就是说一个文件经过创建之后就不再进行改变，这也是大数据的特点：从已经存在的数据进行分"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hadoop"}]},regularPath:"/bigdata/Hadoop/part2.html",relativePath:"bigdata/Hadoop/part2.md",key:"v-0e1bf380",path:"/bigdata/Hadoop/part2/",headers:[{level:2,title:"HDFS 概述",slug:"hdfs-概述"},{level:2,title:"HDFS 中的 Shell 操作",slug:"hdfs-中的-shell-操作"},{level:3,title:"上传",slug:"上传"},{level:3,title:"下载",slug:"下载"},{level:3,title:"HDFS 直接操作",slug:"hdfs-直接操作"},{level:2,title:"HDFS API 操作",slug:"hdfs-api-操作"},{level:3,title:"环境准备",slug:"环境准备"},{level:3,title:"案例实操",slug:"案例实操"},{level:2,title:"HDFS 读写流程",slug:"hdfs-读写流程"},{level:3,title:"文件写入",slug:"文件写入"},{level:3,title:"文件读取",slug:"文件读取"},{level:2,title:"NameNode 和 SecondaryNameNodex",slug:"namenode-和-secondarynamenodex"},{level:3,title:"NN 和 2NN 工作机制",slug:"nn-和-2nn-工作机制"},{level:3,title:"FsImage 和 Edits",slug:"fsimage-和-edits"},{level:2,title:"DataNode",slug:"datanode"},{level:3,title:"DataNode 工作机制",slug:"datanode-工作机制"},{level:3,title:"参数设置",slug:"参数设置"},{level:3,title:"数据的完整性",slug:"数据的完整性"}],readingTime:{minutes:17.48,words:5243},content:' HDFS 概述 \n 概述和优缺点 \n 随着数据量越来越大，一台服务器肯定存不下所有的数据，那么需要一种分布式文件系统来进行文件的存储。HDFS（Hadoop Distributed File System） 就是这样一种分布式文件系统。 \n HDFS 适合用于一次写入，多次读取的场景，也就是说一个文件经过创建之后就不再进行改变，这也是大数据的特点：从已经存在的数据进行分析，寻找规律，而不是创造规律。 \n HDFS 的优点： \n \n 高容错性：数据将会自动保存多个副本，所以当一个副本丢失之后可以自动恢复。 \n 适合处理大量的数据：能够处理 TB、甚至 PB 级别的数据，可以处理百万级别的文件数量。 \n 廉价：可以构建在廉价的机器上，性价比高。 \n \n HDFS 的缺点： \n \n 毫秒级别的存储做不到，适合使用小时、天、甚至周的事件来处理任务。 \n 小文件处理不佳，无法高效地对小文件进行处理：会占用大量的 NameNode 内存，寻址时间将超过读取时间，这其实违背了设计的目的。 \n 不支持并发写入，随机修改：也就是说一个文件只能有一个线程进行写操作，而且仅支持数据的追加（append），不支持文件的随机修改。 \n \n HDFS 组成架构 \n \n \n NameNode \n 简写为 NN，就是 Master，是一个主管，它有如下作用： \n \n 管理 HDFS 名称空间（namespace）。 \n 管理副本的生成策略，一个文件应该生成几个副本来存储，副本应该在哪台 DataNode 存储。 \n 管理数据块（Block）的映射信息，例如什么文件大小多少、位置在哪等。 \n 处理客户端的读写请求。 \n \n \n \n DataNode \n 可以看成干活的人，可以叫做 Slave，Worker，NameNode 下达命令，DataNode 执行： \n \n 存储数据块。 \n 执行数据块的读写操作。 \n \n \n \n Client \n 其实就是客户端，做以下事情： \n \n 文件切分：当文件上传到 HDFS 之前，Client 会判断文件是否过大，如果文件超过预定义的值将会把文件切分为一个个的块（Block）。 \n 与 NameNode 交互：获取文件应该存储到那个 DataNode，或者已经存储到了哪个 DataNode。 \n 与 DataNode 交互：进行文件的读写操作。 \n 提供了一些命令管理 HDFS，例如 NameNode 的格式化。 \n 提供了一些命令访问 HDFS，例如 HDFS 的增删改查。 \n \n \n \n Secondary Name Node \n 简写为 2NN，虽然名字是这样，但是并不是热备，更多类似于秘书的角色，能起到一定作用，但不能代替 NN 原有的共做： \n \n 辅助 NN，分担工作，例如定期合并 Fsimage 和 Edists，并推送给 DataNode。 \n 紧急情况下可恢复 NN，但是注意，这里并不能恢复 NN 下的所有数据，之后会讲。 \n \n 在真正的企业中，一般使用 Hadoop 的高可用来替换掉 2NN。 \n \n \n HDFS 文件块大小 \n 上面说过，Client 在进行文件上传之前，首先会检测文件的大小，如果文件过大会将文件切分为块（Block）。 \n Hadoop 2.x 和 Hadoop 3.x 默认大小为 128M，1.x 版本为 64M，但是块大小可以通过配置参数  dfs.blocksize  来规定。 \n 但其实块的大小不能太大，也不能太小，HDFS 块大小的设置主要取决于磁盘的传输速率： \n \n 文件块太大，从磁盘传输数据的速度会很长。 \n 文件块太小，寻址时间会超过磁盘加载数据的时间。 \n HDFS 中的 Shell 操作 \n Shell 操作之前，需要首先启动 Hadoop 集群，注意至少要启动 HDFS 和 YARN。 \n 在使用每个命令的时候，可以使用  --help  参数来查看使用方式，例如： hadoop fs -help rm \n 上传 \n 本地文件移动到 HDFS \n hadoop fs -moveFromLocal ${本地文件路径/文件名称} \n 本地文件复制到 HDFS \n hadoop fs -copyFromLocal ${本地文件路径/文件名称} \n hadoop fs -put ${本地文件路径/文件名称} ：等同于  copyFromLocal ，但是因为敲的代码少一点，生产环境更喜欢用  put  上传。 \n 本地文件追加到 HDFS 中已有的一个文件末尾 \n hadoop fs -appendToFile ${本地文件路径/文件名称} \n 下载 \n 从 HDFS 拷贝到本地 \n hadoop fs -copyToLocal ${HDFS 的路径/HDFS 的文件名称} ${本地路径/本地文件名称} \n HDFS 直接操作 \n 显示目录信息 \n hadoop fs -ls ${目录} \n 显示文件内容 \n hadoop fs -cat ${文件} \n 修改文件所属权限 \n 类似于 Linux 系统，使用  hadoop fs -chmod/chown/chgrp ${权限} ${文件} \n 创建目录 \n hadoop fs -mkdir ${目录} \n HDFS 中的拷贝 \n 将文件从 HDFS 中的一个路径拷贝到 HDFS 中的另一个路径。 \n hadoop fs -cp ${源路径} ${目标路径} \n HDFS 中的移动 \n 将文件从 HDFS 中的一个路径移动到另一个路径。 \n hadoop fs -mv ${源路径} ${目标路径} \n 显示 HDFS 上一个文件末尾的数据 \n hadoop fs -tail ${文件} \n 删除文件/文件夹 \n hadoop fs -rm [-r] ${文件/文件夹} \n 统计文件夹大小信息 \n hadoop fs -du -s -h ${文件夹} \n 设置 HDFS 中文件的副本数量 \n hadoop fs -setrep ${副本数量} ${文件} \n HDFS API 操作 \n 环境准备 \n 可以使用 API 来对 HDFS 进行操作： \n \n \n 原本 Windows 并没有 Hadoop 的相关配置，需要将 Windows 依赖添加到环境中，只需要 Hadoop 的一个 bin 文件夹即可，其余都不需要。 \n \n 其中比较重要的是  winutils.exe  这个程序。Java 环境变量不再赘述，这里主要是 Hadoop 的配置。 \n \n \n 配置环境变量，指向 Hadoop 的配置。 \n \n \n \n 双击  winutils.exe ，假如出现错误  由于找不到 MSVCR120.dll ，说明缺少微软运行库，可以去 3DM 或者果核剥壳一类的网站找一下。 \n \n \n 重启系统。 \n \n \n 在 IDEA 中创建一个 Maven 工程，导入对应的依赖。 \n < dependencies > \n     < dependency > \n         < groupId > org.apache.hadoop </ groupId > \n         < artifactId > hadoop-client </ artifactId > \n         < version > 3.1.3 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > junit </ groupId > \n         < artifactId > junit </ artifactId > \n         < version > 4.12 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.slf4j </ groupId > \n         < artifactId > slf4j-log4j12 </ artifactId > \n         < version > 1.7.30 </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n \n 使用  log4j.properties  文件： \n log4j.rootLogger = INFO, stdout \n log4j.appender.stdout = org.apache.log4j.ConsoleAppender \n log4j.appender.stdout.layout = org.apache.log4j.PatternLayout \n log4j.appender.stdout.layout.ConversionPattern = %d %p [%c] - %m%n \n log4j.appender.logfile = org.apache.log4j.FileAppender \n log4j.appender.logfile.File = target/spring.log \n log4j.appender.logfile.layout = org.apache.log4j.PatternLayout \n log4j.appender.logfile.layout.ConversionPattern = %d %p [%c] - %m%n \n \n 1 2 3 4 5 6 7 8 \n 案例实操 \n 创建目录 \n public   class   HDFSClient   { \n\n   Configuration  conf ; \n   FileSystem  fs ; \n\n   @Before \n   public   void   before ( )   throws   URISyntaxException ,   IOException ,   InterruptedException   { \n    conf  =   new   Configuration ( ) ; \n     // Linux 对用户权限的管理十分严格，所以不仅需要 HDFS 的路径，配置，还需要指定的用户 \n    fs  =   FileSystem . get ( new   URI ( "hdfs://hadoop102:8020" ) ,  conf ,   "atguigu" ) ; \n   } \n\n   @Test \n   public   void   mkdirs ( )   throws   IOException   { \n     // 在 HDFS 根目录下创建 xiyou/huaguoshan 的目录 \n    fs . mkdirs ( new   Path ( "/xiyou/huaguoshan" ) ) ; \n   } \n\n   @After \n   public   void   after ( )   throws   IOException   { \n    fs . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 上传文件 \n public   class   HDFSClient   { \n\n   Configuration  conf ; \n   FileSystem  fs ; \n\n   @Before \n   public   void   before ( )   throws   URISyntaxException ,   IOException ,   InterruptedException   { \n    conf  =   new   Configuration ( ) ; \n     // 手动设置单个文件的副本数量，这里设置为 2 \n    conf . set ( "dfs.replication" , "2" ) ; \n    fs  =   FileSystem . get ( new   URI ( "hdfs://hadoop102:8020" ) ,  conf ,   "atguigu" ) ; \n   } \n\n   @Test \n   public   void   uploadFile ( )   throws   IOException   { \n     // 手动指定 Windows 下路径为 sunwukong.txt 的文件，上传到 HDFS 中 /xiyou/huaguoshan 路径下 \n    fs . copyFromLocalFile ( new   Path ( "D:/Temp/sunwukong.txt" ) ,   new   Path ( "/xiyou/huaguoshan" ) ) ; \n   } \n\n   @After \n   public   void   after ( )   throws   IOException   { \n    fs . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 注意，这里在进行上传文件之前，进行了一次设置文件副本数量的操作，最终形成的副本数量将为 2。 \n 事实上，对于一些配置而言（不仅仅是这些切片的配置，还有更多配置）我们可以在多个地点定义配置： \n \n \n 默认配置，权限最低。 \n 以 HDFS 的配置文件举例，它的位置是： $HADOOP_HOME/share/hadoop/hdfs/hadoop-hdfs-3.1.3.jar ，在此 jar 包中，可以看到  hdfs-default.xml ，记载的就是默认配置项。 \n \n 可以看到默认是 3，也就是说默认切片数量为 3。 \n \n \n 服务器自定义配置，权限高于默认配置。 \n 仍然以 HDFS 配置举例，自定义配置的路径一般在于  $HADOOP_HOME/etc/hadoop/hdfs-site.xml ，以  xxx-site.xml  为格式的文件，一般都是自定义配置。 \n 这套规则不仅在 Hadoop 下生效，其实已经类似于一种约定俗成的习惯了。 \n \n \n ClassPath 下的配置，权限高于自定义配置。 \n 文件仍然叫做  hdfs-site.xml ，不过位置将会放到项目的 resources 资源目录下，这也是最终对应 ClassPath 的位置。 \n <?xml version="1.0" encoding="UTF-8"?> \n <?xml-stylesheet type="text/xsl" href="configuration.xsl"?> \n\n < configuration > \n   < property > \n     < name > dfs.replication </ name > \n         < value > 1 </ value > \n   </ property > \n </ configuration > \n \n 1 2 3 4 5 6 7 8 9 \n \n 代码中设置的配置，权限高于 ClassPath 的配置，这个在上面的代码中有写。 \n \n \n 文件下载 \n @Test \n public   void   downloadFile ( )   throws   IOException   { \n   /*\n    参数一：是否删除源文件。\n    参数二：Hadoop 中源文件路径。\n    参数三：下载的文件路径。\n    参数四：是否开启文件校验。\n    */ \n  fs . copyToLocalFile ( false ,   new   Path ( "/xiyou/huaguoshan/sunwukong.txt" ) ,   new   Path ( "d:/sunwukong.txt" ) ,   true ) ; \n } \n \n 1 2 3 4 5 6 7 8 9 10 Before 和 After 不再写。第四个选项是否开启文件校验其实指的是 CRC 文件校验（循环冗余校验），CRC 的作用就是为了确保下载的文件数据是完整的。 \n HDFS 改名和移动 \n @Test \n public   void   mvFile ( )   throws   IOException   { \n   // rename 类似于 Linux 中的 mv 操作，可以改变文件的位置以及名称 \n  fs . rename ( new   Path ( "/xiyou/huaguoshan/sunwukong.txt" ) ,   new   Path ( "/xiyou/huaguoshan/meihouwang.txt" ) ) ; \n } \n \n 1 2 3 4 5 HDFS 删除 \n @Test \n public   void   removeFileAndDir ( )   throws   IOException   { \n   /*\n    参数一：需要删除的对象\n    参数二：是否递归删除，一般用于目录\n    */ \n  fs . delete ( new   Path ( "/xiyou" ) ,   true ) ; \n } \n \n 1 2 3 4 5 6 7 8 HDFS 查看文件详情 \n @Test \n public   void   descFile ( )   throws   IOException   { \n   /*\n    参数一：查看某目录下的文件。\n    参数二：是否递归查看。\n    */ \n   RemoteIterator < LocatedFileStatus >  files  =  fs . listFiles ( new   Path ( "/" ) ,   true ) ; \n   while   ( files . hasNext ( ) )   { \n     LocatedFileStatus  fileStatus  =  files . next ( ) ; \n     // 路径 \n     Path  path  =  fileStatus . getPath ( ) ; \n     // path hdfs://hadoop102:8020/input/word.txt \n     System . out . printf ( "path %s%n" ,  path ) ; \n\n     // 名称 \n     String  name  =  fileStatus . getPath ( ) . getName ( ) ; \n     // name word.txt \n     System . out . printf ( "name %s%n" ,  name ) ; \n\n     // 权限 \n     FsPermission  permission  =  fileStatus . getPermission ( ) ; \n     // permission rw-r--r-- \n     System . out . printf ( "permission %s%n" ,  permission ) ; \n\n     // 所属人 \n     String  owner  =  fileStatus . getOwner ( ) ; \n     // owner atguigu \n     System . out . printf ( "owner %s%n" ,  owner ) ; \n\n     // 所属用户组 \n     String  group  =  fileStatus . getGroup ( ) ; \n     // group supergroup \n     System . out . printf ( "group %s%n" ,  group ) ; \n\n     // 文件大小 \n     long  len  =  fileStatus . getLen ( ) ; \n     // len 26，这里其实是 26B \n     System . out . printf ( "len %s%n" ,  len ) ; \n\n     // 最后更新时间 \n     long  modificationTime  =  fileStatus . getModificationTime ( ) ; \n     System . out . printf ( "modificationTime %s%n" ,  modificationTime ) ; \n\n     // 副本数量 \n     short  replication  =  fileStatus . getReplication ( ) ; \n     System . out . printf ( "replication %s%n" ,  replication ) ; \n\n     // 块大小 \n     long  blockSize  =  fileStatus . getBlockSize ( ) ; \n     // blockSize 134217728，除两次之后将得到 128M \n     System . out . printf ( "blockSize %s%n" ,  blockSize ) ; \n\n     // 块信息 \n     BlockLocation [ ]  blockLocations  =  fileStatus . getBlockLocations ( ) ; \n     System . out . println ( Arrays . toString ( blockLocations ) ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 判断文件/文件夹 \n @Test \n public   void   testFileFolderStatus ( )   throws   IOException   { \n   // 获取文件信息 \n   FileStatus [ ]  listStatus  =  fs . listStatus ( new   Path ( "/" ) ) ; \n   for   ( FileStatus  fileStatus  :  listStatus )   { \n     System . out . printf ( "%s is %s%n" ,  fileStatus . getPath ( ) ,  fileStatus . isFile ( )   ?   "File"   :   "DIR" ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 #  HDFS 读写流程 \n 文件写入 \n 文件写入 \n \n 使用时序图大致先了解一下内容，接下来将详细讲解： \n \n \n 客户端通过 Distributed FileSystem （分布式文件系统）模块，向 NameNode 请求上传文件。 \n \n \n NameNode 会检查该客户端是否有权限访问，是否目录或者目标文件已经存在，进而返回是否可以上传的应答。 \n \n \n 客户端向 NameNode 发起请求，询问第一个 Block 应该存储至那几个 DataNode 上。 \n \n \n NameNode 进行计算，得到三个 DataNode 节点，并返回。（之后会讲解节点如何选择） \n \n \n 通信管道建立： \n \n 客户端通过 FSDataOutputStream 模块请求向 DataNode1 上传数据。 \n DataNode1 接收到了客户端的请求，将会调用 DataNode2，同理，DataNode2 将会调用 DataNode3，直到通信管道建立完成。 \n DataNode3 应答给 DataNode2，DataNode2 应答给 DataNode1，DataNode1 应答给客户端，至此，通信管道建立完成。 \n \n \n \n 客户端向 DataNode1 上传第一个 Block。 \n 注意，这里从客户端向 DataNode1 节点上传时，有以下注意点： \n \n 客户端上传 Block 会首先从磁盘中读取数据，并且放到一个本地内存缓存中。 \n \n \n \n Block 并不是一次全部上传，而是分批上传。 \n 字节流过来之后，首先会形成 chunk： 512byte 的 chunk + 4byte 的 chunksum（检验数据完整性） 。chunk 的真实数据和校验值比值为 128：1。 \n 当 chunk 攒够 64KB 的时候，就会形成一个大的 Packet（默认 Packet 为 64KB），然后进行发送，所以上传单位其实是 Packet。 \n \n \n \n DataNode 收到一个 packet 会做两件事：向磁盘中写数据，直接从内存中将 packet 发送给下一个节点。这样做保证了快速写入。 \n DataNode 向下个节点发送 Packet 的时候还会向自己的 ACK 队列中添加这个 Packet，避免因为传输失败导致数据丢失。等待应答之后会将 ACK 队列中的 Packet 删除。 \n 下一个 DataNode 接受之后，向上一个发送应答，表示成功接收。 \n \n \n \n 客户端上传第二个 Block。 \n \n \n \n 机架感知 \n 假如客户端在集群中： \n \n 第一个文件副本就是当前客户端所在的节点上，也被叫做本地节点。 \n 第二个文件副本会随机在另一个机架（比如选择了 B 机架）上随机选择一个节点。 \n 第三个文件副本将会在机架 B 上选择一个其他的节点。 \n \n \n 假如客户端不在集群中，会进行网络拓扑，节点计算，算出第一个文件副本的位置。剩下的两个副本位置和上面的计算方式相同。 \n 网络拓扑，节点计算 \n 在 HDFS 写数据的时候，会进行一次网络拓扑的节点距离计算。那么节点的选择有两个参考因素：节点距离最近，负载均衡。 \n 找到离 NameNode 最近的 DataNode 来接受数据，也就是节点距离最小的 DataNode，那么节点距离其实就是两个节点到达它们共同祖先的距离总和。 \n \n 对于 d1 集群中的 r1 机架来说，他自己就是他的祖先，所以节点距离为0。 \n 对于 d1 集群中的 r1 和 r2 节点来说，它们共同祖先是机架 r1，所以节点距离为 2。 \n 文件读取 \n \n 客户端通过 DistributedFileSystem 向 NameNode 请求下载文件，NameNode 通过查询元数据，找到文件块所在的 DataNode 地址。 \n 就近挑选一台存储文件副本的服务器，假如有多台距离相同的，那么随机一个。 \n DataNode 开始传输数据给客户端（从磁盘中读取文件流，然后以 Packet 为单位校验）。 \n 客户端以 Packet 为单位接受，首先本地缓存，之后写入文件。 \n NameNode 和 SecondaryNameNodex \n NN 和 2NN 工作机制 \n NameNode 需要向外提供服务，响应客户请求，那么元数据必须要高效，要想速度快就必须存储到 内存 中。 \n 但是假如元数据仅仅存储在内存中，一旦发生 NameNode 所在服务器断电或者其他问题，内存中的数据将会全部丢失。所以在磁盘中也会备份一份  FsImage 。 \n 但是这样又会产生一个新的问题，当内存中的元数据更新时，假如同时更新 FsImage，那么就会导致效率过低，不更新则会产生一致性问题。 \n 为了解决一致性问题，引入了一个新的文件  Edits ，此文件只保存修改的操作，效率极高。当元数据出现了更新操作或增加操作时，内存中修改的部分将会追加到  Edits  中。 \n 所以最后内存中的元数据其实是  FsImage  +  Edits  合成的。 \n 这样会有另一个问题：假如长时间不断添加  Edits ，那么  Edits  文件将会越来越大，最终效率会降低，因此需要定期将 FsImage 和 Edits 合并，这就是 SecondaryNameNode 的工作，专门用于 FsImage 和 Edits 的合并。 \n 以下是具体的工作流程： \n \n NameNode（NN） 启动：\n \n NameNode 首次格式化并启动，创建 FsImage 和 Edits 文件。如果非首次启动，则直接加载编辑日期和镜像文件到内存。 \n 客户端发起对元数据进行增删改的请求。 \n NameNode 记录操作日志，更新滚动日志。 \n NameNode 在内存中对元数据进行修改。 \n \n \n SecondaryNameNode（2NN） 工作：\n \n 2NN 检查 NN 是否需要 CheckPoint，如果满足条件 NN 则返回需要。 \n 2NN 发起请求执行 CheckoutPoint。 \n NN 滚动正在写的 Edits 日志。 \n 2NN 将滚动前的编辑日志和镜像文件添加到内存，执行合并。 \n 2NN 生成新的镜像文件  fsimage.checpoint 。 \n 2NN 将 fsimage.checkpoint 拷贝到 NN。 \n NN 将 fsimage.checkpoint 重命名为  fsimage 。 \n FsImage 和 Edits \n NameNode 下 FsImage 和 Edits 的位置： \n \n \n FsImage：HDFS 文件系统元数据的一个 永久性 的检查点。其中包含 HDFS 文件系统中所有的目录和文件的序列化信息。 \n Edits：存放 HDFS 文件系统中，所有元数据的更新操作的路径，客户端执行的所有写操作会首先记录到 Edits 中。 \n seen_txid：保存最后一个 edits 的数据，以上图举例，就是 494，即  edits_inprogress_0000000000000000494 \n \n NameNode 每次启动时，都会将 FsImage 写入内存，加载 Edits 文件中的更新操作，以保证元数据是最新的。 \n \n 可以使用命令 oiv 或者 oev 来查看 fsimage/edits 文件： \nhdfs oiv -p ${使用何种文件类型查看} -i ${fsimage 文件} -o ${转换后的文件输出路径} \nhdfs oiv -p XML -i fsimage_0000000000000000493 -o /tmp/fs.xml\nhdfs oev -p ${使用何种文件类型查看} -i ${Edits 文件} -o ${转换后的文件输出路径} \nhdfs oev -p XML -i edits_0000000000000000134-0000000000000000308 -o /tmp/edit.xml\n \n 1 2 3 4 5 \n 默认情况下，CheckPoint 会同时生效两种策略： \n \n \n 2NN 按照时间来执行，默认为一小时执行一次合并。 \n hdfs-default.xml \n < property > \n   < name > dfs.namenode.checkpoint.period </ name > \n   < value > 3600s </ value > \n   < description > \n    The number of seconds between two periodic checkpoints.\n    Support multiple time unit suffix(case insensitive), as described\n    in dfs.heartbeat.interval.\n   </ description > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 \n \n 2NN 按照操作次数来执行，2NN 每分钟去检查一次，当操作次数达到一百万时，2NN 合并一次。 \n hdfs-default.xml \n < property > \n   < name > dfs.namenode.checkpoint.txns </ name > \n   < value > 1000000 </ value > \n   < description > The Secondary NameNode or CheckpointNode will create a checkpoint\n  of the namespace every \'dfs.namenode.checkpoint.txns\' transactions, regardless\n  of whether \'dfs.namenode.checkpoint.period\' has expired.\n   </ description > \n </ property > \n\n < property > \n   < name > dfs.namenode.checkpoint.check.period </ name > \n   < value > 60s </ value > \n   < description > The SecondaryNameNode and CheckpointNode will poll the NameNode\n  every \'dfs.namenode.checkpoint.check.period\' seconds to query the number\n  of uncheckpointed transactions. Support multiple time unit suffix(case insensitive),\n  as described in dfs.heartbeat.interval.\n   </ description > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n \n 这两个策略也完全可以重写，重写的方式之前已经讲过（文件/代码）。 \n DataNode \n DataNode 工作机制 \n \n DataNode 启动，向 NameNode 进行注册。 \n NameNode 返回注册成功的信息。 \n DataNode 开启存活性判断，默认每隔三秒钟向 NameNode 汇报一次心跳，假如 NameNode 以默认策略（10 分钟 + 30 秒）没有接收到 DataNode 的心跳，则认为此 DataNode 死亡。 \n DataNode 在存活时，默认每隔六小时（一周期）上报所有的块信息。 \n 参数设置 \n 默认情况下，DataNode 向 NameNode 汇报当前块信息的时间周期为六小时，在  hdfs-default.xml  中可以找到： \n < property > \n   < name > dfs.blockreport.intervalMsec </ name > \n   < value > 21600000 </ value > \n   < description > Determines block reporting interval in milliseconds. </ description > \n </ property > \n \n 1 2 3 4 5 DataNode 扫描字节块节点信息列表的时间默认为六小时（注意这里的单位是 s，而上面的为 ms）： \n < property > \n   < name > dfs.datanode.directoryscan.interval </ name > \n   < value > 21600s </ value > \n   < description > Interval in seconds for Datanode to scan data directories and\n  reconcile the difference between blocks in memory and on the disk.\n  Support multiple time unit suffix(case insensitive), as described\n  in dfs.heartbeat.interval.\n   </ description > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 默认 DataNode 的心跳检测时间为 3s 一次，当 DataNode 掉线后，NameNode 不会立刻将其标记为死亡，而是会等待超时时长（默认为 10 分钟 + 30s），之后判定为死亡。 \n 这个超时时间的公式为： TimeOut = 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval \n \x3c!-- 需要注意，这个单位为毫秒 --\x3e \n < property > \n     < name > dfs.namenode.heartbeat.recheck-interval </ name > \n     < value > 300000 </ value > \n </ property > \n\n \x3c!-- 需要注意，这个单位为 s --\x3e \n < property > \n     < name > dfs.heartbeat.interval </ name > \n     < value > 3 </ value > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 10 11 #  数据的完整性 \n DataNode 是存储文件的节点，一个数据块在 DataNode 上有两个文件进行存储： \n \n 数据本身。 \n 元数据，也就是记录数据的长度、校验和（保证数据完整性）、时间戳等等。 \n \n DataNode 保证数据完整性的方法如下： \n \n 当 DataNode 读取 Block 的数据时，会计算 CheckSum。 \n 如果计算后的 CheckSum 和 Block 创建时不一致，则说明 Block 已损坏。 \n 客户端会读取其他 DataNode 的 Block，再次检测。 \n DataNode 在文件创建后会周期性检测 CheckSum。 \n \n 常见的校验算法有：CRC(32)，MD5(128)，SHA1(160)。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"November 10, 2021 20:54",createTimeStamp:163654888e4,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:4},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hadoop-03-MapReduce",frontmatter:{title:"Hadoop-03-MapReduce",categories:["bigdata"],tags:["hadoop"],author:"causes",summary:"MapReduce 起步 概述 概述和优缺点 MapReduce，一个分布式运算程序的编程框架，基于 Hadoop。它将用户的业务代码和自身的默认组件整合，形成一个完整的分布式程序。 MapReduce 的优点： 易于编程：实现一些接口即可完成一个分布式程序。; 扩展性好：可以简单地增加机器来提高计算资源。; 高容错：一台机器挂掉，它的计算任务会自动转移到另",meta:[{property:"og:url",content:"/bigdata/Hadoop/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hadoop-03-MapReduce"},{property:"og:description",content:"MapReduce 起步 概述 概述和优缺点 MapReduce，一个分布式运算程序的编程框架，基于 Hadoop。它将用户的业务代码和自身的默认组件整合，形成一个完整的分布式程序。 MapReduce 的优点： 易于编程：实现一些接口即可完成一个分布式程序。; 扩展性好：可以简单地增加机器来提高计算资源。; 高容错：一台机器挂掉，它的计算任务会自动转移到另"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hadoop"}]},regularPath:"/bigdata/Hadoop/part3.html",relativePath:"bigdata/Hadoop/part3.md",key:"v-0958eb04",path:"/bigdata/Hadoop/part3/",headers:[{level:2,title:"MapReduce 起步",slug:"mapreduce-起步"},{level:3,title:"概述",slug:"概述"},{level:3,title:"常用数据序列化类型",slug:"常用数据序列化类型"},{level:3,title:"MapReduce 编程规范",slug:"mapreduce-编程规范"},{level:3,title:"环境准备",slug:"环境准备"},{level:3,title:"案例",slug:"案例"},{level:2,title:"Hadoop 序列化",slug:"hadoop-序列化"},{level:2,title:"MapReduce 原理",slug:"mapreduce-原理"},{level:3,title:"InputFormat",slug:"inputformat"},{level:3,title:"MapReduce",slug:"mapreduce"},{level:3,title:"Shuffle",slug:"shuffle"},{level:3,title:"OutputFormat",slug:"outputformat"},{level:2,title:"Hadoop 数据压缩",slug:"hadoop-数据压缩"}],readingTime:{minutes:22.14,words:6641},content:' MapReduce 起步 \n 概述 \n 概述和优缺点 \n MapReduce，一个分布式运算程序的编程框架，基于 Hadoop。它将用户的业务代码和自身的默认组件整合，形成一个完整的分布式程序。 \n MapReduce 的优点： \n \n 易于编程：实现一些接口即可完成一个分布式程序。 \n 扩展性好：可以简单地增加机器来提高计算资源。 \n 高容错：一台机器挂掉，它的计算任务会自动转移到另一个节点上。 \n 海量数据：PB 以上的海量数据进行离线处理。 \n \n 缺点： \n \n 不擅长实时计算：无法在毫秒或者秒内返回结果。 \n 不擅长流式计算：流式计算的输入数据是动态的，而 MapReduce 处理的是静态的。 \n 不擅长 DAG（有向无环图）计算：也就是说多个计算之间存在依赖关系的时候，MapReduce 计算效率低，因为中间结果全部会写入到磁盘，产生大量磁盘 IO，导致性能低下。 \n \n MapReduce 的核心思想 \n MapReduce 类似分治算法的思想，分为两个阶段： \n \n Map 阶段：对应 MapTask 任务，完全并行执行，互不相关。 \n Reduce 阶段：对应 ReduceTask，每一个 ReduceTask 之间互不相关，完全并行执行，但是每一个 ReduceTask，依赖 MapTask 的结果，它们会将 MapTask 的结果拉取到 ReduceTask 中。 \n \n MapReduce 变成模型中，有两个阶段（Map、Reduce）而且只有这两个阶段，假如一个业务逻辑十分复杂，那么就只能多个 MapReduce 串行执行。 \n MapReduce 进程 \n 完整的 MR（MapReduce）程序在分布式运行时有三个进程实例： \n \n MrAppMaster：管理整个程序运行的老大，负责过程调度和状态协调。 \n MapTask：负责 Map 阶段的整个数据处理流程。 \n ReduceTask：负责 Reduce 阶段的整个数据处理流程。 \n 常用数据序列化类型 \n \n \n \n Java 类型 \n Hadoop Writable 类型 \n \n \n \n \n Boolean \n BooleanWritable \n \n \n Byte \n ByteWritable \n \n \n Int \n IntWritable \n \n \n Float \n FloatWritable \n \n \n Long \n LongWritable \n \n \n Double \n DoubleWritable \n \n \n String \n Text \n \n \n Map \n MapWritable \n \n \n Array \n ArrayWritable \n \n \n Null \n NullWritable \n \n \n \n 可以看到，除了 String 之外，Hadoop 的类型全都是 Java 类型 + Writable，非常容易记忆。 \n MapReduce 编程规范 \n \n \n Mapper 阶段： \n \n 用户自定义 Mapper，需要继承父类。 \n Mapper 输入数据为 KV 形式。 \n Mapper 中的业务逻辑写在  map()  方法中。 \n Mapper 的输出数据为 KV 键值对，KV 类型可自定义。 \n map()  方法（MapTask 进程）对每一个 KV 调用一次。 \n \n \n \n Reduce 阶段 \n \n 用户自定义 Reduce，需要继承父类。 \n Reducer 的输入数据类型对应 Mapper 的输出数据类型，也就是 KV 键值对。 \n Reduce 中的业务逻辑写在  reduce()  方法中。 \n reduce()  方法（ReduceTask 进程）对每一组的 KV 调用一次。每一组 KV 指的是 K 相同但是 V 不相同的数据，也就是说相同 K 的数据会分到一组。 \n \n \n \n Driver 阶段： \n 相当于 YARN 集群的客户端，用于提交我们整个程序到 YARN 集群，提交的是封装了 MapReduce 程序相关运行参数的 job 对象。 \n 环境准备 \n 要想在 windows 连接 Hadoop 集群实现 MapReduce 程序，需要进行环境准备： \n \n \n 创建 maven 工程： \n < dependencies > \n     < dependency > \n         < groupId > org.apache.hadoop </ groupId > \n         < artifactId > hadoop-client </ artifactId > \n         < version > 3.1.3 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > junit </ groupId > \n         < artifactId > junit </ artifactId > \n         < version > 4.12 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.slf4j </ groupId > \n         < artifactId > slf4j-log4j12 </ artifactId > \n         < version > 1.7.30 </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n \n 在 resources 目录下填写  log4j.properties ： \n log4j.rootLogger = INFO, stdout \n log4j.appender.stdout = org.apache.log4j.ConsoleAppender \n log4j.appender.stdout.layout = org.apache.log4j.PatternLayout \n log4j.appender.stdout.layout.ConversionPattern = %d %p [%c] - %m%n \n log4j.appender.logfile = org.apache.log4j.FileAppender \n log4j.appender.logfile.File = target/spring.log \n log4j.appender.logfile.layout = org.apache.log4j.PatternLayout \n log4j.appender.logfile.layout.ConversionPattern = %d %p [%c] - %m%n \n \n 1 2 3 4 5 6 7 8 \n \n maven 打为 jar 包插件： \n < build > \n     < plugins > \n         < plugin > \n             < artifactId > maven-compiler-plugin </ artifactId > \n             < version > 3.6.1 </ version > \n             < configuration > \n                 < source > 1.8 </ source > \n                 < target > 1.8 </ target > \n             </ configuration > \n         </ plugin > \n         < plugin > \n             < artifactId > maven-assembly-plugin </ artifactId > \n             < configuration > \n                 < descriptorRefs > \n                     < descriptorRef > jar-with-dependencies </ descriptorRef > \n                 </ descriptorRefs > \n             </ configuration > \n             < executions > \n                 < execution > \n                     < id > make-assembly </ id > \n                     < phase > package </ phase > \n                     < goals > \n                         < goal > single </ goal > \n                     </ goals > \n                 </ execution > \n             </ executions > \n         </ plugin > \n     </ plugins > \n </ build > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n 案例 \n \n \n 首先进行一次 WordCount 作为开始，统计各个单词出现的次数： \n atguigu atguigu\nss ss\ncls cls\njiao\nbanzhang\nxue\nhadoop\n \n 1 2 3 4 5 6 7 \n \n 按照 MapReduce 的编程规范，分别编写 Mapper、Reducer、Driver： \n package   com . causes . mapreduce . wordcount ; \n\n import   org . apache . hadoop . io . IntWritable ; \n import   org . apache . hadoop . io . LongWritable ; \n import   org . apache . hadoop . io . Text ; \n import   org . apache . hadoop . mapreduce . Mapper ; \n\n import   java . io . IOException ; \n\n /**\n* wordcount 程序的 map 阶段，四个泛型分别为：输入 K、输入 V、输出 K、输出 V\n*/ \n public   class   WordCountMapper   extends   Mapper < LongWritable ,   Text ,   Text ,   IntWritable >   { \n\n   // 因为 mapreduce 程序中，map 操作会对每一个 kv 键值对调用一次 map 方法，所以要将变量提取到类中：避免重复 new 对象，减少空间浪费。 \n   Text  k  =   new   Text ( ) ; \n   IntWritable  v  =   new   IntWritable ( ) ; \n\n   /**\n  * mapreduce 阶段中，MapTask 的 map 方法，对每一个 kv 键值对都会调用一次。\n  *\n  * @param key 输入的 key\n  * @param value 输入的 value\n  * @param context 输出的值，其中 context 也必须为 kv 的形式\n  */ \n   @Override \n   protected   void   map ( LongWritable  key ,   Text  value ,   Mapper < LongWritable ,   Text ,   Text ,   IntWritable > . Context context )   throws   IOException ,   InterruptedException   { \n     // 1. 获取一行的数据 \n     String  line  =  value . toString ( ) ; \n\n     // 2. 将一行数据切割为单词，将单词输出 \n     String [ ]  words  =  line . split ( " " ) ; \n\n     // 3. 输出，这里的输出不是真正的输出，而是转向 mapreduce 的下一个阶段 \n     for   ( String  word  :  words )   { \n      k . set ( word ) ; \n      context . write ( k , v ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package   com . causes . mapreduce . wordcount ; \n\n import   org . apache . hadoop . io . IntWritable ; \n import   org . apache . hadoop . io . Text ; \n import   org . apache . hadoop . mapreduce . Reducer ; \n\n import   java . io . IOException ; \n import   java . util . Collections ; \n\n /**\n* mapreduce 的 reduce 阶段，四个泛型为：map 的输出 k，map 的输出 v，输出 k，输出 v\n*/ \n public   class   WordCountReducer   extends   Reducer < Text ,   IntWritable ,   Text ,   IntWritable >   { \n\n   IntWritable  v  =   new   IntWritable ( ) ; \n\n   /**\n  * reduce 阶段，其中 reduce 根据分组处理数据，map 阶段输出的值，相同 key 为一组。\n  *\n  * @param key map 的输出 key\n  * @param values  map 的输出 values，复数，是因为相同 key 会分到一组中，所以这里才是多个 value\n  * @param context 输出\n  */ \n   @Override \n   protected   void   reduce ( Text  key ,   Iterable < IntWritable >  values ,   Reducer < Text ,   IntWritable ,   Text ,   IntWritable > . Context context )   throws   IOException ,   InterruptedException   { \n     int  count  =   Collections . singletonList ( values ) . size ( ) ; \n    v . set ( count ) ; \n    context . write ( key , v ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package   com . causes . mapreduce . wordcount ; \n\n import   org . apache . hadoop . conf . Configuration ; \n import   org . apache . hadoop . fs . Path ; \n import   org . apache . hadoop . io . IntWritable ; \n import   org . apache . hadoop . io . Text ; \n import   org . apache . hadoop . mapreduce . Job ; \n import   org . apache . hadoop . mapreduce . lib . input . FileInputFormat ; \n import   org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; \n\n import   java . io . IOException ; \n\n /**\n* 有了 Map 和 Reduce，需要将它们关联起来，并且需要和集群关联起来，Driver 顾名思义，驱动\n*/ \n public   class   WordCountDriver   { \n   public   static   void   main ( String [ ]  args )   throws   IOException ,   InterruptedException ,   ClassNotFoundException   { \n     // 1. 获取配置信息和获取 job 对象 \n     Configuration  conf  =   new   Configuration ( ) ; \n     Job  job  =   Job . getInstance ( conf ) ; \n\n     // 2. 关联本 driver 程序的 jar \n    job . setJarByClass ( WordCountDriver . class ) ; \n\n     // 3. 关联 mapper 和 reducer 的 jar \n    job . setMapperClass ( WordCountMapper . class ) ; \n    job . setReducerClass ( WordCountReducer . class ) ; \n\n     // 4. 设置 mapper 输出类型 \n    job . setMapOutputKeyClass ( Text . class ) ; \n    job . setMapOutputValueClass ( IntWritable . class ) ; \n\n     // 5. 设置最终输出类型 \n    job . setOutputKeyClass ( Text . class ) ; \n    job . setOutputValueClass ( IntWritable . class ) ; \n\n     // 6. 设置输出和输出路径 \n     FileInputFormat . setInputPaths ( job ,   new   Path ( args [ 0 ] ) ) ; \n     FileOutputFormat . setOutputPath ( job ,   new   Path ( args [ 1 ] ) ) ; \n\n     // 7. 提交 job \n     boolean  result  =  job . waitForCompletion ( true ) ; \n     System . exit ( result  ?   0   :   1 ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \n \n 启动集群，测试。 \n Hadoop 序列化 \n 什么是序列化 \n 序列化就是将内存中的对象转换为字节序列的过程，目的是方便存储到磁盘中（序列化）或者方便网络传输。 \n 反序列化就是将磁盘中的字节序列转换为内存中的对象的过程。 \n 为什么不使用 Java 的序列化 \n Java 的序列化是一个比较重的框架（Serializable），它不仅有对象的一些信息，而且还自带对象的各种信息（校验头、继承体系），这些信息虽然可以保证数据的安全性，但是不便于在网络中高效传输。所以 Hadoop 自己开发了一套序列化机制（Writable）。 \n Hadoop 序列化特点： \n \n 快速：读写数据的额外开销小。 \n 紧凑：高效使用存储空间。 \n 互操作：支持多语言的互动。 \n \n 自定义 Bean 对象实现序列化接口 \n /**\n * 1. 注意，必须要实现 writable 接口\n * 2. 反序列化的时候需要调用空参构造，所以需要一个空参构造\n * 3. 重写序列化方法\n * 4. 如果要将当前 Bean 对象作为 K 传递，那么必须实现排序方法，因为 Shuffle 阶段需要根据 K 排序\n */ \n @Data \n public   class   FlowBean   implements   Writable ,   Comparable < FlowBean >   { \n\n   private   Long  upFlow ; \n   private   Long  downFlow ; \n   private   Long  sumFlow ; \n\n   /**\n   * 注意，写入（序列化）的顺序和读取的顺序要保持一致\n   */ \n   @Override \n   public   void   write ( DataOutput  out )   throws   IOException   { \n    out . writeLong ( upFlow ) ; \n    out . writeLong ( downFlow ) ; \n    out . writeLong ( sumFlow ) ; \n   } \n\n   /**\n   * 注意，反序列化的顺序要和序列化的顺序保持一致，因为不是强类型的赋值，所以这一点要格外注意\n   */ \n   @Override \n   public   void   readFields ( DataInput  in )   throws   IOException   { \n    upFlow  =  in . readLong ( ) ; \n    downFlow  =  in . readLong ( ) ; \n    sumFlow  =  in . readLong ( ) ; \n   } \n\n\n   /**\n   * 如果要将当前 Bean 对象作为 K 传递，那么必须要实现排序，因为 Shuffle 阶段要将 K 进行排序。\n   */ \n   @Override \n   public   int   compareTo ( FlowBean  o )   { \n     return   this . sumFlow  >  o . getSumFlow ( )   ?   - 1   :   1 ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #  MapReduce 原理 \n \n 从上图可以看到，MapReduce 在大体上要经过三个阶段： \n \n MapTask \n Shuffle \n ReduceTask \n \n 我们将要按照顺序，从 Input 开始，一直到 Output。 \n InputFormat \n 数据切片和 MapTask 的并行度决定机制 \n MapTask 的并行度决定了 Map 阶段的任务处理的并发度，进而影响到整个 Job 的处理速度。 \n 但是问题在于，这个 MapTask 的并行度是怎么来决定的？因为并行度并不是越多越好，一个 1K 的数据量启动 8 个 MapTask 不仅不会提升性能，反而会影响集群性能。 \n MapTask 的并行度其实是受以下因素影响： \n \n \n 数据块： \n 数据块（Block）是 HDFS 的存储数据的单位，其实就是在物理上，将数据分为一块一块的，叫做数据块（Block）。 \n \n \n 数据切片： \n 数据切片是 MapReduce 程序计算时输入数据的单位，一个数据切片会启动一个 MapTask，所以 MapTask 的个数取决于数据切片的个数。 \n 数据切片和数据块不同，数据切片只是在逻辑上将输入进行分片，在物理上还是完整的一块。但是在默认情况下，切片的大小就等同于数据块的大小。 \n 举个例子，现在假设一个文件数据为 300M，假如我们将数据块大小设置为 100M（也就是说在逻辑上我们将 100M 划分为一个数据块），那么在默认情况下，分片大小等于数据块大小，这块数据在物理和逻辑上都将被分为三片，分别为 0-100M、100-200M、200-300M。 \n 假设我们将数据块的大小设置为 128M，那么对于这 300M 的数据，将分为三片，分别为：0-128M、128-256M、256-300M。 \n \n \n 总结： \n \n 一个 Job 的 Map 阶段并行度取决于客户端在提交 Job 时的切片数量决定。 \n 每一个 Split 切片都会分配一个 MapTask 并行处理。 \n 在默认情况下，数据切片大小和数据块大小相同，但是也可以自己设置。 \n 切片时不会去考虑数据集整体，而是对每一个文件单独进行切片。比如上传了两个文件，对每个文件都会做单独的切片处理而不是两个加到一起去考虑。 \n \n InputFormat 的体系 \n \n 可以看到，InputFormat 是一个接口，它的下面有实现类  FileInputFormat ， TextInputFormat 、 CombineFileInputFormat  等，我们将使用这几种切片类来进行举例。 \n FileInputFormat \n 这是一个抽象类，顾名思义，FileInputFormat 是根据文件来进行切片的，切片的详细流程都在  getSplits  这个方法中： \n \n \n 程序首先找到存储数据的目录。 \n \n \n 开始遍历处理目录下的所有文件。 \n 遍历第一个文件： \n \n 获取文件大小： fs.sizeOf() \n 计算切片大小： computeSplitSize(blockSize, minSize, maxSize); \n 默认情况下，切片大小 = blockSize。 \n 开始切片，注意每次切片时，都要注意当切片是不是大于块大小的 1.1 倍，假如不超过 1.1 倍则划分为一个切片。 \n 将切片信息写入到一个切片规划文件中。 \n \n 遍历第二个文件，如上…… \n \n \n 注意： \n \n InputSplit  仅仅记录和切片的元数据信息，例如长度、起始位置、所在的节点列表等。 \n 提交切片规划文件到 YARN 上，YARN 上的 MrAppMaster 就可以根据切片规划文件计算开启 MapTask 的个数。 \n \n 总结： \n \n FileInputFormat 仅仅是简单地按照文件的内容长度进行切片。 \n 切片大小默认为 Block 的大小。 \n 切片时不考虑数据的整体，只考虑每一个文件，根据每一个文件进行单独切片。 \n \n 案例：输入两个文件： file1.txt - 320M ， file2.txt - 10M 。经过切片机制运算之后，得到如下信息： \n file1.txt.split1 - 0~128\nfile1.txt.split2 - 128~256\nfile1.txt.split3 - 256~320\n\nfile2.txt.split1 - 0~10\n \n TextInputFormat \n FileInputFormat 是一个抽象类，它常见的实现类有  TextInputFormat 、 KeyValueTextInputFormat 、 NLineInputFormat 、 CombineTextInputFormat 、自定义的 InputFormat 等。 \n TextInputFormat 是默认的 FileInputFormat 的实现类，它的实现方式就是按行去读取每一条记录，key 是当前行在文件中的起始字节偏移量，LongWritable 类型；value 是该行的值（没有回车、换行），Text 类型。 \n 例如： \n Rich learning form\nIntelligent learning engine\nLearning more convenient\nFrom the real demand for more close to the enterprise\n \n 1 2 3 4 那么按照 TextInputFormat 的读取方式，它是这样的： \n (0,Rich learning form)\n(20,Intelligent learning engine)\n(49,Learning more convenient)\n(74,From the real demand for more close to the enterprise)\n \n 1 2 3 4 CombineTextInputFormat \n 默认的 TextInputFormat 是针对文件划分，不管文件多小，都会是一个单独的切片，都会交给一个 MapTask。这样做是优缺点的，如果有大量的小文件，那么就会产生大量的 MapTask，大量的 MapTask 占用大量的内存，这样完全够不上成本。 \n 针对这种处理十分低下的切片机制，出现了  CombineTextInputFormat ，它适用于小文件过多的场景，可以将多个小文件从逻辑上规划到一个切片中，这样一来，多个小文件就可以规划到一个 MapTask 来处理，效率增加了。 \n 可以使用  CombineTextInputFormat.setMaxInputSplitSize(job, 切片大小);  来设置虚拟存储切片的最大值。 \n MapReduce \n 一个文件经过多个切片，每一个切片都会形成一个 MapTask，而每一个 MapTask 都会进行之前的 Map 程序，也就是说，直到 Reduce 阶段之前，Map 应当是多个并行的，这里为了方便查看只列出了一个 MapTask 的内容。 \n \n 着重说一下环形缓冲区的内容，环形缓冲区同样是在 Map 阶段的，也就是说每一个 MapTask 都会有一个环形缓冲区，默认大小为 100M，可以使用  mapreduce.task.io.sort.mb  调节，但是注意每一个分片默认就是 128M，不需要设置太大。 \n 在 Mapper 类使用  write()  方法之后，其实不会立刻到达 Reduce，而是会首先到达一块叫做环形缓冲区的内存区域。 \n \n 环形缓冲区分为三块区域： \n \n 空闲区 \n 数据区 \n 索引区 \n \n 初始位置为上图白色的部分，叫做赤道。初始状态下，索引和数据均为 0，所有空间均为空闲状态。环形缓冲区开始写入的时候，数据在赤道右边写入，索引在赤道左边写入（索引每次申请 4KB）。 \n 在数据大小写到了 80%（参数  mapreduce.map.sort.spill.percent  设置）的时候，会同时进行以下两个动作： \n \n 对已经写入的数据进行排序，排序好之后将索引和数据全都写到磁盘上去，形成一个文件（比如  sort00 ）。这个文件是带有分区性质的文件，并且经过了排序操作，分区间的数据是有序的。 \n 在空闲的 20% 的空间里，重新算出一个新的赤道，然后在新赤道的右边写数据，左边写索引。注意，当空闲的 20% 已经写满之后，假如 80% 的数据还没有写完成，那么只能等待，等到空间腾出来之后继续写。 \n \n 环形缓冲区不需要申请新的内存空间，始终用的都是这个，避免了 Full GC 的问题，也避免了频繁申请内存的问题。 \n 环形缓冲区过后，就是将每一个分区间，刚才使用环形缓冲区进行排序的文件合并。 \n 合并之后有一步操作是 combiner 合并，这个步骤是可选的，combiner 这个步骤并不是排序，而是类似于 reduce，只不过在这个阶段属于预处理阶段。 \n 我们都知道，在 map 阶段之后就会进入 reduce，map 阶段有很多 MapTask，但是 reduce 阶段的 ReduceTask 要远远少于 MapTask。 \n 也就是说，在 reduce 过程中，大量的数据都会被拉取到同一个服务器进行处理，假如数据过大，就会对网络和服务器造成影响，进而可能会导致各种各样的问题。 \n 假如我们可以在 Map 阶段就对数据进行一定的处理，如果提前做出合并，那么就相当于减轻 reduce 阶段的压力。 \n 但是注意，并不是所有的数据操作都可以使用 combiner 的，比如相加的操作可以使用，但是求平均值的操作就不行。所以 combiner 操作是可选项。 \n Shuffle \n Shuffle \n 在 map 方法之后，reduce 之前的数据处理过程称为 Shuffle，也就是从环形缓冲区到 Combiner 的位置。 \n \n Partition \n Partition，分区。如果我们需要根据不同的条件，将结果分到不同的文件中，那么这个过程就叫做分区。 \n 默认的分区是按照  hashCode()  来进行的分区，也就是： \n public   class   HashPartitioner < K ,   V >   extends   Partitioner < K ,   V >   { \n\n   /** Use {@link Object#hashCode()} to partition. */ \n   public   int   getPartition ( K  key ,   V  value ,   int  numReduceTasks )   { \n     return   ( key . hashCode ( )   &   Integer . MAX_VALUE )   %  numReduceTasks ; \n   } \n } \n \n 1 2 3 4 5 6 7 假如我们需要自己手动定义一个 Partitioner，需要继承 Partitioner，重写  getPartition() 。 \n 举例：根据手机号码的归属地，将相同省份的手机号码放到一个文件中，按照省份划分不同的文件。 \n \n \n 自定义分区器，重写方法： \n public   class   CustomPartitioner   extends   Partitioner < Text ,   FlowBean >   { \n\n   /**\n  * 控制分区逻辑，返回值即分区\n  */ \n   @Override \n   public   int   getPartition ( Text  text ,   FlowBean  flowBean ,   int  numPartitions )   { \n     return   0 ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 \n \n 在 Job 驱动中，设置自定义的 partitioner \n job . setPartitionerClass ( CustomPartitioner . class ) ; \n \n 1 \n \n 根据 partitioner 设置对应的 reduceTask \n job . setNumReduceTasks ( num ) ; \n \n 1 \n \n 之前在讲解 MapTask 数量的影响因素时，曾经说到文件的切片数量是最终 MapTask 的个数。 \n ReduceTask 也有它的影响因素，就是参数  job.setNumReduceTasks(num) ，比起 MapTask 来说比较好理解，但是它和分区息息相关，有如下注意点： \n \n 如果  ReduceTask 数量 > 分区数量 ，则会产生几个空的输出文件。 \n 如果  1 < ReduceTask < 分区数量 ，则有一部分分区数据无处安放，就会抛出异常。 \n 如果  ReduceTask = 1 ，那么无论分区数量为多少，都会放到一个文件中。 \n 分区号必须从 0 开始累加，逐渐递增。 \n \n WritableComparable \n WritableComparable，排序，这是 MapReduce 中最重要的操作之一。 \n 在执行 MapTask 和 ReduceTask 的过程中均会对数据进行排序，而且是按照 key 进行排序。所有的数据都会被排序，无论在业务上是否需要，这是 Hadoop 的默认行为。 \n \n \n MapTask： \n 在环形缓冲区的内容到达阈值（80%）并且溢写到磁盘之前，对缓冲区的数据进行一次快速排序。 \n 在环形缓冲区中所有数据处理完毕之后，会对磁盘上的所有文件进行一次归并排序。 \n \n \n ReduceTask： \n 在从 MapTask 拷贝数据文件到内存，假如文件超过一定阈值则溢写到磁盘上。 \n 如果磁盘上的文件到达一定阈值，则进行一次归并排序成为一个更大的文件。 \n 在所有数据拷贝完成之后，ReduceTask 会对内存和磁盘上的所有数据进行一次归并排序。 \n \n \n 自定义排序：MapReduce 的 Key 必须为可排序字段，当 Bean 对象作为 Key 值传输的时候，那么就要重写  compareTo  方法，这样即可实现排序： \n /**\n * 1. 注意，必须要实现 writable 接口\n * 2. 反序列化的时候需要调用空参构造，所以需要一个空参构造\n * 3. 重写序列化方法\n * 4. 如果要将当前 Bean 对象作为 K 传递，那么必须实现排序方法，因为 Shuffle 阶段需要根据 K 排序\n */ \n @Data \n public   class   FlowBean   implements   Writable ,   Comparable < FlowBean >   { \n\n   private   Long  upFlow ; \n   private   Long  downFlow ; \n   private   Long  sumFlow ; \n\n   /**\n   * 注意，写入（序列化）的顺序和读取的顺序要保持一致\n   */ \n   @Override \n   public   void   write ( DataOutput  out )   throws   IOException   { \n    out . writeLong ( upFlow ) ; \n    out . writeLong ( downFlow ) ; \n    out . writeLong ( sumFlow ) ; \n   } \n\n   /**\n   * 注意，反序列化的顺序要和序列化的顺序保持一致，因为不是强类型的赋值，所以这一点要格外注意\n   */ \n   @Override \n   public   void   readFields ( DataInput  in )   throws   IOException   { \n    upFlow  =  in . readLong ( ) ; \n    downFlow  =  in . readLong ( ) ; \n    sumFlow  =  in . readLong ( ) ; \n   } \n\n\n   /**\n   * 如果要将当前 Bean 对象作为 K 传递，那么必须要实现排序，因为 Shuffle 阶段要将 K 进行排序。\n   */ \n   @Override \n   public   int   compareTo ( FlowBean  o )   { \n     return   this . sumFlow  >  o . getSumFlow ( )   ?   - 1   :   1 ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 在 Hadoop 中，根据不同排序形成的最终效果，将排序分为以下几类: \n \n 部分排序：文件内有序，MapReduce 根据输入记录的键对数据集进行排序操作，保证 每个文件 内部有序。 \n 全排序：输出结果仅有一个文件，且文件内有序。实现方式就是只使用一个 ReduceTask，不推荐这种做法，因为完全丧失了 MapReduce 的并行架构。 \n 辅助排序：也叫做分组排序，组内有序，在 Reduce 端对 Key 进行分组，通常在接受 Bean 对象时，按照 Bean 对象的某个字段或者某几个字段进行分组，组内有序。 \n 二次排序：自定义排序过程中，假如  compareTo  判断条件为两个就叫做二次排序。 \n \n Combiner \n 其实之前在讲 MapTask 的环形缓冲区后，提了一次 Combiner。 \n 简单来说，Combiner 和 Reduce 的功能差不多，但是它们之前是有区别的： \n \n 严格来讲，Combiner 在 MR 代码层面上不属于 Mapper 类也不属于 Reducer 类，而是另一个组件。 \n Combiner 的父类其实就是 Reducer，虽然代码上是分别实现的，但其实用到的还是 Reducer，这样做的好处是可以让你自由选择是否实现。 \n Combiner 运行在 MapTask 节点上，Reducer 运行在 ReduceTask 上。 \n \n Combiner 的主要意义就是用于每一个 MapTask 的汇总，用于减少网络传输，减少 ReduceTask 的压力。 \n 注意，不是所有的业务都适合使用 Combiner 来实现的，比如算一个平均值的例子，每个 MapTask 先算出各自的平均值，和最后预料的肯定会有差异。所以要十分清楚业务是否可以使用 Combiner。 \n 自定义 Combiner： \n \n \n 自定义一个 Combiner，继承 Reducer，重写 Reduce 方法。 \n public   class   CustomCombiner   extends   Reducer < Text ,   IntWritable ,   Text ,   IntWritable >   { \n\n   private   IntWritable  out  =   new   IntWritable ( ) ; \n\n   /**\n  * 相加的操作肯定可以首先利用 Combiner 来实现\n  */ \n   @Override \n   protected   void   reduce ( Text  key ,   Iterable < IntWritable >  values ,   Reducer < Text ,   IntWritable ,   Text ,   IntWritable > . Context context )   throws   IOException ,   InterruptedException   { \n     int  sum  =   0 ; \n     for   ( IntWritable  value  :  values )   { \n      sum  +=  value . get ( ) ; \n     } \n    out . set ( sum ) ; \n    context . write ( key ,  out ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n \n 在 Job 中设置。 \n job . setCombinerClass ( CustomCombiner . class ) ; \n \n 1 \n OutputFormat \n 经过了 InputFormat、Map、Shuffle、Reduce 之后，文件应该输出了。文件输出就是利用了 OutputFormat，默认情况下使用的是  TextOutputFormat 。 \n \n 这个输出默认情况下还好，但是一旦我们想要输出到多种数据源中（比如 MySQL、HBase、ElasticSearch），这个就不太好用了，需要自定义 OutputFormat。 \n 自定义 OutputFormat： \n \n \n 继承  FileOutputFormat \n public   class   CustomOutputFormat   extends   FileOutputFormat < Text ,   NullWritable >   { \n   @Override \n   public   RecordWriter < Text ,   NullWritable >   getRecordWriter ( TaskAttemptContext  job )   throws   IOException ,   InterruptedException   { \n     // 自定义一个新 RecordWriter 的返回 \n     OutputWriter  writer  =   new   OutputWriter ( job ) ; \n     return  writer ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 \n \n 改写  RecordWriter \n class   OutputWriter   extends   RecordWriter < Text ,   NullWritable >   { \n\n   FSDataOutputStream  outPutStream ; \n\n   public   OutputWriter ( TaskAttemptContext  job )   { \n     try   { \n       // 获取文件系统 \n       FileSystem  fs  =   FileSystem . get ( job . getConfiguration ( ) ) ; \n       // 创建输出目录 \n      outPutStream  =  fs . create ( new   Path ( "d:/tmp/log.log" ) ) ; \n     }   catch   ( IOException  e )   { \n      e . printStackTrace ( ) ; \n     } \n   } \n\n   @Override \n   public   void   write ( Text  key ,   NullWritable  value )   throws   IOException ,   InterruptedException   { \n     // 输出到对应目录 \n    outPutStream . writeBytes ( key . toString ( ) ) ; \n   } \n\n   @Override \n   public   void   close ( TaskAttemptContext  context )   throws   IOException ,   InterruptedException   { \n     // 关闭流 \n     IOUtils . closeStream ( outPutStream ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \n \n Tips \n TODO：Join \n Hadoop 数据压缩 \n \n \n 压缩的优劣： \n 压缩可以减少磁盘 IO，减少磁盘存储空间，但缺点是增加 CPU 的开销。 \n \n \n 压缩的原则： \n 对于运算密集型的 Job 少用压缩，对于 IO 密集型的 Job 多用压缩。 \n \n \n MR 支持的压缩编码 \n \n \n \n 压缩格式 \n 是否为 Hadoop 自带 \n 算法 \n 文件名扩展 \n 是否可切片 \n 切换压缩格式后程序是否需要修改 \n \n \n \n \n DEFAULT \n 是，可直接使用 \n DEFAULT \n .default \n 否 \n 无需修改 \n \n \n GZip \n 是，可直接使用 \n DEFAULT \n .gz \n 否 \n 无需修改 \n \n \n bzip2 \n 是，可直接使用 \n bzip2 \n .bz2 \n 是 \n 无需修改 \n \n \n LZO \n 否，需要额外安装 \n LZO \n .lzo \n 是 \n 需要修改，需要建立索引，指定输入格式 \n \n \n Snappy \n 是，可直接使用 \n Snappy \n .snappy \n 否 \n 无需修改 \n \n \n \n 压缩性能 \n \n \n \n 压缩算法 \n 原始文件 \n 压缩文件 \n 压缩速度 \n 解压速度 \n \n \n \n \n gzip \n 8.3G \n 1.8G \n 17.5MB/s \n 58MB/s \n \n \n bzip2 \n 8.3G \n 1.1G \n 2.4MB/s \n 9.5MB/s \n \n \n LZO \n 8.3G \n 2.9G \n 49.3MB/s \n 74.6MB/s \n \n \n \n 压缩位置 \n 压缩可以在 MapReduce 作用的任意阶段启用。 \n \n 编码器和解码器 \n 为了支持多种压缩和解压缩算法，Hadoop 引入和编码器和解码器。 \n \n \n \n 压缩格式 \n 编码器/解码器 \n \n \n \n \n DEFLATE \n org.apache.hadoop.io.compress.DefaultCodec \n \n \n gzip \n org.apache.hadoop.io.compress.GzipCodec \n \n \n bzip2 \n org.apache.hadoop.io.compress.BZip2Codec \n \n \n LZO \n com.hadoop.compression.lzo.LzopCodec \n \n \n Snappy \n org.apache.hadoop.io.compress.SnappyCodec \n \n \n \n Hadoop 启用压缩 \n \n \n \n 参数 \n 默认值 \n 阶段 \n 建议 \n \n \n \n \n io.compression.codecs（在core-site.xml中配置） \n 无，这个需要在命令行输入hadoop checknative查看 \n 输入压缩 \n Hadoop使用文件扩展名判断是否支持某种编解码器 \n \n \n mapreduce.map.output.compress（在mapred-site.xml中配置） \n false \n mapper输出 \n 这个参数设为true启用压缩 \n \n \n mapreduce.map.output.compress.codec（在mapred-site.xml中配置） \n org.apache.hadoop.io.compress.DefaultCodec \n mapper输出 \n 企业多使用LZO或Snappy编解码器在此阶段压缩数据 \n \n \n mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置） \n false \n reducer输出 \n 这个参数设为true启用压缩 \n \n \n mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置） \n org.apache.hadoop.io.compress.DefaultCodec \n reducer输出 \n 使用标准工具或者编解码器，如gzip和bzip2 \n \n \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"December 29, 2021 17:23",createTimeStamp:1640769813e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hadoop-04-Yarn",frontmatter:{title:"Hadoop-04-Yarn",categories:["bigdata"],tags:["hadoop"],author:"causes",summary:"Yarn 概述 Yarn 概述 Yet Another Resource Negotiator，另一种资源调度器，简称 Yarn。 在 Hadoop 中，之前的 MapReduce 组件是进行数据的计算，但是有个问题：数据的计算必须要使用服务器的资源，那么服务器的资源是由什么来进行管理的呢？ 在 Hadoop1.x 时代，资源的调度和数据的计算全都是由 Ma",meta:[{property:"og:url",content:"/bigdata/Hadoop/part4.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hadoop-04-Yarn"},{property:"og:description",content:"Yarn 概述 Yarn 概述 Yet Another Resource Negotiator，另一种资源调度器，简称 Yarn。 在 Hadoop 中，之前的 MapReduce 组件是进行数据的计算，但是有个问题：数据的计算必须要使用服务器的资源，那么服务器的资源是由什么来进行管理的呢？ 在 Hadoop1.x 时代，资源的调度和数据的计算全都是由 Ma"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hadoop"}]},regularPath:"/bigdata/Hadoop/part4.html",relativePath:"bigdata/Hadoop/part4.md",key:"v-0495e288",path:"/bigdata/Hadoop/part4/",headers:[{level:2,title:"Yarn 概述",slug:"yarn-概述"},{level:2,title:"Yarn 调度器和调度算法",slug:"yarn-调度器和调度算法"}],readingTime:{minutes:4.53,words:1360},content:" Yarn 概述 \n Yarn 概述 \n Yet Another Resource Negotiator，另一种资源调度器，简称 Yarn。 \n 在 Hadoop 中，之前的 MapReduce 组件是进行数据的计算，但是有个问题：数据的计算必须要使用服务器的资源，那么服务器的资源是由什么来进行管理的呢？ \n 在 Hadoop1.x 时代，资源的调度和数据的计算全都是由 MapReduce 来进行管理的，但是在 Hadoop2.x 时代，将资源的调度从 MapReduce 中分离，形成了 Yarn 这一单独的组件。 \n Yarn 的基础架构 \n Yarn 的架构如下： \n \n \n ResourceManager： \n 简称 RM，作用是： \n \n 处理客户端请求。 \n 监控 NodeManager。 \n 启动及监控 ApplicationMaster。 \n 资源的分配和调度。 \n \n \n \n NodeManager： \n 简称 NM，作用是： \n \n 管理单个节点上的资源。 \n 处理来自 ResourceManager 的请求。 \n 处理来自 ApplicationMaster 的请求。 \n \n \n \n ApplicationMaster： \n 简称 AM，作用是： \n \n 为应用程序申请资源，并且给内部分配任务。 \n 任务的监控与容错。 \n \n \n \n Container： \n 它是资源的抽象，我们将 内存、CPU、磁盘、网络 等资源看成 Container，任务在 Container 中运行。 \n \n \n 综上，可以简单地看出，RM 是整个集群资源的老大，NM 是单个节点资源的老大，AM 是每个 Job 资源的老大，Container 是具体资源的抽象。 \n \n Yarn 的工作机制 \n \n MR 程序提交到客户端所在的节点，使用  waitForCompletion()  之后，在集群环境下会 new 一个  YarnRunner ，用于将程序提交到 Yarn 中。 \n YarnRunner 会向 RM 申请一个 Application，RM 返回给一个资源路径和 applicationId。 \n 客户端提交资源（ jar 、切片信息、配置文件）到 HDFS 的  路径/applicationId 。 \n 客户端发送给 Yarn 资源提交完毕的消息，申请运行 MR AM。 \n RM 将请求初始化为一个 Task 放到其内部的容器队列（容器调度器）中。 \n RM 将队列中的 Task 分配给一个 NM。 \n NM 创建 Container，产生 MR AM。 \n Container 从 HDFS 上拷贝资源到本地。 \n MR AM 向 RM 申请运行 MapTask。 \n RM 将 MapTask 分给 NM（此 NM 可能有一个或多个，可能在同一台机器上也可能不同）。 \n 得到任务的 NM 领取任务，分别创建 Container。 \n AM 向执行任务的 NM 发送程序执行脚本，程序开始执行。 \n MapTask 执行完毕，AM 向 RM 申请运行 ReduceTask。 \n RM 将 ReduceTask 分给 NM。 \n NM 领取任务并创建 Container。 \n ReduceTask 从 MapTask 中获取对应分区的数据。 \n 程序运行完毕，MR 向 RM 申请注销。 \n Yarn 调度器和调度算法 \n 之前讲 Yarn 工作机制的时候，有一个过程是：客户端申请运行 MR AM 的时候，RM 会将请求初始化为一个 Task 放到容器调度器中。 \n Hadoop 的容器调度器有三种： \n \n FIFO：先进先出。 \n Capacity Scheduler：容量调度器，apache 版本的 Hadoop 默认。具体参数可以到  yarn-default.xml  查看  yarn.resourcemanager.scheduler.class  选项，就是  Capacity Scheduler 。 \n Fair Scheduler：公平调度器，CDH 版本的 Hadoop 默认。 \n \n FIFO \n 调度器如名，Task 按照到达 RM 的时间被排序，先进来的先服务。只有一个单队列，生产环境中很少使用。 \n Capacity Scheduler \n Yahoo 开发的多用户调度器。 \n \n 有多个队列。 \n 可以分别设置每个队列的资源上下限。 \n 有富裕资源的队列可以暂时共享给其他需要资源的队列，但是一旦需要资源会将资源取回。 \n 支持多用户和多应用执行。该调度器会对单个用户提交的作业所占资源量进行限制。 \n \n 容量调度器中，任务的优先级执行顺序是按照资源的利用率来进行资源调度的。资源利用率低的队列会优先分配。 \n \n \n Fair Scheduler \n Facebook 开发的多用户调度器。顾名思义，十分公平。它的核心思想就是让队列中的所有任务在时间上公平。 \n 与容量调度器的相同点： \n \n 多队列。 \n 可以为每个队列设置资源上下限。 \n 有富裕资源的队列可以暂时共享资源给需要资源的队列，但是一旦需要资源会将资源取回。 \n 支持多用户同时运行，并且会对同一个用户所占资源量进行限制。 \n \n \n \n 缺额，这其实是说，在一个任务进入队列之后，这个任务不一定能够得到需要的所有资源，可能只得到一半或者其他，总之不会是百分百。这种情况就叫做缺额，也就是拿到的少于期望的资源量。 \n 虽然公平调度器的主要原则是最终在时间上看，每一个任务所分配的资源都几乎相同，但是任务和任务之间总会有一个优先级的概念，也就是谁先执行，谁后执行。 \n 在公平调度器的调解下，缺额比较大的队列优先分配资源。 \n \n 公平调度器有三种队列资源的分配方式： \n \n \n FIFO： \n 在这种情况下，相当于容量调度器。 \n \n \n Fair： \n 默认策略。 \n \n \n DRF： \n 可以针对不同应用进行不同资源的比例限制。 \n \n \n",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"December 29, 2021 17:23",createTimeStamp:1640769813e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hive-01-起步",frontmatter:{title:"Hive-01-起步",categories:["bigdata"],tags:["hive"],author:"causes",summary:"数据仓库 什么是数据仓库 数据仓库（Data Warehouse），简称 DW，数仓。目的是为了分析数据，提供决策支持的数据存放地点。 数仓本身不产生数据，不消费数据，数据从各种数据源进来，开放给各个外部组件使用。这也是为什么叫做仓库，而不叫工厂的原因。 那么为什么需要数仓而不用传统的数据库呢？因为传统的数据库首先是面向业务，同时要支持增删改查，但是数仓基本",meta:[{property:"og:url",content:"/bigdata/Hive/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hive-01-起步"},{property:"og:description",content:"数据仓库 什么是数据仓库 数据仓库（Data Warehouse），简称 DW，数仓。目的是为了分析数据，提供决策支持的数据存放地点。 数仓本身不产生数据，不消费数据，数据从各种数据源进来，开放给各个外部组件使用。这也是为什么叫做仓库，而不叫工厂的原因。 那么为什么需要数仓而不用传统的数据库呢？因为传统的数据库首先是面向业务，同时要支持增删改查，但是数仓基本"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hive"}]},regularPath:"/bigdata/Hive/part1.html",relativePath:"bigdata/Hive/part1.md",key:"v-7c98df2c",path:"/bigdata/Hive/part1/",headers:[{level:2,title:"数据仓库",slug:"数据仓库"},{level:2,title:"Hive 概述",slug:"hive-概述"},{level:2,title:"Hive 安装",slug:"hive-安装"},{level:3,title:"安装、部署、使用",slug:"安装、部署、使用"},{level:3,title:"Hive 的启动",slug:"hive-的启动"},{level:3,title:"脚本",slug:"脚本"},{level:3,title:"日志",slug:"日志"},{level:3,title:"参数配置",slug:"参数配置"}],readingTime:{minutes:13.83,words:4150},content:' 数据仓库 \n 什么是数据仓库 \n 数据仓库（Data Warehouse），简称 DW，数仓。目的是为了分析数据，提供决策支持的数据存放地点。 \n 数仓本身不产生数据，不消费数据，数据从各种数据源进来，开放给各个外部组件使用。这也是为什么叫做仓库，而不叫工厂的原因。 \n 那么为什么需要数仓而不用传统的数据库呢？因为传统的数据库首先是面向业务，同时要支持增删改查，但是数仓基本不会对数据进行更改和删除，因为数仓是为了发现规律而创造的。 \n 数仓分层 \n 数仓的特点是不生产数据，也不消费数据。 \n 但是大量的、各种各样的数据源的数据不可能一下子加载进来就可以使用了，有可能有很多多余的字段，我们需要做的其实就是将数据精简再精简，最终剩下有用的部分。 \n 那么为了这个目的，分层就显得尤为重要。 \n 数仓分层每个企业都有自己不同的业务需求，可以根据这个业务需求分为不同的层次，但是最基础的分层是有三个层次： \n \n ODS 层：操作型数据层，这一层的数据其实就是外部数据加载进来，没有什么其他操作。 \n DW 层：数据仓库层，这一层对 ODS 层中，数据多余的内容（比如字段之类）做了精简，是真正存储有用数据的地方。 \n DA 层：数据应用层，这一层通常是直接使用的地方，比如使用这些数据直接生成图像、报表等。 \n \n 阿里巴巴的数据分层更加细节： \n \n 注意的是 DW 层，多出了 DWD、DWB、DWS、DIM 这几层，这几层为不同的业务做了不同的数据支持。 \n 为什么要进行分层： \n \n 明确的数据结构：每一个分层都有自己的作用域，在使用表的时候能够更方便地定位和理解。 \n 数据血缘追踪：假如数仓的数据来源有很多，那么假如有一张来源表出了问题，我们希望能够快速定位。 \n 减少重复开发：一些通用的中间数据可以减少重复计算。 \n 复杂问题简单化：每一层处理单一的步骤比较容易理解。 \n 屏蔽原始数据：不需要关注数据源的业务。 \n \n ETL \n 之前讲，数仓的数据来源于各个数据源，但是各个数据源的数据结构有可能不一致，所以在从数据源加载到数据仓库的过程中，我们都有：抽取数据源的数据、转换数据格式、加载到数仓。 \n 这三步叫做 ETL，即  抽取 Extract 、 转化 Transfer 、 加载 Load  的过程，但其实在将数据加载到数仓中，并不一定是 ETL，也有可能是 ELT，ELTL 等，根据业务的不同做不同的处理。 \n Hive 概述 \n 什么是 Hive \n Hive 是 Facebook 开源的一款数据仓库系统，它可以将存储在 Hadoop 的结构化、半结构化的文件进行映射，形成一张数据库表。 \n Hive 同时还提供类似 SQL 的查询模型，被称为 HQL（Hive 查询语言），它可以访问和分析 Hadoop 文件中的数据集，其本质是将 HQL 转换为 MapReduce 程序，减少了开发难度，让没有学习过 MapReduce 的程序员也能快速上手。 \n \n Hive 组件 \n \n \n 用户接口：包括  CLI（Command Line Interface，命令行） 、 JDBC/ODBC（JDBC 或 ODBC 协议） 、 WebGUI（浏览器） 。 \n \n \n 元数据存储：一般来说，可以存在 MySQL 或者 Derby 中，但是大部分都会在 MySQL 中，因为 Derby 存在缺陷（下文会提到）。 \n 元数据，就是描述数据的数据，比如说表的名字、表的列、分区属性、所在目录等等。 \n \n \n Driver 驱动程序：包括语法解析器、计划编译器、优化器、执行器。这几个程序会将 HQL 分析，转换为 MapReduce，进行优化，并将查询计划存在 HDFS 中，由执行引擎调用执行。 \n \n \n 执行引擎：Hive 本身并不直接处理数据文件，而是通过执行引擎处理。当前 Hive 支持 MapReduce、Tez、Spark 三种执行引擎。 \n \n \n 数据模型 \n Hive 的数据模型可以用来描述数据、组织数据、对数据进行操作，是现实世界数据特征的描述。类似于 RDBMS 库表结构，不过也不尽相同。 \n Hive 中的数据可以在粒度上分为三类： \n \n Table：最粗粒度，表。 \n Partition：中等粒度，分区。 \n Bucket：最细粒度，分桶。 \n \n 其实比较好理解，Table 可以包含多个 Partition，Partition 可以包含多个 Bucket。可以对比一下阿里云 OSS，OSS 在进行对象存储时也需要分地区存储，然后创建多个 bucket。 \n \n Databases \n Hive 的外在表现十分像一个数据库，在结构上也会分数据库（schema），默认使用的 schema 是 default。 \n 虽然 Hive 外在像数据库，但其实数据是存储在存储系统中的。 \n 我们以 HDFS 为例，它有一个默认的根目录，可以在  hive-site.xml  中查看，由  hive.metastore.warehouse.dir  指定，默认为  /user/hive/warehouse ，所以 Hive 在 HDFS 中的存储路径为： ${hive.metastore.warehouse.dir}/${databaseName}.db 。 \n Tables \n Hive 表和关系型数据库的表相同，Hive 中的表所对应的数据是存储在 Hadoop 的文件系统中，而表相关的元数据是存储在 RDBMS 中。 \n Hive 其实本质上分为两种表：内部表、外部表。两种表的区别在下文中会提到。Hive 表在 HDFS 上的存储路径为： ${hive.metastore.warehouse.dir}/${databaseName}/${tableName} \n Partition \n 其实本质来讲，分区是一种优化手段，不同分区的数据在 HDFS 上本质会存储到不同的文件夹中。 \n 假如有一百万条会员的信息，假如我们按照年龄每 10 岁一个分区，那么假如我们想要查询 25 岁的人群就可以到对应的文件夹中查找，而不需要遍历所有文件。 \n Hive 分区在 HDFS 上的存储路径为： ${hive.metastore.warehouse.dir}/${databaseName}/${tableName}/${partition} 。 \n 说明一下，最后的 partition 文件夹的命名规则是： 分区列=分区值 ，比如我按照日期进行分区，那么有可能会出现一个文件夹叫做  day=20220126 \n Bucket \n Bucket，分桶，本质上也是一种 Hive 的优化手段。 \n 分桶在分区的规则上，可以进行更细粒度的划分，但是这次的划分不是划分成为文件夹，而是分成一个个的小文件，这样查询的数据就只需要查询指定的文件即可。 \n Hive 和 MySQL \n 首先讲一点，Hive 本质上不是数据库，也不能取代 MySQL。Hive 的使用场景是离线数据分析，而 MySQL 是数据的业务处理。 \n 在 Hive 中执行数据分析，数据量是极大的，分析几小时甚至几天出结果都是很正常的，但是 MySQL 往往要求实时性。 \n Hive 基本不会已有数据进行增删改，但是 MySQL 是必然的。 \n Hive 安装 \n 安装、部署、使用 \n Metastore \n 在 Hive 中，存在元数据服务，也就是 Metastore，元数据我们之前提过，描述数据的数据，比如表的存放位置、表的名字等。 \n Metastore 服务作用是管理元数据 metastore，对外暴露地址，可以让多个客户端链接 metastore 服务间接去存取元数据，一定程度上保证了 Hive 元数据的安全。 \n \n \n 安装 \n \n \n 首先要安装 MySQL 内容，在此之前先看一下服务器中是否含有 MySQL，有则卸载： rpm -qa | grep -E mysql\\|mariadb | xargs -n1 sudo rpm -e --nodeps \n rpm -qa ：查询 rpm 包。\n mysql 、 mariadb  都是 MySQL，不同版本而已。\n xxx | xargs -n1 ：前面的内容通过管道符作为参数，一个一个地传递给后面的命令 \n \n \n 使用 MySQL 安装包，解压 tar 包： tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar -C /opt/software/mysql \n \n \n 进入到 mysql 目录中，按照如下次序依次进行安装： \n sudo rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm\nsudo rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm\nsudo rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm\nsudo rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm\nsudo rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm\n \n 1 2 3 4 5 \n \n 初始化数据库： sudo mysqld --initialize --user=mysql \n \n \n 查看生成的 root 密码： cat /var/log/mysqld.log ，其中有一行叫做  A temprary is generated for xxxx  的就是密码。 \n \n \n 启动 MySQL： sudo systemctl start mysqld \n \n \n 登录 MySQL，修改 root 的新密码： set password = password("新密码") 。 \n \n \n 修改 MySQL 的 root 用户为任何 ip 可连接： update mysql.user set host=\'%\' where user=\'root\'; \n \n \n 刷新： flush privileges; \n \n \n 至此，MySQL 安装完毕。 \n \n \n \n Hive 的安装比较简单，首先解压包到对应目录下。 \n \n \n 之后修改环境变量： \nHIVE_HOME\nexport HIVE_HOME=/opt/module/hive\nexport PATH=$PATH:$HIVE_HOME/bin\n \n 1 2 3 \n \n Hive 和 Hadoop 的日志包冲突了，解决 jar 包冲突： rm $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar ，让 Hive 去寻找 Hadoop 的 jar。 \n \n \n 拷贝 JDBC 驱动到 Hive 的 lib 下： cp /op/software/mysql/mysql-connector-java-5.1.48.jar $HIVE_HOME/lib \n \n \n 配置 metastore 到 MySQL，在 $HIVE_HOME/conf 下面新建文件  hive-site.xml ： \n 配置 \n <configuration>\n    \x3c!-- jdbc连接的URL --\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionURL</name>\n        <value>jdbc:mysql://hadoop102:3306/metastore?useSSL=false</value>\n    </property>\n\n    \x3c!-- jdbc连接的Driver--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionDriverName</name>\n        <value>com.mysql.jdbc.Driver</value>\n    </property>\n\n    \x3c!-- jdbc连接的username--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionUserName</name>\n        <value>root</value>\n    </property>\n\n    \x3c!-- jdbc连接的password --\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionPassword</name>\n        <value>123456</value>\n    </property>\n\n    \x3c!-- Hive默认在HDFS的工作目录 --\x3e\n    <property>\n        <name>hive.metastore.warehouse.dir</name>\n        <value>/user/hive/warehouse</value>\n    </property>\n\n    \x3c!-- Hive元数据存储的验证 --\x3e\n    <property>\n        <name>hive.metastore.schema.verification</name>\n        <value>false</value>\n    </property>\n\n    \x3c!-- 元数据存储授权  --\x3e\n    <property>\n        <name>hive.metastore.event.db.notification.api.auth</name>\n        <value>false</value>\n    </property>\n\n    \x3c!-- 指定存储元数据要连接的地址 --\x3e\n    <property>\n        <name>hive.metastore.uris</name>\n        <value>thrift://hadoop102:9083</value>\n    </property>\n\n    \x3c!-- 指定hiveserver2连接的host --\x3e\n    <property>\n        <name>hive.server2.thrift.bind.host</name>\n        <value>hadoop102</value>\n    </property>\n\n    \x3c!-- 指定hiveserver2连接的端口号 --\x3e\n    <property>\n        <name>hive.server2.thrift.port</name>\n        <value>10000</value>\n    </property>\n\n    \x3c!-- 配置运行 hiveserver2 的用户登入 --\x3e\n    <property>\n        <name>hive.server2.thrift.port</name>\n        <value>10000</value>\n    </property>\n\n    \x3c!-- 配置当前运行 hiveserver2 的用户有权限连接 --\x3e\n    <property>\n        <name>hive.server2.enable.doAs</name>\n        <value>false</value>\n    </property>\n\n    \x3c!-- 打印表头 --\x3e\n    <property>\n        <name>hive.cli.print.header</name>\n        <value>true</value>\n    </property>\n\n    \x3c!-- 打印库名称 --\x3e\n    <property>\n        <name>hive.cli.print.current.db</name>\n        <value>true</value>\n    </property>\n\n</configuration>\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 \n \n \n 至此，Hive 配置完成。 \n Hive 的启动 \n 之前我们讲过元数据，那么 Hive Metadata 就是 Hive 的元数据，它包含在关系型数据库中，之后就会放到我们刚刚安装的 MySQL 中。 \n Metastore 即元数据服务，元数据服务的作用是管理 metadata 元数据，对外暴露服务地址，让客户端通过连接 metastore 服务连接 MySQL，进而存取元数据。 \n 有了 metastore 服务，就可以多个客户端进行连接，这些客户端不需要知道用户名和密码，只需要连接 metastore 服务即可。某种程度上也保证了元数据的安全。 \n metastore 服务有三种模式：内嵌、本地、远程。区分三种方式主要在于两点：metastore 是否需要单独启动、metadata 是存放到内置的 derby 中还是第三方的关系型数据库（如 MySQL）。 \n \n \n \n x \n 内嵌模式 \n 本地模式 \n 远程模式 \n \n \n \n \n metastore 服务是否单独配置 \n 否 \n 否 \n 是 \n \n \n metadata 的存储介质 \n 内置的 derby \n mysql \n mysql \n \n \n \n 那么我们之前所做的内容就是让 metastore 服务单独启动、metadata 放到 MySQL 中的，那么这就是远程模式。 \n \n 内嵌模式下，元数据存储在内置的 derby 中，这种情况下，一次仅支持一个用户，不适合生产环境。不做讲解。 \n \n \n 本地模式下，外部数据库存储元数据，但是 metastore 也不需要单独配置，比内嵌模式好些，支持多个用户，但是问题是每次启动一次 hive 服务，都内置启动一个 metastore 服务。 \n 启动本地模式只需要使用  bin/hive  便可以一键启动。 \n \n \n 远程模式下，metastore 需要单独启动，元数据也需要放到第三方的关系型数据库。 \n 在远程模式下，我们也可以采用 hiveserver2 这个服务来访问 metastore，进而访问 hive 元数据，也就是在原本的 metastore 基础上再次做了一层封装，这样做的好处就是可以完全屏蔽掉数据层，带来更高的安全性和可靠性。 \n 首先进入 MySQL，新建  metadata  库： create database metastore; \n 之后初始化 Hive 元数据库： schematool -initSchema -dbType mysql -verbose \n 启动了 hiveserver2 之后，我们可以使用 beelin 来通过 JDBC 连接 hiveserver2 服务： \n \n \n 启动 metastore： bin/hive --service metastore \n \n \n 启动 hiveserver2： bin/hive --service hiveserver2 \n \n \n 启动 beeline 客户端： bin/beeline -u jdbc:hive2://hadoop102:10000 -n atguigu \n 这里注意，因为我们在配置中配置了  hive.server2.enable.doAs ，所以这里的  atguigu  是你启动 hiveserver2 的用户 \n 并且需要注意的是，hiveserver2 并不会立刻启动，如果连接不上可能是因为服务没有启动，可以通过  sudo netstat -anp | grep 10000  查看 hiveserver2 是否在这个端口中启动了。 \n \n \n \n 发展史 \n Hive 发展至今，一共经历了两代客户端工具，第一代客户都安是  bin/hive ，他是一个 shell util，可以处理 hive 查询，也可以启动 hive 相关的服务。 \n 到目前为止，我们一般只需要利用它来启动 hive 相关的服务。 \n 第二代客户端是 beeline，它是一个 JDBC 客户端，性能和安全性比第一代有提高，所以我们现在一般使用这个。 \n \n \n 再次梳理一下 hive 几个服务和客户端之间的关系： \n hiveserver2 会通过 metastore 服务读写元数据，所以启动 hiveserver2 之前需要启动 metastore 服务。 \n beeline 客户端通过操纵 hiveserver2 去操作 metastore，进而操作元数据。 \n 第一代客户端 hive 会直接操作 metastore，进而操作元数据。 \n 脚本 \n \n \n 编写脚本  $HIVE_HOME/bin/hiveservices.sh \n 脚本 \n #!/bin/bash\nHIVE_LOG_DIR=$HIVE_HOME/logs\nif [ ! -d $HIVE_LOG_DIR ]\nthen\n    mkdir -p $HIVE_LOG_DIR\nfi\n#检查进程是否运行正常，参数 1 为进程名，参数 2 为进程端口\nfunction check_process()\n{\n    pid=$(ps -ef 2>/dev/null | grep -v grep | grep -i $1 | awk \'{print $2}\')\n    ppid=$(netstat -nltp 2>/dev/null | grep $2 | awk \'{print $7}\' | cut -d \'/\' -f 1)\n    echo $pid\n    [[ "$pid" =~ "$ppid" ]] && [ "$ppid" ] && return 0 || return 1\n}\n\nfunction hive_start()\n{\n    metapid=$(check_process HiveMetastore 9083)\n    cmd="nohup hive --service metastore >$HIVE_LOG_DIR/metastore.log 2>&1 &"\n    cmd=$cmd" sleep 4; hdfs dfsadmin -safemode wait >/dev/null 2>&1"\n    [ -z "$metapid" ] && eval $cmd || echo "Metastroe服务已启动"\n    server2pid=$(check_process HiveServer2 10000)\n    cmd="nohup hive --service hiveserver2 >$HIVE_LOG_DIR/hiveServer2.log 2>&1 &"\n    [ -z "$server2pid" ] && eval $cmd || echo "HiveServer2服务已启动"\n}\n\nfunction hive_stop()\n{\n    metapid=$(check_process HiveMetastore 9083)\n    [ "$metapid" ] && kill $metapid || echo "Metastore服务未启动"\n    server2pid=$(check_process HiveServer2 10000)\n    [ "$server2pid" ] && kill $server2pid || echo "HiveServer2服务未启动"\n}\n\ncase $1 in\n"start")\n    hive_start\n    ;;\n"stop")\n    hive_stop\n    ;;\n"restart")\n    hive_stop\n    sleep 2\n    hive_start\n    ;;\n"status")\n    check_process HiveMetastore 9083 >/dev/null && echo "Metastore服务运行正常" || echo "Metastore服务运行异常"\n    check_process HiveServer2 10000 >/dev/null && echo "HiveServer2服务运行正常" || echo "HiveServer2服务运行异常"\n    ;;\n*)\n    echo Invalid Args!\n    echo \'Usage: \'$(basename $0)\' start|stop|restart|status\'\n    ;;\nesac\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 \n shell 命令： nohup [命令]> file 2>&1 & \n nohup  表示不挂起（关闭终端继续运行）， &  代表后台运行， 2  代表错误输出， 1  代表标准输出， 0  代表标准输入。 2>&1  代表错误重定向到标准输出上。 \n \n \n 添加执行权限： chmod u+x $HIVE_HOME/bin/hiveservices.sh \n 日志 \n Hive 的日志默认放在  /tmp/${user}/hive.log  下（当前用户名下），修改日志位置到  $HIVE_HOME/logs  下： \n \n 修改  $HIVE_HOME/conf/hive-log4j2.properties.template  名称为  hive-log4j2.properties \n 修改配置  property.hive.log.dir=/opt/module/apache-hive-3.1.2-bin/logs \n 参数配置 \n \n \n 进入 hive 之后，可以使用  set;  查看配置信息。 \n \n \n hive 有三种配置方式： \n \n \n 配置文件： \n \n 默认配置文件： hive-default.xml 。 \n 用户自定义配置： hive-site.xml ，它将会覆盖默认配置文件。 \n \n \n \n 命令行参数： \n 启动 hive 的时候，可以添加  hiveconf param=value ，但是这种方式只会在此次 hive 会话中生效。 \n \n \n 参数声明设置： \n 在 HQL（Hive SQL，之后需要学到的内容） 中，使用  set xxx  设置，也是对本次 hive 会话中生效。 \n \n \n \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 26, 2022 10:02",createTimeStamp:1643162539e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hive-03-DML",frontmatter:{title:"Hive-03-DML",categories:["bigdata"],tags:["hive"],author:"causes",summary:"加载数据 LOAD 加载数据 Hive 每当创建一张表，就会在 HDFS 上产生一个文件夹，此时我们可以将文件上传到这个文件夹中，这样 hive 就可以解析文件。 我们可以使用 hadoop fs -put 方式直接将文件上传到指定的文件夹下，但是官方推荐我们使用 load 命令将数据加载到表中。 那么 load 就是一个纯粹的数据移动的操作，不会对数据做任",meta:[{property:"og:url",content:"/bigdata/Hive/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hive-03-DML"},{property:"og:description",content:"加载数据 LOAD 加载数据 Hive 每当创建一张表，就会在 HDFS 上产生一个文件夹，此时我们可以将文件上传到这个文件夹中，这样 hive 就可以解析文件。 我们可以使用 hadoop fs -put 方式直接将文件上传到指定的文件夹下，但是官方推荐我们使用 load 命令将数据加载到表中。 那么 load 就是一个纯粹的数据移动的操作，不会对数据做任"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hive"}]},regularPath:"/bigdata/Hive/part3.html",relativePath:"bigdata/Hive/part3.md",key:"v-61a49f28",path:"/bigdata/Hive/part3/",headers:[{level:2,title:"加载数据",slug:"加载数据"},{level:3,title:"LOAD 加载数据",slug:"load-加载数据"},{level:3,title:"INSERT + SELECT",slug:"insert-select"},{level:2,title:"事务、更新、删除",slug:"事务、更新、删除"}],readingTime:{minutes:5.93,words:1780},content:" 加载数据 \n LOAD 加载数据 \n Hive 每当创建一张表，就会在 HDFS 上产生一个文件夹，此时我们可以将文件上传到这个文件夹中，这样 hive 就可以解析文件。 \n 我们可以使用  hadoop fs -put  方式直接将文件上传到指定的文件夹下，但是官方推荐我们使用  load  命令将数据加载到表中。 \n 那么 load 就是一个纯粹的数据移动的操作，不会对数据做任何修改，换言之，我们需要自己保证数据没有问题。 \n LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]\n\nLOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)] [INPUTFORMAT 'inputformat' SERDE 'serde'] (3.0 or later)\n \n 1 2 3 \n \n filepath：文件/文件夹：可以使用相对路径，绝对路径，完全的 URI（hdfs://xxx） \n \n \n LOCAL：LOCAL 所在的本地，意思是 hiveserver2 上所在的位置。 \n \n 如果指定了 LOCAL 关键字，那么相对路径将会解析为 hiveserver2 所在的本地文件系统。 \n 假如没有指定 LOCAL 关键字，那么相对路径就会使用 Hadoop 中，配置文件参数  fs.default.name  指定的（例如将会指向 HDFS） \n \n \n OVERWRITE：覆盖重写。 \n \n \n -- 创建表 \n CREATE   TABLE  student  ( \n    num  int , \n    name string , \n    sex string , \n    age  int , \n    dept string\n )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n -- 创建外部表 \n CREATE  EXTERNAL  TABLE  student_external  ( \n    num  int , \n    name string , \n    sex string , \n    age  int , \n    dept string\n )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n -- 创建分区表 \n CREATE   TABLE  student_partitioner  ( \n    num  int , \n    name string , \n    sex string , \n    age  int , \n    dept string\n )  PARTITIONED  BY   ( country string )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n SHOW   TABLES   ; \n\n -- 从本地文件系统中（hiveserver2 所在的位置）加载数据，直接指定文件夹 \n LOAD   DATA   LOCAL  INPATH  '/tmp/students'   INTO   TABLE  student ; \n\n -- 从外部存储中加载数据，此存储是使用 Hadoop 配置文件中，fs.default.name 指定 \n LOAD   DATA  INPATH  '/tmp/students.txt'   INTO   TABLE  student_external ; \n\n -- 加载数据并且给出静态分区 \n LOAD   DATA   LOCAL  INPATH  '/tmp/students'   INTO   TABLE  student_partitioner  PARTITION   ( country = \"CHINA\" ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 HIVE 在 3.0 版本之后，LOAD 命令增加了新的特性： \n \n \n 可能变为  INSERT AS SELECT ，即查询加载。 \n 比如，假如表具有分区，并且 LOAD 命令没有指定分区字段，那么在 HIVE3.0 之前必定会报错，因为没有指定静态分区。 \n 但是在 HIVE3.0 之后会假定最后一列为分区列，将 LOAD 改为  INSERT AS SELECT  模式。但是假如文件不符合预期，也一样会报错。 \n \n \n 支持使用  InputFormat 、 SerDe  指定输入格式。 \n \n \n -- HIVE3.0 LOAD 插入动态分区 \n /* 数据\n95001,李勇,男,20,CS\n95002,刘晨,女,19,IS\n95003,王敏,女,22,MA\n95004,张立,男,19,IS\n95005,刘刚,男,18,MA\n95006,孙庆,男,23,CS\n95007,易思玲,女,19,MA\n95008,李娜,女,18,CS\n95009,梦圆圆,女,18,MA\n95010,孔小涛,男,19,CS\n95011,包小柏,男,18,MA\n95012,孙花,女,20,CS\n95013,冯伟,男,21,CS\n95014,王小丽,女,19,CS\n95015,王君,男,18,MA\n95016,钱国,男,21,MA\n95017,王风娟,女,18,IS\n95018,王一,女,19,IS\n95019,邢小丽,女,19,IS\n95020,赵钱,男,21,IS\n95021,周二,男,17,MA\n95022,郑明,男,20,MA\n*/ \n -- 创建分区表 \n CREATE   TABLE  student_dynamic_partitioner  ( \n    num  int , \n    name string , \n    sex string , \n    age  int \n )  PARTITIONED  BY   ( dept string )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n -- 使用 LOAD 命令，这个时候没有指定分区列，那么这个时候它会将 LOAD 转换为 INSERT AS SELECT \n LOAD   DATA   LOCAL  INPATH  '/tmp/students'   INTO   TABLE  student_dynamic_partitioner ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 从时间上看，明显边长了，并且经历了一次 MapReduce： \n INSERT + SELECT \n 在 HIVE 中也有类似传统关系型数据库的语法： INSERT xxx SELECT xxx ，但是 HIVE 和传统内容不同，在 HIVE 中，这个语句是要转换为 MapReduce 程序的。 \n 官方推荐的方式是将数据清洗之后，使用 LOAD 命令加载到 HIVE 中，但是这并不是说  INSERT SELECT  没有用武之地。 \n 事实上，它会用于将查询的结果插入到一张新表中。此时注意： \n \n 需要保证查询的结果列的数目和需要插入的表的列数目一致。 \n 数据类型不一致会尝试转换，但是转换失败会为 NULL。 \n \n INSERT [OVERWRITE] TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1 FROM from_statement;\n \n 1 \n 在查询插入的这个方式下，有一种类型叫做多重插入，简单来说就是扫描一次源表，多次插入新表。 \n -- 一次扫描 from_table，插入 name 到 table1，插入 age 到 table2。\nFROM from_table\nINSERT OVERWRITE TABLE table1 SELECT name\nINSERT OVERWRITE TABLE table2 SELECT age;\n \n 1 2 3 4 \n 动态分区插入之前的章节（DDL 中）也提到过，这里不再赘述。 \n 数据导出 \n HIVE 可以将 SELECT 的数据放到文件系统中，语法如下： \n -- 将结果导出到 HDFS 中，注意是 OVERWRITE，所以目标目录要谨慎 \n INSERT  OVERWRITE DIRECTORY  '/tmp/hive_export/data1'   SELECT   *   FROM  student ; \n\n -- 指定分隔符和文件格式 \n INSERT  OVERWRITE DIRECTORY  '/tmp/hive_export/data2'   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   ',' \n SELECT   *   FROM  student ; \n\n -- 导出到本地文件（hiveserver2 所在服务器）目录下 \n INSERT  OVERWRITE  LOCAL  DIRECTORY  '/tmp/hive_export/data'   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   ',' \n SELECT   *   FROM  student ; \n \n 1 2 3 4 5 6 7 8 9 10 #  事务、更新、删除 \n Hive 一开始是不支持事务的，因为 Hive 本身的需求是对数据进行分析处理，所以不支持 update、delete 等操作，自然也不支持事务。 \n 从 Hive 0.14 版本开始，具有ACID 语义的事务开始支持了，因为有一些场景确实需要使用，比如： \n \n 流式传输数据，就是说用 flume 或者 kafka 之类的工具，将数据流式传输到现有分区中，但是这会令用户感到脏读（开始查询后可以看到刚刚写入的数据）。 \n 收集的数据不正确，需要修正。 \n \n 虽然 Hive 支持了事务，但是不可能像传统的关系型数据库那样方便，它仍然有一些局限性： \n \n 事务不支持手动提交，也就是说 Hive 中的事务全部都是自动提交。 \n 仅支持 ORC 文件格式。 \n 默认事务是关闭的，需要配置参数手动打开。 \n 事务必须在分桶表上打开。 \n 外部表无法创建事务，不能成为 ACID 表，不允许从非 ACID 会话读取/写入 ACID 表。 \n 表的参数  transaction  必须为  true 。 \n \n 案例 \n -- Hive 中手动配置事务，使用 set 设置为当前会话中生效，也可以在 hive-site.xml 中配置 \n\n -- 1. 开启事务表的配置 \n -- 支持并发 \n SET  hive . support . concurrency  =   true ; \n -- 开启分桶功能，从 HIVE 2.0 开始不需要此配置 \n SET  hive . enforce . bucketing  =   true ; \n -- 开启动态分区模式（非严格模式） \n SET  hive . exec . dynamic . partition . mode   =  nonstrict ; \n SET  hive . txn . manager  =  org . apache . hadoop . hive . ql . lockmgr . DbTxnManager ; \n -- 在 metastore 实例上运行启动压缩合并 \n SET  hive . compactor . initiator . on   =   true ; \n -- 在 metastore 实例上运行多少个压缩程序工作线程 \n SET  hive . compactor . worker . threads  =   1 ; \n\n -- 2. 创建 Hive 事务表 \n -- 表为内部表，存为两个分桶，设置以 ORC 格式存储，并且设置表的属性 transactional 为 true \n CREATE   TABLE  trans_student ( \n    id  int , \n    name string , \n    age  int \n )   CLUSTERED   BY   ( id )   INTO   2  BUCKETS STORED  AS  ORC TBLPROPERTIES  ( 'transactional'   =   'true' ) ; \n\n -- 3. 针对事务表进行 INSERT、UPDATE、DELETE 操作 \n INSERT   INTO  trans_student  ( id ,  name ,  age )   VALUES   ( 1 ,   \"allen\" ,   18 ) ; \n UPDATE  trans_student  SET  age  =   20   WHERE  id  =   1 ; \n DELETE   FROM  trans_student  WHERE  id  =   1 ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 26, 2022 10:02",createTimeStamp:1643162539e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hive-04-DQL",frontmatter:{title:"Hive-04-DQL",categories:["bigdata"],tags:["hive"],author:"causes",summary:"基础查询 Hive 这款工具是基于 Hadoop，面向数据进行分析的工具，因此 SELECT 是十分重要的内容。 数据准备 基础案例 语句执行顺序：FROM -> WHERE -> GROUP -> HAVING -> ORDER -> SELECT 假如发生 OOM，在 yarn-site.xml 增加可用内存，比如： 高阶查询 ORDER BY Hive",meta:[{property:"og:url",content:"/bigdata/Hive/part4.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hive-04-DQL"},{property:"og:description",content:"基础查询 Hive 这款工具是基于 Hadoop，面向数据进行分析的工具，因此 SELECT 是十分重要的内容。 数据准备 基础案例 语句执行顺序：FROM -> WHERE -> GROUP -> HAVING -> ORDER -> SELECT 假如发生 OOM，在 yarn-site.xml 增加可用内存，比如： 高阶查询 ORDER BY Hive"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hive"}]},regularPath:"/bigdata/Hive/part4.html",relativePath:"bigdata/Hive/part4.md",key:"v-542a7f26",path:"/bigdata/Hive/part4/",headers:[{level:2,title:"基础查询",slug:"基础查询"},{level:2,title:"高阶查询",slug:"高阶查询"},{level:2,title:"JOIN",slug:"join"}],readingTime:{minutes:10.67,words:3202},content:' 基础查询 \n Hive 这款工具是基于 Hadoop，面向数据进行分析的工具，因此 SELECT 是十分重要的内容。 \n 数据准备 \n -- 1. 准备表，我们使用 2021 美国新冠确诊病例和死亡人数作为案例 \n DROP   TABLE   IF   EXISTS  t_usa_covid19 ; \n CREATE   TABLE  t_usa_covid19  ( \n    count_date string , \n    county  string , \n    state string , \n    fips  int , \n    cases  int , \n    deaths  int \n )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   "," ; \n\n /*\n    数据大致类似如此：\n\n    2021-01-28,Oglala Lakota,South Dakota,46102,2036,42\n    2021-01-28,Pennington,South Dakota,46103,12310,167\n    2021-01-28,Perkins,South Dakota,46105,333,11\n    2021-01-28,Potter,South Dakota,46107,343,3\n    2021-01-28,Roberts,South Dakota,46109,1105,34\n    2021-01-28,Sanborn,South Dakota,46111,323,3\n    2021-01-28,Spink,South Dakota,46115,760,25\n*/ \n\n LOAD   DATA   LOCAL  INPATH  "/tmp/hivedata/us-covid19-counties.dat"   INTO   TABLE  t_usa_covid19 ; \n\n -- 2. 创建一张分区表，目的是基于 count_data（日期），state（州）进行分区 \n CREATE   TABLE  t_usa_covid19_p  ( \n    county string , \n    fips  int , \n    cases  int , \n    deaths  int \n )  PARTITIONED  BY   ( count_date string ,  state string )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   "," ; \n\n -- 3. 基于动态分区将数据插入 \n SET  hive . exec . dynamic . partition . mode   =  nonstrict ; \n INSERT   INTO   TABLE  t_usa_covid19_p  PARTITION   ( count_date ,  state ) \n SELECT  county ,  fips ,  cases ,  deaths ,  count_date ,  state  FROM  t_usa_covid19 ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 基础案例 \n --------------------------------------------- 基础查询 --------------------------------------------- \n -- 1. select_expr，它表示需要检索的列，使用 * 或者列举字段，还可以使用正则表达式来匹配字段 \n SELECT   *   FROM  t_usa_covid19_p ; \n SELECT  county  FROM  t_usa_covid19_p ; \n -- 开启正则表达式，带反引号的名称会被解释为正则 \n SET  hive . support . quoted . identifiers  =  none ; \n SELECT   ` ^ c . * `   FROM  t_usa_covid19_p ; \n -- 查询当前数据库，这里省去了 FROM 关键字 \n SELECT  current_database ( ) ; \n SELECT   count ( county )   FROM  t_usa_covid19_p ; \n\n -- 2. ALL、DISTINCT，指定是否应该返回重复的行，默认是 ALL（返回），可以指定 DISTINCT（不返回） \n SELECT  state  FROM  t_usa_covid19_p ; \n SELECT   DISTINCT  state  FROM  t_usa_covid19_p ; \n\n -- 3. WHERE，支持子查询，可以使用一般函数，但是不能使用聚合函数（例如 sum()） \n -- 使用聚合函数的前提是结果已经确定，但是在 WHERE 子句中，结果集仍然处于未确定的状态 \n SELECT   *   FROM  t_usa_covid19_p  WHERE  state  =   "California"   AND  deaths  >   1000 ; \n\n -- 4. 分区查询、分区裁剪 \n -- 分区裁剪的意思是，对分区表进行查询时，只访问符合条件的分区，这样就可以大大提高效率，节省资源。同样的道理，也有一个列裁剪的概念。 \n SELECT   *   FROM  t_usa_covid19_p  WHERE  state  =   "California"   AND  deaths  >   1000 ; \n\n -- 5. GROUP BY，用于聚合函数，根据一个或者多个列对结果集进行分组 \n SELECT  state ,   count ( deaths )   FROM  t_usa_covid19_p  WHERE  count_date  =   "2021-01-28"   GROUP   BY  state ; \n\n -- 6. HAVING，HAVING 同样用来进行过滤，和 WHERE 不同的是，HAVING 子句发生在结果集已经确定之后，所以可以和聚合函数一起使用了 \n SELECT  state ,   sum ( deaths ) \n FROM  t_usa_covid19_p\n WHERE  count_date  =   "2021-01-28" \n GROUP   BY  state\n HAVING   sum ( deaths )   >   10000 ; \n -- 这种写法更好，HAVING 就无需再算一次了 \n SELECT  state ,   sum ( deaths )   AS  count\n FROM  t_usa_covid19_p\n WHERE  count_date  =   "2021-01-28" \n GROUP   BY  state\n HAVING  count  >   10000 ; \n\n -- 7. LIMIT \n SELECT  state ,   sum ( deaths )   AS  count\n FROM  t_usa_covid19_p\n WHERE  count_date  =   "2021-01-28" \n GROUP   BY  state\n HAVING  count  >   10000 \n LIMIT   5 ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 Tips \n 语句执行顺序：FROM -> WHERE -> GROUP -> HAVING -> ORDER -> SELECT \n \n 假如发生 OOM，在  yarn-site.xml  增加可用内存，比如： \n < property > \n     < name > yarn.scheduler.maximum-allocation-mb </ name > \n     < value > 2048 </ value > \n </ property > \n < property > \n     < name > yarn.scheduler.minimum-allocation-mb </ name > \n     < value > 2048 </ value > \n </ property > \n < property > \n     < name > yarn.nodemanager.vmem-pmem-ratio </ name > \n     < value > 2.1 </ value > \n </ property > \n < property > \n     < name > mapred.child.java.opts </ name > \n     < value > -Xmx1024m </ value > \n </ property > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #  高阶查询 \n ORDER BY \n Hive 中的  ORDER BY  和 SQL 中类似，它会对输出的结果进行全局排序，因此底层使用 MapReduce 时仅会使用一个 reduce task 来执行。但正因为如此，排序的时间也很长，并且要注意内存问题。 \n -- 排序默认使用 ASC 升序，可以指定为 DESC 降序。 \n -- 在 Hive 2.1.0 和更高版本中，支持在 ORDER BY 子句中为每个列指定 null 类型结果排序顺序。ASC 默认 null 为首位，而 DESC 为末位。 \n SELECT   *   FROM  t_usa_covid19_p  WHERE  count_date  =   "2021-01-28"   AND  state  =   "California"   ORDER   BY  deaths ; \n \n 1 2 3 强烈建议，将 LIMIT 与 ORDER BY 结合使用，避免数据集行数过大。而且当  hive.mapred.mode  为  strict  严格模式时，必须带  LIMIT 。 \n CLUSTER BY \n Hive 中的  CLUSTER BY  语法是分区排序，简单来说就是将数据首先根据指定的字段进行分区，然后分区间根据这个字段进行正排序（不允许自定排序规则）。 \n 分区的规则基于哈希散列， hash_func(col_name) % reduce task nums ，所以可以看到，分为几组取决于 reduce task 的个数。 \n -- 手动设置 reduce task 的个数 \n SET  mapreduce . job . reduces  =   2 ; \n -- 指定 sno 为分区排序的字段，分区的个数将会为两个 \n SELECT   *   FROM  student CLUSTER  BY  sno ; \n \n 1 2 3 4 DISTRIBUTE BY + SORT BY \n CLUSTER BY  虽然可以进行分区排序，但其实功能还不够强大。假如我们想要将学生表根据性别分为两个部分，然后根据年龄排序，那么  CLUSTER BY  是肯定做不到的。 \n 我们也不能使用  ORDER BY ，因为一旦使用就是全局排序，会强制设置 reduce task 的个数为 1，这样无法满足分区的需求。 \n 此时我们可以使用  DISTRIBUTE BY + SORT BY  来替换， DISTRIBUTE BY  负责分区， SORT BY  负责排序，并且分区和排序可以为不同字段。 \n -- DISTRIBUTE BY 会根据 sex 进行分区，而 SORT BY 会在分区之后，根据 sage 进行倒序排序 \n SELECT   *   FROM  student DISTRIBUTE  BY  sex SORT  BY  sage  DESC ; \n \n 1 2 这样看来，其实  CLUSTER BY  是一个简略版，更加复杂的功能推荐使用  DISTRIBUTE BY + SORT BY 。 \n UNION \n 和 SQL 的用法相同， UNION  的作用就是可以将多个  SELECT  语句的结果合并为一个结果集，可以使用  UNION、UNION ALL、UNION DISTINCT ，但是注意： \n \n 使用  UNION  等同于使用  UNION DISTINCT ，它会默认去除重复行。使用  UNION ALL  则不会去除重复行。 1.2.0  之前的 Hive 版本仅支持  UNION ALL 。 \n 使用  UNION  关键字时，每个  SELECT  语句查询的列的数量和名称必须相同。 \n \n 子查询 \n Hive 现在可以支持嵌套级别的子查询，可以使用关键词  AS  来指定子查询的名称。并且可以支持跟在  FROM  和  WHERE  两个关键词后的子查询。 \n -- 跟在 FROM 后的子查询 \n SELECT  num\n FROM   ( \n     SELECT  num ,  name  FROM  student_local\n     UNION \n     SELECT  num ,  name  FROM  student_hdfs\n )  tmp ; \n\n -- 跟在 WHERE 后的子查询 \n -- 不相关子查询，就是说这样的子查询相当于 IN、NOT IN。 \n SELECT   * \n FROM  student_hdfs\n WHERE  student_hdfs . num  IN   ( \n     SELECT  num  FROM  student_local  LIMIT   2 \n ) ; \n -- 相关子查询，就是说相当于判断 boolean，使用 EXISTS 和 NOT EXISTS 来查询。而且这种情况下，子句中支持对父查询的引用，比如下面就使用了 t1。 \n SELECT  a\n FROM  t1\n WHERE   EXISTS   ( \n     SELECT  b  FROM  t2  WHERE  t1 . x  =  t2 . y\n ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 CTE \n CTE（Common Table Expressions），公用表表达式，它是一种临时的结果集，会放到内存中。它派生于 WITH 子句，这种公用表达式的出现主要是为了改善效率。 \n 简单来说，只要短句中所定义的表名被用到两次以上，那么优化器会自动将获取的数据放到一个临时表中，这就叫做 CTE。需要注意的是，一个 CTE 只在单个 SQL 范围内生效。 \n CTE 的语法格式是  WITH ... AS ... ，并且必须和其他 SQL 一起使用。 \n -- 这里定义了一个 q1，它的内容就是 `SELECT sno, snam,sage FROM student WHERE sno = 95002` 产生的结果集，如果 q1 在此段 SQL 中用到了两次以上，那么优化器就会将结果集放到内存中 \n WITH  q1  AS   ( \n     SELECT  sno ,  snam , sage  FROM  student  WHERE  sno  =   95002 \n ) \n SELECT   *   FROM  q1 ; \n\n -- 这是 FROM 风格，它的作用和上面完全相同，但是不是很好理解 \n WITH  q1  AS   ( \n     SELECT  sno ,  snam , sage  FROM  student  WHERE  sno  =   95002 \n ) \n FROM  q1\n SELECT   * ; \n\n -- 连续定义多个 CTE。顺带一说，CTE 虽然定义了，但是我们仍然可以不用。 \n WITH  q1  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95002 \n ) , \nq2  AS   ( \n     SELECT  sno ,  sname ,  sage  FROM  q1\n ) \n SELECT   *   FROM   ( \n     SELECT  sno  FROM  q2\n )  a ; \n\n -- UNION \n WITH  q1  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95002 \n ) , \nq2  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95004 \n ) \n SELECT   *   FROM  q1\n UNION \n SELECT   *   FROM  q2 ; \n\n -- INSERT \n CREATE   TABLE  s1  LIKE  student ; \n WITH  q1  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95002 \n ) \n FROM  q1\n INSERT  OVERWRITE  table  s1  SELECT   * ; \n\n -- TABLE \n CREATE   TABLE  s2  AS   WITH  q1  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95002 \n ) \n SELECT   *   FROM  q1 ; \n\n -- VIEW \n CREATE   VIEW  v1  AS   WITH  q1  AS   ( \n     SELECT   *   FROM  student  WHERE  sno  =   95002 \n ) \n SELECT   *   FROM  q1 ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 在数据集非常大的情况下，使用 CTE 绝对是一个很好的选择。 \n JOIN \n 传统的关系型数据库的设计基础原则就是三大范式。对于平常来说，我们不会将所有类型的数据全都放到一张大表中，而是根据业务和类型划分不同的表进行存储。 \n 比如说，我们的订单表中可以使用外键来关联客户编号，而不会直接在订单表中填写客户的信息。 \n 这种情况下，我们需要基于多张表来查询，最终形成完整的结果，这就是 JOIN。 \n Hive 作为面向分析数据的工具，整体来说和 RDBMS 的 JOIN 类似，不过有一些自己的特点。 \n JOIN 语法 \n 在 Hive 中，当下支持六种语法，分别为： \n INNER JOIN（内链接） 、 LEFT JOIN（左外链接） 、 RIGHT JOIN（右外链接） 、 FULL OUTER JOIN（全外链接） 、 LEFT SEMI JOIN（左半开链接） 、 CROSS JOIN（交叉链接、笛卡尔积） \n 环境准备 \n 我们将以三张表为例子，来做 JOIN 练习： \n -- 员工表 \n /*\n    1201,gopal,manager,50000,TP\n    1202,manisha,cto,50000,TP\n    1203,khalil,dev,30000,AC\n    1204,prasanth,dev,30000,AC\n    1206,kranthi,admin,20000,TP\n*/ \n CREATE   TABLE  employee ( \n    id  int , \n    name string , \n    deg string , \n    salary string , \n    dept string\n )   ROW  FORMAT DELIMITED\n FIELDS   TERMINATED   BY   "," ; \n LOAD   DATA   LOCAL  INPATH  \'/tmp/hivedata/employee.txt\'   INTO   TABLE  employee ; \n\n -- 员工地址表 \n /*\n    1201,288A,vgiri,jublee\n    1202,108I,aoc,ny\n    1204,144Z,pgutta,hyd\n    1206,78B,old city,la\n    1207,720X,hitec,ny\n*/ \n CREATE   TABLE  employee_address  ( \nid  int , \nhno string , \nstreet string , \ncity string\n )   row  format delimited\n fields   terminated   by   \',\' ; \n LOAD   DATA   LOCAL  INPATH  \'/tmp/hivedata/employee_address.txt\'   INTO   TABLE  employee_address ; \n\n -- 员工联系方式表 \n /*\n    1201,2356742,gopal@tp.com\n    1203,1661663,manisha@tp.com\n    1204,8887776,khalil@ac.com\n    1205,9988774,prasanth@ac.com\n    1206,1231231,kranthi@tp.com\n*/ \n CREATE   TABLE  employee_connection  ( \n    id  int , \n    phno string , \n    email string\n )   row  format delimited\n fields   terminated   by   \',\' ; \n LOAD   DATA   LOCAL  INPATH  \'/tmp/hivedata/employee_connection.txt\'   INTO   TABLE  employee_connection ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 INNER JOIN \n 最常见的一种链接，只有进行链接的两个表中均存在与链接条件相匹配的数据才会被保留下来。其中  INNER JOIN  和  JOIN  无区别。 \n -- INNER JOIN，等价于 JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  INNER   JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n\n -- WHERE 的等值连接等价于 INNER JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e ,  employee_address e_a  WHERE  e . id  =  e_a . id ; \n \n 1 2 3 4 5 6 7 LEFT JOIN \n 左外链接， LEFT JOIN ，或者叫做  LEFT OUTER JOIN ， OUTER  可以省略。 \n 它的核心就在于左，只要左表中存在符合的数据，那么肯定会返回，右表中关联不上的使用  null  来返回。 \n -- LEFT JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  LEFT   JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n \n 1 2 3 RIGHT JOIN \n 右外链接，类似左外链接，以右表为主。 \n -- RIGHT JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  RIGHT   JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n \n 1 2 3 FULL JOIN \n 全外链接，它的做法是：分别求出左外链接和右外链接，然后进行合并，之后进行去重操作。 \n -- FULL JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  FULL   JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n \n 1 2 3 LEFT SEMI JOIN \n 左半开链接，从效果上看有点像  INNER JOIN  只返回左表的结果。 \n -- LEFT SEMI JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  LEFT  SEMI  JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n \n 1 2 3 CROSS JOIN \n 交叉连接，将会返回笛卡尔积，慎用。交叉连接其实在效果上就是无条件的  INNER JOIN ，在 Hive 中，交叉链接后面可以跟上 WHERE 或者 ON 继续过滤。 \n -- CROSS JOIN \n SELECT  e . id ,  e . name ,  e_a . city ,  e_a . street\n FROM  employee e  CROSS   JOIN  employee_address e_a  ON  e . id  =  e_a . id ; \n \n 1 2 3 JOIN 注意事项 \n \n \n Hive 中，假如每个表在链接子句中使用到了相同的列，那么 Hive 将会将多个表上的链接转换为单个 MR 作业： \n -- 会转换为 2 个 MR 作业。 \n -- 在第一个连接条件中使用了 b 中的 key1 列，而在第二个连接条件中使用了 b 中的 key2 列。 \n -- 第一个 map / reduce 作业将 a 与 b 联接在一起，然后将结果与 c 联接到第二个 map / reduce 作业中。 \n SELECT  a . val ,  b . val ,  c . val\n FROM  a  JOIN  b  ON   ( a . key   =  b . key1 )   JOIN  c  ON   ( c . key   =  b . key2 ) \n\n -- 两个条件中，涉及相同内容 b 的 key1 列，因此被转换为 1 个 MR 作业来执行。 \n SELECT  a . val ,  b . val ,  c . val\n FROM  a  JOIN  b  ON   ( a . key   =  b . key1 )   JOIN  c  ON   ( c . key   =  b . key1 ) \n \n 1 2 3 4 5 6 7 8 9 \n \n JOIN 时的最后一个表会通过 reducer 流式传输，并且在其中缓冲之前的其他表，因此大表在最后利于减少 reducer 阶段缓存数据需要的内存。 \n \n \n JOIN 时可以通过语法  STREAMTABLE  提示需要进行流式传输的表，假如省略此关键字，则默认流式传输最右边的表。 \n \n \n JOIN 在 WHERE 之前执行。 \n \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 26, 2022 10:02",createTimeStamp:1643162539e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hive-02-DDL",frontmatter:{title:"Hive-02-DDL",categories:["bigdata"],tags:["hive"],author:"causes",summary:"DDL 概述 数据定义语言：Data Definition Language，DDL，是 SQL 中对数据库内部对象（数据库 schema、数据表 table、数据视图 view、索引 index）的结构进行增删改的操作语言。 核心语法即：CREATE、ALTER、DROP 等。 HQL 基本和 SQL 相同，在此基础上添加了一些特有的语法，例如分区 par",meta:[{property:"og:url",content:"/bigdata/Hive/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hive-02-DDL"},{property:"og:description",content:"DDL 概述 数据定义语言：Data Definition Language，DDL，是 SQL 中对数据库内部对象（数据库 schema、数据表 table、数据视图 view、索引 index）的结构进行增删改的操作语言。 核心语法即：CREATE、ALTER、DROP 等。 HQL 基本和 SQL 相同，在此基础上添加了一些特有的语法，例如分区 par"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hive"}]},regularPath:"/bigdata/Hive/part2.html",relativePath:"bigdata/Hive/part2.md",key:"v-6f1ebf2a",path:"/bigdata/Hive/part2/",headers:[{level:2,title:"DDL 概述",slug:"ddl-概述"},{level:2,title:"DDL 基础",slug:"ddl-基础"},{level:3,title:"Hive 数据类型",slug:"hive-数据类型"},{level:3,title:"Hive 读写文件机制",slug:"hive-读写文件机制"},{level:3,title:"Hive 数据存储",slug:"hive-数据存储"},{level:2,title:"DDL 深入",slug:"ddl-深入"},{level:3,title:"Hive 内外表",slug:"hive-内外表"},{level:3,title:"Hive 分区",slug:"hive-分区"},{level:3,title:"Hive 分桶",slug:"hive-分桶"},{level:3,title:"Hive 事务和视图",slug:"hive-事务和视图"},{level:2,title:"DDL 其余相关操作",slug:"ddl-其余相关操作"},{level:3,title:"数据库操作",slug:"数据库操作"},{level:3,title:"表操作",slug:"表操作"},{level:3,title:"Hive show 展示语法",slug:"hive-show-展示语法"}],readingTime:{minutes:14,words:4200},content:" DDL 概述 \n 数据定义语言：Data Definition Language，DDL，是 SQL 中对数据库内部对象（数据库 schema、数据表 table、数据视图 view、索引 index）的结构进行增删改的操作语言。 \n 核心语法即： CREATE 、 ALTER 、 DROP  等。 \n HQL 基本和 SQL 相同，在此基础上添加了一些特有的语法，例如分区 partition。 \n DDL 基础 \n Hive 数据类型 \n 完整建表语法 \n CREATE   [ TEMPORARY ]   [ EXTERNAL ]   TABLE   [ IF   NOT   EXISTS ]   [ db_name . ] table_name\n [ ( col_name data_type  [ COMMENT  col_comment ] ,  …… ) ] \n [ COMMENT  table_comment ] \n [ PARTITIONED  BY   ( col_name data_type  [ COMMENT  col_comment ] ,  …… ) ] \n [ CLUSTERED   BY   ( col_name ,  col_name ,  …… )   [ SORTED  BY   ( col_name  [ ASC | DESC ] ,  …… ) ]   INTO  num_buckets BUCKETS ] \n [ ROW  FORMAT DELIMITED  [ FIELDS   TERMINATED   BY   char ]   [ COLLECTION ITEMS  TERMINATED   BY   char ]    [ MAP  KEYS   TERMINATED   BY   char ]   [ LINES   TERMINATED   BY   char ]   |  SERDE serde_name  WITH  SERDEPROPERTIES  ( property_name = property_value ,  …… ) ] \n [ STORED  AS  file_format ] \n [ LOCATION hdfs_path ] \n [ TBLPROPERTIES  ( property_name = property_value ,  …… ) ] \n \n 1 2 3 4 5 6 7 8 9 大写字母为关键字。中括号内语法表示可选。分隔符表示左右语法二选一。 \n \n Hive 数据类型 \n Hive 中，数据类型分为： \n \n \n 原生数据类型：数值、时间、字符串、杂项。 \n \n \n \n 复杂数据类型：array 数组、map 映射、struct 结构、union 联合体。 \n \n \n \n Tips \n \n \n Hive 对英文字母大小写不敏感，除了 SQL 数据类型还支持 Java 数据类型（例如 String）。 \n \n \n 复杂类型的使用通常和分隔符语法配合。 \n \n \n 如果定义的数据类型不一致，Hive 会尝试隐式转换，但是不一定能成功 \n \n \n \n 除了隐式转换之外，还可以使用  CAST  来进行显式类型转换 CAST(数据字段 AS 新类型)，例如  CAST ('INT' AS INT)  强制转为 INT 类型，但是转换失败，返回 NULL。 \n Hive 读写文件机制 \n SerDe \n SerDe，是 Serializer、Deserializer 的简称目的是序列化（对象到字节码）和反序列化（字节码到对象）。Hive 可使用 SerDe 进行对象的读取和写入。 \n Hive 读写文件流程 \n Hive 读取文件：调用 InputFormat（Hadoop 默认是使用 TextInputFormat），返回 KV 键值对，然后调用 SerDe（默认是 LazySimpleSerDe），将 value 根据分隔符切分为各个字段。 \n Hive 写文件：调用 SerDe（默认是 LazySimpleSerDe）转为字节序列，然后调用 OutputFormat 写入 HDFS。 \n SerDe 相关语法 \n [ROW FORMAT DELIMITED | SERDE] \n 其中， ROW FORMAT  为关键字，DELIMITED 和 SERDE 二选一。 \n DELIMITED  表示使用默认的 SERDE 类： LazySimpleSerDe  类来进行数据处理。假如数据格式特殊，可以使用  ROW FORMAT SERDE serde_name  指定其他的 SERDE 类来进行处理，甚至还可以自定义 SERDE 类。 \n LazySimpleSerDe \n LazySimpleSerDe 是 Hive 中默认的序列化类，可以指定字段之间、集合元素之间、map 映射之间、换行之间的分隔符，在建表的时候可以灵活搭配。 \n \n Tips \n 假如没有指定默认的  ROW FORMAT ，那么默认的字段分隔符是  \\001 ，使用的是 ASCII 编码，显示为  SOH ，在 vim 中显示为  ^A 。使用键盘无法打出。 \n Hive 数据存储 \n 默认存储路径 \n Hive 默认存储在  ${HIVE_HOME}/conf/hive-site.xml  配置文件的  hive.metastore.warehouse.dir  中指定，默认值为  /user/hive/warehouse 。 \n Hive 的库、表均存储在此路径下。 \n 指定存储路径 \n 在 Hive 建表时可使用  LOCATION ${location}  指定在 HDFS 上的路径。 \n DDL 深入 \n Hive 内外表 \n Hive 内部表 \n 内部表，Internal Table，被称为被 Hive 拥有和管理的托管表，默认创建的就是内部表。 \n 当删除内部表时，Hive 会同时删除内部表的数据和内部表的元数据。 \n 使用  DESCRIBE FORMATTED ${table_name}  查看表的描述信息，进而查看表的类型，其中 Table Type 为  MANAGED_TABLE  表示的就是内部表。 \n \n Hive 外部表 \n 外部表，External Table，它的元数据被 Hive 管理但是实际数据不会被 Hive 管理。 \n 简单来说，删除外部表不会删除表的数据，只会删除表的元数据。 \n 外部表需要使用关键字  EXTERNAL  声明，并且一般搭配  LOCATION  指定数据的具体路径。 \n 使用  DESCRIBE FORMATTED ${table_name}  查看表的描述信息，进而查看表的类型，其中 Table Type 为  EXTERNAL_TABLE  表示的就是外部表。 \n \n 内外表的其他区别 \n 除了数据管理的区别之外，它们还有其他区别： \n \n 内外表互相转换 \n -- 修改表为外部表 \n ALTER   TABLE  hero  SET  tblproperties  ( 'EXTERNAL' = 'TRUE' ) ; \n -- 查询表，此时 Table Type 一栏中已经变为了 EXTERNAL_TABLE，代表外部表 \n DESC  FORMATTED hero ; \n\n -- 设置表为内部表，此时 Table Type 一栏中变为了 MANAGED_TABLE，代表内部表，也就是受管理的表 \n ALTER   TABLE  hero  SET  tblproperties  ( 'EXTERNAL' = 'FALSE' ) ; \n \n 1 2 3 4 5 6 7 #  Hive 分区 \n 分区概念 \n 之前我们提到过分区这个概念，分区其实是为了帮助数据查找的一种手段。 \n 比如，我们将一年的数据根据月份划分为十二个分区，在物理上，不同分区的数据会存储到 HDFS 中的不同文件夹下面。这样一来，查询某个月份的分区就只需要从某个文件夹下面查找，避免了全部数据的扫描。 \n 分区需要使用  PARTITIONED BY  关键字指定按照什么字段进行分区： \n CREATE   TABLE  hero ( \n    id  int , \n    name string\n )  PARTITIONED  BY   ( role string ) \n ROW  FORMAT DELIMITED\n FIELDS   TERMINATED   BY   \"\\t\" ; \n \n 1 2 3 4 5 6 上面这张表 hero 存在 id 和 name 两个字段，使用  role  字段进行分区，使用 DELIMITED 代表的 LazySimpleSerDe 进行文件读写，使用 \"\\t\" 作为分隔符。 \n 需要注意的是，分区字段  role  不能是表中已经存在的字段，因为最终分区字段也会以一种虚拟字段的形式显示在表结构上。 \n 分区也分为静态分区和动态分区： \n \n 静态分区：在创建表的时候手动指定分区字段和分区值。 \n 动态分区：基于查询结果动态推断出分区字段和分区值。 \n \n 静态分区 \n 之前已经说明了，静态分区是手动指定的分区字段和分区值，那么首先就要创建一个表： \n CREATE   TABLE  hero  ( \n      id  int , \n      name string , \n      hp_max  int , \n      mp_max  int , \n      attack_max  int , \n      defense_max  int , \n      attack_range string , \n      role_main string , \n      role_assist string\n )  PARTITIONED  BY   ( role string ) \n ROW  FORMAT DELIMITED\n FIELDS   TERMINATED   BY   \"\\t\" ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 之后进行数据的导入，在导入时指定字段的静态分区，语法为： LOAD DATA [LOCAL] INPATH '' INTO TABLE ${table_name} PARTITION (${partition_key}=${partition_value}) \n LOAD 表示加载数据，之后详解。LOCAL 则表示从本地文件系统加载，默认是 HDFS 加载。 \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/archer.txt'   INTO   TABLE  hero  PARTITION   ( role = 'archer' ) ; \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/assassin.txt'   INTO   TABLE  hero  PARTITION   ( role = 'assassin' ) ; \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/mage.txt'   INTO   TABLE  hero  PARTITION   ( role = 'mage' ) ; \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/support.txt'   INTO   TABLE  hero  PARTITION   ( role = 'support' ) ; \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/tank.txt'   INTO   TABLE  hero  PARTITION   ( role = 'tank' ) ; \n LOAD   DATA   LOCAL  INPATH  '/tmp/hero/warrior.txt'   INTO   TABLE  hero  PARTITION   ( role = 'warrior' ) ; \n \n 1 2 3 4 5 6 以上情况加载了文件，在 HDFS 上将会有分区，分别存储对应的文件： \n \n \n 动态分区 \n 启用动态分区，首先要在 hive 的 session 中设置两个参数： \n -- 开启动态分区\nSET hive.exec.dynamic.partition=true;\n-- 指定动态分区的模式为非严格模式，非严格模式下不必有静态分区；严格模式设置为 strict，要求至少有一个分区为静态分区。\nSET hive.exec.dynamic.partition.mode=nonstrict;\n \n 1 2 3 4 执行动态分区，其实是执行的动态分区 + 插入，核心就是  INSERT + SELECT 。 \n -- 创建表，这里的内容和之前的静态分区的 hero 表相同 \n CREATE   TABLE  dynamicHero ( \n    id  int , \n    name string , \n    hp_max  int , \n    mp_max  int , \n    attack_max  int , \n    defense_max  int , \n    attack_range string , \n    role_main string , \n    role_assist string\n )  PARTITIONED  BY   ( role string ) \n ROW  FORMAT DELIMITED\n FIELDS   TERMINATED   BY   \"\\t\" ; \n\n -- 执行动态分区插入，核心思想是使用 INSERT + SELECT \n -- 分区值将会通过返回字段的位置确定，普通的为 tmp.*，之后的 role 就是 tmp.role_main \n INSERT   INTO   TABLE  dynamicHero  PARTITION ( role ) \n SELECT  tmp . id ,  tmp . name ,  tmp . hp_max ,  tmp . mp_max ,  tmp . attack_max ,  tmp . defense_max ,  tmp . attack_range ,  tmp . role_main ,  tmp . role_assist ,  tmp . role_main  FROM  hero tmp ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 动态分区在插入的时候会使用位置自动推断。 \n 之前讲过，分区字段 hero 在表现上也会占用一个字段，也就是说从我们的角度看，hero 表有四个字段：id、name、role_main、role。 \n 以上这段 SQL 在查询的时候，首先会查询出原有的三个字段，分别对应着 id、name、role_main，之后我们查询出的 tmp.role_main 将会被分配到 hero 字段上，所以在分配分区的时候其实是根据 role_main 来分配的。 \n 分区的本质 \n 之前说过，分区的本质其实就是将分区分为了多个文件夹，数据存放到不同的分区文件夹中，分区文件夹的名字为  分区字段=分区值 。 \n 分区字段是虚拟字段，数据不会存储在底层文件中。分区本质上是一种优化手段，是可选项。Hive 支持在分区的基础上继续分区，也就是多重分区。 \n 多重分区 \n 在多重分区下，分区是一种递进关系，在物理上表现为：在分区文件夹下面继续划分子分区文件夹。 \n 创建多重分区只需要指定多个 partition，比如： CREATE TABLE hero(...) PARTITIONED BY (partition1 string, partition2 string, ...) \n 常见的多重分区，例如按照地区划分（省市县）、按照时间划分（年月日）等。 \n Hive 分桶 \n 分桶概念 \n 分桶表也叫做桶表，来源于 bucket。Hive 的分桶也是一种优化手段，不过和分区不同，分区是将数据分到多个文件夹下存储，但分区文件夹下面还是一份文件；分桶则是将一个分区中的数据分为多个文件。 \n 桶的编号相同就会分到同一个 bucket 中。 \n 分桶语法 \n [ CLUSTERED   BY   ( ${col_name} )   [ SORTED  BY   ( ${col_name  ASC | DESC } ) ]   INTO  N BUCKETS ] ; \n \n 1 CLUSTERED BY (${col_name}) SORTED BY (${col_name ASC|DESC})  表示根据什么字段进行分， INTO N BUCKETS  表示分为 N 桶。 \n 注意，和分区表不同，分桶表的字段必须是表中已经存在的字段。 \n -- 分桶，分桶表的字段必须为表中已经存在的字段 \n -- 按照 ID 划分为 5 桶 \n CREATE   TABLE   IF   NOT   EXISTS  bucketHero ( \n    id  int , \n    name string , \n    hp_max  int , \n    mp_max  int , \n    attack_max  int , \n    defense_max  int , \n    attack_range string , \n    role_main string , \n    role_assist string\n )   CLUSTERED   BY   ( id )   INTO   5  BUCKETS ; \n\n INSERT   INTO  bucketHero  SELECT  id ,  name ,  hp_max ,  mp_max ,  attack_max ,  defense_max ,  attack_range ,  role_main ,  role_assist  FROM  hero ; \n\n -- 按照 ID 划分为 5 桶，并且按照 attack_max 进行排序 \n CREATE   TABLE   IF   NOT   EXISTS  bucketHeroWithSort  ( \n    id  int , \n    name string , \n    hp_max  int , \n    mp_max  int , \n    attack_max  int , \n    defense_max  int , \n    attack_range string , \n    role_main string , \n    role_assist string\n )   CLUSTERED   BY   ( id )  SORTED  BY   ( attack_max  DESC )   into   5  BUCKETS ; \n\n INSERT   INTO  bucketHeroWithSort  SELECT  id ,  name ,  hp_max ,  mp_max ,  attack_max ,  defense_max ,  attack_range ,  role_main ,  role_assist  FROM  hero ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 分桶表的好处 \n \n 减少全表扫描。 \n JOIN 时可以减少笛卡尔积。 \n 数据量特别大时，可以使用分桶对数据进行抽样检测。 \n Hive 事务和视图 \n 事务 \n Hive 的核心目标是为了数据的查询和分析用的，所以在设计之初不支持事务。 \n 但是有些数据仍然有可能会出现一些错误，这些数据就需要修改和删除，那么从 Hive0.14 开始，Hive 就开始支持更新删除以及事务操作。 \n 虽然 Hive 现在支持事务，但是 Hive 本质上不是用来做这个的，所以限制会比较多，并且不像 MySQL 那样方便： \n \n 所有语言操作都是自动提交的，不支持手动事务。 \n 默认情况下为关闭，必须手动配置开启。 \n 必须是分桶表才可以支持事务功能。 \n 表的参数  transactional  必须为 true。 \n 外部表不可能成为 ACID 表。 \n \n 视图 \n Hive 中的视图分为两种，一种是普通视图（view），一种是物化视图（materialized view）。 \n 普通视图是用来简化操作的，比如我们有很复杂的查询语句，每次都写一遍太过复杂，就可以创建这样一种视图来简化操作，每次查询这个视图的时候就相当于执行了之前的复杂查询语句。 \n 普通视图是虚表，不会提高查询性能，也没有缓存记录，当然也不可以进行数据的插入或者更改： \n -- 创建视图 \n CREATE   VIEW  v_hero  AS   SELECT   *   FROM  hero ; \n\n -- 从已有的视图中创建新的视图 \n CREATE   VIEW  v_hero_inside  AS   SELECT  name  FROM  v_hero ; \n\n -- 展示视图 \n SHOW  VIEWS ; \n\n -- 查看视图定义 \n SHOW   CREATE   TABLE  v_hero_inside ; \n\n -- 删除视图，因为视图是虚拟的，所以不会对数据进行操作 \n DROP   VIEW  v_hero_inside ; \n\n -- 改变视图定义 \n ALTER   VIEW  v_hero  AS   SELECT  attack_max  FROM  hero ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 物化视图 \n 物化视图和视图不同，这里的物化视图其实就可以看作是传统关系型数据库的物化视图。物化视图是一个包含查询结果的数据库对象，是实表，是有真实数据的，在查询的时候可以预先计算保存，然后避免耗时操作。 \n 当然，因为通过了预计算得到了结果，当然需要一定的存储空间。Hive3.0 开始引入了物化视图，结果可以存储到 Hive 中，也可以存储到自定义的系统中。 \n Hive 引入物化视图就是为了抛弃 index 索引的语法，逐渐转为物化视图加快存储速度，但是当前特性还不是很多，只能说未来可期。 \n DDL 其余相关操作 \n 数据库操作 \n 数据库创建 \n CREATE   SCHEMA   |   DATABASE   [ IF   NOT   EXISTS ]  demo\n COMMENT   \"注释\" \nLOCATION  \"${HDFS LOCATION}\" \n WITH  DBPROPERTIES  ( ${属性名} = ${属性值} ) \n \n 1 2 3 4 -- `COMMENT`：注释 \n -- `LOCATION`：指定存储到 HDFS 的位置，默认采用配置文件中的 `/user/hive/warehouse` \n -- `WITH DBPROPERTIES`：指定一些数据库的属性配置。 \n CREATE   SCHEMA   IF   NOT   EXISTS  demo\n COMMENT   \"CREATE THE DEMO DATABASE\" \n WITH  DBPROPERTIES  ( \"author\" = \"causes\" ) \n \n 1 2 3 4 5 6 数据展示信息 \n -- 展示更多信息，DESCRIBE DATABASE/SCHEMA EXTENDED ${table_name}; \n -- EXTENDED 用于展示更多信息 \n DESCRIBE   SCHEMA   EXTENDED  demo ; \n \n 1 2 3 切换数据库 \n -- USE ${table_name} \n USE  demo ; \n \n 1 2 删除数据库 \n -- 删除数据库，DROP DATABASE IF EXISTS ${demo} RESTRICT | CASCADE \n -- RESTRICT：仅仅在数据库为空（没有表）才可以删除，默认值 \n -- CASCADE：强制删除 \n DROP   DATABASE  demo ; \n \n 1 2 3 4 更改与当前数据库关联的元数据信息 \n -- ALTER DATABASE | SCHEMA ${db_name} SET DBPROPERTIES (${property_name}=${property_value}) \n ALTER   DATABASE  demo  SET  DBPROPERTIES  ( \"author\" = \"causes\" ) ; \n\n -- 更改用户所有者，ALTER DATABASE | SCHEMA ${db_name} SET OWNER USER | ROLE ${user}; \n ALTER   SCHEMA  demo  SET  OWNER ROLE causes ; \n\n -- 更改数据库位置，ALTER DATABASE | SCHEMA ${db_name} SET LOCATION ${HDFS_PATH} \n ALTER   DATABASE  demo  SET  LOCATION  \"${HDFS_PATH}\" ; \n \n 1 2 3 4 5 6 7 8 #  表操作 \n 查看表 \n -- 查看表，DESCRIBE EXTENDED | FORMATTED ${table_name} \n --  EXTENDED：Thrift 序列化形式展示表的元数据 \n -- FORMATTED：表格形式展示元数据 \n DESCRIBE  FORMATTED hero ; \n \n 1 2 3 4 删除表 \n -- 删除表，DROP TABLE IF EXISTS ${table_name} PURGE \n -- 普通情况下，表数据不会被立刻删除，而是进入垃圾桶（假如已经配置了垃圾桶，则会进入 .Trash/Current 目录），假如指定了 PURGE 则会跳过垃圾桶，立刻删除 \n DROP   TABLE   IF   EXISTS  hero  PURGE ; \n \n 1 2 3 清空表 \n -- TRUNCATE TABLE ${table_name} \n -- 清空表的数据，但是保留元数据，假如 HDFS 启动了垃圾桶则会进入垃圾桶，否则会被立刻删除 \n TRUNCATE   TABLE  hero ; \n \n 1 2 3 修改表 \n -- 更改表名 \n ALTER   TABLE  table_name  RENAME   TO  new_table_name ; \n\n -- 更改表属性 \n ALTER   TABLE  table_name  SET  TBLPROPERTIES  ( property_name  =  property_value ,   . . .   ) ; \n\n -- 更改表注释 \n ALTER   TABLE  student  SET  TBLPROPERTIES  ( 'comment'   =   \"new comment for student table\" ) ; \n\n -- 更改 SerDe 属性 \n ALTER   TABLE  table_name  SET  SERDE serde_class_name  [ WITH  SERDEPROPERTIES  ( property_name  =  property_value ,   . . .   ) ] ; \n ALTER   TABLE  table_name  [ PARTITION  partition_spec ]   SET  SERDEPROPERTIES serde_properties ; \n ALTER   TABLE  table_name  SET  SERDEPROPERTIES  ( 'field.delim'   =   ',' ) ; \n\n --移除 SerDe 属性 \n ALTER   TABLE  table_name  [ PARTITION  partition_spec ]  UNSET SERDEPROPERTIES  ( property_name ,   . . .   ) ; \n\n -- 更改表的文件存储格式 该操作仅更改表元数据。现有数据的任何转换都必须在 Hive 之外进行 \n ALTER   TABLE  table_name   SET  FILEFORMAT file_format ; \n -- 更改表的存储位置路径 \n ALTER   TABLE  table_name  SET  LOCATION  \"new location\" ; \n\n -- 更改列名称/类型/位置/注释 \n ALTER   TABLE  test_change CHANGE a a1  INT   COMMENT   'this is column a1' ; ; \n\n -- 添加 / 替换列 \n -- 使用 ADD COLUMNS，您可以将新列添加到现有列的末尾但在分区列之前 \n -- REPLACE COLUMNS 将删除所有现有列，并添加新的列集 \n ALTER   TABLE  table_name  ADD | REPLACE   COLUMNS   ( col_name data_type , . . . ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #  Hive show 展示语法 \n SHOW 相关的语句提供了一系列的，查询 Hive Metastore 的命令，可以帮助用户查询相关信息，在这里我们讲解一下比较常见的内容。 \n -- 展示某个数据库中的所有表，不填 IN xxx 则为当前数据库。视图也是类似。 \n SHOW   TABLES   IN   default ; \n\n -- 展示某张表的分区信息 \n SHOW  PARTITIONS hero ; \n\n -- 展示表的扩展信息，例如名称、所属用户、位置、inputformat、outputformat 等 \n SHOW   TABLE   EXTENDED   LIKE  hero ; \n\n -- 展示表的属性信息，例如 是否为外部表、最后修改用户等 \n SHOW  TBLPROPERTIES hero ; \n\n -- 展示表中的所有列，包括分区列 \n SHOW   COLUMNS   IN  hero ; \n\n -- 展示可用函数，包括内置和自定义的 \n SHOW  FUNCTIONS ; \n\n -- 查看表信息，可以使用 FORMATTED 格式化 \n DESC   EXTENDED  hero ; \n\n -- 查看数据库相关信息 \n DESCRIBE   DATABASE   default ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 26, 2022 10:02",createTimeStamp:1643162539e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Kafka-03-组件对接",frontmatter:{title:"Kafka-03-组件对接",categories:["bigdata"],tags:["kafka"],author:"causes",summary:"Flume 和 Kafka 对接 简单实现 对于 Flume 和 Kafka 来讲，最重要的就是组件之间的对接。Kafka 本身是没有什么组件一说的，最主要的就是 Flume。 Flume 官方提供了 Kafka Source、Kafka Sink 以及 Kafka Channel，用于对接。 kafka source，flume 从 kafka 读取数据。",meta:[{property:"og:url",content:"/bigdata/Kafka/part3.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Kafka-03-组件对接"},{property:"og:description",content:"Flume 和 Kafka 对接 简单实现 对于 Flume 和 Kafka 来讲，最重要的就是组件之间的对接。Kafka 本身是没有什么组件一说的，最主要的就是 Flume。 Flume 官方提供了 Kafka Source、Kafka Sink 以及 Kafka Channel，用于对接。 kafka source，flume 从 kafka 读取数据。"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"kafka"}]},regularPath:"/bigdata/Kafka/part3.html",relativePath:"bigdata/Kafka/part3.md",key:"v-0f870848",path:"/bigdata/Kafka/part3/",headers:[{level:2,title:"Flume 和 Kafka 对接",slug:"flume-和-kafka-对接"},{level:3,title:"简单实现",slug:"简单实现"}],readingTime:{minutes:2.58,words:775},content:' Flume 和 Kafka 对接 \n 简单实现 \n 对于 Flume 和 Kafka 来讲，最重要的就是组件之间的对接。Kafka 本身是没有什么组件一说的，最主要的就是 Flume。 \n Flume 官方提供了  Kafka Source 、 Kafka Sink  以及  Kafka Channel ，用于对接。 \n kafka source，flume 从 kafka 读取数据。那么对于 kafka 来说，kafka source 就是一个消费者的角色。 \n kafka sink，flume 写到 kafka 中，对于 kafka 来说，kafka sink 是一个生产者的角色。 \n 对于 flume 来说，channel 是一个 source 到 sink 的一个缓存，那么 kafka channel 就是使用 kafka 来做缓。 \n 而且不仅如此，官方其实提供了三种使用场景： \n \n kafka source -> kafka channel -> kafka sink，全都使用 kafka，就是一种相当可靠的解决方案。 \n kafka source -> kafka channel，此场景中没有 sink，但是数据也直接进入到了 kafka 中。 \n kafka channel -> kafka sink，此场景中没有 kafka source，但是使用 kafka channel 也可以直接读取数据。 \n \n 所以 kafka channel 相当于是一个万金油的组件，功能十分强大。 \n 案例 \ndefine \na1.sources  =  r1\na1.sinks  =  k1\na1.channels  =  c1\nsource \na1.sources.r1.type  =   exec \na1.sources.r1.command  =   tail  -F  /opt/module/data/flume.log\nsink \na1.sinks.k1.type  =  org.apache.flume.sink.kafka.KafkaSink\na1.sinks.k1.kafka.bootstrap.servers  =  hadoop102:9092,hadoop103:9092,hadoop104:9092\na1.sinks.k1.kafka.topic  =  first\na1.sinks.k1.kafka.flumeBatchSize  =   20 \na1.sinks.k1.kafka.producer.acks  =   1 \na1.sinks.k1.kafka.producer.linger.ms  =   1 \nchannel \na1.channels.c1.type  =  memory\na1.channels.c1.capacity  =   1000 \na1.channels.c1.transactionCapacity  =   100 \nbind \na1.sources.r1.channels  =  c1\na1.sinks.k1.channel  =  c1\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 拦截器案例 \n a1.sources  =  r1\na1.sinks  =  k1\na1.channels  =  c1\n\na1.sources.r1.type  =  netcat\na1.sources.r1.bind  =   0.0 .0.0\na1.sources.r1.port  =   6666 \n\na1.sinks.k1.type  =  org.apache.flume.sink.kafka.KafkaSink\na1.sinks.k1.kafka.topic  =  third\na1.sinks.k1.kafka.bootstrap.servers  =  hadoop102:9092,hadoop103:9092,hadoop104:9092\na1.sinks.k1.kafka.flumeBatchSize  =   20 \na1.sinks.k1.kafka.producer.acks  =   1 \na1.sinks.k1.kafka.producer.linger.ms  =   1 \n注意，这里的拦截器需要配置好，首先将 jar 放到 flume 下的 lib 目录下，之后配置 \na1.sources.r1.interceptors  =  i1\na1.sources.r1.interceptors.i1.type  =  com.atguigu.kafka.flumeInterceptor.FlumeKafkaInterceptor $MyBuilder \n\na1.channels.c1.type  =  memory\na1.channels.c1.capacity  =   1000 \na1.channels.c1.transactionCapacity  =   100 \n\na1.sources.r1.channels  =  c1\na1.sinks.k1.channel  =  c1\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 通过拦截器，我们可以实现将分流的操作，也就是按照数据的不同类型分给 kafka 的多个 topic 上。 \n package   com . atguigu . kafka . flumeInterceptor ; \n\n import   org . apache . flume . Context ; \n import   org . apache . flume . Event ; \n import   org . apache . flume . interceptor . Interceptor ; \n\n import   javax . swing . text . html . HTMLEditorKit ; \n import   java . util . List ; \n import   java . util . Map ; \n\n public   class   FlumeKafkaInterceptor   implements   Interceptor   { \n     @Override \n     public   void   initialize ( )   { \n\n     } \n\n     /**\n     * 如果包含"atguigu"的数据，发送到first主题\n     * 如果包含"sgg"的数据，发送到second主题\n     * 其他的数据发送到third主题\n     * @param event\n     * @return\n     */ \n     @Override \n     public   Event   intercept ( Event  event )   { \n         //1.获取event的header \n         Map < String ,   String >  headers  =  event . getHeaders ( ) ; \n         //2.获取event的body \n         String  body  =   new   String ( event . getBody ( ) ) ; \n         if ( body . contains ( "atguigu" ) ) { \n            headers . put ( "topic" , "first" ) ; \n         } else   if ( body . contains ( "sgg" ) ) { \n            headers . put ( "topic" , "second" ) ; \n         } \n         return  event ; \n\n     } \n\n     @Override \n     public   List < Event >   intercept ( List < Event >  events )   { \n         for   ( Event  event  :  events )   { \n           intercept ( event ) ; \n         } \n         return  events ; \n     } \n\n     @Override \n     public   void   close ( )   { \n\n     } \n\n     public   static   class   MyBuilder   implements    Builder { \n\n         @Override \n         public   Interceptor   build ( )   { \n             return    new   FlumeKafkaInterceptor ( ) ; \n         } \n\n         @Override \n         public   void   configure ( Context  context )   { \n\n         } \n     } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 ',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"April 29, 2022 10:23",createTimeStamp:1651199022e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Hive-05-函数",frontmatter:{title:"Hive-05-函数",categories:["bigdata"],tags:["hive"],author:"causes",summary:"函数基础 Hive SQL 内置了不少函数，能满足在开发时的基本需求，可以使用 show functions 查看当前版本支持的函数，并且可以通过 DESCRIBE FUNCTION EXTENDED func_name; 来查看函数的使用方法。 内置函数 内置函数（buildin），指的是 Hive 已经开发实现好，等待调用的函数，也叫做内建函数。官方文档",meta:[{property:"og:url",content:"/bigdata/Hive/part5.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Hive-05-函数"},{property:"og:description",content:"函数基础 Hive SQL 内置了不少函数，能满足在开发时的基本需求，可以使用 show functions 查看当前版本支持的函数，并且可以通过 DESCRIBE FUNCTION EXTENDED func_name; 来查看函数的使用方法。 内置函数 内置函数（buildin），指的是 Hive 已经开发实现好，等待调用的函数，也叫做内建函数。官方文档"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"hive"}]},regularPath:"/bigdata/Hive/part5.html",relativePath:"bigdata/Hive/part5.md",key:"v-46b05f24",path:"/bigdata/Hive/part5/",headers:[{level:2,title:"函数基础",slug:"函数基础"},{level:3,title:"内置函数",slug:"内置函数"},{level:3,title:"自定义函数",slug:"自定义函数"},{level:3,title:"函数高阶",slug:"函数高阶"}],readingTime:{minutes:16.79,words:5037},content:" 函数基础 \n Hive SQL 内置了不少函数，能满足在开发时的基本需求，可以使用  show functions  查看当前版本支持的函数，并且可以通过  DESCRIBE FUNCTION EXTENDED func_name;  来查看函数的使用方法。 \n 内置函数 \n 内置函数（buildin），指的是 Hive 已经开发实现好，等待调用的函数，也叫做内建函数。官方 文档 。 \n 内置函数根据应用类型可以分为八类，使用频率最高的将举例。 \n 字符串函数 \n 字符串函数主要是对字符串数据类型进行操作 \n -------------------------------------------- 字符串函数 -------------------------------------------- \n -- 字符串长度 \n SELECT  length ( 'HELLO WORLD' ) ; \n -- 字符串反转 \n SELECT  reverse ( 'HELLO WORLD' ) ; \n -- 字符串连接 \n SELECT  concat ( 'HELLO' ,   'WORLD' ) ; \n -- 使用分隔符进行连接 concat_ws(separator, [string | array(string)]+) \n SELECT  concat_ws ( '.' ,   'www' ,  array ( 'baidu' ,   'com' ) ) ; \n -- 字符串截取，注意，索引是从 1 开始，给定负数的意思是倒着数 substr(str, pos [, len]) \n SELECT  substr ( 'HELLO WORLD' ,   - 2 ) ; \n -- 字符串转大写，这两个没有区别 \n SELECT  upper ( 'hello world' ) ; \n SELECT   ucase ( 'hello world' ) ; \n -- 字符串转小写，这两个没有区别 \n SELECT  lower ( 'HELLO WORLD' ) ; \n SELECT   lcase ( 'HELLO WORLD' ) ; \n -- 去除字符串两边空格 \n SELECT  trim ( \" HELLO WORLD \" ) ; \n -- 去除左边空格 \n SELECT  ltrim ( \" HELLO WORLD\" ) ; \n -- 去除右边空格 \n SELECT  ltrim ( \"HELLO WORLD \" ) ; \n -- 正则替换，最终形成 num-num \n SELECT  regexp_replace ( '100-200' ,   '(\\\\d+)' ,   'num' ) ; \n -- 正则解析，可以提取指定的组的内容 \n SELECT  regexp_extract ( '100-200' ,   '(\\\\d)-(\\\\d)' ,   2 ) ; \n -- url 解析，想要一次解析多个 url 可以使用 parse_url_tuple 这个 UDTF 函数，最终形成 baike.baidu.com \n SELECT  parse_url ( 'https://baike.baidu.com/item/hello/38467?fr=aladdin' ,   'HOST' ) ; \n -- json 解析 \n SELECT  get_json_object ( '' ) ; \n -- 空格字符串函数，返回指定个数的空格 \n SELECT  space ( 4 ) ; \n -- 重复字符串 n 次 \n SELECT   repeat ( 'HELLO' ,   2 ) ; \n -- 将字符串的首字母转为 ASCII，返回 72 \n SELECT  ascii ( 'HELLO' ) ; \n -- 左补函数，使用指定符号，在此字符串的左边补齐到指定长度，这里最终为 `???hi` \n SELECT  lpad ( 'hi' ,   5 ,   '??' ) ; \n -- 右补函数，假如字符串的长度大于指定长度，则消减，这里最终为 `h` \n SELECT  rpad ( 'hi' ,   1 ,   '??' ) ; \n -- 字符串分割，[\"HELLO\",\"WORLD\"] \n SELECT  split ( 'HELLO WORLD' ,   '\\\\s+' ) ; \n -- 集合查找 \n SELECT  find_in_set ( 'a' , 'abc,b,a,cd,fe' ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 日期函数 \n 针对日期进行操作的函数 \n -------------------------------------------- 日期函数 -------------------------------------------- \n -- 获取当前日期：2022-03-25 \n SELECT   current_date ( ) ; \n -- 获取当前时间戳，在一次查询中，current_timestamp() 返回值相同 \n -- 返回值比 current_date() 更细致：2022-03-25 21:39:26.202000000 \n SELECT   current_timestamp ( ) ; \n -- 获取当前 UNIX 时间戳：1648215568 \n SELECT  unix_timestamp ( ) ; \n -- UNIX 时间戳转日期函数，可以进行格式化，返回 2022-03-25 13:39:28 \n SELECT  from_unixtime ( 1648215568 ) ; \n SELECT  from_unixtime ( 0 ,   'yyyy-MM-dd HH:mm:ss' ) ; \n -- 日期转 UNIX 时间戳函数，可以指定格式转换 \n SELECT  unix_timestamp ( '1999-12-12 13:01:03' ) ; \n SELECT  unix_timestamp ( '1999-12-12 13:01:03' ,   'yyyy-MM-dd HH:mm:ss' ) ; \n -- 抽取日期，返回 1999-07-12 \n SELECT  to_date ( '1999-07-12 04:12:52' ) ; \n -- 日期转年 \n SELECT   year ( '1999-07-12 04:12:52' ) ; \n -- 日期转月 \n SELECT   month ( '1999-07-12 04:12:52' ) ; \n -- 日期转天 \n SELECT   day ( '1999-07-12 04:12:52' ) ; \n -- 日期转分钟 \n SELECT   minute ( '1999-07-12 04:12:52' ) ; \n -- 日期转秒 \n SELECT   second ( '1999-07-12 04:12:52' ) ; \n -- 日期转周，weekofyear 表示年的第几周 \n SELECT  weekofyear ( '1999-07-12 04:12:52' ) ; \n -- 日期比较，要求格式为 yyyy-MM-dd \n SELECT  datediff ( '2012-12-08' ,   '2012-05-09' ) ; \n -- 日期增加 \n SELECT  date_sub ( '2012-01-1' ,   10 ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 数学函数 \n 主要进行数值运算 \n -------------------------------------------- 数学函数 -------------------------------------------- \n -- 取整，四舍五入，默认取整数，可以指定精度 \n SELECT   round ( 3.1415926 ) ; \n SELECT   round ( 3.1415926 ,   4 ) ; \n -- 向下取整 \n SELECT  floor ( 3.1415926 ) ; \n -- 向上取整 \n SELECT  ceil ( 3.1415926 ) ; \n -- 随机，默认返回一个 0-1 的随机数，可以指定种子得到一个稳定的随机数序列 \n SELECT  rand ( ) ; \n SELECT  rand ( 2 ) ; \n -- 二进制函数 \n SELECT  bin ( 18 ) ; \n -- 进制转换，将 17 从 10 进制转为 16 进制 \n SELECT  conv ( 17 ,   10 ,   16 ) ; \n -- 绝对值 \n SELECT  abs ( - 3 ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 集合函数 \n -------------------------------------------- 集合函数 -------------------------------------------- \n -- 长度 \n SELECT  size ( array ( 11 ,   22 ,   33 ) ) ; \n SELECT  size ( map ( 'id' ,   10086 ,   'name' ,   'zhangsan' ,   'age' ,   18 ) ) ; \n -- 取 map 的 keys \n SELECT  map_keys ( map ( 'id' ,   10086 ,   'name' ,   'zhangsan' ,   'age' ,   18 ) ) ; \n -- 取 map 的 values \n SELECT  map_values ( map ( 'id' ,   10086 ,   'name' ,   'zhangsan' ,   'age' ,   18 ) ) ; \n -- 判断数组是否包含指定元素 \n SELECT  array_contains ( array ( 11 ,   22 ,   33 ) ,   11 ) ; \n -- 数组排序 \n SELECT  sort_array ( array ( 11 ,   2 ,   3 ) ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 条件函数 \n -------------------------------------------- 条件函数 -------------------------------------------- \n -- 条件判断，假如 sex 为男，则返回 M，否则返回 W \n SELECT   if ( sex  =   '男' ,   'M' ,   'W' )   FROM  student ; \n -- 判空 \n SELECT  isnull ( '' ) ; \n -- 判非空 \n SELECT  isnotnull ( '' ) ; \n -- 空则转换 \n SELECT  nvl ( null ,   'HELLO' ) ; \n -- 非空查找，返回参数中第一个非空的值，假如全部为 null 则返回 null \n SELECT   coalesce ( null ,   11 ,   22 ,   33 ) ; \n -- 条件转换，类似 switch .. case .. default \n SELECT   CASE   100 \n            WHEN   50   THEN   'Jack' \n            WHEN   100   THEN   'Mary' \n            WHEN   150   THEN   'Tom' \n            ELSE   'Larry' \n            END ; \n -- nullif，假如 a == b，则返回 null，否则返回一个 \n SELECT   nullif ( 11 ,   11 ) ; \n -- 假如条件为 false 则抛异常，为 true 返回 null \n SELECT  assert_true ( 11   >   0 ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 类型转换函数 \n 可以转为任何类型 \n -------------------------------------------- 类型转换函数 -------------------------------------------- \n SELECT  cast ( 3.1415926   as   bigint ) ; \n SELECT  cast ( 3.1415926   as  string ) ; \n \n 1 2 3 数据脱敏函数 \n 对数据进行脱敏 \n -------------------------------------------- 数据脱敏函数 -------------------------------------------- \n -- 大写字母转为 X，小写字母转为 x，数字转为 n，可自定义替换 \n SELECT  mask ( 'ABc123def' ) ; \n -- 自定义替换的字母 \n SELECT  mask ( 'ABc123def' ,   '-' ,   '.' ,   '^' ) ; \n -- 对前 n 个字母脱敏 \n SELECT  mask_first_n ( 'ABc123def' ,   4 ) ; \n -- 对后 n 个字母脱敏 \n SELECT  mask_last_n ( 'ABc123def' ,   4 ) ; \n -- 除前 n 个，其余掩码 \n SELECT  mask_show_first_n ( 'ABc123def' ,   4 ) ; \n -- 除后 n 个，其余掩码 \n SELECT  mask_show_last_n ( 'ABc123def' ,   4 ) ; \n -- 返回字符串 hash 值掩码 \n SELECT  mask_hash ( 'ABc123def' ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 杂项函数 \n 杂项函数 \n -------------------------------------------- 杂项函数 -------------------------------------------- \n -- 调用 Java 函数 \n SELECT  java_method ( 'java.lang.Math' ,   'max' ,   11 ,   22 ) ; \n -- Java 反射 \n SELECT  reflect ( 'java.lang.Math' ,   'max' ,   11 ,   22 ) ; \n -- hash \n SELECT   hash ( 'HELLO' ) ; \n -- SHA-1 加密 \n SELECT  sha1 ( 'HELLO' ) ; \n -- SHA-2 家族算法加密：sha2(string/binary, int)、SHA-224, SHA-256, SHA-384, SHA-521 \n SELECT  sha2 ( 'HELLO' ,   224 ) ; \n -- CRC 32 加密 \n SELECT  crc32 ( 'HELLO' ) ; \n -- md5，md5 现在已经不安全了 \n SELECT  md5 ( 'HELLO' ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #  自定义函数 \n UDF、UDAF、UDTF 概述 \n 虽然 Hive 内置的函数有很多，但是可能会有有些业务需求是内置函数无法满足的，这种情况下如果我们可以自己针对业务自定义函数来实现需求。 \n 用户自定义函数简称 UDF，来源于 User Defined Function，自定义函数一共分为三种类型： \n \n UDF，User Defined Function：普通的用户自定义函数，一进一出。 \n UDAF，User Defined Aggregation Function：聚合函数，多进一出。 \n UDTF，User Defined Table Generating Function：表生成函数，一进多出。 \n \n 虽然 UDF、UDAF、UDTF 表面上看起来是用户编写开发的函数，但其实这套标准可以扩大到 Hive 的所有函数中，比如  count()  是多进一出，就可以归类到 UDAF 标准中。 \n 编写代码之前，首先准备 maven： \n < dependencies > \n     < dependency > \n         < groupId > org.apache.hive </ groupId > \n         < artifactId > hive-exec </ artifactId > \n         < version > 3.1.2 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.apache.hadoop </ groupId > \n         < artifactId > hadoop-common </ artifactId > \n         < version > 3.1.4 </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 UDF 案例 \n 现在有一个需求，就是将字符串的长度返回 \n \n \n 代码实现： \n package   udf ; \n\n import   org . apache . hadoop . hive . ql . exec . UDFArgumentException ; \n import   org . apache . hadoop . hive . ql . exec . UDFArgumentLengthException ; \n import   org . apache . hadoop . hive . ql . exec . UDFArgumentTypeException ; \n import   org . apache . hadoop . hive . ql . metadata . HiveException ; \n import   org . apache . hadoop . hive . ql . udf . generic . GenericUDF ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . ObjectInspector ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . primitive . PrimitiveObjectInspectorFactory ; \n\n import   java . io . IOException ; \n import   java . util . Objects ; \n\n /**\n* 定义 UDF 函数，继承 GenericUDF\n*/ \n public   class   StringLength   extends   GenericUDF   { \n\n /**\n* 可以执行函数的初始化，并且返回函数的返回值类型鉴别器对象\n*\n* @param arguments 输入参数类型的鉴别器对象\n* @return 返回值类型的鉴别器对象\n* @throws UDFArgumentException\n*/ \n @Override \n public   ObjectInspector   initialize ( ObjectInspector [ ]  arguments )   throws   UDFArgumentException   { \n     if   ( arguments . length  !=   1 )   { \n     throw   new   UDFArgumentLengthException ( \"input args length error\" ) ; \n     } \n     // 取得参数的鉴别器对象 \n     ObjectInspector  argument  =  arguments [ 0 ] ; \n     /*\n    ObjectInspector.Category，一个枚举类，支持 Hive 的五种类型：\n\n    - PRIMITIVE：基本类型\n    - LIST：集合\n    - MAP：kv 键值对\n    - STRUCT：结构体\n    - UNION：联合体\n    */ \n     // 判断参数的类型，假如不是基本类型则直接抛异常 \n     if   ( ! argument . getCategory ( ) . equals ( ObjectInspector . Category . PRIMITIVE ) )   { \n     throw   new   UDFArgumentTypeException ( 0 ,   \"input args type error\" ) ; \n     } \n     // 返回字符串长度为 int，所以需要返回 int 类型的鉴别器对象 \n     return   PrimitiveObjectInspectorFactory . javaIntObjectInspector ; \n } \n\n /**\n* 函数的逻辑处理\n*\n* @param arguments 输入参数\n* @return 返回值\n* @throws HiveException\n*/ \n @Override \n public   Object   evaluate ( DeferredObject [ ]  arguments )   throws   HiveException   { \n     Object  argument  =  arguments [ 0 ] . get ( ) ; \n     if   ( Objects . isNull ( argument ) )   { \n     return   0 ; \n     } \n     return  argument . toString ( ) . length ( ) ; \n } \n\n /**\n* 显示函数的帮助信息\n*/ \n @Override \n public   String   getDisplayString ( String [ ]  strings )   { \n     return   \"\" ; \n } \n\n /**\n* 可选，map 结束后执行关闭操作\n*\n* @throws IOException\n*/ \n @Override \n public   void   close ( )   throws   IOException   { \n     super . close ( ) ; \n } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 \n \n 将代码打为 jar 包，上传到 HiveServer2 所在的 Linux 系统，或者 HDFS 系统。 \n \n \n 进入客户端，使用命令  add jar jap_path.jar  将 jar 包添加到 classpath： ADD JAR /tmp/hivedata/StringLength.jar; 。 \n \n \n 创建一个临时函数，和 java class 关联： CREATE TEMPORARY FUNCTION func_name AS 'package.class_name'; ： CREATE TEMPORARY FUNCTION str_len AS 'udf.StringLength'; 。 \n \n \n 使用函数： SELECT func_name(name) FROM table_name; ： SELECT str_len('HELLO WORLD'); 。 \n \n \n UDTF 案例 \n 其他过程十分相似就不写了，关键在于代码： \n package   udtf ; \n\n import   org . apache . hadoop . hive . ql . exec . UDFArgumentException ; \n import   org . apache . hadoop . hive . ql . metadata . HiveException ; \n import   org . apache . hadoop . hive . ql . udf . generic . GenericUDTF ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . ObjectInspector ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . ObjectInspectorFactory ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . StructObjectInspector ; \n import   org . apache . hadoop . hive . serde2 . objectinspector . primitive . PrimitiveObjectInspectorFactory ; \n\n import   java . util . ArrayList ; \n import   java . util . Arrays ; \n import   java . util . List ; \n\n /**\n * 定义一个 UDTF 函数，可以将字符串按照分隔符切割成为独立的单词\n */ \n public   class  splitStr  extends   GenericUDTF   { \n\n   private   List < String >  outList  =   new   ArrayList < > ( ) ; \n\n   @Override \n   public   StructObjectInspector   initialize ( StructObjectInspector  argOIs )   throws   UDFArgumentException   { \n     // 1. 自定义输出数据的列名称和类型 \n     List < String >  fieldNames  =   new   ArrayList < > ( ) ; \n     List < ObjectInspector >  fieldOIs  =   new   ArrayList < > ( ) ; \n     // 2. 添加输出数据的列名和类型 \n    fieldNames . add ( \"lineToWord\" ) ; \n    fieldOIs . add ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ) ; \n     return   ObjectInspectorFactory . getStandardStructObjectInspector ( fieldNames ,  fieldOIs ) ; \n   } \n\n   @Override \n   public   void   process ( Object [ ]  args )   throws   HiveException   { \n     // 获取输入的值的原始数据 \n     String  arg  =  args [ 0 ] . toString ( ) ; \n     // 按照传入参数的第二个参数作为分隔符进行分隔 \n     String  splitKey  =  args [ 1 ] . toString ( ) ; \n     String [ ]  fields  =  arg . split ( splitKey ) ; \n     // 注意，最终在 Hive 呈现时，是很多行，在这里我们不要一次性输出集合内容，而是以集合为单位，一条一条输出内容 \n     Arrays . stream ( fields ) . forEach ( field  ->   { \n       try   { \n        outList . clear ( ) ; \n        outList . add ( field ) ; \n         // 以集合为单位，将数据写出 \n         forward ( outList ) ; \n       }   catch   ( HiveException  e )   { \n        e . printStackTrace ( ) ; \n       } \n     } ) ; \n   } \n\n   @Override \n   public   void   close ( )   throws   HiveException   { \n\n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #  函数高阶 \n UDTF 和 侧视图 \n explode \n 爆炸函数，explode，在分类上也属于 UDTF。 \n 简单来说，它可以将集合或者键值对进行拆分，一条/一对数据单独占用一行。 \n \n explode  函数本身就已经违反了关系型数据库设计准则的第一范式，但是在面向分析的数据仓库中，我们可以改变这些规则。 \n 一般情况下， explode  会和侧视图 lateral view 一起使用，单独用当然也可以。 \n explode  不能和其他字段一起出现，否则就会报错，这是因为： \n explode  属于 UDTF 函数。 \n 它的返回值可以理解为一张虚拟的表，其数据来源于源表，不能查询源表的同时查询虚拟表，简单来讲就是不能查一张表返回两张表的字段。 \n 从 SQL 的层面来说应该进行连表查询。Hive 专门提供了侧视图 lateral view，专门搭配 UDTF 这样的函数，以满足上述需求。 \n lateral view 侧视图 \n 它是一种特殊的语法，主要的作用就是搭配 UDTF 函数一起使用，用于解决 UDTF 函数一些查询限制的问题。 \n 侧视图的原理是将 UDTF 的结果构建成一张类似于视图的表，然后将源表的每一行和 UDTF 函数输出的每一行进行链接，形成一张虚拟的表，这样就避免了 UDTF 使用限制问题。 \n 使用侧视图时同时也可以针对 UDTF 产生的记录设置字段名称，产生的字段可以用于  group by 、 order by 、 limit  等语句中，不需要再单独嵌套一层子查询。 \n 侧视图语法： SELECT ... FROM table_name LATERAL VIEW UDTF() 别名 AS col1, col2, col3, ...; \n 案例： \n SELECT  a . name ,  b . year \n FROM  tableA a LATERAL  VIEW  explode ( year )  b  AS   year \n ORDER   BY  b . year   DESC ; \n \n 1 2 3 #  聚合 \n HQL 提供了几种内置的 UDAF 聚合函数，例如  max 、 min 、 avg ，我们将这些称为基础聚合函数。 \n 除了基础聚合之外，我们还有增强聚合。 \n 增强聚合需要根据多个维度进行分析，维度指的就是看待数据的角度，比如根据天、周、月三个角度进行数据的分析。 \n 数据准备 \n 我们首先来准备一些数据，来作为增强聚合的案例： \n /*\n    数据类似如下：\n\n    2018-03,2018-03-10,cookie1\n    2018-03,2018-03-10,cookie5\n    2018-03,2018-03-12,cookie7\n    2018-03,2018-03-12,cookie3\n    2018-03,2018-03-13,cookie2\n    2018-03,2018-03-13,cookie4\n    2018-03,2018-03-16,cookie4\n    2018-04,2018-03-10,cookie2\n    2018-04,2018-03-12,cookie3\n    2018-04,2018-03-13,cookie5\n    2018-04,2018-03-15,cookie6\n    2018-04,2018-03-15,cookie3\n    2018-04,2018-03-16,cookie2\n */ \n CREATE   TABLE  cookie_info  ( \n   month  string , \n   day  string , \n  cookieId string\n )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n LOAD   DATA   LOCAL  INPATH  '/tmp/hivedata/cookie_info.txt'   INTO   TABLE  cookie_info ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 grouping sets \n grouping sets ，它是一种将多个  group by  写到一个 sql 中的便利写法，等于将多个不同纬度的 group by 进行 union 操作。 \n -- 使用 grouping sets \n -- grouping__id 表示这一组结果属于哪个分组集合，注意有两个下划线 \n -- 根据 grouping sets 中的分组条件 month、day，1 代表 month，2 代表 day \n SELECT   month ,   day ,   count ( DISTINCT  cookieId )   AS  nums ,  GROUPING__ID\n FROM  cookie_info\n GROUP   BY   month ,   day \nGROUPING SETS  ( month ,   day ) \n ORDER   BY  GROUPING__ID ; \n\n -- 以上等价于 \n SELECT   month ,   null ,   count ( DISTINCT  cookieid )   AS  nums ,   1   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   month \n UNION   ALL \n SELECT   null ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,   2   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   day ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 SELECT   month ,   day ,   count ( DISTINCT  cookieId )   AS  nums ,  GROUPING__ID\n FROM  cookie_info\n GROUP   BY   month ,   day \nGROUPING SETS  ( month ,   day ,   ( month ,   day ) ) \n ORDER   BY  GROUPING__ID ; \n\n -- 以上等价于 \n SELECT   month ,   null ,   count ( DISTINCT  cookieid )   AS  nums ,   1   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   month \n UNION   ALL \n SELECT   null ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,   2   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   day \n UNION   ALL \n SELECT   month ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,   3   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   month ,   day ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 cube \n cube 的意思是，根据  group by  的维度的所有组进行聚合。对于 cube，假如存在 n 个维度，那么所有组合的个数为 2^n。 \n 例如，有三个维度 a、b、c，那么所有组合为： (a, b, c)、(a, b)、(a, c)、(b, c), (a), (b), (c), () 。 \n SELECT   month ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,  GROUPING__ID\n FROM  cookie_info\n GROUP   BY   month ,   day \n WITH  CUBE\n ORDER   BY  GROUPING__ID ; \n\n -- 等价于 \n SELECT   null ,   null ,   count ( DISTINCT  cookieid )   AS  nums ,   0   AS  GROUPING__ID  FROM  cookie_info\n UNION   ALL \n SELECT   month ,   null ,   count ( DISTINCT  cookieid )   AS  nums ,   1   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   month \n UNION   ALL \n SELECT   null ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,   2   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   day \n UNION   ALL \n SELECT   month ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,   3   AS  GROUPING__ID  FROM  cookie_info  GROUP   BY   month ,   day ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 rollup \n rollup 是 cube 的子集，以最左侧的维度为主 \n 比如有三个维度  a, b, c ，那么所有的聚合情况为： (a, b, c)、(a, b)、(a, c)、(a)、() \n SELECT   month ,   day ,   count ( DISTINCT  cookieid )   AS  nums ,  GROUPING__ID\n FROM  cookie_info\n GROUP   BY   month ,   day \n WITH ROLLUP \n ORDER   BY  GROUPING__ID ; \n \n 1 2 3 4 5 #  窗口函数 \n Window Function 窗口函数，也叫做 OLAP 函数，非常适合数据分析。 \n 最大的特点就是：输入值是从 SELECT 语句的结果集中的一行或者多行的窗口中获取的，也可以理解为行有多少窗口就开多大。 \n 通过 over 子句，窗口函数和其他的 SQL 函数有了区别，假如一个函数具有 over 子句，那么它是窗口函数，如果它缺少 over 子句，则它是一个普通聚合函数。 \n 窗口函数类似聚合函数，但是有些区别。通过 group by 子句组合的常规聚合会隐藏聚合中的行，最终输出为一行。 \n 窗口聚合函数不会隐藏聚合中的各个行（可以访问当中的各个行），并且可以将这些行的属性添加到结果集中。 \n \n 窗口函数语法： ... OVER ([PARTITION BY ...] [ORDER BY ...]) ... \n -- sum + group by 的常规聚合操作 \n SELECT   sum ( salary )   AS  total  FROM  employee  GROUP   BY  dept ; \n\n -- sum + 窗口函数聚合操作 \n SELECT  id ,  name ,  deg ,  salary ,  dept ,   sum ( salary )   over   ( PARTITION   BY  dept )   AS  total  FROM  employee ; \n \n 1 2 3 4 5 \n 窗口聚合函数 \n 首先我们准备一下数据： \n 数据 \n cookie1,2018-04-10,1\ncookie1,2018-04-11,5\ncookie1,2018-04-12,7\ncookie1,2018-04-13,3\ncookie1,2018-04-14,2\ncookie1,2018-04-15,4\ncookie1,2018-04-16,4\ncookie2,2018-04-10,2\ncookie2,2018-04-11,3\ncookie2,2018-04-12,5\ncookie2,2018-04-13,6\ncookie2,2018-04-14,3\ncookie2,2018-04-15,9\ncookie2,2018-04-16,7\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE   TABLE  website_pv_info  ( \n    cookieId string , \n    createdTime string , \n    pv  int \n )   ROW  FORMAT DELIMITED  FIELDS   TERMINATED   BY   \",\" ; \n\n LOAD   DATA   LOCAL  INPATH  '/tmp/hivedata/website_pv_info.txt'   INTO   TABLE  website_pv_info ; \n \n 1 2 3 4 5 6 7 \n -- 查询网站的总 pv 数量 \n SELECT  cookieId ,   sum ( pv )   over ( )   AS  total_pv  FROM  website_pv_info ; \n -- 分别查询每个用户的总 pv 数量 \n SELECT  cookieId ,   sum ( pv )   over ( PARTITION   BY  cookieId )   AS  total_pv  FROM  website_pv_info ; \n -- 求出每个用户截止到当天，累计的总 pv 数 \n -- sum(...) over(PARTITION BY ... ORDER BY ...)，在每个分组中连续累计求和 \n SELECT \n    cookieId , \n    createdTime , \n    pv , \n     sum ( pv )   over ( \n         PARTITION   BY  cookieId\n         ORDER   BY  createdTime\n     )   AS  current_total_pv\n FROM  website_pv_info ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 可以看到在上面的例子中，over 函数中有时没有条件，有时存在一个  PARTITION BY  的条件，有时还存在  ORDER BY  的条件。 \n 其中要注意的就是  ORDER BY  有无的条件，没有则是所有行的整体求和，有则是累计求和。 \n \n \n 窗口表达式 \n 窗口函数给了一个累积求和的行为，但是累积行为是可控的，默认情况下就是从第一行开始聚合到最后一行，窗口表达式给了一种控制行动范围的能力，比如向前两行或者向后三行。 \n 窗口表达式关键词是  ROWS BETWEEN ，包括如下选项： \n \n PRECEDING ：向前。 \n FOLLOWING ：向后。 \n CURRENT ROW ：当前行。 \n UNBOUNDED ：边界。 \n UNBOUNDED PRECEDING ：第一行。 \n UNBOUNDED FOLLOWING ：最后一行。 \n \n -- 第一行到当前行 \n SELECT \n    cookieId , \n    createdTime , \n     sum ( pv )   over ( \n         PARTITION   BY  cookieId\n         ORDER   BY  createdTime\n         ROWS   BETWEEN   UNBOUNDED   PRECEDING   AND   CURRENT   ROW \n     )   AS  pv\n FROM  website_pv_info ; \n\n -- 从前面三行到当前行 \n SELECT \n    cookieId , \n    createdTime , \n     sum ( pv )   over ( \n         PARTITION   BY  cookieId\n         ORDER   BY  createdTime\n         ROWS   BETWEEN   3   PRECEDING   AND   CURRENT   ROW \n     )   AS  pv\n FROM  website_pv_info ; \n\n -- 从前面三行到后一行 \n SELECT \n    cookieId , \n    createdTime , \n     sum ( pv )   over ( \n         PARTITION   BY  cookieId\n         ORDER   BY  createdTime\n         ROWS   BETWEEN   3   PRECEDING   AND   1   FOLLOWING \n     )   AS  pv\n FROM  website_pv_info ; \n\n -- 从当前行到最后一行 \n SELECT \n    cookieId , \n    createdTime , \n     sum ( pv )   over ( \n         PARTITION   BY  cookieId\n         ORDER   BY  createdTime\n         ROWS   BETWEEN   CURRENT   ROW   AND   UNBOUNDED   FOLLOWING \n     )   AS  pv\n FROM  website_pv_info ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 窗口排序函数 \n 用于给每个分组内的数据打上排序的标记。注意，窗口排序函数不支持窗口表达式。 \n 窗口排序函数有四个函数： \n \n row_number ：每个小组中，为每一行分配一个从 1 开始的序列号，此序列号递增不考虑重复。 \n rank ：每组中为每行分配从 1 开始的序列号，考虑重复，挤占后续位置。 \n dense_rank ：每组中为每行分配一个从 1 开始的序列号，考虑重复，不挤占后续位置。 \n \n SELECT \n    cookieId , \n    createdTime , \n    pv , \n    rank ( )   over   ( PARTITION   BY  cookieId  ORDER   BY  pv  DESC )   AS  rn1 , \n    dense_rank ( )   over   ( PARTITION   BY  cookieId  ORDER   BY  pv  DESC )   AS  rn2 , \n    row_number ( )   over   ( PARTITION   BY  cookieId  ORDER   BY  pv  DESC )   AS  rn3\n FROM  website_pv_info\n WHERE  cookieId  =   'cookie1' ; \n \n 1 2 3 4 5 6 7 8 9 \n 窗口排序函数还有一个函数叫做  ntile ，功能是将每组的数据分为若干个部分（桶），每个桶分配一个桶编号。假如不能平均分配，则优先分配较小的桶，并且各个桶中能放的行数最多相差 1。 \n SELECT \n    cookieId , \n    createdTime , \n    pv , \n    ntile ( 3 )   over   ( PARTITION   BY  cookieId  ORDER   BY  pv  DESC )   AS  rn2\n FROM  website_pv_info\n WHERE  cookieId  =   'cookie1' ; \n \n 1 2 3 4 5 6 7 \n 抽样函数 \n 数据量过大时，我们可以抽出数据的子集来加快数据处理和速度分析，这就叫做抽样。抽样是抽出部分数据来推测整个数据集的模式。 \n 在 HQL 中，可以采用随机采样、存储桶表采样、块采样。 \n Random 随机抽样 \n -- 随机抽取两个 \n SELECT   *   FROM  student DISTRIBUTE  BY  rand ( )  SORT  BY  rand ( )   LIMIT   2 ; \n -- 使用 ORDER BY + rand() 也可以查看，但是效率不高 \n SELECT   *   FROM  student  ORDER   BY  rand ( )   LIMIT   2 ; \n \n 1 2 3 4 Block 块抽样 \n -- 根据行数抽样 \n SELECT   *   FROM  student tablesample ( 1   ROWS ) ; \n -- 百分比抽样 \n SELECT   *   FROM  student tablesample ( 50   PERCENT ) ; \n -- 根据数据大小抽样，支持 b/B、k/K、m/M、g/G \n SELECT   *   FROM  student tablesample  ( 1 k ) ; \n \n 1 2 3 4 5 6 分桶表抽样 \n 根据分桶表做了优化，是一种特殊的取样方法。 \n --根据整行数据进行抽样 \n SELECT   *   FROM  t_usa_covid19_bucket tablesample ( BUCKET  1   OUT   OF   2   ON  rand ( ) ) ; \n --根据分桶字段进行抽样 效率更高 \n DESCRIBE  FORMATTED t_usa_covid19_bucket ; \n SELECT   *   FROM  t_usa_covid19_bucket tablesample ( BUCKET  1   OUT   OF   2   ON  state ) ; \n \n 1 2 3 4 5 ",updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"March 24, 2022 17:25",createTimeStamp:1648113949e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Kafka-01-起步",frontmatter:{title:"Kafka-01-起步",categories:["bigdata"],tags:["kafka"],author:"causes",summary:"Kafka 概述 Kafka 是一个消息队列，是分布式的、基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 消息队列的两种模式： 1. 点对点模式： 一对一模式，消费者主动去拉取数据，消息收到之后清除。 1. 发布订阅模式： 一对多模式，消费者消费数据之后并不会清除数据。 生产者将消息发布到 topic 中，多个消费",meta:[{property:"og:url",content:"/bigdata/Kafka/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Kafka-01-起步"},{property:"og:description",content:"Kafka 概述 Kafka 是一个消息队列，是分布式的、基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 消息队列的两种模式： 1. 点对点模式： 一对一模式，消费者主动去拉取数据，消息收到之后清除。 1. 发布订阅模式： 一对多模式，消费者消费数据之后并不会清除数据。 生产者将消息发布到 topic 中，多个消费"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"kafka"}]},regularPath:"/bigdata/Kafka/part1.html",relativePath:"bigdata/Kafka/part1.md",key:"v-8d04e3f0",path:"/bigdata/Kafka/part1/",headers:[{level:2,title:"Kafka 概述",slug:"kafka-概述"},{level:2,title:"Kafka 安装",slug:"kafka-安装"},{level:2,title:"命令行操作 Kafka",slug:"命令行操作-kafka"}],readingTime:{minutes:6.28,words:1883},content:' Kafka 概述 \n Kafka 是一个消息队列，是分布式的、基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 \n 消息队列的两种模式： \n \n \n 点对点模式： \n 一对一模式，消费者主动去拉取数据，消息收到之后清除。 \n \n \n \n 发布订阅模式： \n 一对多模式，消费者消费数据之后并不会清除数据。 \n 生产者将消息发布到 topic 中，多个消费者消费这个消息。 \n \n \n \n Kafka 基本架构 \n \n 上图中描述了 Kafka 的基本架构： \n \n \n Broker \n 这里有三个 broker，在集群中，每一个 Kafka 服务（一般来说多个服务是在多台机器上的）我们称为 broker。 \n 每一个 broker 都有自己的 ID。 \n \n \n Producer \n 生产者，用于生产消息放到 kafka 中。 \n \n \n Topic \n topic 位于 broker 中，每一个 broker 都包含至少一个 topic。生产者会将消息放到 topic 中。 \n topic 也是存在分区的概念的，比如 broker1 中放了是 topicA 的 partition0，broker2 放了 topicA 的 partition2。 \n 为了保证数据的可靠性，每一个 topic 的分区都存在副本（replica），比如在 broker1 中，topicA 的 partition0 是 Leader，broker2 中 topicA 的 partition0 是 follower。 \n 注意，每一个 topic 的分区可以存在一个 broker 上，但是副本必须分开到不同的 broker 上，这是为了数据安全考虑。 \n \n \n Consumer \n 消费者，用于消费数据。消费者是从 topic 中的某个分区中消费的，但是在 leader 可用时，它是面对 topic 的 leader 来消费的。 \n kafka 中存在消费者组的概念，消费者是没有个人的概念的，即使只有一个 consumer，也是一个消费者组的概念。 \n 在上图架构中，consumerA 和 consumerB 在同一个消费者组中。consumerC 在一个消费者组中。 \n kafka 消费有一个原则： 一个消费者组中的一个消费者，可以消费同一个主题中的多个分区的数据；但是一个主题中的一个分区的数据只能被一个消费者组中的一个消费者消费 。 \n 以 consumerA、consumerB 这个消费者组为例，当消费 topicA 时，两个消费者可以各自消费一个分区，例如 partition0 交给 A 消费，partition1 交给 B 消费。 \n 但是假如一个主题中有三个分区，那么可以随意分配。假如一个主题中有一个分区，那么只能被一个消费者组中的一个消费者消费。 \n Kafka 安装 \n Hadoop102、Hadoop103、Hadoop104 三台机器分别部署 Zookeeper 和 Kafka。 \n Kafka 下载 地址 ，我们需要  kafka_2.11-2.41.tgz \n \n \n 解压到  /opt/module ，修改名称为  kafka ，配制好环境变量 \n \n \n 在  /opt/module/kafka  下创建文件夹  logs \n \n \n 修改配置文件： vim conf/server.properties \nbroker 的全局唯一编号，不能重复 \nbroker.id = 0 \n删除topic 功能使能,当前版本此配置默认为 true，已从配置文件移除 \ndelete.topic.enable = true\n处理网络请求的线程数量 \nnum.network.threads = 3 \n用来处理磁盘 IO 的线程数量 \nnum.io.threads = 8 \n发送套接字的缓冲区大小 \nsocket.send.buffer.bytes = 102400 \n接收套接字的缓冲区大小 \nsocket.receive.buffer.bytes = 102400 \n请求套接字的缓冲区大小 \nsocket.request.max.bytes = 104857600 \nkafka 运行日志存放的路径 \nlog.dirs = /opt/module/kafka/logs\ntopic 在当前 broker 上的分区个数 \nnum.partitions = 1 \n用来恢复和清理 data 下数据的线程数量 \nnum.recovery.threads.per.data.dir = 1 \nsegment 文件保留的最长时间，超时将被删除 \nlog.retention.hours = 168 \n配置连接 Zookeeper 集群地址 \nzookeeper.connect = hadoop102:2181,hadoop103:2181,hadoop104:2181\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n \n 分发到其他机器： xsync kafka/ \n \n \n 修改其他机器的配置文件  conf/server.properties ，一定要修改  broker.id ，可以分别为  broker.id=1、broker.id=2 . \n \n \n 启动 kafka 之前，首先要启动 zookeeper 集群 \n \n \n 依次在 hadoop102、hadoop103、hadoop104 上启动 kafka： bin/kafka-server-start.sh -daemon config/server.properties \n \n \n 关闭 kafka： bin/kafka-server-stop.sh stop \n \n \n kafka 群起脚本： \n #!/bin/bash \n if   [   $#  -lt  1   ] \n then \n echo   "Input Args Error....." \n exit \n fi \n for   i   in  hadoop102 hadoop103 hadoop104\n do \n     case   $1   in \n        start ) \n             echo   "==================START  $i  KAFKA===================" \n             ssh   $i  /opt/module/kafka_2.11-2.4.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.11-2.4.1/config/server.properties\n         ; ; \n        stop ) \n             echo   "==================STOP  $i  KAFKA===================" \n             ssh   $i  /opt/module/kafka_2.11-2.4.1/bin/kafka-server-stop.sh stop\n         ; ; \n        * ) \n             echo   "Input Args Error....." \n             exit \n         ; ; \n     esac \n done \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n 命令行操作 Kafka \n topic 操作 \n 所有使用  topic  的命令都使用  bin/kafka-topics.sh  来进行操作。 \n 本质上来讲， topic  只是我们逻辑上的一个概念，实际上在存储的时候是按照分区来存储的。 \n \n \n 查看 topic 列表： bin/kafka-topics.sh --list --bootstrap-server hadoop102:9092 \n \n \n 创建名为 first 的 topic： bin/kafka-topics.sh --create --bootstrap-server hadoop102:9092 --topic first \n \n \n 带分区和副本创建 topic： bin/kafka-topics.sh --create --bootstrap-server hadoop102:9092 --topic second --partitions 2 --replication-factor 3 \n 副本不能随意指定，当前只有三台机器，所以只能有三个副本。 \n \n \n 查看 topic 详情： bin/kafka-topics.sh --describe --bootstrap-server hadoop102:9092 --topic first \n \n \n 修改 topic： bin/kafka-topics.sh --alter --bootstrap-server hadoop102:9092 --topic second --partitions 2 --replication-factor 3 \n 分区数量可以向大的改，不能向小的改，否则会报错。因为可能已经有消费者去消费了数据，记录下了 offset，万一将其他分区的数据放到一个分区，offset 没办法维护。 \n \n \n 删除 topic： bin/kafka-topics.sh --delete --bootstrap-server hadoop102:9092 --topic first \n \n \n 生产者和消费者操作 \n 生产者使用的是  bin/kafka-console-producer.sh  命令。消费者使用的是  bin/kafka-console-consumer.sh  命令，消费者在启动的时候会默认分配一个组。 \n \n \n 生产者进入到某个 broker 中的某个 topic 中： bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first \n 进入到 broker 中的 topic 中后，就可以生产数据。 \n 生产者生产的数据在逻辑上是放到 topic 中，但是 topic 毕竟只是一个逻辑的概念，所以在物理上是放到了分区中。 \n \n \n 消费者进入到某个 broker 中的某个 topic 中： bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first \n 进入到 broker 中的 topic 中，就可以消费数据。 \n 消费者在启动的时候会被默认分配到一个组，如果要将多个消费者放到通过一个组就需要显示指定。 \n 新启动的消费者组中的消费者默认不会消费 topic 中早已经存在的数据，这涉及到一个 offset 重置问题。 \n 如果需要从头消费，需要加上命令  --from-beginning  表示从头消费。但是注意，这样只能保证消费过程中，分区是有序的，但是哪个分区先消费就不一定了。 \n \n \n 消费者组 \n 在  config/consumer.properties  文件下，有一个配置项  group.id=test-consumer-group \n 我们在启动消费者的时候，指定这个文件就可以使用这个  group.id ，那么消费者就可以放到同一个消费者组中了。 \n bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties \n 当消费者的个数发生变化之后（无论是增加还是减少），topic 的分区就会重新规划一次，确保所有分区都会被消费到。 \n 假如我们不想指定配置文件，那也可以直接指定组的名称来确保放到同一个组中： \n bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --group groupA \n \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"April 17, 2022 15:40",createTimeStamp:1650181244e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Kafka-02-架构和 API",frontmatter:{title:"Kafka-02-架构和 API",categories:["bigdata"],tags:["kafka"],author:"causes",summary:"架构 工作流程和文件存储机制 offset offset 的维护，就是根据 group + topic + partition 来维护的。 topic 和 partition 和 log topic 是逻辑上的概念，partition 是一个物理的存储。 每个分区都会有自己的分区文件夹，命名规则是 topic-partition，例如 first 这个 to",meta:[{property:"og:url",content:"/bigdata/Kafka/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Kafka-02-架构和 API"},{property:"og:description",content:"架构 工作流程和文件存储机制 offset offset 的维护，就是根据 group + topic + partition 来维护的。 topic 和 partition 和 log topic 是逻辑上的概念，partition 是一个物理的存储。 每个分区都会有自己的分区文件夹，命名规则是 topic-partition，例如 first 这个 to"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"kafka"}]},regularPath:"/bigdata/Kafka/part2.html",relativePath:"bigdata/Kafka/part2.md",key:"v-36fb69b0",path:"/bigdata/Kafka/part2/",headers:[{level:2,title:"架构",slug:"架构"},{level:3,title:"工作流程和文件存储机制",slug:"工作流程和文件存储机制"},{level:3,title:"生产者",slug:"生产者"},{level:3,title:"消费者",slug:"消费者"},{level:2,title:"kafka API",slug:"kafka-api"},{level:3,title:"Producer API",slug:"producer-api"},{level:3,title:"Consumer API",slug:"consumer-api"},{level:3,title:"简单消费",slug:"简单消费"},{level:3,title:"维护 offset",slug:"维护-offset"},{level:3,title:"自定义拦截器",slug:"自定义拦截器"}],readingTime:{minutes:17.24,words:5172},content:' 架构 \n 工作流程和文件存储机制 \n \n offset \n offset 的维护，就是根据  group + topic + partition  来维护的。 \n topic 和 partition 和 log \n topic 是逻辑上的概念，partition 是一个物理的存储。 \n 每个分区都会有自己的分区文件夹，命名规则是  topic-partition ，例如 first 这个 topic 有三个分区，那么对应文件夹为  first-0 、 first-1 、 first-2 。 \n 每一个 partition 都会对应一个 log 文件（直接存在分区文件夹中），这个文件存着 producer 生产的数据，producer 生产的数据会不断追加到这个文件中，并且每条数据都有自己的 offset（也就是说，kafka 虽然吞吐量高，但其实还是利用文件来存储的，而不是利用内存）。 \n 消费者组中的每个消费者都会实时记录自己消费到了哪个 offset，在出错恢复时，会从上次的位置继续消费。 \n segment \n \n 为了防止 log 文件过大导致数据定位效率低，kafka 采取了分片 + 索引的机制。 \n 当 log 文件过大时，会分为多个 segment，每个 partition 分为多个  segment ，当分区不大那就只有一个 segment。 \n 每个 segment 都对应两个文件： .log 、 .index 。这两个文件也会放到分区文件夹下。 \n 两个文件的命名也有规则，也就是  ${offset}.log ： \n \n \n 第一个 segment 的 offset 为 0，那么就是  00000000000000000000.log 、 00000000000000000000.index \n \n \n 第二个 segment 可能是 1000，那么就是  0000……1000.log 、 0000……1000.index \n 每个 log 文件的开头都会是 offset 对应的消息，但是  .index  这个文件的索引的计数还是会从 0 开始。 \n 当我们需要找数据时，会首先根据 offset 找到对应的 index 文件，然后找到对应的数据索引。 \n 找到索引之后，offset 会减去 index 的文件名（因为文件名是 offset 的开头），得到在 log 文件中，真实数据的位置，这样就找到了最终的数据。 \n 总结一下就是：index 文件中存储的是逻辑上的数据位置，最终查找需要 offset 这个真实地址转化为 log 文件中的地址。 \n 之所以这样做，是为了防止数据太多，导致索引过长的问题。 \n \n \n 我们之前说，每个消息都会有自己的 offset，这个是没有问题的，但是 kafka 并不会给每条消息都加一个 index，这样太浪费空间了。 \n kafka 会隔一段消息放一个 index，在根据 offset 寻找索引时，寻找的往往也是一个十分小的片段，然后在对应的片段中遍历查找消息。 \n 生产者 \n 分区策略 \n topic 中会有多个 partition，分区的原因主要是可以提高并发、可以方便扩展。 \n 首先说明一点，即使 kafka 的吞吐量相当快，它也会有一个上限，这个上限就是硬盘的读写速度，这是硬件的限制，没有办法。 \n 当我们存在多个分区时，因为有副本的存在，我们在每台机器上都会有对应分区的存在。 \n kafka 在给分区选择 leader 时，会尽量分散到不同的机器上，这样就相当于每个分区的 leader 在不同的硬盘上。 \n 我们写数据会向分区的 leader 中读写，这样就相当于多块硬盘一起工作，所以 kafka 的并发是十分重要的。 \n \n 那么究竟是向哪个 partition 中放数据，这个是生产者来决定的，生产者中会有自己的一套分区策略，按照策略行事。 \n \n \n 直接指定了 partition：数据会放到指定的 partition 中。 \n \n \n 没有指定 partition，但是有 key：根据 key 的 hash 和 topic 做取余操作。 \n \n \n 没有 partition 和 key \n 这是默认情况。也是粘性分区（Sticky Partition），它首先会随机选择一个分区，然后一直用，直到满足切换分区的条件后，会再换一个分区。 \n 数据可靠性 \n producer 到 topic partition \n 使用的是 ack（acknowledgement 确认收到）。 \n topic 中的每个 partition 收到 producer 发送到数据之后，都需要向 producer 发送 ack，如果 producer 收到 ack，就说明消息发送成功，否则会重新发送数据。 \n 对于 partition 来讲，消息会首先到达 leader，然后 leader 会转给 follower，当 leader 发现全部的 follower 同步了，就会发送 ack。 \n Tips \n zookeeper 的同步机制是半数以上，但是 kafka 做的是全部都同步。 \n 其实这也就是一种策略的选择，半数以上的同步完成，那么说明机器最好的数量就是  2n + 1  台，而全部同步，机器就没什么限制了。 \n \n 而全部都同步完的这种方案，代表也是延迟高。只要有一个节点挂了，那么相应的响应也就慢了。 \n ISR \n 为了解决 follower 迟迟不能同步完数据的这个问题，kafka 提出了一项技术，ISR。 \n leader 会维护一个动态的同步列表  in-sync replication set（ISR） ，leader 和 follower 都会在这个列表中。 \n 当 follower 在这个列表中，leader 就会向 follower 发送消息来同步数据。 \n 当某个 follower 同步数据超时了，leader 会经这个 follower 从这个列表中踢出去。当 follower 恢复正常了（指定时间内可以同步数据），leader 会再将 follower 加到列表中。 \n 当 leader 故障后，会从 ISR 中选择新的 leader。 \n 时间阈值由  replication.lag.time.max.ms  参数设置。默认 10000ms，可以在 kafka 官网上看。 \n ack 应答级别 \n 对于数据而言，不是所有数据都需要完整的保存下来，有些数据可能很重要，有些数据丢了就丢了无所谓。那么对应不同的数据，ack 也有不同的应答级别。 \n kafka 共提供了三种应答级别，用户可以自己权衡来挑选级别： \n \n 0 ：提供了一个最低的延迟，只要 leader 收到了消息，在 leader 自己还没向磁盘写的时候就响应 ack。 \n 1 ：leader 落盘之后响应 ack。 \n -1 ：leader 和 follower 全部落盘之后响应 ack，默认。注意，这种情况可能会导致数据重复。 \n \n leader 和 follower 故障处理 \n \n 每个副本中最后一个 offset 叫做 LEO（Log End Offset），所有副本中最小的 LEO 叫做 HW（High Watermark）。 \n 所以其实 HW 这个值保证的就是：这个水位对应的值在所有的副本中都存在，而且一定是响应过 ack 的，而且 HW 对应的值才可以被消费者消费。 \n \n \n leader 故障： \n kafka 启动之后会自动维护一个副本的顺序，当 leader 故障了，他就会看下一个副本是否在 ISR 中，假如在 ISR 中说明可用，则直接使用这个副本作为新的 leader。 \n 新的 leader 上任之后，他会看当前的 HW，不管是自己还是其他 follower，全都扔掉 HW 之后的数据，然后等待生产者重新发送。 \n \n \n follower 故障： \n 这个 follower 不要了，回来之后会从他自己当时对应的 HW 的位置开始重新同步数据。 \n \n \n Exactly Once \n 精准一次，在 kafka 中解决数据同步且同步一次的问题，其实就是将重复数据放到 kafka 来做。也就是  至少一次 + 幂等性操作  来实现这个精准一次。 \n 启用幂等性需要将  Producer  参数中的  enable.idempotence  设置为 true。 \n 开启幂等性的 producer 会在初始化分配一个 PID，发往同一个 partition 的消息会附带 sequence number。 \n broker 端会对  <PID, Partition, SeqNumber>  做缓存，具有相同主键的数据提交时仅会持久化一条。 \n 消费者 \n 消费者会使用拉取方式来从 broker 中读取数据。假如拉取时没有数据可以被消费，就会停留一个时间，时间过了之后再去拉取。 \n 分区策略 \n 一个 consumer group 有多个 consumer，一个 topic 有多个 partition，所以必然涉及 partition 分配问题。 \n kafka 有三种分配策略： \n \n \n RoundRobin \n 轮询，现在有一个消费者组中的三个消费者，一个 topic 中的七个 partition \n \n \n 消费者个数发生变化时，所有 consumer 负责消费的 partition 会重新分配。 \n \n \n Range \n 默认使用的分区。 \n 范围分区，首先会使用分区数和消费者组中的消费者进行一个取余操作，假如能整除那就分成 n 份，每一份是一个范围，一个范围的分给一个 consumer。 \n 除不尽的话，会让最后一个 consumer 少一个，假如最后一个 consumer 少了还不行，那就让倒数第二个 consumer 少一个…… \n \n \n \n Sticky \n 粘性分区，第一次分区和 RoundRobin 比较像，当消费者个数减少时，原有的 consumer 负责的 partition 保持不变。 \n 如果还有新的 partition 会按照 RoundRobin 的方式重新分配。 \n 当消费者个数增加时，consumer 对应的 partition 会重新分配。 \n \n \n offset 维护 \n 由于 consumer 在消费过程中可能会发生故障，因此 consumer 需要记录自己消费到了哪个 offset，便于故障恢复。 \n 在 kafka 0.9 之后，consumer 默认将 offset 保存在内置的一个 topic 中，就是  __consumer_offsets \n \n 这是 kafka 自己创建维护的，而且每消费一个数据都需要维护一次 offset。 \n kafka API \n Producer API \n 简单发送 \n Kafka 的生产者可以同步发送消息，也可以异步发送消息，主要涉及到了两个线程： main 、 sender ，涉及到了一个线程共享变量： RecordAccumulator 。 \n \n 在 main 线程中： \n \n 生产者生产消息，经过了  send() \n 消息发送给拦截器 \n 消息发送给序列化器 \n 消息发送给分区器 \n 消息交给共享变量对应的位置 \n \n 在共享变量 RecordAccumulator 中： \n \n 它会为每一个 topic 中的分区开辟一个缓冲 \n 消息会线发送到共享变量中的内容中 \n 假如消息达到了缓冲/超过指定时间，则发送给 topic 中的分区 \n \n 在 sender 线程中： \n \n 将消息从缓冲中拿出来，然后放到 topic 中 \n \n 环境搭建 \n < dependencies > \n     < dependency > \n         < groupId > org.apache.kafka </ groupId > \n         < artifactId > kafka-clients </ artifactId > \n         < version > 2.4.1 </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 案例 \n 异步发送 \n 异步发送，消息发送之后不阻塞，不等待 ack 回来就发送下一条消息。 \n /**\n * 生产者异步发送，不带回调\n */ \n public   class   KafkaProducerDemo   { \n   public   static   void   main ( String [ ]  args )   { \n     /*\n      1. 创建配置对象\n\n      配置类：\n\n      - CommonClientConfigs：生产者和消费者通用的配置类\n      - ProducerConfig：生产者配置类\n      - ConsumerConfig：消费者配置类\n     */ \n     Properties  props  =   new   Properties ( ) ; \n     // kafka 集群，broker-list 的位置 \n    props . put ( CommonClientConfigs . BOOTSTRAP_SERVERS_CONFIG ,   "hadoop102:9092" ) ; \n     // ack 的级别，all 就是 -1，默认情况下是 1 \n    props . put ( ProducerConfig . ACKS_CONFIG ,   "all" ) ; \n     // 重试次数，默认次数为 INTEGER.MAX \n    props . put ( CommonClientConfigs . RETRIES_CONFIG ,   3 ) ; \n     // 批次大小，这个批次大小指的是 main 线程攒一批多大的数据发送给线程共享变量 \n    props . put ( ProducerConfig . BATCH_SIZE_CONFIG ,   16384 ) ; \n     // 指的是线程共享变量 RecordAccumulator 中，等待多长时间就发送给 sender 线程 \n    props . put ( ProducerConfig . LINGER_MS_CONFIG ,   1 ) ; \n     // 指的是线程共享变量 RecordAccumulator 中，给 topic 每个分区开辟缓冲区的大小，32M \n    props . put ( ProducerConfig . BUFFER_MEMORY_CONFIG ,   33554432 ) ; \n     // kv 的序列化器，因为我们指定的 kv 都是字符串，所以这里就是字符串的序列化器 \n    props . put ( ProducerConfig . KEY_SERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringSerializer" ) ; \n    props . put ( ProducerConfig . VALUE_SERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringSerializer" ) ; \n\n     // 2. 创建生产者对象，泛型为：消息的 key 的类型、消息本身的类型 \n     KafkaProducer < String ,   String >  kafkaProducer  =   new   KafkaProducer < String ,   String > ( props ) ; \n\n     // 3. 定义 ProducerRecord，包装一些信息，例如 topic、partition、timestamp 等，发送 \n     for   ( int  i  =   0 ;  i  <   10 ;  i ++ )   { \n      kafkaProducer . send ( new   ProducerRecord < String ,   String > ( "topic-first" ,   "value"   +  i ) ) ; \n     } \n\n     // 4. 关闭对象 \n    kafkaProducer . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 /**\n * 生产者异步发送，带回调\n */ \n public   class   KafkaProducerDemo   { \n   public   static   void   main ( String [ ]  args )   { \n     Properties  props  =   new   Properties ( ) ; \n     KafkaProducer < String ,   String >  kafkaProducer  =   new   KafkaProducer < > ( props ) ; \n     ProducerRecord < String ,   String >   record   =   new   ProducerRecord < > ( "topic-first" ,   "value" ) ; \n    kafkaProducer . send ( record ,   new   Callback ( )   { \n       /**\n       * 消息发送完成后调用此方法\n       * @param recordMetadata 消息元数据信息\n       * @param e 消息发送后失败就会抛出异常\n       */ \n       @Override \n       public   void   onCompletion ( RecordMetadata  recordMetadata ,   Exception  e )   { \n         if   ( Objects . nonNull ( e ) )   { \n           System . out . println ( String . format ( "消息失败 %s" ,  e . getMessage ( ) ) ) ; \n           return ; \n         } \n         System . out . println ( \n             String . format ( "消息发送成功 topic: %s partition: %s offset: %s" , \n                recordMetadata . topic ( ) , \n                recordMetadata . partition ( ) , \n                recordMetadata . offset ( ) \n             ) \n         ) ; \n       } \n     } ) ; \n    kafkaProducer . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 同步发送 \n 同步发送，消息发送之后阻塞，等待 ack 回来之后才会发送下一条消息。 \n /**\n * 生产者同步发送，带回调\n */ \n public   class   KafkaProducerDemo   { \n   public   static   void   main ( String [ ]  args )   throws   ExecutionException ,   InterruptedException   { \n     Properties  props  =   new   Properties ( ) ; \n     KafkaProducer < String ,   String >  kafkaProducer  =   new   KafkaProducer < > ( props ) ; \n     ProducerRecord < String ,   String >   record   =   new   ProducerRecord < > ( "topic-first" ,   "value" ) ; \n     // 接受返回值 \n     Future < RecordMetadata >  future  =  kafkaProducer . send ( record ,   ( recordMetadata ,  e )   ->   { \n       if   ( Objects . nonNull ( e ) )   { \n         System . out . println ( String . format ( "消息失败 %s" ,  e . getMessage ( ) ) ) ; \n         return ; \n       } \n       System . out . println ( \n           String . format ( "消息发送成功 topic: %s partition: %s offset: %s" , \n              recordMetadata . topic ( ) , \n              recordMetadata . partition ( ) , \n              recordMetadata . offset ( ) \n           ) \n       ) ; \n     } ) ; \n     // 调用此方法之后就会阻塞当前线程，一直等到该方法的返回值返回为止，它会抛出 InterruptedException 异常，也就是打断异常 \n    future . get ( ) ; \n    kafkaProducer . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #  分区策略 \n 指定 key，根据 key 的 hash 取余 \n // 参数分别为：topic、key、value，根据 key 的 hash 取余来得到最终的 partition \n new   ProducerRecord < String ,   String > ( "topic-first" ,    "key" ,   "1" ) ; \n \n 1 2 手动指定分区 \n // 参数分别为：topic、partition、key、value，发送给 topic 的 0 号分区 \n new   ProducerRecord < String ,   String > ( "topic-first" ,   0 ,   "key" ,   "1" ) ; \n \n 1 2 当手动指定了 partition 之后，key 这个字段就没用了 \n 粘性分区 \n 默认情况下（即仅指定 topic 和 value）就是粘性分区。 \n new   ProducerRecord < String ,   String > ( "topic-first" ,   "value" ) ; \n \n 1 粘性分区下，首先会只使用一个 partition，满足条件（partition 满了/超过  ProducerConfig.LINGER_MS_CONFIG  时间）之后就会切换另外的 partition。 \n \n 其实之前默认分区器是采用轮询的做法，也就是 main 线程到共享变量的缓冲区的这段是轮询的，但是这样有一个问题： \n 当数据量很小的时候，共享变量中的每一个缓冲区也都只放了一点点的数据，最后分给不同的 partition，这样是完全没有必要的。 \n 所以之后改为了粘性分区，当数据量小的时候直接放到一个缓冲区，给到一个 partition，这样是比较合理的。 \n 自定义分区器 \n \n 对于分区器来讲，kafka 提供的共三个分区器： DefaultPartitioner（默认，粘性分区器） 、 UniformStickyPartitioner（类似粘性分区器） 、 RoundRobinPartitioner（轮询分区器） 。 \n 自定义分区器，实现  Partitioner  接口即可。 \n /**\n * 自定义分区器\n */ \n public   class   CustPartitioner   implements   Partitioner   { \n\n   /**\n   * 计算分区号码\n   *\n   * @param topic      发送的主题\n   * @param key        当前消息的 Key\n   * @param keyBytes   当前消息 key 序列化之后的字节数组\n   * @param value      当前消息\n   * @param valueBytes 当前消息序列化之后的字节数组\n   * @param cluster    上下文\n   * @return 分区号\n   */ \n   @Override \n   public   int   partition ( String  topic ,   Object  key ,   byte [ ]  keyBytes ,   Object  value ,   byte [ ]  valueBytes ,   Cluster  cluster )   { \n     // 实现分区逻辑 \n     return   0 ; \n   } \n\n   @Override \n   public   void   close ( )   { \n   } \n\n   @Override \n   public   void   configure ( Map < String ,   ? >  map )   { \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public   class   KafkaProducerDemo   { \n   public   static   void   main ( String [ ]  args )   throws   ExecutionException ,   InterruptedException   { \n     Properties  props  =   new   Properties ( ) ; \n     // 手动设置分区器 \n    props . setProperty ( ProducerConfig . PARTITIONER_CLASS_CONFIG , "producer.partitioner.CustPartitioner" ) ; \n     KafkaProducer < String ,   String >  kafkaProducer  =   new   KafkaProducer < > ( props ) ; \n     ProducerRecord < String ,   String >   record   =   new   ProducerRecord < > ( "topic-first" ,   "value" ) ; \n    kafkaProducer . send ( record ) ; \n    kafkaProducer . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 #  Consumer API \n 简单消费 \n /**\n * Kafka 消费者\n */ \n public   class   KafkaConsumerDemo   { \n   public   static   void   main ( String [ ]  args )   { \n     // 1. 配置类 \n     Properties  props  =   new   Properties ( ) ; \n     // Kafka 集群配置 \n    props . put ( ConsumerConfig . BOOTSTRAP_SERVERS_CONFIG ,   "hadoop102:9092" ) ; \n     // 消费者组 ID \n    props . put ( ConsumerConfig . GROUP_ID_CONFIG ,   "test" ) ; \n     // 自动提交 offset \n    props . put ( ConsumerConfig . ENABLE_AUTO_COMMIT_CONFIG ,   "true" ) ; \n     // offset 提交的间隔 \n    props . put ( ConsumerConfig . AUTO_COMMIT_INTERVAL_MS_CONFIG ,   "1000" ) ; \n     // kv 的反序列化 \n    props . put ( ConsumerConfig . KEY_DESERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \n    props . put ( ConsumerConfig . VALUE_DESERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \n\n     // 2. 消费者对象，泛型是生产者生产的数据的泛型 \n     KafkaConsumer < String ,   String >  kafkaConsumer  =   new   KafkaConsumer < > ( props ) ; \n\n     /*\n      3. 消费者指定多个 topic 来消费，首先需要订阅多个 topic。\n\n      可以订阅不存在的 topic，会自动创建。但是这个自动创建的 topic 就只有一个分区一个副本。\n     */ \n    kafkaConsumer . subscribe ( Arrays . asList ( "first-topic" ,   "second-topic" ) ) ; \n\n     // 4. 持续消费数据，正常来说不应该是一个死循环，现在就是意思一下 \n     while   ( true )   { \n       // 假如拉不到数据，那么就等待两秒钟 \n       ConsumerRecords < String ,   String >  records  =  kafkaConsumer . poll ( Duration . ofSeconds ( 10 ) ) ; \n      records . forEach ( record   ->   System . out . println ( \n               String . format ( "消费到 topic: %s partition: %s offset: %s key: %s value: %s" , \n                   record . topic ( ) , \n                   record . partition ( ) , \n                   record . offset ( ) , \n                   record . key ( ) , \n                   record . value ( ) \n               ) \n           ) \n       ) ; \n     } \n\n     // 5. 关闭对象 \n    kafkaConsumer . close ( ) ; \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #  维护 offset \n 自动提交 offset \n 在配置 properties 中指定自动提交 offset  props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true") \n 指定超时时间  props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000"); \n 这个时候，我们的 offset 会自动重置，会自动重置到当前分区下最大的 offset，所以说之前的数据不可能被消费，只有新进来的数据才会被消费到。 \n 自动重置 offset \n 自动重置由  auto.offset.reset  参数控制，有几个值： \n \n earliest : 重置到最开始位置（有些超过七天的数据可能被删掉了，所以最开始位置不一定是 0）。 \n latest : 重置到最后位置，默认值。 \n \n 自动重置的情况： \n \n kafka 中没有一个 offset 时（没有消费记录时）。 \n 当前 offset 在 kafka 中已经不存在时（被删掉的数据）。 \n \n 需要改变自动重置的规则，则需要在 properties 中指定  props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest"); 。 \n 手动提交 offset \n 首先在配置中禁用自动提交： props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false") \n 这个时候我们没有设置有关手动提交的参数，所以当前 offset 只是维护在了 consumer 内存中，而没有提交给 kafka。 \n 当前状态下持续消费没啥问题，但是只要 consumer 重启，因为 offset 没有提交到 kafka 中，所以会读取 kafka 保存的之前的 offset，然后开始消费。 \n 手动提交 offset 也有两种方式： \n \n 同步提交 commitSync：消费完数据之后提交，提交完成之前不进行下次消费，提交失败则自动重试，直到成功为止。 \n 异步提交 commitAsync：消费完数据之后提交，在提交过程中仍然进行下次消费，提交失败不重试，所以有可能失败。 \n \n 无论是同步还是异步，都会将最高的 offset 提交给 kafka。 \n public   class   KafkaConsumerDemo   { \n   public   static   void   main ( String [ ]  args )   { \n     Properties  props  =   new   Properties ( ) ; \n    props . put ( ConsumerConfig . BOOTSTRAP_SERVERS_CONFIG ,   "hadoop102:9092" ) ; \n    props . put ( ConsumerConfig . GROUP_ID_CONFIG ,   "test" ) ; \n     // 禁用自动提交 offset \n    props . put ( ConsumerConfig . ENABLE_AUTO_COMMIT_CONFIG ,   "true" ) ; \n    props . put ( ConsumerConfig . KEY_DESERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \n    props . put ( ConsumerConfig . VALUE_DESERIALIZER_CLASS_CONFIG ,   "org.apache.kafka.common.serialization.StringDeserializer" ) ; \n\n     KafkaConsumer < String ,   String >  kafkaConsumer  =   new   KafkaConsumer < > ( props ) ; \n\n    kafkaConsumer . subscribe ( Arrays . asList ( "first-topic" ,   "second-topic" ) ) ; \n     while   ( true )   { \n       // 消费数据 \n       ConsumerRecords < String ,   String >  records  =  kafkaConsumer . poll ( Duration . ofSeconds ( 10 ) ) ; \n      records . forEach ( record   ->   System . out . println ( \n               String . format ( "消费到 topic: %s partition: %s offset: %s key: %s value: %s" , \n                   record . topic ( ) , \n                   record . partition ( ) , \n                   record . offset ( ) , \n                   record . key ( ) , \n                   record . value ( ) \n               ) \n           ) \n       ) ; \n       // 手动提交 offset，同步 \n      kafkaConsumer . commitSync ( ) ; \n       // 手动提交 offset，异步 \n      kafkaConsumer . commitAsync ( ) ; \n     } \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 异步提交有一个回调方法，用于查看是成功还是失败： \n kafkaConsumer . commitAsync ( new   OffsetCommitCallback ( )   { \n   @Override \n   public   void   onComplete ( Map < TopicPartition ,   OffsetAndMetadata >  offsets ,   Exception  e )   { \n     if   ( Objects . nonNull ( e ) )   { \n       System . out . println ( "失败" ) ; \n       return ; \n     } \n     System . out . println ( offsets ) ; \n   } \n } ) ; \n \n 1 2 3 4 5 6 7 8 9 10 漏消费和重复消费 \n \n \n 重复消费：假定我们先消费数据，然后提交 offset。 \n 假如我们在消费数据的过程中抛出了异常，那么 consumer 就执行失败了，offset 肯定也提交失败。等到下次给到的这一批同样的数据，其实已经有一些是已经消费过的。 \n \n \n 漏消费：假定我们先提交 offset，然后再消费数据。 \n 假如我们在消费数据的过程抛出了异常，那么 consumer 就执行失败了。但是此时 offset 早已提交完成，等到下次就不会给到这批数据了。 \n \n \n 假如我们想要实现精准一次消费，就要将消费和提交 offset 这两件事做成一个事务。kafka 是不能做到这种事情的，所以我们需要借助第三方可以实现事务的组件，比如 MySQL 等。 \n 自定义拦截器 \n /**\n * 自定义拦截器\n */ \n public   class   CustInterceptor   implements   ProducerInterceptor   { \n\n   /**\n   * 将方法封装到 producer.send() 方法中，也就是说它运行在 main 线程中\n   * <p>\n   * 消息序列化和计算分区前会调用此方法\n   */ \n   @Override \n   public   ProducerRecord   onSend ( ProducerRecord  producerRecord )   { \n     return  producerRecord ; \n   } \n\n   /**\n   * 线程间共享变量发送成功 / 失败时调用\n   *\n   * @param recordMetadata\n   * @param e\n   */ \n   @Override \n   public   void   onAcknowledgement ( RecordMetadata  recordMetadata ,   Exception  e )   { \n\n   } \n\n   @Override \n   public   void   close ( )   { \n\n   } \n\n   /**\n   * 获取配置信息，初始化使用\n   *\n   * @param configs 配置\n   */ \n   @Override \n   public   void   configure ( Map < String ,   ? >  configs )   { \n\n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 Properties  props  =   new   Properties ( ) ; \nprops . put ( ProducerConfig . INTERCEPTOR_CLASSES_CONFIG ,   Arrays . asList ( "interceptor.CustInterceptor" ) ) ; \n KafkaProducer < String ,   String >  kafkaProducer  =   new   KafkaProducer < > ( props ) ; \n ProducerRecord < String ,   String >   record   =   new   ProducerRecord < > ( "topic-first" ,   "value" ) ; \nkafkaProducer . send ( record ) ; \nkafkaProducer . close ( ) ; \n \n 1 2 3 4 5 6 拦截器可以有多个，所以放一个 List 也是十分合理的。 \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"April 25, 2022 11:31",createTimeStamp:1650857475e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Spark-01-SparkCore",frontmatter:{title:"Spark-01-SparkCore",categories:["bigdata"],tags:["spark"],author:"causes",summary:"Spark 概述 之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。 但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。 Spark 其实也是一个计",meta:[{property:"og:url",content:"/bigdata/Spark/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Spark-01-SparkCore"},{property:"og:description",content:"Spark 概述 之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。 但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。 Spark 其实也是一个计"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"spark"}]},regularPath:"/bigdata/Spark/part1.html",relativePath:"bigdata/Spark/part1.md",key:"v-3ee237e8",path:"/bigdata/Spark/part1/",headers:[{level:2,title:"Spark 概述",slug:"spark-概述"},{level:2,title:"环境搭建",slug:"环境搭建"},{level:2,title:"快速起步",slug:"快速起步"},{level:2,title:"Spark 运行环境",slug:"spark-运行环境"},{level:3,title:"Local 模式",slug:"local-模式"},{level:3,title:"Standalone 模式",slug:"standalone-模式"},{level:3,title:"Yarn 模式",slug:"yarn-模式"},{level:3,title:"K8s && Mesos 模式",slug:"k8s-mesos-模式"},{level:3,title:"Windows 模式",slug:"windows-模式"},{level:2,title:"Spark 运行架构",slug:"spark-运行架构"},{level:2,title:"RDD",slug:"rdd"},{level:3,title:"RDD 概述",slug:"rdd-概述"},{level:3,title:"RDD 基础编程",slug:"rdd-基础编程"},{level:3,title:"RDD 算子",slug:"rdd-算子"},{level:3,title:"RDD 序列化",slug:"rdd-序列化"},{level:3,title:"RDD 依赖关系",slug:"rdd-依赖关系"},{level:3,title:"RDD 持久化",slug:"rdd-持久化"},{level:3,title:"RDD 分区器",slug:"rdd-分区器"},{level:2,title:"累加器",slug:"累加器"},{level:2,title:"广播变量",slug:"广播变量"}],readingTime:{minutes:30.65,words:9195},content:' Spark 概述 \n 之前我们接触过一些大数据的内容，简而言之，大数据就是要处理海量数据的存储和计算。之前我们接触过 Hadoop，其中 Hadoop 的 MapReduce 就是 Hadoop 的计算框架。 \n 但是 MapReduce 有个缺点，就是它在任务之间使用了磁盘操作，导致磁盘 IO 使用极多，这样实现的性能肯定是比较差劲的。 \n Spark 其实也是一个计算框架，它和 MapReduce 的主要不同点就是：Spark 是基于内存进行计算的框架，多个作业之间的衔接也是用的内存，那么它的效率就大大提高了。在现在的大数据框架中，Spark 往往是替代 MapReduce 的方案。 \n Spark 的核心模块： \n \n Spark Core：Spark 的核心，在它的基础上，Spark 进行了很多扩展的功能。 \n Spark SQL：类似于 Hive SQL 简化了 MapReduce 的操作，Spark SQL 也简化了编写 Spark 代码的操作，同样类似 HSQL，也专门用于处理结构化数据。 \n Spark Streaming：根据 Spark Core 扩展，用于流式计算，但是相较于 Flink 这种框架来说，Spark 的流式计算要差劲一些。 \n Spark MLlib：根据 Spark Core 扩展，处理机器学习，这里不做涉及。 \n Spark GraphX：根据 Spark Core 扩展，处理图形挖掘计算，这里不做涉及。 \n 环境搭建 \n 学习 Spark Core，首先就需要进行环境搭建。 \n \n \n Scala 环境： scala_2.12.11 ，注意配置好环境变量。 \n \n \n 将 Scala 加入到 IDEA 中的全局库中，并且将框架假如到当前模块中。 \n \n \n \n \n \n 添加 Spark 依赖到当前项目中。 \n < dependencies > \n     < dependency > \n         < groupId > org.apache.spark </ groupId > \n         < artifactId > spark-core_2.12 </ artifactId > \n         < version > 3.0.0 </ version > \n     </ dependency > \n </ dependencies > \n\n < build > \n     < plugins > \n         \x3c!-- 该插件用于将 Scala 代码编译成 class 文件 --\x3e \n         < plugin > \n             < groupId > net.alchim31.maven </ groupId > \n             < artifactId > scala-maven-plugin </ artifactId > \n             < version > 3.2.2 </ version > \n             < executions > \n                 < execution > \n                     \x3c!-- 声明绑定到 maven 的 compile 阶段 --\x3e \n                     < goals > \n                         < goal > testCompile </ goal > \n                     </ goals > \n                 </ execution > \n             </ executions > \n         </ plugin > \n         < plugin > \n             < groupId > org.apache.maven.plugins </ groupId > \n             < artifactId > maven-assembly-plugin </ artifactId > \n             < version > 3.1.0 </ version > \n             < configuration > \n                 < descriptorRefs > \n                     < descriptorRef > jar-with-dependencies </ descriptorRef > \n                 </ descriptorRefs > \n             </ configuration > \n             < executions > \n                 < execution > \n                     < id > make-assembly </ id > \n                     < phase > package </ phase > \n                     < goals > \n                         < goal > single </ goal > \n                     </ goals > \n                 </ execution > \n             </ executions > \n         </ plugin > \n     </ plugins > \n </ build > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \n \n log4j.properties ：Spark 在运行时会产生大量日志，所以直接设置日志配置信息： \n log4j.rootCategory=ERROR, console\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\nSet the default spark-shell log level to ERROR. When running the spark-shell, the\nlog level for this class is used to overwrite the root logger\'s log level, so that\nthe user can have different defaults for the shell and regular Spark apps. log4j.logger.org.apache.spark.repl.Main=ERROR\nSettings to quiet third party logs that are too verbose log4j.logger.org.spark_project.jetty=ERROR log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR log4j.logger.org.apache.parquet=ERROR\nlog4j.logger.parquet=ERROR\nSPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR\n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n \n 假如使用的是 Windows，那么可能会由于缺少 Hadoop 的相关支持，可能会报错，直接关联 Hadoop 的配置到 Windows 即可，这一步在之前学习 Hadoop 应该已经做过。 \n 快速起步 \n 下面来实现一个大数据版本的 HELLO WORLD：实现一次 Word Count，使用 Java 语言也完全支持，但是 Scala 开发比较快速，所以本次采用的是 Scala 语言。 \n // 1. 定义 Spark 的配置，之后详细讲配置是什么东西 \nval sparkConf  =   new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "WordCount" ) \n // 2. 创建 Spark 上下文，也就是创建 Spark 环境 \nval sc  =   new   SparkContext ( sparkConf ) \n\n // 3. 读取文件数据 \nval fileRDD :  RDD [ String ]   =  sc . textFile ( "input/word.txt" ) \n /*\n    1. 将数据进行转换，学过 Scala 或者 Java 应该有一定的基础。\n\n    其中 \'_\' 代表的就是任意的单词：\n    _.split(" ")：代表将每一行使用空格符切割\n    flatMap 为扁平化处理\n    map((_, 1)) 代表将 word => (word, 1)\n    reduceByKey 代表将 (word, 1) 按照 word 分组，组内聚合\n    */ \nval wordRDD :  RDD [ ( String ,   Int ) ]   =  fileRDD . flatMap ( _ . split ( " " ) ) . map ( ( _ ,   1 ) ) . reduceByKey ( _  +  _ ) \n // 5. collect 代表收集，最终形成的结果如：(A, 2), (B, 3), (D, 2), .... \nval wordCount :   Array [ ( String ,   Int ) ]   =  wordRDD . collect ( ) \nwordCount . foreach ( println ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #  Spark 运行环境 \n Local 模式 \n Local 模式指的就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学、调试、演示等。我们之前在 IDEA 的快速开始案例是开发环境，和 Local 模式不太一样。 \n TODO：待补充 \n Standalone 模式 \n TODO：待补充 \n Yarn 模式 \n TODO：待补充 \n K8s && Mesos 模式 \n TODO：待补充 \n Windows 模式 \n TODO：待补充 \n Spark 运行架构 \n Driver && Executor \n Spark 核心是一个计算引擎，采用了标准 master-slave 架构，Spark 在执行时的基本架构为 Driver-Executor。 \n 其中 Driver 就是 master，负责任务调度；Executor 是 slave，负责任务的实际执行。下图的 Cluster Manager 的主要作用就是启动 Executor，之后 Executor 就与 Driver 直接通信了。 \n \n 从上图可以看到，Spark 有两个核心组件： \n \n \n Driver：Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行操作。 \n 主要用于：将用户程序转换为作业（Job）、在各个 Executor 中调度任务（Task）、跟踪 Executor 的执行情况、通过 UI 展示运行情况。 \n 简单来说，Driver 用于统一调度，也叫 Driver 类。 \n \n \n Executor： \n Spark 中的工作节点，每一个 Executor 都是一个 JVM 进程。Executor 负责运行具体任务（Task），任务之间相互独立，互不影响。 \n Spark 启动时 Executor 会同时启动，并且伴随整个 Spark 的生命周期。假如有 Executor 发生故障，Spark Task 调度到其他 Executor 上继续执行。 \n Executor 有两个核心功能：负责运行 Spark Task，并将结果返回 Driver、通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。 \n \n \n Master && Worker \n Spark 集群的独立部署模式中，不需要其他资源调度框架，所以自己实现了一套资源调度框架：Master、Worker。 \n Master 是一个进程，主要用于集群资源分配、调度，类似于 YARN 的 RM。Worker 类似于 YARN 中的 NM，可以提供给 Executor 资源（例如 CPU 核心数量 Core、内存大小等）。 \n Application Master \n 类似 Hadoop ，Application Master 是单个任务的老大，简单来说就是：ResourceManager 和 Driver 之间的解耦合就是利用 ApplicationMaster。 \n 并行度 \n 并行度 Parallelism：这里是并行，不是并发。 \n 在分布式计算框架中，一般都是多个任务同时执行，由于任务分布在不同的计算节点上进行计算，所以可以实现真正的多任务并行执行，集群中并行执行任务的个数叫做并行度。 \n 一个作业（Job）的并行度主要取决于配置，当然也可以在运行中动态修改。 \n 有向无环图 \n 有向无环图 DAG：Spark 擅长进行有向无环图的计算，而 Hadoop 不行。 \n 简单来说，有向无环图就是这个任务依赖于上个任务的执行结果，是一种抽象的结构，其中箭头所指向的方向是依赖的方向，例如：  A -> B ，就是 A 依赖于 B 的结果，下图中 stage0 依赖于 stage1 的结果。 \n \n Spark 数据结构 \n Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构，用于处理不同的应用场景： \n \n RDD：弹性分布式数据集。 \n 累加器：分布式共享只写变量。 \n 广播变量：分布式共享只读变量。 \n RDD \n RDD 概述 \n RDD，Resilient Distributed Dataset，弹性分布式数据集，是 Spark 最基本的数据处理模型： \n \n 弹性：存储弹性（内存和磁盘自动切换）、容错弹性（数据丢失自动恢复）、计算弹性（计算出错重试）、分片弹性（根据需要重新分片）。 \n 分布式：数据存储到大数据集群不同节点上。 \n 数据集：RDD 封装了计算逻辑，并不保存数据。 \n 不可变：RDD 封装的计算逻辑不可改变，如果要改变只能重新生成新的 RDD。 \n 数据抽象：RDD 是一个抽象类，需要子类具体实现。 \n \n RDD 核心属性 \n \n 上图是 RDD 的注解，其中说明了五大核心属性： \n \n 分区列表：RDD 数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。 \n 分区计算函数：Spark 使用分区计算函数对每一个分区进行计算。 \n RDD 依赖：RDD 之间存在依赖关系。 \n 分区器：可选，当为 KV 类型数据时，可以设定分区器自定义数据分区。 \n 首选位置：可选，计算数据可以根据计算节点的状态选择不同位置计算。 \n \n RDD 简易理解 \n 使用文字的方式确实比较抽象了，所以在这里先行一个概述，有人使用薯片的加工流程做了比喻。 \n \n 首先一开始那一袋子土豆，就可以将其看为一个 RDD。 \n RDD 中有分区的概念，这其实就可以看成带泥土豆阶段，在这个阶段中，每一个带泥土豆都是 RDD 的一个分区。 \n 接下来进行土豆的清洗、切片、烘焙、分发、装桶，这其实就是 RDD 使用算子的过程中进行的转换。具体算子是什么之后会讲。 \n 从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承。 \n 在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承。 \n RDD 基础编程 \n RDD 创建 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n // 1. 从集合（内存）中创建 RDD，其实 makeRDD 底层就是 parallelize \n val  memoryRDD :  RDD [ Int ]   =  sc . parallelize ( List ( 1 ,   2 ,   3 ,   4 ) ) \n val  memoryRDD2 :  RDD [ Int ]   =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) \n\n // 2. 从文件（磁盘）创建 RDD \n val  diskRDD :  RDD [ String ]   =  sc . textFile ( "input.txt" ) \n\n // 3. 基于 RDD 创建 RDD，是运算完成之后产生新的 RDD，详情见后续张杰 \n val  rddtoRDD :  RDD [ Array [ String ] ]   =  diskRDD . map ( _ . split ( " " ) ) \n\n // 4. 直接创建 RDD，一般是 Spark 框架自身使用 \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 RDD 的并行度与分区 \n \n \n 并行度： \n Spark 将一个 Job 切分为多个 Task，然后将这些 Task 发送给 Executor 去执行。能够同时并行计算的 Task 的数量被被称为并行度。 \n 注意，Job 切分 Task 的个数和 Executor 能够执行 Task 的个数不一定相同，能够执行 Task 的个数才叫做并行度。 \n \n \n 分区： \n 默认情况下，分区的规则在使用内存和使用文件有所不同： \n 读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，读取文件数据时，默认采用 Hadoop 的规则进行切片分区。 \n RDD 算子 \n RDD 的算子其实就是封装的数据计算逻辑，类似于俄罗斯套娃，上一个 RDD 可以根据规则形成新的 RDD。RDD 的算子就分为两类： \n \n RDD 转换算子：这一类 RDD 算子可以看成只是封装了逻辑，每一层的封装都会产生新的 RDD，但是这些 RDD 不会真正去执行数据操作。 \n RDD 行动算子：这一类 RDD 算子是真正的去执行数据操作的算子，只要出现 RDD 的行动算子，那么 RDD 之前的所有逻辑（包括转换算子的逻辑）都会按顺序执行。 \n RDD 转换算子 \n RDD 根据数据处理方式的不同，可以分为 Value 类型、双 Value 类型，Key Value 类型。 \n Value 类型 \n \n \n map：将输入数据逐条映射转换，包括值和类型的转换。 \n \n \n mapPartitions：将待处理的数据以分区为单位，发送到计算节点进行处理，这里的处理可以为任意处理，比如过滤数据。 \n map 和 mapPartitions 有区别： \n 从数据的角度考虑，map 是一个数据一个数据地执行，而 mapPartitions 是以分区为单位进行批处理操作。 \n 从功能的角度考虑，map 是将数据进行转换，但是不会去改变数据的数量，而 mapPartitions 需要一个迭代器，返回一个迭代器，没有要求总数不变，所以可以对数据进行增删。 \n 从性能的角度来考虑：map 类似串行执行，而 mapPartitions 类似批处理，但是 mapPartitions 会长时间占用内存，有可能会导致内存溢出。所以内存有限情况下优先使用 map。 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n // map：一进一出，将数据逐条进行转换处理，这里就是乘 2 处理操作。 \nsc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) . map ( _  *   2 ) . foreach ( println ) \n\n /*\n    mapPartitions：按照分区为单位，将数据发送到计算节点去处理。输入为一个迭代器，输入也是一个迭代器。\n\n    与 map 有所不同：\n        - map 是按照分区内的数据为单位去处理，速度较慢。\n        - mapPartitions：按照分区为单位去处理，速度较快，但是应当警惕当数据量过于庞大时，内存可能会溢出。\n*/ \nsc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) . mapPartitions ( iterator  =>  iterator . filter ( _  %   2   ==   0 ) ) . foreach ( println ) \nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n \n flatMap：将数据扁平化处理： \n 例如  List(List(1, 2), List(3, 4)) => List(1, 2, 3, 4) \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n /*\n在这里可以将 List(1, 2) 和 List(3, 4) 看成两条河流：\n    - 一般的 map 操作都是对这里两条河流分别进行操作，最后分别输出。\n    - flatMap 可以看成将这两条河流分别进行处理，然后将处理的结果汇总到一起输出。在这里没有对 list 进行处理，直接输出，就是做了一层汇总的效果。\n*/ \nsc . makeRDD ( List ( List ( 1 ,   2 ) ,  List ( 3 ,   4 ) ) ) . flatMap ( list  =>  list ) . foreach ( println ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 \n \n glom：将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变。 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n val  rdd :  RDD [ Int ]   =  sc . makeRDD ( List ( List ( 1 ,   2 ) ,  List ( 3 ,   4 ) ) ) \n val  arrRDD :  RDD [ Array [ Int ] ]   =  rdd . glom ( ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 \n \n groupBy：将数据根据指定的规则进行分组： \n 分区默认不变，但是数据会被打乱重新组合，这种操作我们称为 Shuffle，极限情况下，数据有可能被分到同一个分区中，Shuffle 还有其他的坏处，要尽量避免 Shuffle 操作。 \n 注意，上面说的分组并不是分区，一个分区中可能有多个分组。 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n /*\n    数字对 2 进行取余共有两种结果：0、1.\n\n    这里进行分组，条件为 List 中的元素是否为 2 的余数，那么就会分为两组：\n    - 一组的 key 为 0，value 为 2 的余数。\n    - 一组的 key 为 1，value 非 2 的余数。\n*/ \n val  rdd :  RDD [ ( Int ,  Iterable [ Int ] ) ]   =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) . groupBy ( _  %   2 ) \n // scala 中 ，_1 和 _2 分别对应 key、value \nrdd . foreach ( group  =>   { \n    println ( group . _1 ) \n    println ( group . _2 . toString ( ) ) \n } ) \nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n \n filter：按照指定规则进行过滤，分区不变。过滤之后有可能导致数据倾斜。 \n \n \n sample：按照指定的规则从数据集中抽取数据。 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) \n\n /*\n    sample，简单来说是做随机取样的一个函数，它可以根据指定的规则从数据集中抽取数据。\n\n    简单来说，假如有这样一个箱子，箱子里有各种各样的小球，对于这些小球，有这样的抽取方法：\n\n    - 抽到的数据不放回箱子：伯努利算法：\n\n        也叫做 0、1 算法，简单来说就是非黑即白，和扔硬币一样，不是正面就是反面，采取这样的算法，sample 有三个参数：\n\n        - 参数一：抽取的数据是否放回，选择伯努利算法当然是 false。\n        - 参数二：一个数据被抽取到的几率，范围在 [0, 1]，0 为全取，1 为全不取。\n        - 参数三：随机种子，一般来说可以不填。\n\n    - 抽到的数据放回箱子：泊松算法：\n\n        如果选择泊松分布，有以下几个参数：\n\n        - 参数一：抽取的数据是否放回，选择泊松分布当然选择 true。\n        - 参数二：重复数据的几率，范围 >= 0，表示每个元素被期望抽取到的次数。\n        - 参数三：随机数种子，一般来说可以不填。\n*/ \n\nrdd . sample ( false ,   0.5 ) . foreach ( print ) \nprintln ( ) \nrdd . sample ( true ,   2 ) . foreach ( print ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 为啥这里说第三个参数中子数可以不填呢，如果玩过游戏都知道，地图的种子确定了，那么地图就确定了，如果写死了种子，写死了算法，那么最终的数据就是确定的。 \n \n \n distinct：数据集去重。 \n \n \n coalesce：缩减分区： \n 如果当前 Spark 程序中存在过多的小任务，每个任务的数据量都很少，那么启动多个 task 就显得很不划算： \n \n 因为资源有时候是不太好动态调整的。比如每启动一个 task，都需要给 executor 1核2G 来进行计算一个 1M 的数据，简直大材小用，还容易导致资源紧张。 \n 调度问题也是个问题，有那调度的时间，早就算好好几次了。 \n \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n // 指定分区为 6 \n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ,   5 ,   6 ) ,   6 ) \n // 将分区数缩减到 2 \nrdd . coalesce ( 2 ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 coalesce 参数： \n \n 参数一：想要缩减到几个分区。 \n 参数二：shuffle，默认为 false。 \n 参数三：分区器。 \n \n \n \n repartition：重置分区。 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "Operator" ) ) \n\n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ,   5 ,   6 ) ,   2 ) \nrdd . repartition ( 6 ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 其实调用了 coalesce，参数 shuffle 的默认值为 true。其实无论是将分区多的 RDD 转为分区少的 RDD，还是将分区少的 RDD 转换为分区多的 RDD，它都可以胜任，因为无论如何都会经过 shuffle。 \n coalesce 的 shuffle 可以自由选择，而 repartition 必须进行 shuffle。这里其实涉及到了一个宽窄依赖的问题，宽窄依赖在后面会有详细的解释。 \n \n \n sortBy：按照规则进行排序：用于排序处理，排序后，新产生的 RDD 分区数量和原来的 RDD 分区数量保持一致，中间存在 shuffle 过程。 \n \n \n 双 Value 型 \n \n intersection：两个 RDD 取交集，返回一个新的 RDD。 \n union：两个 RDD 去并集，返回一个新的 RDD。 \n subtract：两个 RDD 取差集：以一个 RDD 为主，去除两个 RDD 的重复元素，将其他的元素保留。 \n zip：将两个 RDD 中的元素以键值对形式进行合并，注意这不是压缩。 \n \n Key Value 型 \n \n \n partitionBy：将数据按照指定 partitioner 重新分区，Spark 默认分区器为 HashPartitioner。 \n \n \n reduceByKey：将数据按照相同的 key 对 value 进行聚合。 \n \n \n groupByKey：将数据按照相同的 key 对 value 进行分组。 \n reduceByKey 和 groupByKey 其实很相似： \n 两者都存在 shuffle 操作，但是 reduceByKey 会在 shuffle 之前对分区内相同 key 的数据进行一次预聚合，类似于 MapReduce 的 combine 阶段，这样做的好处是可以减少落盘的数据量。 \n groupByKey 仅仅是分组，不会进行 combine 操作。 \n 所以从 reduceByKey 性能较高。 \n \n \n aggregateByKey：将分区内和分区间指定两套规则，分区内和分区间分别使用这两套规则进行计算。 \n \n \n foldByKey：指定一套规则，分区内和分区间的计算都使用这一套规则，相当于 aggregateByKey 的简化版。 \n \n \n combineByKey：进行聚集操作，它允许用户的返回值类型和输入类型不一致。 \n \n \n sortByKey：根据 key 来进行排序，其中 key 必须可以排序（自定义的 Bean 实现排序接口）。 \n \n \n join：在两个 RDD 之间进行 JOIN 操作，返回一个相同的 key 连接到一起的 RDD。 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n val  rdd1  =  sc . makeRDD ( Array ( ( 1 ,   "a" ) ,   ( 2 ,   "b" ) ,   ( 3 ,   "c" ) ) ) \n val  rdd2  =  sc . makeRDD ( Array ( ( 1 ,   "x" ) ,   ( 2 ,   "y" ) ,   ( 3 ,   "z" ) ) ) \n /*\n(1,(a,x))\n(2,(b,y))\n(3,(c,z))\n*/ \nrdd1 . join ( rdd2 ) . collect ( ) . foreach ( println ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 \n \n leftOuterJoin：类似 SQL 的左外链接。 \n \n \n cogroup：两种 (K, V) 和 (K, W) 类型的 RDD 调用形成： (K, (Iterable<V>, (Iterable<W>))) \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n val  rdd1  =  sc . makeRDD ( Array ( ( 1 ,   "a" ) ,   ( 2 ,   "b" ) ,   ( 3 ,   "c" ) ) ) \n val  rdd2  =  sc . makeRDD ( Array ( ( 1 ,   "x" ) ,   ( 2 ,   "y" ) ,   ( 3 ,   "z" ) ) ) \n /*\n(1, (CompactBuffer(a), CompactBuffer(x)))\n(2, (CompactBuffer(b), CompactBuffer(y)))\n(3, (CompactBuffer(c), CompactBuffer(z)))\n*/ \nrdd1 . cogroup ( rdd2 ) . collect ( ) . foreach ( println ) \n /*\nax\nby\ncz\n*/ \nrdd1 . cogroup ( rdd2 ) . collect ( ) . foreach ( v => { \n     val  value  =  v . _2\n    value . _1 . foreach ( print ) \n    value . _2 . foreach ( print ) \n    println ( ) \n } ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n RDD 行动算子 \n \n \n reduce：聚集 RDD 中的元素，首先聚集分区内，之后聚集分区间。 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) \nprintln ( rdd . reduce ( _  +  _ ) ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 \n \n collect：将 RDD 中的所有数据从 Executor 收集到 Driver。 \n \n \n count：返回 RDD 中元素的个数。 \n \n \n first：返回 RDD 中第一个元素。 \n \n \n task：返回一个由 RDD 的前 n 个元素组成的数组。 \n \n \n taskOrdered：返回 RDD 的后 n 个元素组成的数组。 \n \n \n aggregate：分区数值进行聚合。给一个初始值，初始值聚合第一个元素，形成的结果聚合第二个元素，形成的结果聚合第三个元素…… \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n // 切片数量为 2，最终分区数量为 2 \n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ,   2 ) \n /*\n第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}\n10 + 1 + 2 = 13\n10 + 3 + 4 = 17\n10 + 13 + 17 = 40\n*/ \nprintln ( rdd . aggregate ( 10 ) ( _  +  _ ,  _  +  _ ) ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n \n fold：aggregate 的简化版本，两个分区的聚合方式都相同。 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n\n // 切片数量为 2，最终分区数量为 2 \n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ,   2 ) \n /*\n第一个参数 10 为从 10 开始聚合，也就是每个分区内 10 + ${1} + ${2}，之后分区之间相加也是 10 + ${1} + ${2}\n10 + 1 + 2 = 13\n10 + 3 + 4 = 17\n10 + 13 + 17 = 40\n*/ \nprintln ( rdd . fold ( 10 ) ( _  +  _ ) ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n \n countByKey：根据 key 统计 value 的个数，返回  key, count(value) 。 \n \n \n saveAsTextFile：保存为 Text。 \n \n \n saveAsObjectFile：序列化为对象保存文件。 \n \n \n saveAsSequenceFile：保存为 sequence 文件。 \n \n \n foreach：分布式遍历每个，所以有可能顺序不一致。 \n RDD 序列化 \n 闭包检查 \n 从计算的角度来考虑，RDD 算子之外的代码其实都是在 Driver 端运行，算子内的逻辑都是在 Executor 中运行。 \n object  CreateRDDDemo   { \n  def  main ( args :   Array [ String ] ) :   Unit   =   { \n    val sparkConf  =   new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n    val sc  =   new   SparkContext ( sparkConf ) \n\n    val search  =   new   Search ( "SPARK" ) \n\n    search . getMatch ( sc . makeRDD ( List ( "HELLO WORLD" ,   "HELLO SPARK" ) ) ) . collect ( ) . foreach ( println ) \n\n    sc . stop ( ) \n   } \n } \n\n class   Search ( query :   String )   extends   Serializable   { \n  def  isMatch ( s :   String ) :   Boolean   =   { \n    s . contains ( query ) \n   } \n\n  def  getMatch ( rdd :  RDD [ String ] ) :  RDD [ String ]   =   { \n    rdd . filter ( this . isMatch ) \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 在 Scala 中，当算子内使用到了算子外的变量，也就是说 Executor 使用到了 Driver 的变量，这个时候假如对应的变量没有进行序列化，就无法通过网络传输给 Executor。 \n 在执行任务之前，检测对象是否可以进行序列化，这个过程叫做闭包检测。 \n Kryo \n 原生的 Java 序列化字节比较多，比较重，序列化之后对象比较大，Spark 出于性能考虑，从 Spark2.0 开始支持 kryo 。 \n 它是一个序列化框架，速度是 Serializable 的 10 倍，但是注意，即使是使用 kryo 也需要实现 Serializable。 \n RDD 依赖关系 \n RDD 的血缘关系 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n val  sc  =   new  SparkContext ( sparkConf ) \n /*\n(2) input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/ \n val  fileRDD :  RDD [ String ]   =  sc . textFile ( "input/1.txt" ) \nprintln ( fileRDD . toDebugString ) \nprintln ( "----------------------" ) \n\n /*\n(2) MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/ \n val  wordRDD :  RDD [ String ]   =  fileRDD . flatMap ( _ . split ( " " ) ) \nprintln ( wordRDD . toDebugString ) \nprintln ( "----------------------" ) \n\n /*\n(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []\n |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/ \n val  mapRDD :  RDD [ ( String ,   Int ) ]   =  wordRDD . map ( ( _ , 1 ) ) \nprintln ( mapRDD . toDebugString ) \nprintln ( "----------------------" ) \n\n /*\n(2) ShuffledRDD[4] at reduceByKey at CreateRDDDemo.scala:23 []\n +-(2) MapPartitionsRDD[3] at map at CreateRDDDemo.scala:19 []\n    |  MapPartitionsRDD[2] at flatMap at CreateRDDDemo.scala:15 []\n    |  input/1.txt MapPartitionsRDD[1] at textFile at CreateRDDDemo.scala:11 []\n    |  input/1.txt HadoopRDD[0] at textFile at CreateRDDDemo.scala:11 []\n*/ \n val  resultRDD :  RDD [ ( String ,   Int ) ]   =  mapRDD . reduceByKey ( _ + _ ) \nprintln ( resultRDD . toDebugString ) \n\nresultRDD . collect ( ) \nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 RDD 使用这种直接记录操作的方式记录下了一系列血缘（Lineage），当分区丢失时，可以使用重新走一遍操作的方式恢复丢失的分区。 \n 除了直接记录操作之外，RDD 还会记录相邻的 RDD 之间的关系，我们叫做依赖关系： \n def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "spark" ) \n   val  sc  =   new  SparkContext ( sparkConf ) \n\n   // List(org.apache.spark.OneToOneDependency@5dd903be)，一对一的关系 \n   val  fileRDD :  RDD [ String ]   =  sc . textFile ( "input/1.txt" ) \n  println ( fileRDD . dependencies ) \n  println ( "----------------------" ) \n\n   // List(org.apache.spark.OneToOneDependency@784abd3e)，一对一的关系 \n   val  wordRDD :  RDD [ String ]   =  fileRDD . flatMap ( _ . split ( " " ) ) \n  println ( wordRDD . dependencies ) \n  println ( "----------------------" ) \n\n   // List(org.apache.spark.OneToOneDependency@37df14d1)，一对一的关系 \n   val  mapRDD :  RDD [ ( String ,   Int ) ]   =  wordRDD . map ( ( _ , 1 ) ) \n  println ( mapRDD . dependencies ) \n  println ( "----------------------" ) \n\n   // List(org.apache.spark.ShuffleDependency@34585ac9)，进行了 Shuffle 操作 \n   val  resultRDD :  RDD [ ( String ,   Int ) ]   =  mapRDD . reduceByKey ( _ + _ ) \n  println ( resultRDD . dependencies ) \n\n  resultRDD . collect ( ) \n\n  sc . stop ( ) \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 RDD 宽窄依赖、阶段划分、任务划分 \n RDD 的算子就像是俄罗斯套娃，之前讲过 RDD 的逻辑不能更改，如果需要更改，那么就要重新生成一个新的算子。 \n 在从老的 RDD 到新 RDD 之间就产生了变化，例如： \n sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ) ) . map ( _  *   2 ) . foreach ( println ) \n \n 1 在这里， makeRDD  就产生了 RDD（老的 RDD），之后经过  map  操作就产生了一个新的 RDD。 \n \n 还是使用薯片制作的流程看宽窄依赖。 \n 从清洗到烘焙的过程中，可以看到 RDD 的分区没有进行改变，这个过程叫做窄依赖，也就是父 RDD 的数据只能被一个子 RDD 所继承，也可以理解为独生子女。 \n 在即食薯片到装桶的过程中间，经过了一个分发的阶段，也就是将大小不一的薯片归类为三种相同大小的薯片，这个过程叫做宽依赖，也就是父 RDD 中的数据可能被多个子 RDD 所继承，可以理解为多胎。 \n 在进行宽依赖的过程中，进行了一个薯片重新分区的情况，这其实就是进行了数据的 Shuffle，就是打乱重新排序。 \n \n 每一个 Spark 程序都是一个 Application，每一个 Application 遇到行动算子之后就会形成一个 Job，所以一个 Application 中可能有多个 Job。 \n 在 Job 的执行过程中，可能会遇到 Shuffle，那么此时就会划分为一个或者多个可以并行计算的 stage。 \n 每一个 stage 可以根据当前 RDD 的 partition 分为多个 Task，Task 由 Executor 去执行。 \n \n \n 在上图中，RDD 经过了 map、filter 操作，这两个操作并没有改变 RDD 的分区，但是经过 ReduceByKey 算子之后，分区中的数据被打乱重新排序了，这个操作就是宽依赖。 \n 我们任务的阶段划分即从开始的 RDD 到 Filtered RDD 为一个阶段。Reduced RDD 为一个阶段。也就是说任务阶段的划分完全取决与可以进行 Shuffle 的算子。 \n 在上图第一个阶段中，Task 的数量取决于此阶段最后一个 RDD 中分区数量，也就是 Filtered RDD 中的 4 个分区将会形成 4 个 Task。 \n 在第二个阶段中，Task 的数量取决于最后此阶段最后一个 RDD 中分区数量，也就是说取决于 Reduced RDD 的数量，也是 4 个。 \n RDD 持久化 \n RDD 虽然叫做弹性分布式数据集，但其实没有进行 Shuffle 之前，它并不会保存数据。不会保存数据的意思是，假如在计算的过程中出现了某些错误，那么并不会从之前的 RDD 开始算，而是从头开始，例如： \n val  fileRDD :  RDD [ String ]   =  sc . textFile ( "input/1.txt" ) \n val  wordRDD :  RDD [ String ]   =  fileRDD . flatMap ( _ . split ( " " ) ) \n val  mapRDD :  RDD [ ( String ,   Int ) ]   =  wordRDD . map ( ( _ , 1 ) ) \n val  resultRDD :  RDD [ ( String ,   Int ) ]   =  mapRDD . reduceByKey ( _ + _ ) \n \n 1 2 3 4 在这个例子中，假如中间在计算时忽然发生了错误导致任务失败（例如在进行 map 操作时失败），那么数据的计算不会从 map 再次开始，而是从数据的源头开始，也就是  textFile 。 \n 这肯定是我们不能忍受的，假如有一批数据量很大，耗时很久的任务，在执行过程中失败了，我们肯定不能接受从头再来。 \n 所以 Spark 提供了保存中间结果的功能，也就是 RDD 的持久化。利用 RDD 的持久化可以将计算结果中间的 RDD 保存到 JVM 的堆中。 \n 但是注意，进行持久化的操作并不是行动算子，也仅仅是一个逻辑的封装，要等到行动算子进行任务的执行之后，到达缓存的逻辑才会将 RDD 缓存起来。 \n Cache \n val  fileRDD :  RDD [ String ]   =  sc . textFile ( "input/1.txt" ) \n val  wordRDD :  RDD [ String ]   =  fileRDD . flatMap ( _ . split ( " " ) ) \n\nwordRDD . cache ( ) \n\n val  mapRDD :  RDD [ ( String ,   Int ) ]   =  wordRDD . map ( ( _ , 1 ) ) \n val  resultRDD :  RDD [ ( String ,   Int ) ]   =  mapRDD . reduceByKey ( _ + _ ) \n \n 1 2 3 4 5 6 7 简单来说，利用  cache()  方法就可以将 RDD 缓存，假如上述案例在 map 操作时出错了，也不需要从头开始计算。 \n 但是我们也说过，存储默认是存到 JVM 堆中的，那么假如内存不够了，缓存也可以丢失，所以可以更改存储级别： \n val  fileRDD :  RDD [ String ]   =  sc . textFile ( "input/1.txt" ) \n val  wordRDD :  RDD [ String ]   =  fileRDD . flatMap ( _ . split ( " " ) ) \n\nwordRDD . cache ( ) \nwordRDD . persist ( StorageLevel . MEMORY_ONLY_SER ) \n\n val  mapRDD :  RDD [ ( String ,   Int ) ]   =  wordRDD . map ( ( _ , 1 ) ) \n val  resultRDD :  RDD [ ( String ,   Int ) ]   =  mapRDD . reduceByKey ( _ + _ ) \n \n 1 2 3 4 5 6 7 8 \n \n \n 级别 \n 备注 \n \n \n \n \n MEMORY_ONLY \n 以序列化的方式，仅存在内存中。内存不够不会再缓存。默认方式。 \n \n \n MEMORY_ONLY_SER \n 以序列化的方式，仅存在内存中。这种方式比反序列化对象的方式很大程度上节省空间，但是会增加 CPU 负担。内存不够不会再缓存。 \n \n \n MEMORY_AND_DISK \n 反序列化方式，内存不够放硬盘。 \n \n \n MEMORY_AND_DISK_SER \n 序列化方式，内存不够放硬盘。 \n \n \n DISK_ONLY \n 在硬盘上缓存 \n \n \n MEMORY_ONLY_2 \n 与上面功能相同，只不过会在集群中的两个节点上建立副本 \n \n \n MEMORY_AND_DISK_2 \n 与上面功能相同，只不过会在集群中的两个节点上建立副本 \n \n \n \n Spark 的存储级别本质其实就是 CPU 和 内存之间的权衡。 \n 如果内存可以缓存全部的 RDD，那么使用默认方式即可，默认方式可以最大程度提高 CPU 效率。\n假如内存不可缓存全部的 RDD，那么可以优先使用  MEMORY_ONLY_SER  以减少磁盘浪费，然后挑一个快速序列化对象的框架（之前说的 Kryo），不必要尽量不要溢写到磁盘，效率太低。 \n CheckPoint \n 和 Cache 不同，CheckPoint 就是将中间 RDD 写入到磁盘中。 \n 如果 RDD 的血缘关系过长，那么还不如在中间节点做点容错处理，好过之后有错误从头开始执行。 \n 但是只要使用了 CheckPoint，就会切断之前的血缘关系，从检查点的这一刻开始作为根。 \n Cache 和 CheckPoint 区别 \n \n Cache 不会切断血缘，CheckPoint 会切断血缘。 \n Cache 可靠性低，一般保存在内存、磁盘中。CheckPoint 通常保存在 HDFS 等高容错系统中。 \n RDD 分区器 \n \n 分区器决定了 RDD 中分区的个数，RDD 中的每条数据经过 Shuffle 之后进入到哪个分区。 \n \n 只有 KV 类型的 RDD 才有分区器，非 KV 类型的 RDD 分区值为 None。 \n 每个 RDD 的分区 ID 范围  0 ~ (numPartitions - 1) ，决定这个值是属于哪个分区的。 \n \n Spark 支持多种分区器，我们主要探索 Hash（默认分区器）、Range、自定义分区。 \n Hash 分区 \n class  HashPartitioner ( partitions :   Int )   extends  Partitioner  { \n\n   . . . \n\n   def  getPartition ( key :   Any ) :   Int   =  key  match   { \n     // 之前说的是，假如不是 KV 类型，那么 K 为 null，这里就是 0 号分区，也就是没有分区。 \n     case   null   =>   0 \n     // 这里调用工具进行分区，第一个参数为 hashcode，第二个参数为指定的分区数量 \n     case  _  =>  Utils . nonNegativeMod ( key . hashCode ,  numPartitions ) \n   } \n\n   . . . \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 def  nonNegativeMod ( x :   Int ,  mod :   Int ) :   Int   =   { \n     // 首先进行 hashCode 对 分区数量取余操作 \n     val  rawMod  =  x  %  mod\n     // 保证为 0 ~ 分区数 \n    rawMod  +   ( if   ( rawMod  <   0 )  mod  else   0 ) \n } \n \n 1 2 3 4 5 6 Range 分区 \n 将一定范围内的数据映射到一个分区中，保证每隔分区内的数据均匀，而且分区见有序。 \n 累加器 \n 累加器的概念和原理 \n 之前说 Spark 为了能够进行高并发和高吞吐的处理，封装了三大数据结构。RDD 我们已经看过了，接下来就是累加器和广播变量。 \n 累加器其实是一个分布式的，只写的变量。它的实现原理是这样的： \n 在 Driver 端先定义变量，在 RDD 形成 Task 分发到每一个 Executor 时，Executor 端的每一个 Task 都会得到累加器的一个新的副本，每一个 Task 更新这个变量之后，都会传到 Driver 端，然后 merge 改变的值。 \n 系统累加器 \n val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "AccumulatorDemo" ) ) \n\n val  rdd  =  sc . makeRDD ( List ( 1 ,   2 ,   3 ,   4 ,   5 ) ) \n // 声明一个 Long 的累加器 \n val  sum  =  sc . longAccumulator ( "sum" ) \n // 累加器的使用 \nrdd . foreach ( num  =>  sum . add ( num ) ) \nprintln ( sum . value ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 除了 longAccumulator 之外，系统的累加器还有： \n \n 自定义累加器 \n 实际上，我们大部分在使用累加器的过程中都不会单纯地使用系统的累加器，结合业务场景，我们需要自定义的累加器。 \n 自定义累加器仅需两个步骤： \n \n 继承  AccumulatorV2 ，设定泛型。 \n 重写抽象方法。 \n 向 Spark 中注册累加器。 \n \n 接下来使用 WordCountAccumulator 来作为案例，实现自定义累加器。 \n /**\n * AccumulatorV2 共有两个泛型：输入、输出。\n * 这里定义了输入为 String，输出为 Map[String, Long]\n */ \n class  WordCountAccumulator  extends  AccumulatorV2 [ String ,  mutable . Map [ String ,   Long ] ]   { \n\n   // 定义 map 作为输出 \n   var  map :  mutable . Map [ String ,   Long ]   =  mutable . Map ( ) \n\n   // 累加器为初始状态的条件，这里就是当 map 为空时 \n   override   def  isZero :   Boolean   =   { \n    map . isEmpty\n   } \n\n   // 复制累加器，这一步用于 Driver 和 Executor 做交互时，复制累加器的副本 \n   override   def  copy ( ) :  AccumulatorV2 [ String ,  mutable . Map [ String ,   Long ] ]   =   { \n     new  WordCountAccumulator\n   } \n\n   // 重置累加器 \n   override   def  reset ( ) :   Unit   =   { \n    map . clear ( ) \n   } \n\n   // 累加器累加数据，word 就是输入的 String \n   override   def  add ( word :   String ) :   Unit   =   { \n     /*\n      查询 map 中是否拥有相同的单词：\n\n      - 假如存在此单词，则在 map 中 +1 数量\n      - 假如不存在此单词，则在 map 中增加这个词\n     */ \n    map ( word )   =  map . getOrElse ( word ,   0L )   +   1L \n   } \n\n   // 用于 Driver 端合并从 Executor 传过来的累加器 \n   override   def  merge ( other :  AccumulatorV2 [ String ,  mutable . Map [ String ,   Long ] ] ) :   Unit   =   { \n     val  map1  =  map\n     val  map2  =  other . value\n\n     // map2 为初始值。innerMap 为返回结果对象，是一个迭代值。kv 表示 map1 中的每个值。 \n    map  =  map1 . foldLeft ( map2 ) ( ( innerMap ,  kv )   =>   { \n         /*\n          查询 innerMap 中是否拥有相同的单词：\n\n          - 假如存在此单词，则在 innerMap 中 +1 数量\n          - 假如不存在此单词，则在 innerMap 中增加这个词\n         */ \n        innerMap ( kv . _1 )   =  innerMap . getOrElse ( kv . _1 ,   0L )   +  kv . _2\n        innerMap\n       } \n     ) \n   } \n\n   // 返回累加器的结果 \n   override   def  value :  mutable . Map [ String ,   Long ]   =  map\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 val  sc  =   new  SparkContext ( new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "AccumulatorDemo" ) ) \n\n val  rdd  =  sc . makeRDD ( List ( "HELLO WORLD" ,   "HELLO SPARK" ,   "HELLO SCALA" ) ) \n val  wcAcc  =   new  WordCountAccumulator ( ) \nsc . register ( wcAcc , "WordCountAccumulator" ) \nrdd . foreach ( word  =>  wcAcc . add ( word ) ) \nprintln ( wcAcc . value ) \n\nsc . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 #  广播变量 \n Spark 的最后一个结构，广播变量，它是一个分布式的，共享的，只读变量。广播变量的分发是比较高效的。 \n 广播变量一般情况下会用来分发较大的对象，它会向所有的 Executor 发送一个较大的只读值，来让一个或多个 Spark 操作使用。 \n val  rdd1  =  sc . makeRDD ( List (   ( "a" , 1 ) ,   ( "b" ,   2 ) ,   ( "c" ,   3 ) ,   ( "d" ,   4 )   ) , 4 ) \n val  list  =  List (   ( "a" , 4 ) ,   ( "b" ,   5 ) ,   ( "c" ,   6 ) ,   ( "d" ,   7 )   ) \n // 声明广播变量 \n val  broadcast :  Broadcast [ List [ ( String ,   Int ) ] ]   =  sc . broadcast ( list ) \n\n val  resultRDD :  RDD [ ( String ,   ( Int ,   Int ) ) ]   =  rdd1 . map  { \n   case   ( key ,  num )   =>   { \n     var  num2  =   0 \n     // 使用广播变量 \n     for   ( ( k ,  v )   <-  broadcast . value )   { \n       if   ( k  ==  key )   { \n        num2  =  v\n       } \n     } \n     ( key ,   ( num ,  num2 ) ) \n   } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 4, 2022 10:35",createTimeStamp:1641263743e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Zookeeper",frontmatter:{title:"Zookeeper",categories:["bigdata"],tags:["zookeeper"],author:"causes",summary:"概述 Zookeeper，是一个开源的、分布式的、为分布式应用提供协调服务的 Apache 项目。简单来说，就是一剂润滑剂。 从设计模式的角度来理解，Zookeeper 是一个基于观察者模式设计的分布式服务管理框架，负责存储和管理重要的数据，然后接受观察者注册。 简单来说，Zookeeper = 文件系统 + 通知机制。 服务的场景包括：统一命名、统一配置管",meta:[{property:"og:url",content:"/bigdata/Zookeeper/part1.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Zookeeper"},{property:"og:description",content:"概述 Zookeeper，是一个开源的、分布式的、为分布式应用提供协调服务的 Apache 项目。简单来说，就是一剂润滑剂。 从设计模式的角度来理解，Zookeeper 是一个基于观察者模式设计的分布式服务管理框架，负责存储和管理重要的数据，然后接受观察者注册。 简单来说，Zookeeper = 文件系统 + 通知机制。 服务的场景包括：统一命名、统一配置管"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"zookeeper"}]},regularPath:"/bigdata/Zookeeper/part1.html",relativePath:"bigdata/Zookeeper/part1.md",key:"v-6ed3dbc8",path:"/bigdata/Zookeeper/part1/",headers:[{level:2,title:"概述",slug:"概述"},{level:2,title:"安装部署",slug:"安装部署"},{level:2,title:"快速开始",slug:"快速开始"},{level:3,title:"客户端命令行",slug:"客户端命令行"},{level:3,title:"API 使用",slug:"api-使用"},{level:2,title:"Zookeeper 内部原理",slug:"zookeeper-内部原理"}],readingTime:{minutes:10.14,words:3042},content:' 概述 \n Zookeeper ，是一个开源的、分布式的、为分布式应用提供协调服务的 Apache 项目。简单来说，就是一剂润滑剂。 \n 从设计模式的角度来理解，Zookeeper 是一个基于观察者模式设计的分布式服务管理框架，负责存储和管理重要的数据，然后接受观察者注册。 \n 简单来说，Zookeeper = 文件系统 + 通知机制。 \n 服务的场景包括：统一命名、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。 \n Zookeeper 特点 \n \n 一个 leader，多个 follower。 \n 集群中只要有半数以上的节点存活，Zookeeper 就能正常提供服务。 \n Zookeeper 的数据全局一致。无论客户端连接到哪个节点的服务，都会得到相同的数据。 \n 来自一个客户端的请求按照发送顺序依次执行。 \n 数据更新是原子性的，一次的数据更新要么成功，要么失败，没有更新半截的情况。 \n 实时性，在一定的时间范围内，客户端可以读取到最新数据。 \n \n 数据结构 \n Zookeeper 数据结构类似 Unix 文件系统，整体上可以看成一棵树，每个节点叫做  ZNode 。每个 ZNode 默认可以存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识。 \n 安装部署 \n 本地安装 \n \n \n 准备 JDK \n \n \n 拷贝 Zookeeper 到 Linux 中，解压到指定目录，配置环境变量。 \n \n \n 修改  conf  目录下的配置文件  zoo_sample.cfg  为  zoo.cfg ，并且修改如下内容： \n dataDir=/opt/module/apache-zookeeper-3.5.7/zkData\n \n 1 \n \n 操作 Zookeeper： \n \n 启动： bin/zkServer.sh start \n 使用 jps，查看是否启动了进程  QuorumPeerMain 。 \n 查看状态： bin/zkServer.sh status \n 启动客户端： bin/zkCli.sh \n 退出客户端： quit \n 停止 Zookeeper： bin/zkServer.sh stop \n \n \n \n 配置参数介绍 \n通信心跳数，Zookeeper 服务器和客户端的心跳时间，毫秒值 \n tickTime = 2000 \nLeader - Follower 初始通信时限 \n initLimit = 10 \nLeader - Follower 同步通信时限 \n syncLimit = 5 \n数据文件目录 + 数据持久化路径 \n dataDir = /opt/module/apache-zookeeper-3.5.7/zkData\n客户端链接端口 \n clientPort = 2181 \n \n 1 2 3 4 5 6 7 8 9 10 分布式安装 \n \n \n 解压 Zookeeper3.5.7 到对应的  /opt/module  下，配置好环境变量。 \n \n \n 在  $ZOOKEEPER_HOME  下创建 zkData 文件夹。 \n \n \n 创建文件名为  myid  的文件，给 hadoop102 配置为 2，hadoop103 配置为 3，hadoop104 配置为 4。 \n \n \n 配置 zoo.cfg 文件： \n 将  $ZOOKEEPER_HOME/conf  下的  zoo_sample.cfg  改为  zoo.cfg \n 修改  dataDir=/opt/module/zookeeper-3.5.7/zkData \n 增加配置： \n #######################cluster########################## \nserver.2 = hadoop102:2888:3888\nserver.3 = hadoop103:2888:3888\nserver.4 = hadoop104:2888:3888\n \n 1 2 3 4 配置  server.A=B:C:D ： \n \n 其中 A 是服务器编号，在集群模式下配置一个  myid  的文件，这个文件在  dataDir  下，配置的数据就是这个 A 的值 \n B 是服务器地址。 \n C 是服务器的 Follower 和集群中 Leader 交换信息的端口。 \n D 是 Leader 重选时相互通信端口，避免 Leader 挂掉之后没有 Leader 可用的情况。 \n \n \n \n 分别启动 Zookeeper： bin/zkServer.sh start \n \n \n 查看状态： bin/zkServer.sh status \n 快速开始 \n 客户端命令行 \n 客户端命令行基本语法： \n \n \n \n 命令基本语法 \n 功能描述 \n \n \n \n \n help \n 显示所有操作命令 \n \n \n ls path \n 查看  znode  的子节点； -w  可以监听子节点变化； -s  查看次级信息 \n \n \n create \n 普通创建； -s  含序列创建； -e  临时创建，重启或者超时消失 \n \n \n getPath \n 获得节点的值； -w  监听节点内容变化； -s  附加次级信息 \n \n \n set \n 设置节点的具体指 \n \n \n stat \n 查看节点状态 \n \n \n delete \n 删除节点 \n \n \n deleteall \n 递归删除节点 \n查看当前节点 \n [ zk: localhost:2181 ( CONNECTED )   0 ]   ls  /\n [ zookeeper ] \n查看当前节点，附加次级节点 \n [ zk: localhost:2181 ( CONNECTED )   1 ]   ls  -s /\n [ zookeeper ] cZxid  =  0x0\nctime  =  Thu Jan 01 08:00:00 CST  1970 \nmZxid  =  0x0\nmtime  =  Thu Jan 01 08:00:00 CST  1970 \npZxid  =  0x0\ncversion  =  -1\ndataVersion  =   0 \naclVersion  =   0 \nephemeralOwner  =  0x0\ndataLength  =   0 \nnumChildren  =   1 \n创建一个节点，并且给定值 \n [ zk: localhost:2181 ( CONNECTED )   2 ]  create /sanguo  "diaochan" \nCreated /sanguo\n在 sanguo 节点下创建一个节点，并且给定值 \n [ zk: localhost:2181 ( CONNECTED )   3 ]  create /sanguo/shuguo  "liubei" \nCreated /sanguo/shuguo\n获取节点值 \n [ zk: localhost:2181 ( CONNECTED )   4 ]  get /sanguo\ndiaochan\n获取节点值，并且附加次级信息 \n [ zk: localhost:2181 ( CONNECTED )   6 ]  get -s /sanguo/shuguo\nliubei\ncZxid  =  0x7\nctime  =  Tue Mar  29   15 :56:30 CST  2022 \nmZxid  =  0x7\nmtime  =  Tue Mar  29   15 :56:30 CST  2022 \npZxid  =  0x7\ncversion  =   0 \ndataVersion  =   0 \naclVersion  =   0 \nephemeralOwner  =  0x0\ndataLength  =   6 \nnumChildren  =   0 \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # 创建一个临时节点 \n [ zk: localhost:2181 ( CONNECTED )   7 ]  create -e /sanguo/wuguo  "zhouyu" \nCreated /sanguo/wuguo\n在当前客户端可以查看 \n [ zk: localhost:2181 ( CONNECTED )   8 ]   ls  /sanguo\n [ shuguo, wuguo ] \n使用 quit 退出再重新登录，临时节点已经删除了 \n [ zk: localhost:2181 ( CONNECTED )   0 ]   ls  /sanguo\n [ shuguo ] \n \n 1 2 3 4 5 6 7 8 9 # 创建一个普通的节点 \n [ zk: localhost:2181 ( CONNECTED )   1 ]  create /sanguo/weiguo  "caocao" \nCreated /sanguo/weiguo\n再次创建时，显示已经存在了这个节点，不允许再次创建 \n [ zk: localhost:2181 ( CONNECTED )   2 ]  create /sanguo/weiguo  "caocao" \nNode already exists: /sanguo/weiguo\n创建一个带序号的节点 \n [ zk: localhost:2181 ( CONNECTED )   3 ]  create -s /sanguo/weiguo  "caocao" \nCreated /sanguo/weiguo0000000003\n查看节点，发现已经有了带序号的节点 \n [ zk: localhost:2181 ( CONNECTED )   4 ]   ls  /sanguo\n [ shuguo, weiguo, weiguo0000000003 ] \n \n 1 2 3 4 5 6 7 8 9 10 11 12 # 修改节点值 \n [ zk: localhost:2181 ( CONNECTED )   2 ]   set  /sanguo/weiguo  "caopi" \n \n 1 2 #  API 使用 \n \n \n 环境搭建： \n < dependencies > \n     < dependency > \n         < groupId > junit </ groupId > \n         < artifactId > junit </ artifactId > \n         < version > RELEASE </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.apache.logging.log4j </ groupId > \n         < artifactId > log4j-core </ artifactId > \n         < version > 2.8.2 </ version > \n     </ dependency > \n     < dependency > \n         < groupId > org.apache.zookeeper </ groupId > \n         < artifactId > zookeeper </ artifactId > \n         < version > 3.5.7 </ version > \n     </ dependency > \n </ dependencies > \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n \n log4j.properties \n log4j.rootLogger = INFO, stdout \n log4j.appender.stdout = org.apache.log4j.ConsoleAppender \n log4j.appender.stdout.layout = org.apache.log4j.PatternLayout \n log4j.appender.stdout.layout.ConversionPattern = %d %p [%c] - %m%n \n log4j.appender.logfile = org.apache.log4j.FileAppender \n log4j.appender.logfile.File = target/spring.log \n log4j.appender.logfile.layout = org.apache.log4j.PatternLayout \n log4j.appender.logfile.layout.ConversionPattern = %d %p [%c] - %m%n \n \n 1 2 3 4 5 6 7 8 注意一点，log4j 的漏洞问题，非个人项目需要注意。 \n \n \n API \n public   class   Zookeeper   { \n\n private   String  connectString ; \n private   int  sessionTimeout ; \n private   ZooKeeper  zkClient ; \n\n /**\n* 获取客户端对象\n*/ \n @Before \n public   void   init ( )   throws   IOException   { \n\n    connectString  =   "hadoop102:2181,hadoop103:2181,hadoop104:2181" ; \n    sessionTimeout  =   10000 ; \n\n     /*\n    1. 集群连接字符串\n    2. 连接超时时间，单位为毫秒\n    3. 当前客户端默认的监控器\n    */ \n    zkClient  =   new   ZooKeeper ( connectString ,  sessionTimeout ,   new   Watcher ( )   { \n     @Override \n     public   void   process ( WatchedEvent  event )   { \n     } \n     } ) ; \n } \n\n @Test \n public   void   create ( )   throws   InterruptedException ,   KeeperException   { \n     /*\n    1. path: 节点路径\n    2. data: 节点内容，需要 byte\n    3. acl: 对操作用户的权限控制\n    4. createMode: 持久化选项\n        - PERSISTENT：持久的\n        - PERSISTENT_SEQUENTIAL：持久带序列\n        - EPHEMERAL：临时的\n        - EPHEMERAL_SEQUENTIAL：临时带序列\n    */ \n    zkClient . create ( "/sanguo" ,   "guanyu" . getBytes ( ) ,   ZooDefs . Ids . OPEN_ACL_UNSAFE ,   CreateMode . PERSISTENT ) ; \n } \n\n /**\n* 获取子节点列表，不监听\n*/ \n @Test \n public   void   ls ( )   throws   InterruptedException ,   KeeperException   { \n     List < String >  children  =  zkClient . getChildren ( "/" ,   false ) ; \n     System . out . println ( children ) ; \n } \n\n /**\n* 获取子节点列表并监听\n*/ \n @Test \n public   void   lsAndWatch ( )   throws   InterruptedException ,   KeeperException   { \n     List < String >  children  =  zkClient . getChildren ( "/" ,   new   Watcher ( )   { \n     @Override \n     public   void   process ( WatchedEvent  watchedEvent )   { \n         System . out . println ( "结果发生变化" ) ; \n     } \n     } ) ; \n     System . out . println ( children ) ; \n     // 因为设置了监听，所以当前线程不能结束 \n     Thread . sleep ( Long . MAX_VALUE ) ; \n } \n\n /**\n* 判断 node 是否存在\n*/ \n @Test \n public   void   exist ( )   throws   InterruptedException ,   KeeperException   { \n     String  path  =   "/sanguo" ; \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     boolean  isExit  =   Objects . isNull ( stat ) ; \n     System . out . printf ( "%s %s%n" ,  path ,  isExit  ?   "not exist"   :   "exist" ) ; \n } \n\n /**\n* 获取节点数据，不监听\n*/ \n @Test \n public   void   getData ( )   throws   InterruptedException ,   KeeperException   { \n     String  path  =   "/sanguo" ; \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     if   ( Objects . isNull ( stat ) )   { \n     System . out . printf ( "%s not exist" ,  path ) ; \n     return ; \n     } \n     byte [ ]  data  =  zkClient . getData ( path ,   false ,  stat ) ; \n     System . out . println ( new   String ( data ) ) ; \n } \n\n /**\n* 获取节点数据并监听\n*/ \n @Test \n public   void   getDataAndWatch ( )   throws   InterruptedException ,   KeeperException   { \n     String  path  =   "/sanguo" ; \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     if   ( Objects . isNull ( stat ) )   { \n     System . out . printf ( "%s not exist" ,  path ) ; \n     return ; \n     } \n     byte [ ]  data  =  zkClient . getData ( path ,   new   Watcher ( )   { \n     @Override \n     public   void   process ( WatchedEvent  watchedEvent )   { \n         System . out . println ( "节点变化……" ) ; \n     } \n     } ,  stat ) ; \n     System . out . println ( new   String ( data ) ) ; \n     Thread . sleep ( Long . MAX_VALUE ) ; \n } \n\n /**\n* 设置节点数据\n*/ \n @Test \n public   void   setData ( )   throws   InterruptedException ,   KeeperException   { \n     String  path  =   "/sanguo" ; \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     if   ( Objects . isNull ( stat ) )   { \n     System . out . printf ( "%s not exist" ,  path ) ; \n     return ; \n     } \n     /*\n    1. 节点路径\n    2. 节点新值\n    3. 节点版本号\n    */ \n    zkClient . setData ( path ,   "liubei" . getBytes ( ) ,  stat . getVersion ( ) ) ; \n } \n\n /**\n* 删除空节点\n*/ \n @Test \n public   void   deleteNullNode ( )   throws   InterruptedException ,   KeeperException   { \n     String  path  =   "/a" ; \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     if   ( Objects . isNull ( stat ) )   { \n     System . out . printf ( "%s not exist" ,  path ) ; \n     return ; \n     } \n    zkClient . delete ( path ,  stat . getVersion ( ) ) ; \n } \n\n /**\n* 递归删除节点，可以删除非空节点\n*/ \n @Test \n public   void   deleteNode ( )   throws   InterruptedException ,   KeeperException   { \n     deleteAll ( "/sanguo" ) ; \n } \n\n public   void   deleteAll ( String  path )   throws   InterruptedException ,   KeeperException   { \n     Stat  stat  =  zkClient . exists ( path ,   false ) ; \n     if   ( Objects . isNull ( stat ) )   { \n     return ; \n     } \n     List < String >  children  =  zkClient . getChildren ( path ,   false ) ; \n     if   ( children . isEmpty ( ) )   { \n    zkClient . delete ( path ,  stat . getVersion ( ) ) ; \n     return ; \n     } \n    children . forEach ( child  ->   { \n     try   { \n         deleteAll ( String . format ( "%s/%s" ,  path ,  child ) ) ; \n     }   catch   ( InterruptedException   |   KeeperException  e )   { \n        e . printStackTrace ( ) ; \n     } \n     } ) ; \n     // 注意最后不要忘记删除当前节点 \n    zkClient . delete ( path ,  stat . getVersion ( ) ) ; \n } \n\n /**\n* 关闭客户端对象\n*/ \n @After \n public   void   close ( )   throws   InterruptedException   { \n    zkClient . close ( ) ; \n } \n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 \n Zookeeper 内部原理 \n 内部节点 \n Zookeeper 内部节点有： \n \n 持久型节点 PERSISTENT：客户端和服务器断开连接之后，节点不删除。 \n 临时型节点 EPHEMERAL：客户端和服务器断开连接之后，节点删除。 \n \n \n \n \n \n 持久型节点 PERSISTENT \n 临时型节点 EPHEMERAL \n \n \n \n \n 编号 \n 持久化目录节点 \n 持久化顺序编号目录节点 \n \n \n 不编号 \n 临时目录节点 \n 临时顺序编号目录节点 \n \n \n \n 在创建顺序标识时，顺序号是一个单调递增计数器，由父节点进行维护。 \n 在分布式系统中，顺序号可以被用于全局排序，这样客户端可以根据顺序号推断事件的顺序。 \n 结构体 Stat \n \n \n czxid：数据节点被创建节点的事务 id。 \n 每次修改 zookeeper 的状态都会收到一个 zxid 形式的时间戳，也就是 zookeeper 事务 id。每个修改都有唯一的 zxid。 \n 加入 zxid1 < zxid2，那么 zxid1 在 zxid2 之前发生。 \n \n \n ctime：znode 被创建的毫秒数，从 1970 年开始。 \n \n \n mzxid：最后更新的事务 zxid。 \n \n \n mtime：最后修改的毫秒数，从 1970 年开始。 \n \n \n pZxid：znode 最后更新的子节点 zxid。 \n \n \n cversion：znode 最后修改的版本号，修改次数。 \n \n \n dataversion：znode 数据变化号。 \n \n \n aclVersion：znode 访问控制列表的变化号。 \n \n \n ephemeralOwner：假如不是临时节点则为 0，假如是临时节点则为拥有者的 session id。 \n \n \n dataLength：znode 数据长度。 \n \n \n numChildren：znode 子节点数量。 \n \n \n 监听器原理 \n \n 在主线程中创建 zookeeper 客户端，这时会创建两个线程：connect 网络连接通信、listener 监听。 \n connect 线程会将注册的监听事件发送给 zookeeper。 \n zookeeper 的注册监听器会将监听事件添加到监听列表中。 \n zookeeper 监听到事件，发送给 listener 线程。 \n listener 内部调用 process() \n \n \n 选举机制 \n 半数机制：在 zookeeper 中有半数以上的机器存活，则正常提供服务。所以 zookeeper 适合安装奇数台服务器。 \n zookeeper 没有在配置文件中指定 master 和 slave，但是在工作时有一个是 lead，其他都是 follower，这是选举决定的。 \n 现在有 5 台机器，模拟选举机制过程： \n \n \n 服务器 1 启动： \n 服务器 1 发起一次选举，投自己一票。此时服务器 1 一票，不够半数以上，选举无法完成，服务器 1 保持状态为 LOOKING。 \n \n \n 服务器 2 启动： \n 服务器 2 发起一次选举，服务器 1 和服务器 2 分别投自己一票，并且交换选票信息。 \n 服务器 1 发现服务器 2 的 id 高于自己，将选票交给服务器 2。 \n 此时服务器 1 为 0 票，服务器 2 为 2 票，不够半数以上，两者均保持为 LOOKING。 \n \n \n 服务器 3 启动： \n 类似上一个步骤，服务器 1、2 会将选票交给服务器 3，此时服务器 1、2 为 0 票，服务器 3 为 3 票。 \n 票数达到半数以上，服务器 3 当选 Leader，服务器 1、2 更改状态为 FOLLOWING。 \n 服务器 3 改变状态为 LEADING。 \n \n \n 服务器 4、5 启动，分别发起选举，但是此时服务器 1、2、3 都不是 LOOKING 状态，最后交换选票信息之后成为 FOLLOWING 状态。 \n \n \n 写数据流程 \n \n 客户端向 Zookeeper 上的 Server1 写数据，发送一个请求。 \n 假如 Server1 非 Leader，则会将请求转交给 Leader。 \n Leader 广播请求给 Follower。 \n 各个 Follower 将请求加入待写队列，并发送给 Leader 消息。 \n 当 Leader 收到半数以上 Follower 的信息，则说明写操作可以执行，Leader 会向各个 Follower 发送提交信息，各个 Follower 会落实队列中的写请求。 \n Server1 返回客户端写操作成功的消息。 \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"March 28, 2022 14:56",createTimeStamp:1648450571e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:2},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{title:"Spark-02-SparkSQL",frontmatter:{title:"Spark-02-SparkSQL",categories:["bigdata"],tags:["spark"],author:"causes",summary:"Spark SQL 概述 Spark SQL 其实和 Hive 很像，Hive 是将 Hive SQL 转化为 Hadoop 的 MapReduce，Spark SQL 是转为 Spark 算子。 Spark SQL 前身是 Shark，是伯克利实验室 Spark 生态环境组件之一，一开始是基于 Hive 开发的工具，让它能运行在 Spark 上。 但是随着",meta:[{property:"og:url",content:"/bigdata/Spark/part2.html"},{property:"og:site_name",content:"知识库"},{property:"og:title",content:"Spark-02-SparkSQL"},{property:"og:description",content:"Spark SQL 概述 Spark SQL 其实和 Hive 很像，Hive 是将 Hive SQL 转化为 Hadoop 的 MapReduce，Spark SQL 是转为 Spark 算子。 Spark SQL 前身是 Shark，是伯克利实验室 Spark 生态环境组件之一，一开始是基于 Hive 开发的工具，让它能运行在 Spark 上。 但是随着"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"},{property:"article:author",content:"causes"},{property:"article:tag",content:"spark"}]},regularPath:"/bigdata/Spark/part2.html",relativePath:"bigdata/Spark/part2.md",key:"v-69e6f508",path:"/bigdata/Spark/part2/",headers:[{level:2,title:"Spark SQL 概述",slug:"spark-sql-概述"},{level:2,title:"DataFrame",slug:"dataframe"},{level:3,title:"SparkSession",slug:"sparksession"},{level:3,title:"创建 DF",slug:"创建-df"},{level:3,title:"SQL 语法",slug:"sql-语法"},{level:3,title:"DSL",slug:"dsl"},{level:3,title:"RDD 与 DF 互相转换",slug:"rdd-与-df-互相转换"},{level:2,title:"Dataset",slug:"dataset"},{level:3,title:"创建 DS",slug:"创建-ds"},{level:3,title:"RDD、DF、DS 相互转换",slug:"rdd、df、ds-相互转换"},{level:3,title:"RDD、DF、DS 区别与联系",slug:"rdd、df、ds-区别与联系"},{level:2,title:"用户自定义函数",slug:"用户自定义函数"},{level:3,title:"UDF",slug:"udf"},{level:3,title:"UDAF",slug:"udaf"},{level:2,title:"数据的加载和保存",slug:"数据的加载和保存"}],readingTime:{minutes:11.35,words:3404},content:' Spark SQL 概述 \n Spark SQL 其实和 Hive 很像，Hive 是将 Hive SQL 转化为 Hadoop 的 MapReduce，Spark SQL 是转为 Spark 算子。 \n Spark SQL 前身是 Shark，是伯克利实验室 Spark 生态环境组件之一，一开始是基于 Hive 开发的工具，让它能运行在 Spark 上。 \n 但是随着 Spark 的发展，Shark 对于 Hive 的太多依赖制约了 Spark，所以分出了两条线：Spark SQL、Hive on Spark。 \n Spark SQL 出现了，它抛弃了原有 Shark 的代码，汲取了部分优点并重新开发。 \n Spark SQL 当前兼容 Hive、RDD、parquet、JSON 等多种数据源，未来甚至支持 NOSQL。性能优化良好，组件扩展方面（SQL 语法解析器、分析器、优化器）都可以重新定义和扩展。 \n 对于开发人员来讲，Spark SQL 可以简化 RDD 开发，提高开发效率，并且执行效率很快。 \n 为了简化 RDD 的开发，Spark SQL 提供了两个编程抽象，类似 Spark Core 的 RDD。 \n \n DataFrame（DF） \n 在 Spark 中，DF 基于 RDD，类似二维表格，但是与 RDD 不同的是，RDD 没有元数据信息，而 DF 存在。 \n 比如说，一个 Person 类，包含  name、age、height  属性，在 RDD 中，这三个属性是不会表现出来的，但是在 DF 中会表现出来。 \n \n 同时，DF 也支持嵌套数据类型（struct、map、array），API 也比较易操作。在性能方面，依赖于优化器，DF 的执行效率比 RDD 更高，并且也是懒执行的，所以 DF 更加友好。 \n 但是 DF 也有缺点，即 DF 是若类型的，例如上面说的 Person，如果要获得 name 属性，只能使用类似  person[0]  的方式来获取，也就是说，虽然它支持类型，但在开发时不是强类型。 \n \n DataSet \n DS 是 DF 的一个扩展，在 Spark1.6 添加的一个新的抽象。它对 DF 增强了，最大的特点就是变为了强类型，这时候获取 person 的 name 就可以使用类似  person[name] 。 \n 此时，我们就可以将 DF 看成是 DS 的一个特例，即： DataSet[Row] = DataFrame 。 \n DataFrame \n DF 比 RDD 多了一层元数据信息，但是本质上是一种弱类型的数据集合，可以简单理解为 JS 中，所有变量都是用  val  来定义的，然而在 DF 中，统一使用  Row  来作为属性的类型。 \n SparkSession \n 在单纯使用 RDD 的时候，我们构建出  SparkContext  来进行 Spark 的入口，那么在新的 Spark SQL 中，我们使用  SparkSession  来作为 SQL 查询的起点。 \n SparkSession 内部封装了 SparkContext，所以查询其实本质还是 SparkContext，只不过为了使用方便，我们又封装了一层。 \n def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n   val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n  spark . stop ( ) \n } \n \n 1 2 3 4 5 < dependency > \n     < groupId > org.apache.spark </ groupId > \n     < artifactId > spark-core_2.12 </ artifactId > \n     < version > 3.0.0 </ version > \n </ dependency > \n < dependency > \n     < groupId > org.apache.spark </ groupId > \n     < artifactId > spark-sql_2.12 </ artifactId > \n     < version > 3.0.0 </ version > \n </ dependency > \n \n 1 2 3 4 5 6 7 8 9 10 #  创建 DF \n 创建 DF 有三种方式： \n \n 从 Spark 的数据源创建。 \n 从 RDD 转换（后续讨论）。 \n 从 Hive Table 查询返回（后续讨论）。 \n \n 从 Spark 数据源进行创建 \n Spark 数据源支持很多，比如： csv 、 jdbc 、 json 、 orc 、 parquet 、 text 、 textFile  等，还可以通过 maven 添加第三方的，比如  avro ： \n < dependency > \n     < groupId > org.apache.spark </ groupId > \n     < artifactId > spark-avro_2.12 </ artifactId > \n     < version > 3.0.1 </ version > \n </ dependency > \n \n 1 2 3 4 5 \n { "username" :   "zhangsan" ,   "age" :   18 } \n \n 1 def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n   val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n   val  df  =  spark . read . json ( "person.json" ) \n  df . show ( false ) \n\n  spark . stop ( ) \n } \n \n 1 2 3 4 5 6 7 8 9 Tips \n \n 以上的 JSON 必须要在同一行，假如为多行则会报错。 \n 如果从内存中读取数据，Spark 可以知道具体的数据类型是什么。假如是数字，默认作为 int 处理。 \n 如果从文件中读取数据，Spark 不知道具体的数据类型是什么，如果是数字，默认作为 bigint 处理，可以和 long 转换，但是不能和 int 转换。 \n SQL 语法 \n Spark SQL 查询，其实表面上看和 SQL 差不多，但是它必须要借助视图来进行查询，不管是临时视图还是全局视图均可。 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n // 1. 读取 JSON \n val  df  =  spark . read . json ( "person.json" ) \n\n // 2. 创建临时视图 \ndf . createOrReplaceTempView ( "people" ) \n\n // 3. 查询临时视图 \nspark . sql ( "SELECT * FROM people" ) . show ( false ) \n\n // 4. 创建全局视图 \ndf . createGlobalTempView ( "person" ) \n\n // 5. 查询全局视图 \nspark . sql ( "SELECT * FROM global_temp.person" ) . show ( false ) \n\nspark . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Tips \n \n Spark SQL 必须借助视图，不管是临时视图还是全局视图。 \n 普通的临时视图是单个 Session 范围内的，如果想要在全局内有效，需要创建全局临时视图。 \n 全局临时视图访问需要加上  global_temp ，比如  global_temp.person 。 \n DSL \n 视图创建是比较麻烦的一件事情，为了简化，DF 提供了 DSL（Domain-Specific-Language）去管理结构化的数据。 \n DSL 可以跨语言使用（即可以在 Scala、Java、Python、R 中使用），使用 DSL 就不必再创建临时视图了。 \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n // 1. 读取 JSON \n val  df  =  spark . read . json ( "person.json" ) \n\n // 2. 查看 df 的 schema \ndf . printSchema ( ) \n\n // 3. 查看 username 列 \ndf . select ( "username" ) . show ( false ) \ndf . select ( df . col ( "username" ) ) . show ( false ) \n\n // 4. 查看 age + 1 列的数据，这里的 spark.implicits._ 中，spark 就是当前的 sparkSession 变量名称 \n import   spark . implicits . _\ndf . select ( $ "age"   +   1 ) . show ( false ) \ndf . select ( \'age   +   1  as  "newAge" ) . show ( false ) \n\n // 5. 查看 age > 30 的数据 \ndf . filter ( $ "age"   >   30 ) . show ( false ) \n\n // 6. 按照 age 进行分组 \ndf . groupBy ( "age" ) . count ( ) . show ( false ) \n\nspark . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 SparkSession  spark  =   SparkSession . builder ( ) . config ( new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) ) . getOrCreate ( ) ; \n\n Dataset < Row >  df  =  spark . read ( ) . json ( "person.json" ) ; \n\ndf . select ( "username" ) . show ( false ) ; \n\ndf . select ( df . col ( "age" ) . plus ( 1 ) . as ( "newAge" ) ) . show ( false ) ; \n\ndf . filter ( df . col ( "age" ) . gt ( 30 ) ) . show ( false ) ; \n\ndf . groupBy ( "age" ) . count ( ) . show ( false ) ; \n\nspark . stop ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 Tips \n 以上代码在 Spark  官网 中存在。 \n RDD 与 DF 互相转换 \n def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n   val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n   // 1. 因为 SparkSession 里面包含 SparkContext，所以可以直接得到 SparkContext \n   val  sc  =  spark . sparkContext\n\n   // 2. 和之前一样，引入 \n   import   spark . implicits . _\n\n   // 4. 生成 RDD \n   val  rdd  =  sc . makeRDD ( List ( ( "zhangsan" ,   18 ) ,   ( "lisi" ,   20 ) ,   ( "wangwu" ,   23 ) ) ) \n\n   // 5. scala 直接生成 DataFrame 即可 \n   val  df  =  rdd . map ( t  =>  Person ( t . _1 ,  t . _2 ) ) . toDF ( ) \n\n   // 6. 使用 \n  df . select ( "name" ) . show ( false ) \n\n   // 7. df 转 RDD \n  df . select ( "name" ) . rdd . foreach ( println ) \n\n  spark . stop ( ) \n } \n\n // 3. 定义 Scala 的类 \n case   class  Person ( name :   String ,  age :   Int ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Tips \n DataFrame 本质上其实就是对 RDD 的封装，所以可以直接从内部获得 RDD。 \n 但是 RDD 转换到 DF 需要提供对应的类型，但是 DF 其实也是弱类型（统一为  Row  类型）。 \n \n SparkSession  spark  =   SparkSession . builder ( ) . config ( new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) ) . getOrCreate ( ) ; \n\n // 1. 读取文件形成 DS \n Dataset < Row >  DS  =  spark . read ( ) . csv ( "person.csv" ) ; \n\n // 2. DS 可直接形成 RDD \n JavaRDD < Row >  rowJavaRDD  =  DS . toJavaRDD ( ) ; \n\n // 3. RDD 转为 DS，通过类直接转换 \n Dataset < Row >  rowDS  =  spark . createDataFrame ( rowJavaRDD ,   Person . class ) ; \n\n // 4. RDD 转为 DS，通过手动构造 schema 生成 \n StructType  schema  =   new   StructType ( ) ; \nschema  =  schema . add ( "name" ,   DataTypes . StringType ) ; \nschema  =  schema . add ( "age" ,   DataTypes . IntegerType ) ; \nspark . createDataFrame ( rowJavaRDD ,  schema ) ; \n\nspark . stop ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #  Dataset \n 之前提过，DS 其实是对 DF 做了一层增强，是强类型的数据集合。可以简单理解为 JS 升级成了 TS，有了强类型的概念。 \n 创建 DS \n def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n   val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n   // 1. 类似之前，引入 implicits \n   import   spark . implicits . _\n\n   // 2. 定义 RDD \n   val  list  =  List ( Person ( "zhangsan" ,   18 ) ,  Person ( "lisi" ,   20 ) ) \n\n   // 3. 定义 DS \n   val  ds  =  list . toDS ( ) \n\n   // 4. 使用 \n  ds . show ( false ) \n\n  spark . stop ( ) \n } \n\n case   class  Person ( name :   String ,  age :   Int ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #  RDD、DF、DS 相互转换 \n def  main ( args :  Array [ String ] ) :   Unit   =   { \n   val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n   val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n   import   spark . implicits . _\n\n   // 1. RDD \n   val  list  =  List ( Person ( "zhangsan" ,   18 ) ,  Person ( "lisi" ,   20 ) ) \n\n   // 2. RDD to DS，因为是完全按照类型来构造的，所以可以直接转为 Person \n   val  ds : Dataset [ Person ]   =  list . toDS ( ) \n\n   // 3. ds to df \n   val  df : DataFrame  =  ds . toDF ( ) \n\n   // 4. df to ds，需要指定类型，可以使用 df.toDS，但是那样会成为 DS[Row] \n   val  ds2 : Dataset [ Person ]   =  df . as [ Person ] \n\n  spark . stop ( ) \n } \n\n case   class  Person ( name :   String ,  age :   Int ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 SparkSession  spark  =   SparkSession . builder ( ) . config ( new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) ) . getOrCreate ( ) ; \n\n // Java 可以直接通过 List 来转为 DS \n Dataset < Person >  ds  =  spark . createDataset ( Arrays . asList ( new   Person ( "zhangsan" ,   18 ) ) ,   Encoders . bean ( Person . class ) ) ; \n\nspark . stop ( ) ; \n \n 1 2 3 4 5 6 #  RDD、DF、DS 区别与联系 \n 不同点 \n \n 从本质上来看，其实就是套娃的过程，RDD 套娃形成 DF，DF 套娃形成 DS。 \n 从版本的角度来说，RDD 来自 Spark1.0，DF 来自 Spark1.3，DS 来自 Spark1.6。 \n 同样的数据给到这三者结果都是相同的，只不过效率和执行方式不同，所以在未来 DS 可能会取代 RDD 和 DF，形成唯一的 API 接口。 \n RDD 不支持 Spark SQL。 \n DF 每一行为 Row，但是 DS 是强类型，每行不同。 \n \n 相同点 \n \n RDD、DF、DS 全都是 Spark 的分布式弹性数据集。 \n 都有惰性机制（比如到执行算子才会执行），三者都有很多相同函数。 \n DF 和 DS 都需要  import spark.implicits._ 。 \n 都会根据 Spark 内存情况自动缓存计算，不需担心内存溢出。 \n 都有  partition  的概念。 \n \n 三者的相互转换 \n 用户自定义函数 \n 简单来说，我们的算子可能不太够用，假如我们的业务想要实现某种特殊的功能，那么就必须要进行自定义。 \n 用户自定义函数大致上可以分为两种： \n \n 一对一关系，类似 map，一个输入一个输出。UDF（user defined function）。 \n 多对一关系，类似 aggregate，多个输入一个输出。UDAF（user defined aggregate function）。 \n \n Tips \n 其实在 Hive 中，还存在输入一行输出多行的情况，也就是 UDTF，但是很遗憾，Spark 中不支持。 \n UDF \n 使用 udf 函数需要三步： \n \n 创建 UDF \n 注册 UDF \n 使用 UDF \n \n val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n import   spark . implicits . _\n\n // 1. 环境准备 \n val  list  =  List ( Person ( "zhangsan" ,   18 ) ,  Person ( "lisi" ,   20 ) ) \n val  ds  =  list . toDS ( ) \nds . createOrReplaceTempView ( "person" ) \n\n // 2. udf 创建并注册 \nspark . udf . register ( "addName" ,   ( x :   String )   =>   "Name = "   +  x ) \n\n // 3. 使用 udf \nspark . sql ( "SELECT addName(name) as name FROM person" ) . show ( false ) \n\nspark . stop ( ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 SparkSession  spark  =   SparkSession . builder ( ) . config ( new   SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) ) . getOrCreate ( ) ; \n\n // 1. 环境准备 \n Dataset < Person >  ds  =  spark . createDataset ( Arrays . asList ( new   Person ( "zhangsan" ,   18 ) ) ,   Encoders . bean ( Person . class ) ) ; \nds . createOrReplaceTempView ( "person" ) ; \n\n // 2. 注册 udf 并使用 \nspark . udf ( ) . register ( "addName" ,   ( UDF1 < String ,   String > )  s  ->   "Name = "   +  s ,   DataTypes . StringType ) ; \n\n // 3. 使用 \nspark . sql ( "SELECT addName(name) as name FROM person" ) . show ( false ) ; \n\nspark . stop ( ) ; \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 #  UDAF \n object  SparkSQLDemo  { \n   def  main ( args :  Array [ String ] ) :   Unit   =   { \n     val  sparkConf  =   new  SparkConf ( ) . setMaster ( "local[*]" ) . setAppName ( "SQL" ) \n     val  spark  =  SparkSession . builder ( ) . config ( sparkConf ) . getOrCreate ( ) \n\n     import   spark . implicits . _\n\n     // 1. 环境准备 \n     val  list  =  List ( Person ( "zhangsan" ,   18 ) ,  Person ( "lisi" ,   20 ) ) \n     val  ds  =  list . toDS ( ) \n    ds . createOrReplaceTempView ( "person" ) \n\n     // 3. udaf 注册 \n    spark . udf . register ( "avg" , functions . udaf ( AvgUDAF ) ) \n\n     // 4. udaf 使用 \n    spark . sql ( "SELECT avg(age) as name FROM person" ) . show ( false ) \n\n    spark . stop ( ) \n   } \n\n   case   class  Person ( name :   String ,  age :   Int ) \n } \n\n case   class  Average ( var  sum :   Long ,   var  count :   Long ) \n\n // 2. UDAF 创建，求平均值，三个泛型分别为：传入值、中间值、输出值 \n object  AvgUDAF  extends  Aggregator [ Int ,  Average ,   Double ]   { \n\n   // 初始化中间值，应该满足任意 x + zero = x \n   override   def  zero :  Average  =  Average ( 0 ,   0 ) \n\n   // 中间结果与下一个值相加，返回中间值 \n   override   def  reduce ( mid :  Average ,  next :   Int ) :  Average  =   { \n    mid . sum  +=  next\n    mid . count  +=   1 \n    mid\n   } \n\n   // 合并两个中间值 \n   override   def  merge ( mid1 :  Average ,  mid2 :  Average ) :  Average  =   { \n    mid1 . count  +=  mid2 . count\n    mid1 . sum  +=  mid2 . sum\n    mid1\n   } \n\n   // 输出此次的最终结果 \n   override   def  finish ( reduction :  Average ) :   Double   =   { \n    reduction . sum  /  reduction . count\n   } \n\n   // 缓冲区，可以为固定值 \n   override   def  bufferEncoder :  Encoder [ Average ]   =  Encoders . product\n\n   // 输出 \n   override   def  outputEncoder :  Encoder [ Double ]   =  Encoders . scalaDouble\n } \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 Tips \n 更多内容查看 spark  docs \n 数据的加载和保存 \n 数据的加载 \n 之前在写 Java 的时候，使用了一个  spark.read().csv() ，其实这就是加载  csv  文件，点进源码，可以看到，底层调用了： format("csv").load(paths : _*) \n 所以它其实相当于  spark.read().format("csv").load(paths : _*) \n spark.read().load()  是通用的加载方法，可以加载多种数据格式，例如 csv、jdbc、json、orc、parquet 等，读取不同的格式可以使用  format  来指定。 \n 初次之外，还可以使用  option  来指定相应的参数，比如 jdbc 的 url，username，password 等，读取 csv 是否决定第一行是表头，分隔符是什么…… \n spark . read . option ( "delimiter" ,   "\\u0001" ) . option ( "header" ,   true ) . csv ( "odsMember.csv" ) . show ( false ) \n \n 1 Tips \n 以上代码中，读取了 csv 文件，指定分隔符为  \\u0001 ，指定第一行为表头。 \n \n 数据的保存 \n 除了读取之外，还可以进行保存，可以在  csv 、 parquet 、 orc 、 textFile  中传入需要保存数据的路径。 \n   df . write ( ) . option ( "header" ,   true ) . option ( "delimiter" ,   "\\u0001" ) . csv ( path ) ; \n \n 1 Tips \n 其实除了上述的保存方式，还可以自行加入其他的数据格式，比如我通过 maven 加了一个 avro 格式的数据，可以使用： \n < dependency > \n   < groupId > org.apache.spark </ groupId > \n   < artifactId > spark-avro_2.12 </ artifactId > \n   < version > 3.1.2 </ version > \n </ dependency > \n \n 1 2 3 4 5 df . write ( ) . mode ( SaveMode . Overwrite ) . format ( "avro" ) . save ( path ) ; \n \n 1 \n 保存也有很多选项，除了 option 之外，还有  mode()  可以选择，有多种方式： \n \n \n \n Scala/Java \n Any Language \n Meaning \n \n \n \n \n SaveMode.ErrorIfExists ( default ) \n error ( default ) \n 如果文件已经存在则抛出异常 \n \n \n SaveMode.Append \n append \n 如果文件已经存在则追加 \n \n \n SaveMode.Overwrite \n overwrite \n 如果文件已经存在则覆盖 \n \n \n SaveMode.Ignore \n ignore \n 如果文件已经存在则忽略 \n \n \n \n df . write ( ) . mode ( SaveMode . Overwrite ) . format ( "avro" ) . save ( path ) \n \n 1 MySQL \n //方式1：通用的load方法读取 \nspark . read . format ( "jdbc" ) \n   . option ( "url" ,  $ { url } ) \n   . option ( "driver" ,   "com.mysql.jdbc.Driver" ) \n   . option ( "user" ,  $ { username } ) \n   . option ( "password" ,  $ { password } ) \n   . option ( "dbtable" ,   "user" ) \n   . load ( ) . show\n\n\n //方式2:通用的load方法读取 参数另一种形式 \nspark . read . format ( "jdbc" ) \n   . options ( Map ( "url" -> "${url}?user=${username}&password=${password}" , \n     "dbtable" -> "user" , "driver" -> "com.mysql.jdbc.Driver" ) ) . load ( ) . show\n\n //方式3:使用jdbc方法读取 \n val  props :  Properties  =   new  Properties ( ) \nprops . setProperty ( "user" ,  $ { username } ) \nprops . setProperty ( "password" ,  $ { password } ) \n val  df :  DataFrame  =  spark . read . jdbc ( "url" ,   "user" ,  props ) \n \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Tips \n 注意，不仅是在读取的时候，在写入的时候也需要加入 url、username、password \n \n',updateTime:"April 29, 2022 16:43",updateTimeStamp:1651221839e3,createTime:"January 18, 2022 14:50",createTimeStamp:1642488603e3,contributors:[{name:"红枫",email:"2592716753@qq.com",commits:3},{name:"Maple Wang",email:"maple.wang@maiscrm.com",commits:1}]},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/article/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/article/",key:"v-6453f364",path:"/article/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/star/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/star/",key:"v-4340f7e8",path:"/star/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/encrypt/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/encrypt/",key:"v-7d484ebf",path:"/encrypt/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/slide/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/slide/",key:"v-2470be33",path:"/slide/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/timeline/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/timeline/",key:"v-6319eb4e",path:"/timeline/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"Tag",summary:"",meta:[{property:"og:url",content:"/tag/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/",key:"v-b1564aac",path:"/tag/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"Category",summary:"",meta:[{property:"og:url",content:"/category/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/",key:"v-28e6393c",path:"/category/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"concurrent Tag",summary:"",meta:[{property:"og:url",content:"/tag/concurrent/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/concurrent/",key:"v-1218ef24",path:"/tag/concurrent/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"designPatterns Tag",summary:"",meta:[{property:"og:url",content:"/tag/designPatterns/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/designPatterns/",key:"v-203905a4",path:"/tag/designPatterns/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"docker Tag",summary:"",meta:[{property:"og:url",content:"/tag/docker/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/docker/",key:"v-5ae80825",path:"/tag/docker/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"k8s Tag",summary:"",meta:[{property:"og:url",content:"/tag/k8s/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/k8s/",key:"v-32360c9a",path:"/tag/k8s/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"jvm Tag",summary:"",meta:[{property:"og:url",content:"/tag/jvm/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/jvm/",key:"v-32352550",path:"/tag/jvm/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"algorithms Tag",summary:"",meta:[{property:"og:url",content:"/tag/algorithms/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/algorithms/",key:"v-130c19e1",path:"/tag/algorithms/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"linux Tag",summary:"",meta:[{property:"og:url",content:"/tag/linux/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/linux/",key:"v-7418fe36",path:"/tag/linux/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"git Tag",summary:"",meta:[{property:"og:url",content:"/tag/git/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/git/",key:"v-32383f72",path:"/tag/git/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"proxy Tag",summary:"",meta:[{property:"og:url",content:"/tag/proxy/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/proxy/",key:"v-657392aa",path:"/tag/proxy/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"flink Tag",summary:"",meta:[{property:"og:url",content:"/tag/flink/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/flink/",key:"v-88435c0e",path:"/tag/flink/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"hbase Tag",summary:"",meta:[{property:"og:url",content:"/tag/hbase/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/hbase/",key:"v-8290f180",path:"/tag/hbase/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"flume Tag",summary:"",meta:[{property:"og:url",content:"/tag/flume/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/flume/",key:"v-88387c1c",path:"/tag/flume/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"hadoop Tag",summary:"",meta:[{property:"og:url",content:"/tag/hadoop/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/hadoop/",key:"v-16ad2ac0",path:"/tag/hadoop/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"hive Tag",summary:"",meta:[{property:"og:url",content:"/tag/hive/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/hive/",key:"v-14b36356",path:"/tag/hive/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"kafka Tag",summary:"",meta:[{property:"og:url",content:"/tag/kafka/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/kafka/",key:"v-786bbe1a",path:"/tag/kafka/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"spark Tag",summary:"",meta:[{property:"og:url",content:"/tag/spark/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/spark/",key:"v-5b7bc7c8",path:"/tag/spark/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"zookeeper Tag",summary:"",meta:[{property:"og:url",content:"/tag/zookeeper/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/tag/zookeeper/",key:"v-87dcfee6",path:"/tag/zookeeper/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"backend Category",summary:"",meta:[{property:"og:url",content:"/category/backend/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/backend/",key:"v-5e1a0957",path:"/category/backend/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"base Category",summary:"",meta:[{property:"og:url",content:"/category/base/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/base/",key:"v-270affc2",path:"/category/base/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Blog",title:"bigdata Category",summary:"",meta:[{property:"og:url",content:"/category/bigdata/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/bigdata/",key:"v-0bbae601",path:"/category/bigdata/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Layout",title:"Page 2 - backend | Category",summary:"",meta:[{property:"og:url",content:"/category/backend/page/2/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/backend/page/2/",key:"v-78da2c86",path:"/category/backend/page/2/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Layout",title:"Page 2 - bigdata | Category",summary:"",meta:[{property:"og:url",content:"/category/bigdata/page/2/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/bigdata/page/2/",key:"v-955cc6c8",path:"/category/bigdata/page/2/",readingTime:{minutes:0,words:0},content:""},{frontmatter:{layout:"Layout",title:"Page 3 - bigdata | Category",summary:"",meta:[{property:"og:url",content:"/category/bigdata/page/3/"},{property:"og:site_name",content:"知识库"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-US"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image:alt",content:"知识库"}]},regularPath:"/category/bigdata/page/3/",key:"v-955cc68a",path:"/category/bigdata/page/3/",readingTime:{minutes:0,words:0},content:""}],themeConfig:{blog:{sidebarDisplay:"always",autoExcerpt:!1},nav:[{text:"首页",link:"/",icon:"reco-home"},{text:"关于",link:"/about",icon:"reco-faq"}],mdEnhance:{enableAll:!0},footer:{display:!0,content:'<a href="https://beian.miit.gov.cn/#/Integrated/index">鲁ICP备20021989号-2</a>'},repo:"https://gitlab.com/team401/knowledge",locales:{"/":{lang:"en-US",selectText:"Language",label:"English",ariaLabel:"Select language",meta:{contributor:"Contributors",editLink:"Edit this page",updateTime:"Last update"},themeColor:{themeColor:"Theme Color",themeMode:"Theme Mode"},encrypt:{title:"Please enter password",errorHint:"Please enter the correct password!"},error404:{hint:["There’s nothing here.","How did we get here?","That’s a Four-Oh-Four.","Looks like we've got some broken links."],back:"Go back",home:"Take me home"},blog:{article:"Articles",articleList:"Article List",category:"Category",tag:"Tags",timeline:"Timeline",timelineText:"Yesterday Once More!",allText:"All",intro:"Personal Intro",star:"Star",slides:"Slides",encrypt:"Encrypted"}}}}},ft=(t(353),t(92),{"/":{backToTop:"Back to top",openInNewWindow:"Open in new window",pagination:{prev:"Prev",next:"Next",navigate:"Jump to",button:"Go",errorText:"Please enter a number between 1 and $page !"}}}),gt=o.a.extend({name:"BackToTop",props:{threshold:{type:Number,default:300}},data:function(){return{scrollTop:0}},computed:{thresholdDistance:function(){return"number"==typeof this.$themeConfig.backToTop?this.$themeConfig.backToTop:this.threshold},isDisplay:function(){var n=!1!==this.$themeConfig.backToTop,e=this.$page.frontmatter.backToTop;return(e||n&&!1!==e)&&this.scrollTop>this.thresholdDistance},hint:function(){return ft[this.$localePath||"/"].backToTop}},mounted:function(){var n=this;this.scrollTop=this.getScrollTop(),ct=Ae()((function(){n.scrollTop=n.getScrollTop()}),100),window.addEventListener("scroll",ct)},beforeDestroy:function(){window.removeEventListener("scroll",ct)},methods:{getScrollTop:function(){return window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0},scrollToTop:function(){window.scrollTo({top:0,behavior:"smooth"}),this.scrollTop=0}}}),ht=(t(354),Object(it.a)(gt,(function(){var n=this.$createElement,e=this._self._c||n;return e("transition",{attrs:{name:"fade"}},[this.isDisplay?e("button",{staticClass:"back-to-top",attrs:{"aria-label":this.hint,"data-balloon-pos":"left"},on:{click:this.scrollToTop}},[e("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[e("path",{attrs:{d:"M512 0C229.517 0 0 229.517 0 512s227.752 512 512 512c282.483 0 512-227.752 512-512C1024 229.517 794.483\n      0 512 0zM351.338 271.89h305.434c14.125 0 26.483 12.358 26.483 26.482s-12.358 26.483-26.483\n      26.483H351.338c-14.124 0-26.483-12.358-26.483-26.483 0-15.89 12.359-26.482 26.483-26.482z\n      m331.917 303.669c-12.358 12.358-33.545 12.358-45.903 0L531.42 471.393v270.124c0 14.124-12.359\n      26.483-26.483 26.483s-26.483-12.359-26.483-26.483v-271.89l-105.93 104.166c-12.36 12.359-33.546 12.359-45.904\n      0-12.359-12.359-12.359-31.78 0-45.903l155.365-151.835c7.062-7.062 14.124-8.827 22.952-8.827s15.89 3.53 22.952\n      8.827L683.255 527.89c12.359 15.89 12.359 35.31 0 47.669z",fill:"currentColor"}})])]):this._e()])}),[],!1,null,null,null).exports),vt=o.a.extend({name:"Badge",functional:!0,props:{type:{type:String,default:"tip"},text:{type:String,default:""},vertical:{type:String,default:"top"},color:{type:String,default:""}},render:function(n,e){var t=e.props,r=e.slots,a={class:["badge",t.type],style:{verticalAlign:t.vertical}};return t.color&&(a.class.push("diy"),a.style.backgroundColor=t.color,a["data-color"]=t.color),n("span",a,t.text||r().default)}}),yt=(t(355),Object(it.a)(vt,void 0,void 0,!1,null,"7b453e57",null).exports),bt=(t(217),o.a.extend({name:"BreadCrumb",computed:{enable:function(){var n=!1!==this.$themeConfig.breadcrumb,e=this.$page.frontmatter.breadcrumb;return(n&&!1!==e||!0===e)&&this.config.length>1},iconEnable:function(){var n=!1!==this.$themeConfig.breadcrumbIcon,e=this.$page.frontmatter.breadcrumbIcon;return this.enable&&(n&&!1!==e||!0===e)},iconPrefix:function(){var n=this.$themeConfig.iconPrefix;return""===n?"":n||"icon-"},config:function(){for(var n=[],e=this.$site.pages,t=this.getLinks(this.$route),r=1;r<t.length;r++)for(var a=0;a<e.length;a++){var o=e[a];if(o.path===t[r]){n.push({title:o.title,icon:o.frontmatter.icon,url:o.path});break}}return n}},methods:{getLinks:function(n){var e=n.path.split("/"),t=[],r="";return e.forEach((function(n,a){a!==e.length-1?(r+="".concat(n,"/"),t.push(r)):""!==n&&(r+=n,t.push(r))})),t}}})),St=(t(356),Object(it.a)(bt,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("nav",{staticClass:"breadcrumb",class:{disable:!n.enable}},[n.enable?t("ol",{attrs:{vocab:"https://schema.org/",typeof:"BreadcrumbList"}},n._l(n.config,(function(e,r){return t("li",{key:e.url,class:{"is-active":n.config.length-1===r},attrs:{property:"itemListElement",typeof:"ListItem"}},[t("RouterLink",{attrs:{to:e.url,property:"item",typeof:"WebPage"}},[e.icon&&n.iconEnable?t("i",{class:"iconfont "+n.iconPrefix+e.icon}):n._e(),n._v(" "),t("span",{attrs:{property:"name"}},[n._v(n._s(e.title))])]),n._v(" "),t("meta",{attrs:{property:"position",content:r+1}})],1)})),0):n._e()])}),[],!1,null,null,null).exports),kt=o.a.extend({name:"CodeGroup",data:function(){return{codeTabs:[],activeTabIndex:-1}},watch:{activeTabIndex:function(n){this.activateCodeTab(n)}},mounted:function(){this.loadTabs()},methods:{loadTabs:function(){var n=this;this.codeTabs=(this.$slots.default||[]).filter((function(n){return Boolean(n.componentOptions)})).map((function(e,t){var r=e.componentOptions.propsData;return r.active&&(n.activeTabIndex=t),{title:r.title,element:e.elm}})),-1===this.activeTabIndex&&this.codeTabs.length>0&&(this.activeTabIndex=0),this.activateCodeTab(0)},changeCodeTab:function(n){this.activeTabIndex=n},keyDownHandler:function(n,e){" "===n.key||"Enter"===n.key?(n.preventDefault(),this.activeTabIndex=e):"ArrowRight"===n.key?(n.preventDefault(),e+1<this.codeTabs.length&&(this.activeTabIndex=e+1,this.$refs.tab[e+1].focus())):"ArrowLeft"===n.key&&(n.preventDefault(),e-1>=0&&(this.activeTabIndex=e-1,this.$refs.tab[e-1].focus()))},activateCodeTab:function(n){this.codeTabs.forEach((function(e,t){var r=e.element;r&&(n===t?r.classList.add("active"):r.classList.remove("active"))}))}}}),xt=(t(357),Object(it.a)(kt,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("ClientOnly",[t("div",{staticClass:"code-group"},[t("div",{staticClass:"code-group-nav",attrs:{"v:if":"codeTabs.length"}},n._l(n.codeTabs,(function(e,r){return t("button",{key:e.title,ref:"tab",refInFor:!0,staticClass:"code-group-nav-tab",class:{active:r===n.activeTabIndex},attrs:{"aria-pressed":r===n.activeTabIndex,"aria-expanded":r===n.activeTabIndex},domProps:{textContent:n._s(e.title)},on:{click:function(e){return n.changeCodeTab(r)},keydown:function(e){return n.keyDownHandler(e,r)}}})})),0),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length?n._e():t("pre",{staticClass:"hints",domProps:{textContent:n._s("// Make sure to add code blocks to your code group")}})],2)])}),[],!1,null,null,null).exports),Et=o.a.extend({name:"CodeGroupItem",props:{title:{type:String,required:!0},active:{type:Boolean,required:!1,default:!1}},mounted:function(){this.$parent&&this.$parent.loadTabs&&this.$parent.loadTabs()}}),Tt=(t(358),Object(it.a)(Et,(function(){var n=this.$createElement;return(this._self._c||n)("div",{staticClass:"code-group-item",class:{active:this.active},attrs:{"aria-selected":this.active}},[this._t("default")],2)}),[],!1,null,null,null).exports),wt=(t(125),t(126),t(229),o.a.extend({name:"Pagination",model:{prop:"currentPage",event:"change"},props:{total:{type:Number,default:10},perPage:{type:Number,default:10},currentPage:{type:Number,default:1}},data:function(){return{input:""}},computed:{totalPages:function(){return Math.ceil(this.total/this.perPage)},enable:function(){return Boolean(this.totalPages)&&1!==this.totalPages},displayLeftEllipsis:function(){return!(this.totalPages<7)&&this.currentPage>4},displayRightEllipsis:function(){return!(this.totalPages<7)&&this.currentPage<this.totalPages-3},indexs:function(){var n=this.currentPage,e=this.totalPages,t=1,r=e,a=[];e>=7&&(n<=4&&n<e-3?(t=1,r=5):n>4&&n>=e-3?(r=e,t=e-4):e>7&&(t=n-2,r=n+2));for(var o=t;o<=r;o++)a.push(o);return a},locales:function(){return ft[this.$localePath||"/"].pagination}},mounted:function(){var n=this.$route.query.index;this.navigate(n?Number(n):1)},methods:{navigate:function(n){var e=Object.assign({},this.$route.query);e.page===n.toString()||1===n&&!e.page||(this.$emit("change",n),1===n?delete e.page:e.page=n.toString(),this.$router.push({path:this.$route.path,query:e}))},jumpPage:function(n){var e=parseInt(n);e<=this.totalPages&&e>0?this.navigate(e):alert(this.locales.errorText.replace(/\$page/g,this.totalPages.toString()))}}})),Ct=(t(360),Object(it.a)(wt,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"pagination-wrapper"},[n.enable?t("div",{staticClass:"pagination-list"},[t("div",{staticClass:"btn-group"},[n.currentPage>1?t("div",{staticClass:"prev",attrs:{role:"navigation",unselectable:"on"},on:{click:function(e){return n.navigate(n.currentPage-1)}}},[n._v("\n        "+n._s(n.locales.prev)+"\n      ")]):n._e(),n._v(" "),n.displayLeftEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(e){return n.navigate(1)}}},[n._v("\n        1\n      ")]):n._e(),n._v(" "),n.displayLeftEllipsis?t("div",{staticClass:"ellipsis"},[n._v("...")]):n._e(),n._v(" "),n._l(n.indexs,(function(e){return t("div",{key:e,class:{active:n.currentPage===e},attrs:{role:"navigation"},on:{click:function(t){return n.navigate(e)}}},[n._v("\n        "+n._s(e)+"\n      ")])})),n._v(" "),n.displayRightEllipsis?t("div",{staticClass:"ellipsis"},[n._v("...")]):n._e(),n._v(" "),n.displayRightEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(e){return n.navigate(n.totalPages)}}},[n._v("\n        "+n._s(n.totalPages)+"\n      ")]):n._e(),n._v(" "),n.currentPage<n.totalPages?t("div",{staticClass:"next",attrs:{role:"navigation"},on:{click:function(e){return n.navigate(n.currentPage+1)}}},[n._v("\n        "+n._s(n.locales.next)+"\n      ")]):n._e()],2),n._v(" "),t("div",{staticClass:"navigate-wrapper"},[t("label",{attrs:{for:"navigation-text"}},[n._v(n._s(n.locales.navigate)+": ")]),n._v(" "),t("input",{directives:[{name:"model",rawName:"v-model",value:n.input,expression:"input"}],attrs:{id:"navigation-text",type:"text"},domProps:{value:n.input},on:{keypress:function(e){return!e.type.indexOf("key")&&n._k(e.keyCode,"enter",13,e.key,"Enter")?null:n.jumpPage(n.input)},input:function(e){e.target.composing||(n.input=e.target.value)}}}),n._v(" "),t("button",{staticClass:"navigate",attrs:{role:"navigation",title:n.locales.button},on:{click:function(e){return n.jumpPage(n.input)}}},[n._v("\n        "+n._s(n.locales.button)+"\n      ")])])]):n._e()])}),[],!1,null,null,null).exports),Dt=t(64),Ot=o.a.extend({name:"ScreenFull",data:function(){return{canFullscreen:!1,isFullscreen:!1}},mounted:function(){this.canFullscreen=Dt.isEnabled&&!1!==this.$themeConfig.fullscreen},methods:{click:function(){var n=this;Dt.isEnabled&&Dt.toggle().then((function(){n.isFullscreen=Dt.isFullscreen}))}}}),Lt=(t(361),Object(it.a)(Ot,(function(){var n=this.$createElement,e=this._self._c||n;return this.canFullscreen?e("button",{class:this.isFullscreen?"cancel-full-screen":"full-screen",attrs:{"aria-pressed":this.isFullscreen},on:{click:this.click}},[e("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[this.isFullscreen?e("path",{attrs:{d:"M778.46755555 78.62044445H247.92177778c-102.51377778 0-186.02666667 83.51288889-186.02666667 186.02666666v530.432c0 102.51377778 83.51288889 186.02666667 186.02666667 186.02666667h530.432c102.51377778 0 186.70933333-83.51288889 186.02666667-186.02666667V264.64711111c0.11377778-102.62755555-83.39911111-186.02666667-185.9128889-186.02666666zM250.88 574.35022222h171.12177778c23.32444445 0 43.12177778 19.11466667 43.80444444 43.80444445v171.12177778c0 24.00711111-19.11466667 43.12177778-43.12177777 43.12177777-12.06044445 0-22.64177778-5.00622222-30.37866667-12.74311111s-12.74311111-19.11466667-12.74311111-30.37866666v-66.44622223L224.59733333 877.90933333c-16.95288889 16.95288889-44.60088889 16.95288889-61.55377778 0-16.95288889-16.95288889-16.95288889-44.60088889 0-61.55377778l154.96533334-154.96533333h-66.44622222c-24.00711111 0-43.12177778-19.11466667-43.12177778-43.12177777 0-24.12088889 18.432-43.91822222 42.43911111-43.91822223z m521.89866667-98.87288889H601.65688889c-23.32444445 0-43.12177778-19.11466667-43.80444444-43.80444444V260.55111111c0-24.00711111 19.11466667-43.12177778 43.12177777-43.12177778 12.06044445 0 22.64177778 5.00622222 30.37866667 12.74311112s12.74311111 19.11466667 12.74311111 30.37866666v66.44622222l154.96533333-154.96533333c16.95288889-16.95288889 44.60088889-16.95288889 61.55377778 0 16.95288889 16.95288889 16.95288889 44.60088889 0 61.55377778L705.536 388.55111111h66.44622222c24.00711111 0 43.12177778 19.11466667 43.12177778 43.12177778 0.11377778 24.00711111-18.31822222 43.80444445-42.32533333 43.80444444z"}}):e("path",{attrs:{d:"M762.77333333 90.24H265.49333333c-96.10666667 0-174.4 78.29333333-174.4 174.4v497.28c0 96.10666667 78.29333333 174.4 174.4 174.4h497.28c96.10666667 0 175.04-78.29333333 174.4-174.4V264.64c0-96.21333333-78.18666667-174.4-174.4-174.4z m-387.2 761.17333333H215.04c-21.86666667 0-40.42666667-17.92-41.06666667-41.06666666V649.92c0-22.50666667 17.92-40.42666667 40.42666667-40.42666667 11.30666667 0 21.22666667 4.69333333 28.48 11.94666667 7.25333333 7.25333333 11.94666667 17.92 11.94666667 28.48v62.29333333l145.28-145.28c15.89333333-15.89333333 41.81333333-15.89333333 57.70666666 0 15.89333333 15.89333333 15.89333333 41.81333333 0 57.70666667L312.53333333 769.92h62.29333334c22.50666667 0 40.42666667 17.92 40.42666666 40.42666667s-17.17333333 41.06666667-39.68 41.06666666z m274.66666667-685.65333333H810.66666667c21.86666667 0 40.42666667 17.92 41.06666666 41.06666667v160.42666666c0 22.50666667-17.92 40.42666667-40.42666666 40.42666667-11.30666667 0-21.22666667-4.69333333-28.48-11.94666667-7.25333333-7.25333333-11.94666667-17.92-11.94666667-28.48V305.06666667L625.6 450.34666667c-15.89333333 15.89333333-41.81333333 15.89333333-57.70666667 0-15.89333333-15.89333333-15.89333333-41.81333333 0-57.70666667l145.28-145.28h-62.29333333c-22.50666667 0-40.42666667-17.92-40.42666667-40.42666667s17.17333333-41.17333333 39.78666667-41.17333333z"}})])]):this._e()}),[],!1,null,null,null).exports),Rt=function(n){var e=n.Vue;e.component("BackToTop",ht),e.component("Badge",yt),e.component("BreadCrumb",St),e.component("CodeGroup",xt),e.component("CodeGroupItem",Tt),e.component("Pagination",Ct),e.component("ScreenFull",Lt)},_t=function(){function n(e){Ye(this,n),this.registration=e}return Xe(n,[{key:"update",value:function(){return this.registration.update()}},{key:"skipWaiting",value:function(){var n=this.registration.waiting;return n?(console.log("[PWA]: Execute worker.skipWaiting()."),new Promise((function(e,t){var r=new MessageChannel;r.port1.onmessage=function(n){console.log("[PWA]: Finish worker.skipWaiting()."),n.data.error?t(n.data.error):e(n.data)},n.postMessage({type:"skip-waiting"},[r.port2])}))):Promise.resolve()}}]),n}(),At=Object(it.a)({},(function(){var n=this.$createElement,e=this._self._c||n;return e("svg",{staticClass:"icon icon-arrow-left",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[e("path",{attrs:{d:"M401.4 224h-214l83-79.4c11.9-12.5 11.9-32.7 0-45.2s-31.2-12.5-43.2 0L89 233.4c-6 5.8-9 13.7-9 22.4v.4c0 8.7 3 16.6 9 22.4l138.1 134c12 12.5 31.3 12.5 43.2 0 11.9-12.5 11.9-32.7 0-45.2l-83-79.4h214c16.9 0 30.6-14.3 30.6-32 .1-18-13.6-32-30.5-32z"}})])}),[],!1,null,null,null).exports,It=Object(it.a)({},(function(){var n=this.$createElement,e=this._self._c||n;return e("svg",{staticClass:"icon icon-arrow-right",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[e("path",{attrs:{d:"M284.9 412.6l138.1-134c6-5.8 9-13.7 9-22.4v-.4c0-8.7-3-16.6-9-22.4l-138.1-134c-12-12.5-31.3-12.5-43.2 0-11.9 12.5-11.9 32.7 0 45.2l83 79.4h-214c-17 0-30.7 14.3-30.7 32 0 18 13.7 32 30.6 32h214l-83 79.4c-11.9 12.5-11.9 32.7 0 45.2 12 12.5 31.3 12.5 43.3 0z"}})])}),[],!1,null,null,null).exports,Mt=Object(it.a)({},(function(){var n=this.$createElement,e=this._self._c||n;return e("svg",{staticClass:"icon close-icon",attrs:{width:"23",height:"22",xmlns:"http://www.w3.org/2000/svg"}},[e("path",{attrs:{"fill-rule":"evenodd","clip-rule":"evenodd",d:"M1.12.358a1.224 1.224 0 011.729 0l8.92 8.914L20.686.358a1.224 1.224 0 011.73 1.728L13.497 11l8.92 8.913a1.222 1.222 0 11-1.73 1.729l-8.919-8.913-8.92 8.913a1.224 1.224 0 01-1.729-1.729L10.04 11l-8.92-8.914a1.222 1.222 0 010-1.728z",fill:"currentColor"}})])}),[],!1,null,null,null).exports,Ft={"/":{install:"Install",iOSInstall:"Tap the share button and then 'Add to Homescreen'",cancel:"Cancel",close:"Close",prevImage:"Previous Image",nextImage:"Next Image",desc:"Description",feature:"Key Features",explain:"This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. ",update:"New content is available."}},Pt=o.a.extend({name:"PWAInstallModal",components:{ArrowLeftIcon:At,ArrowRightIcon:It,CloseIcon:Mt},props:{useHint:{type:Boolean,default:!1}},data:function(){return{manifest:{},isIOS:!1,deferredprompt:null}},computed:{locales:function(){return Ft[this.$localePath||"/"]}},mounted:function(){var n=this;window.hasOwnProperty("BeforeInstallPromptEvent")&&(ut=function(e){n.deferredprompt=e,n.$emit("can-install",!0),e.preventDefault()},window.addEventListener("beforeinstallprompt",ut),this.getManifest(),lt=function(e){"Escape"===e.key&&n.$emit("toogle",!1)},document.addEventListener("keyup",lt))},beforeDestroy:function(){window.hasOwnProperty("BeforeInstallPromptEvent")&&document.removeEventListener("beforeinstallprompt",ut),document.removeEventListener("keyup",lt)},methods:{getManifest:function(){var n=this;return a(regeneratorRuntime.mark((function e(){var t,r,a;return regeneratorRuntime.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(!(t=localStorage.getItem("manifest"))){e.next=5;break}n.manifest=JSON.parse(t),e.next=19;break;case 5:return e.prev=5,e.next=8,fetch("".concat("/","manifest.webmanifest"));case 8:return r=e.sent,e.next=11,r.json();case 11:a=e.sent,n.manifest=a,localStorage.setItem("manifest",JSON.stringify(a)),e.next=19;break;case 16:e.prev=16,e.t0=e.catch(5),console.error("Error getting manifest, check that you have a valid web manifest or network connection");case 19:case"end":return e.stop()}}),e,null,[[5,16]])})))()},scrollToLeft:function(){var n=document.querySelector(".screenshot");n&&n.scrollBy({left:-n.clientWidth,top:0,behavior:"smooth"})},scrollToRight:function(){var n=document.querySelector(".screenshot");n&&n.scrollBy({left:n.clientWidth,top:0,behavior:"smooth"})},install:function(){var n=this;return a(regeneratorRuntime.mark((function e(){return regeneratorRuntime.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(!n.deferredprompt){e.next=16;break}return n.deferredprompt.prompt(),document.dispatchEvent(new CustomEvent("show")),e.next=5,n.deferredprompt.userChoice;case 5:if("accepted"!==e.sent.outcome){e.next=13;break}return console.info("PWA has been installed"),n.$emit("toogle",!1),n.$emit("can-install",!1),e.abrupt("return",!0);case 13:console.info("You choose to not install PWA"),n.$emit("toogle",!1),n.$emit("can-install",!1);case 16:return e.abrupt("return",!1);case 17:case"end":return e.stop()}}),e)})))()},hint:function(){console.info("You accepted the install hint"),this.$emit("hint")}}}),Nt=(t(362),Object(it.a)(Pt,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{attrs:{id:"install-modal-wrapper"}},[t("div",{staticClass:"background",on:{click:function(e){return n.$emit("toogle",!1)}}}),n._v(" "),t("div",{staticClass:"install-modal"},[t("div",{staticClass:"header"},[t("button",{staticClass:"close-button",attrs:{"aria-label":n.locales.close},on:{click:function(e){return n.$emit("toogle",!1)}}},[t("CloseIcon")],1),n._v(" "),t("div",{staticClass:"logo"},[n.manifest.icons?t("img",{attrs:{src:n.manifest.icons[0].src,alt:"App Logo"}}):n._e(),n._v(" "),t("div",{staticClass:"title"},[t("h1",[n._v(n._s(n.manifest.short_name||n.manifest.name))]),n._v(" "),t("p",{staticClass:"desc"},[n._v(n._s(n.locales.explain))])])])]),n._v(" "),t("div",{staticClass:"content"},[t("div",{staticClass:"highlight"},[n.manifest.features?t("div",{staticClass:"feature-wrapper"},[t("h3",[n._v(n._s(n.locales.feature))]),n._v(" "),n.manifest.features?t("ul",n._l(n.manifest.features,(function(e){return t("li",{key:e,domProps:{textContent:n._s(e)}})})),0):n._e()]):n._e(),n._v(" "),n.manifest.screenshots?t("div",{staticClass:"screenshot-wrapper"},[t("button",{attrs:{"aria-label":n.locales.prevImage},on:{click:n.scrollToLeft}},[t("ArrowLeftIcon")],1),n._v(" "),t("section",{staticClass:"screenshot"},n._l(n.manifest.screenshots,(function(n){return t("div",{key:n.src},[t("img",{attrs:{alt:"App Screenshot",src:n.src}})])})),0),n._v(" "),t("button",{attrs:{"aria-label":n.locales.nextImage},on:{click:n.scrollToRight}},[t("ArrowRightIcon")],1)]):n._e()]),n._v(" "),t("div",{staticClass:"description"},[t("h3",{domProps:{textContent:n._s(n.locales.desc)}}),n._v(" "),t("p",{domProps:{textContent:n._s(n.manifest.description)}})])]),n._v(" "),n.useHint?t("div",{staticClass:"ios-text",on:{click:n.hint}},[t("p",[n._v(n._s(n.locales.iOSInstall))]),n._v(" "),t("button",{staticClass:"success"},[n._v("Got it!")])]):t("div",{staticClass:"button-wrapper"},[t("button",{staticClass:"install-button",on:{click:n.install}},[n._v("\n        "+n._s(n.locales.install)+" "),t("span",[n._v(n._s(n.manifest.short_name))])]),n._v(" "),t("button",{staticClass:"cancel-button",on:{click:function(e){return n.$emit("toogle",!1)}}},[n._v("\n        "+n._s(n.locales.cancel)+"\n      ")])])])])}),[],!1,null,null,null).exports),Ht=o.a.extend({name:"PWAInstall",components:{PWAInstallModal:Nt},data:function(){return{canInstall:!1,hasRelatedApps:!1,isOpen:!1,isIOS:!1,isSafari:!1,hinted:!1}},computed:{install:function(){return Ft[this.$localePath||"/"].install},useHint:function(){return this.isIOS&&this.isSafari&&!1===this.hinted},showInstall:function(){return this.hasRelatedApps&&this.canInstall||this.useHint}},mounted:function(){var n=this;if(this.getInstalledStatus()){var e=navigator.userAgent;this.isIOS=e.includes("iPhone")||e.includes("iPad")||Boolean(e.includes("Macintosh")&&navigator.maxTouchPoints&&navigator.maxTouchPoints>2),this.isSafari=navigator.userAgent.includes("Safari")&&!e.includes("Chrome"),this.hinted=Boolean(localStorage.getItem("iOS-pwa-hint"))}"getInstalledRelatedApps"in navigator&&navigator.getInstalledRelatedApps().then((function(e){n.hasRelatedApps=e.length>0}))},methods:{getInstalledStatus:function(){return navigator.standalone?navigator.standalone:matchMedia("(display-mode: standalone)").matches},hint:function(){this.isOpen=!1,this.hinted=!0,localStorage.setItem("iOS-pwa-hint","hinted")}}}),Bt=(t(363),Object(it.a)(Ht,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{attrs:{id:"pwa-install"}},[n.showInstall?t("button",{staticClass:"modal-button",attrs:{"use-hint":n.useHint},domProps:{textContent:n._s(n.install)},on:{click:function(e){n.isOpen=!0}}}):n._e(),n._v(" "),t("PWAInstallModal",{directives:[{name:"show",rawName:"v-show",value:n.isOpen,expression:"isOpen"}],on:{"can-install":function(e){n.canInstall=e},hint:n.hint,toogle:function(e){n.isOpen=e}}})],1)}),[],!1,null,null,null).exports),jt=new o.a,$t=o.a.extend({name:"SWUpdatePopup",data:function(){return{updateEvent:null}},computed:{enabled:function(){return Boolean(this.updateEvent)},message:function(){return Ft[this.$localePath||"/"].update}},created:function(){jt.$on("sw-updated",this.onSWUpdated.bind(this))},methods:{onSWUpdated:function(n){this.updateEvent=n},reload:function(){var n=this;this.updateEvent&&this.updateEvent.skipWaiting().then((function(){location.reload(),n.updateEvent=null}))}}}),Ut=(t(364),Object(it.a)($t,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("transition",{attrs:{name:"sw-update-popup"}},[n._t("default",(function(){return[n.enabled?t("div",{staticClass:"sw-update-popup",attrs:{role:"button",tabindex:"0"},on:{click:n.reload}},[n._v("\n      "+n._s(n.message)+"\n      "),t("span",{staticClass:"refresh"},[t("svg",{attrs:{viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg",width:"84",height:"84"}},[t("path",{attrs:{d:"M949.948959 146.249899l0 255.82655c0 21.980617-13.988596 35.969213-35.969213 35.969213l-255.82655\n            0c-13.988596 0-25.982768-7.992021-33.972742-21.980617-5.997598-13.988596-4.001127-27.977191\n            7.990998-39.97034l79.941704-77.945233c-55.954383-51.973722-121.917724-77.955466-199.862957-77.955466-37.974893 0-75.949786 8.002254-113.924679 21.99085-37.974893 15.984043-67.947532 37.974893-91.933829\n            63.956637-25.981744 23.986297-47.972595 53.958936-63.956637 91.933829-29.982872 73.954339-29.982872\n            153.895019 0 227.849358 15.984043 37.975916 37.974893 67.947532 63.956637 91.933829 23.986297 25.982768\n            53.958936 47.973618 91.933829 63.956637 37.974893 13.988596 75.949786 21.99085 113.924679 21.99085\n            45.966914 0 87.941911-9.997702 127.913275-29.981848 41.97602-17.989723 75.950809-45.966914\n            101.930507-83.942831 7.993045-4.001127 11.994172-5.995551 13.988596-5.995551 5.997598 0 9.998725\n            1.994424 13.988596 5.995551l77.957513 77.945233c3.988848 4.001127 5.986341 7.993045 5.986341\n            11.994172 0 1.994424-1.99647 5.995551-3.990894 11.994172-43.972491 51.962465-93.940532\n            91.933829-151.898549 117.91455-53.958936 25.982768-115.921149 39.971363-185.874361\n            39.971363-61.96119 0-119.921253-11.983939-169.889295-33.972742C284.40084 889.74325 236.438479\n            857.764931 202.464713\n            821.785485c-35.979446-33.972742-67.957765-81.936127-93.939509-139.897214-45.966914-101.930507-45.966914-237.846036 0-339.777567 25.981744-57.960063 57.960063-105.922425 93.939509-139.89619\n            33.973766-35.979446 81.936127-67.957765 139.89619-93.939509 49.968042-21.99085\n            107.928105-33.973766 169.889295-33.973766 55.963593 0 109.923552 9.987468 161.886017\n            29.972639 53.969169 21.99085 101.932554 51.963489 139.907447 89.938382l73.954339-73.944106c9.987468-9.997702 23.987321-13.988596 39.971363-8.002254C941.956937 120.268154 949.948959 132.261303\n            949.948959 146.249899z"}})])])]):n._e()]}),{reload:n.reload,enabled:n.enabled,message:n.message})],2)}),[],!1,null,null,null).exports),Wt=function(){var n=a(regeneratorRuntime.mark((function n(e){var r,a,o,i,s;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:if(r=e.Vue,a=e.router,o=e.isServer,r.component("PWAInstall",Bt),r.component("SWUpdatePopup",Ut),o){n.next=9;break}return n.next=6,t.e(59).then(t.bind(null,1007));case 6:i=n.sent,s=i.register,a.onReady((function(){s("".concat("/","service-worker.js"),{registrationOptions:{},ready:function(){console.log("[PWA]: Service worker is active"),jt.$emit("sw-ready")},cached:function(n){console.log("[PWA]: Content has been cached for offline usage"),jt.$emit("sw-cached",new _t(n))},updated:function(n){console.log("[PWA]: Content has been updated");var e="service-worker-version",t=Number(localStorage.getItem(e)||0);localStorage.setItem(e,(t+1).toString()),localStorage.removeItem("manifest"),jt.$emit("sw-updated",new _t(n))},offline:function(){console.log("[PWA]: No internet connection，APP runs in offline mode"),jt.$emit("sw-offline")},error:function(n){console.error("[PWA]: Register Service Worker error:",n),jt.$emit("sw-error",n)}})}));case 9:case"end":return n.stop()}}),n)})));return function(e){return n.apply(this,arguments)}}(),Jt=(t(365),function(n){var e=n.Vue;n.router.options.scrollBehavior=function(n,t,r){r?window.scrollTo({top:r.y,behavior:"smooth"}):n.hash?e.$vuepress.$get("disableScrollBehavior")||setTimeout((function(){var e,t,r,a=decodeURI(n.hash.slice(1)),o=document.getElementById(a)||document.querySelector("[name='".concat(a,"']"));o&&window.scrollTo({top:(e=o,t=document.documentElement.getBoundingClientRect(),r=e.getBoundingClientRect(),{x:r.left-t.left,y:r.top-t.top}).y,behavior:"smooth"})}),500):window.scrollTo({top:0,behavior:"smooth"})}}),Vt=t(96),Kt={tag:{concurrent:{key:"concurrent",scope:"tag",path:"/tag/concurrent/",pageKeys:["v-4af972b2"]},designPatterns:{key:"designPatterns",scope:"tag",path:"/tag/designPatterns/",pageKeys:["v-700ad79e","v-59db6648","v-3619c21a","v-cdbd9150"]},docker:{key:"docker",scope:"tag",path:"/tag/docker/",pageKeys:["v-16ce3220","v-192fb65e"]},k8s:{key:"k8s",scope:"tag",path:"/tag/k8s/",pageKeys:["v-0d4b1bdc","v-8af45558"]},jvm:{key:"jvm",scope:"tag",path:"/tag/jvm/",pageKeys:["v-58e0fb48","v-1ddb11e8","v-d83236b0"]},algorithms:{key:"algorithms",scope:"tag",path:"/tag/algorithms/",pageKeys:["v-15ed21e8"]},linux:{key:"linux",scope:"tag",path:"/tag/linux/",pageKeys:["v-2436b22c","v-1d1a5ab0","v-15fe0334","v-0ee1abb8"]},git:{key:"git",scope:"tag",path:"/tag/git/",pageKeys:["v-2dfdfd20"]},proxy:{key:"proxy",scope:"tag",path:"/tag/proxy/",pageKeys:["v-08950870"]},flink:{key:"flink",scope:"tag",path:"/tag/flink/",pageKeys:["v-6c4d9170","v-16441730","v-1fe2b188"]},hbase:{key:"hbase",scope:"tag",path:"/tag/hbase/",pageKeys:["v-13d1b368","v-3ed67088"]},flume:{key:"flume",scope:"tag",path:"/tag/flume/",pageKeys:["v-521bf728"]},hadoop:{key:"hadoop",scope:"tag",path:"/tag/hadoop/",pageKeys:["v-12defbfc","v-0e1bf380","v-0958eb04","v-0495e288"]},hive:{key:"hive",scope:"tag",path:"/tag/hive/",pageKeys:["v-7c98df2c","v-61a49f28","v-542a7f26","v-6f1ebf2a","v-46b05f24"]},kafka:{key:"kafka",scope:"tag",path:"/tag/kafka/",pageKeys:["v-0f870848","v-8d04e3f0","v-36fb69b0"]},spark:{key:"spark",scope:"tag",path:"/tag/spark/",pageKeys:["v-3ee237e8","v-69e6f508"]},zookeeper:{key:"zookeeper",scope:"tag",path:"/tag/zookeeper/",pageKeys:["v-6ed3dbc8"]}},category:{backend:{key:"backend",scope:"category",path:"/category/backend/",pageKeys:["v-4af972b2","v-700ad79e","v-59db6648","v-3619c21a","v-cdbd9150","v-16ce3220","v-192fb65e","v-0d4b1bdc","v-58e0fb48","v-1ddb11e8","v-d83236b0","v-8af45558"]},base:{key:"base",scope:"category",path:"/category/base/",pageKeys:["v-15ed21e8","v-2436b22c","v-2dfdfd20","v-1d1a5ab0","v-15fe0334","v-0ee1abb8","v-08950870"]},bigdata:{key:"bigdata",scope:"category",path:"/category/bigdata/",pageKeys:["v-6c4d9170","v-16441730","v-1fe2b188","v-13d1b368","v-521bf728","v-3ed67088","v-12defbfc","v-0e1bf380","v-0958eb04","v-0495e288","v-7c98df2c","v-61a49f28","v-542a7f26","v-6f1ebf2a","v-0f870848","v-46b05f24","v-8d04e3f0","v-36fb69b0","v-3ee237e8","v-6ed3dbc8","v-69e6f508"]}}},Gt=function(){function n(e,t){var r=this;Ye(this,n),this._metaMap=Object.assign({},e),Object.keys(this._metaMap).forEach((function(n){var e=r._metaMap[n].pageKeys;r._metaMap[n].pages=e.map((function(n){return function(n,e){for(var t=0;t<n.length;t++){var r=n[t];if(r.key===e)return r}return{path:"",frontmatter:{}}}(t,n)}))}))}return Xe(n,[{key:"length",get:function(){return Object.keys(this._metaMap).length}},{key:"map",get:function(){return this._metaMap}},{key:"pages",get:function(){return this.list}},{key:"list",get:function(){return this.toArray()}},{key:"toArray",value:function(){var n=this,e=[];return Object.keys(this._metaMap).forEach((function(t){var r=n._metaMap[t],a=r.pages,o=r.path;e.push({name:t,pages:a,path:o})})),e}},{key:"getItemByName",value:function(n){return this._metaMap[n]}}]),n}(),zt=(t(221),{tag:function(n,e){var r=t(142);return r(n.frontmatter.date)-r(e.frontmatter.date)>0?-1:1},category:function(n,e){var r=t(142);return r(n.frontmatter.date)-r(e.frontmatter.date)>0?-1:1}}),qt={tag:function(n,e,t){var r=e;return["tag","tags"].some((function(e){var t=n.frontmatter[e];return Array.isArray(t)?t.some((function(n){return n===r})):t===r}))},category:function(n,e,t){var r=e;return["category","categories"].some((function(e){var t=n.frontmatter[e];return Array.isArray(t)?t.some((function(n){return n===r})):t===r}))}},Yt=[{pid:"tag",id:"concurrent",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/concurrent/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"designPatterns",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/designPatterns/",interval:[0,4]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"docker",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/docker/",interval:[0,2]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"k8s",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/k8s/",interval:[0,2]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"jvm",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/jvm/",interval:[0,3]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"algorithms",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/algorithms/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"linux",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/linux/",interval:[0,4]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"git",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/git/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"proxy",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/proxy/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"flink",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/flink/",interval:[0,3]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"hbase",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/hbase/",interval:[0,2]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"flume",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/flume/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"hadoop",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/hadoop/",interval:[0,4]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"hive",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/hive/",interval:[0,5]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"kafka",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/kafka/",interval:[0,3]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"spark",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/spark/",interval:[0,2]}],prevText:"Prev",nextText:"Next"},{pid:"tag",id:"zookeeper",filter:qt.tag,sorter:zt.tag,pages:[{path:"/tag/zookeeper/",interval:[0,1]}],prevText:"Prev",nextText:"Next"},{pid:"category",id:"backend",filter:qt.category,sorter:zt.category,pages:[{path:"/category/backend/",interval:[0,9]},{path:"/category/backend/page/2/",interval:[10,12]}],prevText:"Prev",nextText:"Next"},{pid:"category",id:"base",filter:qt.category,sorter:zt.category,pages:[{path:"/category/base/",interval:[0,7]}],prevText:"Prev",nextText:"Next"},{pid:"category",id:"bigdata",filter:qt.category,sorter:zt.category,pages:[{path:"/category/bigdata/",interval:[0,9]},{path:"/category/bigdata/page/2/",interval:[10,19]},{path:"/category/bigdata/page/3/",interval:[20,21]}],prevText:"Prev",nextText:"Next"}],Qt=t(215),Xt=t.n(Qt)()("plugin-blog:pagination"),Zt=function(){function n(e,t,r){Ye(this,n),Xt("pagination",e);var a=e.pages,o=e.prevText,i=e.nextText,s=r.path;this._prevText=o,this._nextText=i;for(var c=0,l=a.length;c<l;c++){if(a[c].path===s){this.paginationIndex=c;break}}this.paginationIndex||(this.paginationIndex=0),this._paginationPages=a,this._currentPage=a[this.paginationIndex],this._matchedPages=t.filter((function(n){return e.filter(n,e.id,e.pid)})).sort(e.sorter)}return Xe(n,[{key:"setIndexPage",value:function(n){this._indexPage=n}},{key:"length",get:function(){return this._paginationPages.length}},{key:"pages",get:function(){var n=Object(be.a)(this._currentPage.interval,2),e=n[0],t=n[1];return this._matchedPages.slice(e,t+1)}},{key:"hasPrev",get:function(){return 0!==this.paginationIndex}},{key:"prevLink",get:function(){return this.hasPrev?this.paginationIndex-1==0&&this._indexPage?this._indexPage:this._paginationPages[this.paginationIndex-1].path:null}},{key:"hasNext",get:function(){return this.paginationIndex!==this.length-1}},{key:"nextLink",get:function(){return this.hasNext?this._paginationPages[this.paginationIndex+1].path:null}},{key:"prevText",get:function(){return this._prevText}},{key:"nextText",get:function(){return this._nextText}},{key:"getSpecificPageLink",value:function(n){return this._paginationPages[n].path}}]),n}(),nr=new(function(){function n(e){Ye(this,n),this.paginations=e}return Xe(n,[{key:"pages",get:function(){return o.a.$vuepress.$get("siteData").pages}},{key:"getPagination",value:function(n,e,t){Xt("id",e),Xt("pid",n);var r=this.paginations.filter((function(t){return t.id===e&&t.pid===n}))[0];return new Zt(r,this.pages,t)}}]),n}())(Yt),er={comment:{enabled:!1,service:""},email:{enabled:!1},feed:{rss:!1,atom:!1,json:!1}},tr=(t(372),Object(it.a)({},(function(){var n=this.$createElement,e=this._self._c||n;return e("svg",{staticStyle:{background:"0 0",display:"block","shape-rendering":"auto"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"200",height:"200",viewBox:"0 0 100 100",preserveAspectRatio:"xMidYMid"}},[e("circle",{attrs:{cx:"50",cy:"50",r:"0",fill:"none",stroke:"currentColor","stroke-width":"2"}},[e("animate",{attrs:{attributeName:"r",repeatCount:"indefinite",dur:"1s",values:"0;40",keyTimes:"0;1",keySplines:"0 0.2 0.8 1",calcMode:"spline",begin:"0s"}}),this._v(" "),e("animate",{attrs:{attributeName:"opacity",repeatCount:"indefinite",dur:"1s",values:"1;0",keyTimes:"0;1",keySplines:"0.2 0 0.8 1",calcMode:"spline",begin:"0s"}})]),this._v(" "),e("circle",{attrs:{cx:"50",cy:"50",r:"0",fill:"none",stroke:"currentColor","stroke-width":"2"}},[e("animate",{attrs:{attributeName:"r",repeatCount:"indefinite",dur:"1s",values:"0;40",keyTimes:"0;1",keySplines:"0 0.2 0.8 1",calcMode:"spline",begin:"-0.3333333333333333s"}}),this._v(" "),e("animate",{attrs:{attributeName:"opacity",repeatCount:"indefinite",dur:"1s",values:"1;0",keyTimes:"0;1",keySplines:"0.2 0 0.8 1",calcMode:"spline",begin:"-0.3333333333333333s"}})]),this._v(" "),e("circle",{attrs:{cx:"50",cy:"50",r:"0",fill:"none",stroke:"currentColor","stroke-width":"2"}},[e("animate",{attrs:{attributeName:"r",repeatCount:"indefinite",dur:"1s",values:"0;40",keyTimes:"0;1",keySplines:"0 0.2 0.8 1",calcMode:"spline",begin:"-0.6666666666666666s"}}),this._v(" "),e("animate",{attrs:{attributeName:"opacity",repeatCount:"indefinite",dur:"1s",values:"1;0",keyTimes:"0;1",keySplines:"0.2 0 0.8 1",calcMode:"spline",begin:"-0.6666666666666666s"}})])])}),[],!1,null,null,null).exports),rr={x:0,y:0,"line-width":2,"line-length":40,"text-margin":8,"font-size":14,"font-color":"#8DA1AC","line-color":"#8DA1AC","element-color":"black",fill:"white","yes-text":"Yes","no-text":"No","arrow-end":"block",scale:1},ar={ant:Object.assign(Object.assign({},rr),{symbols:{start:{class:"start-element","font-color":"#fff",fill:"#595959","line-width":"0px"},end:{class:"end-element","font-color":"#fff",fill:"#595959","line-width":"0px"},operation:{class:"operation-element","font-color":"#fff",fill:"#1890ff","line-width":"0px"},inputoutput:{class:"inputoutput-element","font-color":"#fff",fill:"#1890ff","line-width":"0px"},subroutine:{class:"subroutine-element","font-color":"#fff",fill:"#FF485E","element-color":"#fff","line-color":"red"},condition:{class:"condition-element","font-color":"#fff",fill:"#FF485E","line-width":"0px"},parallel:{class:"parallel-element","font-color":"#fff",fill:"#1890ff","line-width":"0px"}}}),vue:Object.assign(Object.assign({},rr),{symbols:{start:{class:"start-element","font-color":"#fff",fill:"#2F495F","line-width":"0px"},end:{class:"end-element","font-color":"#fff",fill:"#2F495F","line-width":"0px"},operation:{class:"operation-element","font-color":"#fff",fill:"#00BC7D","line-width":"0px"},inputoutput:{class:"inputoutput-element","font-color":"#fff",fill:"#EB4D5D","line-width":"0px"},subroutine:{class:"subroutine-element","font-color":"#fff",fill:"#937AC4","element-color":"#fff","line-color":"red"},condition:{class:"condition-element","font-color":"#fff",fill:"#FFB500","line-width":"0px"},parallel:{class:"parallel-element","font-color":"#fff",fill:"#2F495F","line-width":"0px"}}})},or=o.a.extend({name:"FlowChart",components:{Loading:tr},props:{id:{type:String,required:!0},preset:{type:String,default:"vue"}},data:function(){return{loading:!0,scale:1}},computed:{$preset:function(){var n=ar[this.preset];return n||(console.warn("[md-enhance:flowchart] Unknown preset: ".concat(this.preset)),ar.vue)},resize:function(){var n=this;return Ae()((function(){var e=n.getScale(window.innerWidth);n.scale!==e&&(n.scale=e,pt.drawSVG(n.id,Object.assign(Object.assign({},n.$preset),{scale:e})))}),100)}},mounted:function(){var n=this;this.$el.setAttribute("id",this.id),Promise.all([t.e(49).then(t.t.bind(null,1013,7)),new Promise((function(n){return setTimeout(n,500)}))]).then((function(e){var t=Object(be.a)(e,1)[0].parse;pt=t(decodeURIComponent(n.$el.dataset.code||"")),n.scale=n.getScale(window.innerWidth),pt.drawSVG(n.id,Object.assign(Object.assign({},n.$preset),{scale:n.scale})),n.loading=!1,window.addEventListener("resize",n.resize)}))},beforeDestroy:function(){window.removeEventListener("resize",this.resize)},methods:{getScale:function(n){return n<419?.8:n>1280?1:.9}}}),ir=(t(373),Object(it.a)(or,(function(){var n=this.$createElement,e=this._self._c||n;return e("div",{staticClass:"md-flowchart",class:{loading:this.loading}},[this.loading?e("Loading",{staticClass:"md-flowchart-loading-icon"}):this._e()],1)}),[],!1,null,null,null).exports),sr=(t(374),o.a.extend({name:"Mermaid",components:{Loading:tr},props:{id:{type:String,required:!0}},data:function(){return{loading:!0,svgCode:"",observer:null}},mounted:function(){var n=this,e=decodeURIComponent(this.$el.dataset.code||"");Promise.all([t.e(51).then(t.bind(null,1014)),new Promise((function(n){return setTimeout(n,500)}))]).then((function(t){var r=Object(be.a)(t,1)[0].default,a=r.initialize,i=r.render,s=function(t){var r=document.createElement("div");r.style.position="relative",r.style.top="-9999px";var s=function(e){n.loading=!1,n.svgCode=e,document.body.removeChild(r)};a(Object.assign(Object.assign({theme:"base",themeVariables:{dark:t,background:t?"#1e1e1e":"#fff",primaryColor:t?"#389d70":"#4abf8a",primaryBorderColor:t?"#389d70":"#4abf8a",primaryTextColor:"#fff",secondaryColor:"#f39c12",secondaryBorderColor:t?"#fff":"#000",secondaryTextColor:t?"#ddd":"#333",tertiaryColor:t?"#22182d":"#eeeaf3",tertiaryBorderColor:t?"#fff":"#000",tertiaryTextColor:t?"#ddd":"#333",noteBkgColor:t?"#f6d365":"#fff5ad",noteTextColor:"#242424",noteBorderColor:t?"#f6d365":"#333",lineColor:t?"#d3d3d3":"#333",textColor:t?"#fff":"#242424",mainBkg:t?"#389d70":"#4abf8a",errorBkgColor:"#eb4d5d",errorTextColor:"#fff",nodeBorder:t?"#389d70":"#4abf8a",nodeTextColor:t?"#fff":"#242424",signalTextColor:t?"#9e9e9e":"#242424",classText:"#fff",labelColor:"#fff",fillType0:t?"#cf1322":"#f1636e",fillType1:"#f39c12",fillType2:"#2ecc71",fillType3:"#fa541c",fillType4:"#25a55b",fillType5:"#13c2c2",fillType6:"#096dd9",fillType7:"#aa6fe9"}},{}),{startOnLoad:!1})),n.svgCode="",document.body.appendChild(r),o.a.nextTick((function(){return i(n.id,e,s,r)}))},c=document.querySelector("body");s(c.classList.contains("theme-dark")),n.observer=new MutationObserver((function(){s(c.classList.contains("theme-dark"))})),n.observer.observe(c,{attributeFilter:["class"],attributes:!0})}))},beforeDestroy:function(){this.observer&&this.observer.disconnect()},render:function(n){return this.svgCode?n("div",{class:"md-mermaid",domProps:{innerHTML:this.svgCode}}):n("div",{class:"md-mermaid-loading"},[n(tr)])}})),cr=t(87),lr=t(86),ur=t(46),pr=t(88);var dr,mr=o.a.extend({name:"Presentation",components:{Loading:tr},props:{id:{type:String,required:!0},theme:{type:String,default:"auto"}},data:function(){return{loading:!0,code:""}},mounted:function(){var n=this;this.$el.setAttribute("id",this.id),this.code=decodeURIComponent(this.$el.dataset.code||"");var e=document.querySelector("#".concat(this.id));if(e){e.setAttribute("theme",this.theme);var r=[new Promise((function(n){return setTimeout(n,500)})),t.e(53).then(t.bind(null,1015))];r.push(t.e(53).then(t.bind(null,1016))),Promise.all(r).then((function(t){var r,a=(r=t,Object(cr.a)(r)||Object(lr.a)(r)||Object(ur.a)(r)||Object(pr.a)()),o=a[1],i=a.slice(2),s=new o.default(e,{plugins:i.map((function(n){return n.default}))});s.initialize(Object.assign(Object.assign(Object.assign({backgroundTransition:"slide",hash:"Slide"===n.$frontmatter.layout,mouseWheel:"Slide"===n.$frontmatter.layout,transition:"slide",slideNumber:!0},{}),n.$frontmatter.reveal||{}),{embedded:"Slide"!==n.$frontmatter.layout})).then((function(){n.loading=!1})),s.configure({backgroundTransition:"slide"})}))}}}),fr=(t(375),Object(it.a)(mr,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"md-presentation reveal reveal-viewport",class:{loading:n.loading}},[n.loading?t("Loading",{staticClass:"md-presentation-loading-icon"}):n._e(),n._v(" "),t("div",{directives:[{name:"show",rawName:"v-show",value:!n.loading,expression:"!loading"}],staticClass:"slides"},[t("section",{attrs:{"data-markdown":"","data-separator":"^\\r?\\n---\\r?\\n$","data-separator-vertical":"^\\r?\\n--\\r?\\n$"}},[t("script",{attrs:{type:"text/template"}},[n._v("\n        "+n._s(n.code)+"\n      ")])])])],1)}),[],!1,null,null,null).exports),gr=(t(376),function(n){var e=n.Vue;Promise.all([t.e(0),t.e(54)]).then(t.t.bind(null,1008,7)),Promise.all([t.e(0),t.e(55)]).then(t.t.bind(null,1009,7)),e.component("FlowChart",ir),e.component("Mermaid",sr),e.component("Presentation",fr),Promise.all([t.e(0),t.e(56)]).then(t.t.bind(null,1010,7)),Promise.all([t.e(0),t.e(57)]).then(t.t.bind(null,1011,7)),Promise.all([t.e(0),t.e(58)]).then(t.t.bind(null,1012,7))}),hr={"/":{close:"Close",fullscreen:"Switch to full screen",share:"Share",zoom:"Zoom in/out",prev:"Prev (Arrow Left)",next:"Next (Arrow Right)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]}},vr=o.a.extend({name:"PhotoSwipe",computed:{locales:function(){return hr[this.$localePath||"/"]}},watch:{$route:function(){this.initPhotoSwipe()}},mounted:function(){this.initPhotoSwipe()},methods:{initPhotoSwipe:function(){var n=this,e=document.querySelector(".pswp");Promise.all([t.e(52).then(t.t.bind(null,1017,7)),t.e(52).then(t.t.bind(null,1018,7)),new Promise((function(n){return setTimeout((function(){return n()}),500)}))]).then((function(t){var r=Object(be.a)(t,2),a=r[0],o=r[1];n.getImages().then((function(t){dr.forEach((function(r,i){r.onclick=function(){new a.default(e,o.default,t,Object.assign(Object.assign({shareButtons:n.locales.buttons},{}),{index:i})).init()}}))}))}))},getImageInfo:function(n){return{src:n.src,w:n.naturalWidth,h:n.naturalHeight,title:n.alt}},getImages:function(){var n=this,e=[];return(dr=document.querySelectorAll(".theme-default-content :not(a) > img")).forEach((function(t,r){e[r]=new Promise((function(e,r){t.complete?e(n.getImageInfo(t)):(t.onload=function(){return e(n.getImageInfo(t))},t.onerror=function(n){return r(n)})}))})),Promise.all(e)}}}),yr=(t(377),Object(it.a)(vr,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"pswp",attrs:{tabindex:"-1",role:"dialog","aria-hidden":"true"}},[t("div",{staticClass:"pswp__bg"}),n._v(" "),t("div",{staticClass:"pswp__scroll-wrap"},[n._m(0),n._v(" "),t("div",{staticClass:"pswp__ui pswp__ui--hidden"},[t("div",{staticClass:"pswp__top-bar"},[t("div",{staticClass:"pswp__counter"}),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--close",attrs:{title:n.locales.close,"aria-label":n.locales.close}}),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--share",attrs:{title:n.locales.share,"aria-label":n.locales.share}}),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--fs",attrs:{title:n.locales.fullscreen,"aria-label":n.locales.fullscreen}}),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--zoom",attrs:{title:n.locales.zoom,"aria-label":n.locales.zoom}}),n._v(" "),n._m(1)]),n._v(" "),n._m(2),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--left",attrs:{title:n.locales.prev,"aria-label":n.locales.prev}}),n._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--right",attrs:{title:n.locales.next,"aria-label":n.locales.next}}),n._v(" "),n._m(3)])])])}),[function(){var n=this.$createElement,e=this._self._c||n;return e("div",{staticClass:"pswp__container"},[e("div",{staticClass:"pswp__item"}),this._v(" "),e("div",{staticClass:"pswp__item"}),this._v(" "),e("div",{staticClass:"pswp__item"})])},function(){var n=this.$createElement,e=this._self._c||n;return e("div",{staticClass:"pswp__preloader"},[e("div",{staticClass:"pswp__preloader__icn"},[e("div",{staticClass:"pswp__preloader__cut"},[e("div",{staticClass:"pswp__preloader__donut"})])])])},function(){var n=this.$createElement,e=this._self._c||n;return e("div",{staticClass:"pswp__share-modal pswp__share-modal--hidden pswp__single-tap"},[e("div",{staticClass:"pswp__share-tooltip"})])},function(){var n=this.$createElement,e=this._self._c||n;return e("div",{staticClass:"pswp__caption"},[e("div",{staticClass:"pswp__caption__center"})])}],!1,null,null,null).exports),br=[{},function(n){n.Vue.mixin({computed:{$dataBlock:function(){return this.$options.__data__block__}}})},{},Rt,Wt,Jt,function(n){var e=n.Vue,t=Object.keys(Kt).map((function(n){var e,t=Kt[n],r="$".concat(n);return e={},Object(Vt.a)(e,r,(function(){var n=this.$site.pages;return new Gt(t,n)})),Object(Vt.a)(e,"$current".concat(n.charAt(0).toUpperCase()+n.slice(1)),(function(){var n=this.$route.meta.id;return this[r].getItemByName(n)})),e})).reduce((function(n,e){return Object.assign(n,e),n}),{});t.$frontmatterKey=function(){var n=this["$".concat(this.$route.meta.id)];return n||null},e.mixin({computed:t})},function(n){n.Vue.mixin({computed:{$pagination:function(){return this.$route.meta.pid&&this.$route.meta.id?this.$getPagination(this.$route.meta.pid,this.$route.meta.id):null}},methods:{$getPagination:function(n,e){return e=e||n,nr.getPagination(n,e,this.$route)}}})},function(n){var e={$service:function(){return er}};n.Vue.mixin({computed:e})},{},gr,function(n){n.Vue.component("PhotoSwipe",yr)}],Sr=["BackToTop","SWUpdatePopup","PWAInstall","PhotoSwipe"];t(49),t(50);t(210);function kr(n,e){return(kr=Object.setPrototypeOf||function(n,e){return n.__proto__=e,n})(n,e)}t(211);function xr(n){return(xr=Object.setPrototypeOf?Object.getPrototypeOf:function(n){return n.__proto__||Object.getPrototypeOf(n)})(n)}var Er=t(216),Tr=t.n(Er);function wr(n,e){if(e&&("object"===Tr()(e)||"function"==typeof e))return e;if(void 0!==e)throw new TypeError("Derived constructors may only return object or undefined");return function(n){if(void 0===n)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return n}(n)}function Cr(n){var e=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(n){return!1}}();return function(){var t,r=xr(n);if(e){var a=xr(this).constructor;t=Reflect.construct(r,arguments,a)}else t=r.apply(this,arguments);return wr(this,t)}}var Dr=function(n){!function(n,e){if("function"!=typeof e&&null!==e)throw new TypeError("Super expression must either be null or a function");n.prototype=Object.create(e&&e.prototype,{constructor:{value:n,writable:!0,configurable:!0}}),e&&kr(n,e)}(t,n);var e=Cr(t);function t(){return Ye(this,t),e.apply(this,arguments)}return t}(function(){function n(){Ye(this,n),this.store=new o.a({data:{state:{}}})}return Xe(n,[{key:"$get",value:function(n){return this.store.state[n]}},{key:"$set",value:function(n,e){o.a.set(this.store.state,n,e)}},{key:"$emit",value:function(){var n;(n=this.store).$emit.apply(n,arguments)}},{key:"$on",value:function(){var n;(n=this.store).$on.apply(n,arguments)}}]),n}());Object.assign(Dr.prototype,{getPageAsyncComponent:me,getLayoutAsyncComponent:fe,getAsyncComponent:ge,getVueComponent:he});var Or={install:function(n){var e=new Dr;n.$vuepress=e,n.prototype.$vuepress=e}};function Lr(n){n.beforeEach((function(e,t,r){if(Rr(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){var a=e.path.replace(/\/$/,"")+".html";Rr(n,a)?r(a):r()}else r();else{var o=e.path+"/",i=e.path+".html";Rr(n,i)?r(i):Rr(n,o)?r(o):r()}}))}function Rr(n,e){var t=e.toLowerCase();return n.options.routes.some((function(n){return n.path.toLowerCase()===t}))}var _r={props:{pageKey:String,slotKey:{type:String,default:"default"}},render:function(n){var e=this.pageKey||this.$parent.$page.key;return ye("pageKey",e),o.a.component(e)||o.a.component(e,me(e)),o.a.component(e)?n(e):n("")}},Ar={functional:!0,props:{slotKey:String,required:!0},render:function(n,e){var t=e.props,r=e.slots;return n("div",{class:["content__".concat(t.slotKey)]},r()[t.slotKey])}},Ir={computed:{openInNewWindowTitle:function(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Mr=(t(378),t(379),Object(it.a)(Ir,(function(){var n=this.$createElement,e=this._self._c||n;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports);function Fr(){return(Fr=a(regeneratorRuntime.mark((function n(e){var t,r,a,i;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:return t="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:mt.routerBase||mt.base,Lr(r=new Yn({base:t,mode:"history",fallback:!1,routes:dt,scrollBehavior:function(n,e,t){return t||(n.hash?!o.a.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})}})),a={},n.prev=4,n.next=7,Promise.all(br.filter((function(n){return"function"==typeof n})).map((function(n){return n({Vue:o.a,options:a,router:r,siteData:mt,isServer:e})})));case 7:n.next=12;break;case 9:n.prev=9,n.t0=n.catch(4),console.error(n.t0);case 12:return i=new o.a(Object.assign(a,{router:r,render:function(n){return n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Sr.map((function(e){return n(e)})))])}})),n.abrupt("return",{app:i,router:r});case 14:case"end":return n.stop()}}),n,null,[[4,9]])})))).apply(this,arguments)}o.a.config.productionTip=!1,o.a.use(Yn),o.a.use(Or),o.a.mixin(function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:o.a;Qn(e),t.$vuepress.$set("siteData",e);var r=n(t.$vuepress.$get("siteData")),a=new r,i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(a)),s={};return Object.keys(i).reduce((function(n,e){return e.startsWith("$")&&(n[e]=i[e].get),n}),s),{computed:s}}((function(n){return function(){function e(){Ye(this,e)}return Xe(e,[{key:"setPage",value:function(n){this.__page=n}},{key:"$site",get:function(){return n}},{key:"$themeConfig",get:function(){return this.$site.themeConfig}},{key:"$frontmatter",get:function(){return this.$page.frontmatter}},{key:"$localeConfig",get:function(){var n,e,t=this.$site.locales,r=void 0===t?{}:t;for(var a in r)"/"===a?e=r[a]:0===this.$page.path.indexOf(a)&&(n=r[a]);return n||e||{}}},{key:"$siteTitle",get:function(){return this.$localeConfig.title||this.$site.title||""}},{key:"$canonicalUrl",get:function(){var n=this.$page.frontmatter.canonicalUrl;return"string"==typeof n&&n}},{key:"$title",get:function(){var n=this.$page,e=this.$page.frontmatter.metaTitle;if("string"==typeof e)return e;var t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}},{key:"$description",get:function(){var n=function(n){if(n){var e=n.filter((function(n){return"description"===n.name}))[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}},{key:"$lang",get:function(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}},{key:"$localePath",get:function(){return this.$localeConfig.path||"/"}},{key:"$themeLocaleConfig",get:function(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}},{key:"$page",get:function(){return this.__page?this.__page:function(n,e){for(var t=0;t<n.length;t++){var r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}}]),e}()}),mt)),o.a.component("Content",_r),o.a.component("ContentSlotsDistributor",Ar),o.a.component("OutboundLink",Mr),o.a.component("ClientOnly",{functional:!0,render:function(n,e){var t=e.parent,r=e.children;if(t._isMounted)return r;t.$once("hook:mounted",(function(){t.$forceUpdate()}))}}),o.a.component("Layout",fe("Layout")),o.a.component("NotFound",fe("NotFound")),o.a.prototype.$withBase=function(n){var e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.8.2",hash:"99491ef"},function(n){return Fr.apply(this,arguments)}(!1).then((function(n){var e=n.app;n.router.onReady((function(){e.$mount("#app")}))}))}]);